(window.webpackJsonp=window.webpackJsonp||[]).push([[149],{530:function(_,v,e){"use strict";e.r(v);var a=e(4),i=Object(a.a)({},(function(){var _=this,v=_._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[v("h2",{attrs:{id:"_1-初始化kafkaproducer"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-初始化kafkaproducer"}},[_._v("#")]),_._v(" 1.初始化KafkaProducer")]),_._v(" "),v("p",[_._v("我们知道使用Kafka SDK发消息的第一步是创建一个KafkaProducer实例对象，接下来我们来看一下他的初始化流程。")]),_._v(" "),v("hr"),_._v(" "),v("h3",{attrs:{id:"_1-1-属性"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-属性"}},[_._v("#")]),_._v(" 1.1 属性")]),_._v(" "),v("p",[_._v("首先来看里面的属性：")]),_._v(" "),v("ul",[v("li",[v("code",[_._v("JMX_PREFIX")]),_._v(":Kafka生产者的JMX MBean的前缀。")]),_._v(" "),v("li",[v("code",[_._v("NETWORK_THREAD_PREFIX")]),_._v(":Sender线程名称前缀。")]),_._v(" "),v("li",[v("code",[_._v("PRODUCER_METRIC_GROUP_NAME")]),_._v(":生产者指标前缀名。")]),_._v(" "),v("li",[v("code",[_._v("clientId")]),_._v(":生产者客户端ID。")]),_._v(" "),v("li",[v("code",[_._v("partitioner")]),_._v(":消息分区分配器。")]),_._v(" "),v("li",[v("code",[_._v("maxRequestSize")]),_._v(":消息最大长度，默认1MB。")]),_._v(" "),v("li",[v("code",[_._v("totalMemorySize")]),_._v(":消息发送缓冲区大小，默认32MB。")]),_._v(" "),v("li",[v("code",[_._v("metadata")]),_._v(":客户端元数据信息。")]),_._v(" "),v("li",[v("code",[_._v("accumulator")]),_._v(":消息累加器。")]),_._v(" "),v("li",[v("code",[_._v("sender")]),_._v(":执行消息发送的类。")]),_._v(" "),v("li",[v("code",[_._v("ioThread")]),_._v(":消息发送线程，也叫IO线程。")]),_._v(" "),v("li",[v("code",[_._v("compressionType")]),_._v(":消息压缩类型。")]),_._v(" "),v("li",[v("code",[_._v("keySerializer")]),_._v(":key的序列化器。")]),_._v(" "),v("li",[v("code",[_._v("valueSerializer")]),_._v(":消息的序列化器。")]),_._v(" "),v("li",[v("code",[_._v("producerConfig")]),_._v(":生产者客户端参数配置。")]),_._v(" "),v("li",[v("code",[_._v("maxBlockTimeMs")]),_._v(":元数据更新请求最大等待时间。")]),_._v(" "),v("li",[v("code",[_._v("interceptors")]),_._v(":生产者拦截器链。")]),_._v(" "),v("li",[v("code",[_._v("apiVersions")]),_._v(":api版本信息。")]),_._v(" "),v("li",[v("code",[_._v("transactionManager")]),_._v(":事务管理器。")])]),_._v(" "),v("hr"),_._v(" "),v("h3",{attrs:{id:"_1-2-构造函数"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-构造函数"}},[_._v("#")]),_._v(" 1.2 构造函数")]),_._v(" "),v("p",[_._v("接下来，我们来看一下KafkaProducer的构造函数。")]),_._v(" "),v("ol",[v("li",[_._v("初始化生产者配置信息。")]),_._v(" "),v("li",[_._v("获取客户端配置参数。")]),_._v(" "),v("li",[_._v("获取事务ID，用来保证会话的可靠性，如果配置了事务ID，表示消息的发送会保证幂等性和事务。")]),_._v(" "),v("li",[_._v("设置生产者客户端ID。")]),_._v(" "),v("li",[_._v("根据事务ID决定使用的日志记录方式。")]),_._v(" "),v("li",[_._v("初始化Metric相关的内容。")]),_._v(" "),v("li",[_._v("设置消息的分区分配器。")]),_._v(" "),v("li",[_._v("设置消息发送失败重试的退避时间，默认100ms。")]),_._v(" "),v("li",[_._v("指定key和value对应的序列化器。")]),_._v(" "),v("li",[_._v("定义生产者拦截器列表。")]),_._v(" "),v("li",[_._v("设置消息的最大长度。")]),_._v(" "),v("li",[_._v("设置消息发送缓冲区的大小。")]),_._v(" "),v("li",[_._v("设置消息的压缩方式。")]),_._v(" "),v("li",[_._v("设置元数据更新请求的最大等待时间。")]),_._v(" "),v("li",[_._v("设置消息投递的超时时间。")]),_._v(" "),v("li",[_._v("设置API版本。")]),_._v(" "),v("li",[_._v("初始化事务管理器。")]),_._v(" "),v("li",[_._v("初始化"),v("strong",[_._v("消息累加器")]),_._v("。")]),_._v(" "),v("li",[_._v("构建Kafka服务端的Socket地址。")]),_._v(" "),v("li",[_._v("初始化Kafka"),v("strong",[_._v("集群元数据")]),_._v("。")]),_._v(" "),v("li",[_._v("创建消息发送线程实际执行的Runnable接口-"),v("strong",[_._v("Sender对象实例")]),_._v("。")]),_._v(" "),v("li",[_._v("创建"),v("strong",[_._v("消息发送的I/O线程")]),_._v("。")]),_._v(" "),v("li",[_._v("启动I/O线程。")])]),_._v(" "),v("hr"),_._v(" "),v("h2",{attrs:{id:"_2-初始化recordaccumulator"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-初始化recordaccumulator"}},[_._v("#")]),_._v(" 2.初始化RecordAccumulator")]),_._v(" "),v("p",[_._v("接下来我们看一下消息累加器，也就是消息发送缓冲区的初始化逻辑。 这些字段是 Kafka 生产者端 "),v("code",[_._v("RecordAccumulator")]),_._v(" 类中的成员变量，用于管理和维护生产者的记录（records）累加器。")]),_._v(" "),v("ul",[v("li",[v("code",[_._v("closed")]),_._v(": 标志位，表示累加器是否已关闭。")]),_._v(" "),v("li",[v("code",[_._v("flushesInProgress")]),_._v(": 计数器，用于跟踪正在进行的刷新操作的数量。")]),_._v(" "),v("li",[v("code",[_._v("appendsInProgress")]),_._v(": 计数器，用于跟踪正在进行的追加操作的数量。")]),_._v(" "),v("li",[v("code",[_._v("batchSize")]),_._v(": 记录批次的大小，即每个批次中记录的数量限制。")]),_._v(" "),v("li",[v("code",[_._v("compression")]),_._v(": 记录压缩类型，用于在发送前压缩记录。")]),_._v(" "),v("li",[v("code",[_._v("lingerMs")]),_._v(": 指定发送者在发出请求之前要等待的时间。")]),_._v(" "),v("li",[v("code",[_._v("retryBackoffMs")]),_._v(": 在发生重试时的等待时间。")]),_._v(" "),v("li",[v("code",[_._v("deliveryTimeoutMs")]),_._v(": 发送的超时时间，即发送记录的最大等待时间。")]),_._v(" "),v("li",[v("code",[_._v("free")]),_._v(": 缓冲池，用于管理可用于分配的内存缓冲区。")]),_._v(" "),v("li",[v("code",[_._v("time")]),_._v(": 时间类，用于管理和获取时间戳。")]),_._v(" "),v("li",[v("code",[_._v("apiVersions")]),_._v(": Kafka 支持的 API 版本。")]),_._v(" "),v("li",[v("code",[_._v("batches")]),_._v(": 保存生产者批次（Producer Batch）的映射，按照主题和分区进行存储。")]),_._v(" "),v("li",[v("code",[_._v("incomplete")]),_._v(": 未完成批次的处理器。")]),_._v(" "),v("li",[v("code",[_._v("muted")]),_._v(": 存储被暂停（muted）的分区集合。")]),_._v(" "),v("li",[v("code",[_._v("drainIndex")]),_._v(": 发送者线程专用的索引，用于控制记录的发送。")]),_._v(" "),v("li",[v("code",[_._v("transactionManager")]),_._v(": 事务管理器，处理生产者端的事务性操作。")]),_._v(" "),v("li",[v("code",[_._v("nextBatchExpiryTimeMs")]),_._v(": 下一个批次过期时间的绝对时间戳，标志着一个批次记录的最早过期时间。")])]),_._v(" "),v("p",[_._v("消息累加器/消息缓冲区是kafka生产者中的经典设计，消息并不是在调用完send方法后就直接发送到broker的，而是会先写入一个内存的缓冲池，然后多条消息组成一个批次，达到一定的大小或者超过限制的事件才会一次网络通信把一批次的消息发送出去，这种设计避免了JVM频繁FullGC的问题。")]),_._v(" "),v("hr"),_._v(" "),v("h2",{attrs:{id:"_3-初始化集群元数据"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-初始化集群元数据"}},[_._v("#")]),_._v(" 3.初始化集群元数据")]),_._v(" "),v("p",[_._v("接下来我们看一下集群元数据的初始化。可以看到元数据的初始化首先创建了一个ProducerMetadata对象，然后调用了该对象的"),v("code",[_._v("bootstrap()")]),_._v("方法完成元数据的初始化。")]),_._v(" "),v("h3",{attrs:{id:"_3-1-producermetadata"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-producermetadata"}},[_._v("#")]),_._v(" 3.1 ProducerMetadata")]),_._v(" "),v("p",[_._v("下面是 Kafka 生产者端的 "),v("code",[_._v("ProducerMetadata")]),_._v(" 类中的一些字段。")]),_._v(" "),v("ul",[v("li",[v("code",[_._v("metadataIdleMs")]),_._v(": 控制主题元数据在多长时间内没有访问后将被从缓存中删除。默认情况下是 5 分钟。这个时间用于确定缓存中的主题元数据是否过期，并决定是否需要从集群中重新获取主题的元数据信息。")]),_._v(" "),v("li",[v("code",[_._v("topics")]),_._v(": 存储了带有过期时间的主题。这是一个 "),v("code",[_._v("Map")]),_._v(" 类型的数据结构，将主题名与其对应的过期时间进行了关联。")]),_._v(" "),v("li",[v("code",[_._v("newTopics")]),_._v(": 用于存储新添加的主题集合。这个集合中存储了当前生产者实例中新添加的主题。")])]),_._v(" "),v("p",[v("code",[_._v("ProducerMetadata")]),_._v(" 类在构造函数中显式调用了父类的初始化方法，接下来我们看一下它的父类"),v("code",[_._v("Metadata")]),_._v("的初始化。")]),_._v(" "),v("hr"),_._v(" "),v("h3",{attrs:{id:"_3-2-metadata"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-metadata"}},[_._v("#")]),_._v(" 3.2 Metadata")]),_._v(" "),v("p",[_._v("这些参数是 Kafka 中的 "),v("code",[_._v("Metadata")]),_._v(" 类中的一部分字段，它们的作用如下：")]),_._v(" "),v("ul",[v("li",[v("code",[_._v("refreshBackoffMs")]),_._v(": 元数据刷新的退避时间，即在进行元数据刷新时，如果失败会等待一段时间后再次尝试。这个参数表示在多长时间内避免对元数据进行过多的刷新。")]),_._v(" "),v("li",[v("code",[_._v("metadataExpireMs")]),_._v(": 元数据的过期时间，表示元数据在多长时间内被认为是有效的。如果超过这个时间没有更新，就会被视为过期，需要从新获取。")]),_._v(" "),v("li",[v("code",[_._v("updateVersion")]),_._v(": 每次接收到元数据响应时都会增加该版本号，用于追踪元数据的更新。")]),_._v(" "),v("li",[v("code",[_._v("requestVersion")]),_._v(": 每次添加新主题时都会增加该版本号，用于追踪请求的版本。")]),_._v(" "),v("li",[v("code",[_._v("lastRefreshMs")]),_._v(": 最近一次元数据刷新的时间戳。")]),_._v(" "),v("li",[v("code",[_._v("lastSuccessfulRefreshMs")]),_._v(": 最近一次成功刷新元数据的时间戳。")]),_._v(" "),v("li",[v("code",[_._v("fatalException")]),_._v(": 任何致命的元数据错误都会在此处记录。")]),_._v(" "),v("li",[v("code",[_._v("invalidTopics")]),_._v(": 存储无效主题的集合。")]),_._v(" "),v("li",[v("code",[_._v("unauthorizedTopics")]),_._v(": 存储未授权主题的集合。")]),_._v(" "),v("li",[v("code",[_._v("cache")]),_._v(": 元数据的缓存，初始为空。")]),_._v(" "),v("li",[v("code",[_._v("needFullUpdate")]),_._v(": 表示是否需要进行完整的元数据更新。")]),_._v(" "),v("li",[v("code",[_._v("needPartialUpdate")]),_._v(": 表示是否需要进行部分的元数据更新。")]),_._v(" "),v("li",[v("code",[_._v("clusterResourceListeners")]),_._v(": 集群资源监听器，用于监听集群资源的变化。")]),_._v(" "),v("li",[v("code",[_._v("isClosed")]),_._v(": 标识元数据对象是否已关闭。")]),_._v(" "),v("li",[v("code",[_._v("lastSeenLeaderEpochs")]),_._v(": 记录每个分区的最后一次领导者选举时的领导者分区的版本号。")])]),_._v(" "),v("p",[v("code",[_._v("bootstrap()")]),_._v("方法实际上也是 Metadata 类的方法，这里做了三件事儿：")]),_._v(" "),v("ol",[v("li",[_._v("将是否需要全量更新设置为true。")]),_._v(" "),v("li",[_._v("将元数据的"),v("code",[_._v("updateVersion")]),_._v("加一。")]),_._v(" "),v("li",[_._v("初始化"),v("code",[_._v("MetadataCache")]),_._v("，这也是真实的元数据缓存。")])]),_._v(" "),v("p",[v("code",[_._v("MetadataCache")]),_._v("的具体结构如下所示：")]),_._v(" "),v("p",[v("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/Kafka/202312232025553.png",alt:""}})]),_._v(" "),v("p",[_._v("从这里代码可以看出，这里仅仅是初始化了元数据缓存，并没有进行数据的拉取更新。")]),_._v(" "),v("hr"),_._v(" "),v("h2",{attrs:{id:"_4-初始化io线程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_4-初始化io线程"}},[_._v("#")]),_._v(" 4.初始化IO线程")]),_._v(" "),v("p",[_._v("最后我们看一下初始化Sender线程的逻辑：Sender线程的初始化创建了Sender发送线程类并初始化了NetworkClient，他给Sender的网络IO能力进行了赋能，后面我们在仔细分析。 接下来通过创建一个KafkaThread来创建IO线程，并绑定Sender发送消息的逻辑，最后将线程设置为守护线程并启动。")]),_._v(" "),v("hr"),_._v(" "),v("h2",{attrs:{id:"_5-一条消息的发送"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5-一条消息的发送"}},[_._v("#")]),_._v(" 5.一条消息的发送")]),_._v(" "),v("p",[_._v("消息发送一般都是使用带有回调函数的"),v("code",[_._v("send()")]),_._v("，因此我们以此为抓手分析消息发送的链路。")]),_._v(" "),v("ol",[v("li",[_._v("在消息发送之前先执行所有拦截器的"),v("code",[_._v("onSend()")]),_._v("方法。")]),_._v(" "),v("li",[_._v("检查生产者状态。")]),_._v(" "),v("li",[_._v("等待元数据更新，即确认要发送到的主题的元数据是可用的。")]),_._v(" "),v("li",[_._v("对Record的key和value进行序列化。")]),_._v(" "),v("li",[_._v("通过分区器进行分区计算，得到消息要发送到的分区，并构建TopicPartition。")]),_._v(" "),v("li",[_._v("验证消息大小。")]),_._v(" "),v("li",[_._v("组装消息发送的回调方法和拦截器为一个对象。")]),_._v(" "),v("li",[_._v("尝试往消息追加器追加数据。")]),_._v(" "),v("li",[_._v("如果消息追加被拒绝了且需要创建新的批次，重新进行分区计算，然后重新追加。")]),_._v(" "),v("li",[_._v("如果消息追加器的消息批次队列已经满了，需要唤醒sender线程发送消息。")])]),_._v(" "),v("p",[v("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/Kafka/202312232113927.png",alt:""}})]),_._v(" "),v("hr"),_._v(" "),v("p",[_._v("至此，我们就分析完了Kafka生产者的初始化流程和一条消息的（一半）发送流程，生产者的初始化实际上就是初始化消息累加器，初始化集群元数据的数据结构，最后创建消息发送线程并启动。 消息的发送首先执行拦截器的"),v("code",[_._v("onSend()")]),_._v("，接着获取消息的目标主题元数据，然后进行序列化操作，分区计算逻辑，尝试追加消息到消息追加器，并根据结果决定是否要重试或者唤醒消息发送的IO线程。")]),_._v(" "),v("hr")])}),[],!1,null,null,null);v.default=i.exports}}]);