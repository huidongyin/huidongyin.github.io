(window.webpackJsonp=window.webpackJsonp||[]).push([[170],{551:function(s,t,a){"use strict";a.r(t);var n=a(4),r=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("p",[s._v("当探索 Elasticsearch 7.x 中的丰富概念时，我们进入了一个引人入胜的世界。从集群到文档，从倒排索引到相关性评分，这篇文章将带您深入了解 Elasticsearch 的核心概念。在这个不断演化的搜索和分析引擎中，我们将一一揭示集群、索引、映射以及多个关键概念的内涵，探讨它们是如何相互交织，为您提供强大的数据管理和查询工具。让我们一同探索 Elasticsearch 的精彩世界，解锁其无限可能性。")]),s._v(" "),t("hr"),s._v(" "),t("h2",{attrs:{id:"_1-从架构层面看"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-从架构层面看"}},[s._v("#")]),s._v(" 1.从架构层面看")]),s._v(" "),t("h3",{attrs:{id:"_1-1-集群"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-集群"}},[s._v("#")]),s._v(" 1.1 集群")]),s._v(" "),t("p",[s._v("在 Elasticsearch 世界中，集群是由多个协同工作的 Elasticsearch 实例组成的动态集合。这个集合的力量在于它的分布式架构，它能够容纳海量的数据，同时支撑着更高并发的读写需求。集群不仅仅是为系统提供不间断服务的一种方案，更得益于分布式系统的精妙设计，为 Elasticsearch 赋予了高度的可用性和可扩展性。")]),s._v(" "),t("p",[t("strong",[s._v("高可用性：服务与数据的稳固")])]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("服务高可用性：")]),s._v(" 即使集群中的某些节点出现故障，系统仍然能够持续提供服务。这种极具韧性的能力，使得用户在节点故障的情况下也能无缝继续工作。")]),s._v(" "),t("li",[t("strong",[s._v("数据高可用性：")]),s._v(" 即使集群的一部分节点发生故障，甚至这些节点上的数据无法恢复，数据的丢失也能被最小化，从而保障数据的完整性。")])]),s._v(" "),t("p",[t("strong",[s._v("高可扩展性：应对挑战，实现扩张")])]),s._v(" "),t("p",[s._v("在 Elasticsearch 集群中，高可扩展性是一种突出特点，当并发访问量和数据量迅速上升时，通过水平扩容（增加节点数量）来解决性能问题变得十分轻松。系统可以根据需求增加节点，无需停机，从而快速适应变化的工作负载，确保系统持续高效运转。")]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_1-2-节点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-节点"}},[s._v("#")]),s._v(" 1.2 节点")]),s._v(" "),t("p",[s._v("在 Elasticsearch 世界中，"),t("strong",[s._v("单个服务实例被称为节点，实质上即为一个 Java 进程")]),s._v("。每个节点都拥有独特的名称，即配置文件中的 node.name 设置内容。为了标识每个节点，系统会在其启动后分配一个 UID，并存储于 data 目录中。这些节点在集群的智能调度下协同工作，通过增减节点数量，我们能够轻松实现集群的扩容或减容。")]),s._v(" "),t("p",[s._v("集群内的节点按功能分为不同类型：")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("主节点（Master）：")]),s._v(" 集群中仅有一个主节点，由具备选举资格的节点（Master Eligible）从中选举出。主节点主要负责管理集群变更和元数据的更改。类似于公司的总经办，其地位独特而重要。")]),s._v(" "),t("li",[t("strong",[s._v("数据节点（Data Node）：")]),s._v(" 数据节点负责数据存储，扩容时需增加此类节点。数据节点还负责执行与数据相关的操作，如搜索、聚合、CURD 等。因此，对节点机器的 CPU、内存、I/O 要求较高。")]),s._v(" "),t("li",[t("strong",[s._v("协调节点（Coordinating Node）：")]),s._v(" 协调节点接收客户端请求，将其路由到相应节点进行处理，并将最终结果汇总后返回客户端。需要处理结果集和排序，因此需要较高的 CPU 和内存资源。")]),s._v(" "),t("li",[t("strong",[s._v("预处理节点（Ingest Node）：")]),s._v(" 预处理节点允许在写入文档前通过事先定义的处理器和管道对数据进行转换。节点启动后默认即为预处理节点。")]),s._v(" "),t("li",[t("strong",[s._v("部落节点（Tribe Node）：")]),s._v(" 部落节点可连接不同集群，将其视为单一集群进行处理。但在未来版本中将被淘汰。")]),s._v(" "),t("li",[t("strong",[s._v("Hot & Warm 节点：")]),s._v(" Hot & Warm 架构的实现需要不同硬件配置的数据节点。例如，将高性能硬件用于 Hot 类型节点，将一般性能硬件用于 Warm 节点，以达到降低部署成本的目的。")])]),s._v(" "),t("p",[s._v("在生产环境中，建议为每个节点设置单一角色。若业务量较小或并发量较低，也可以将一个节点设置为多种角色的集群，以节省成本。而在开发环境中，出于资源节约的考虑，一个节点可担任多种角色。")]),s._v(" "),t("p",[t("strong",[s._v("下表是7.8 及之前各个节点类型的配置方式")]),s._v("（Hot & Warm Node 需要通过其他方式来设定，不在此列）：")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("节点类型")]),s._v(" "),t("th",[s._v("配置")]),s._v(" "),t("th",[s._v("默认值")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("Master Eligible")]),s._v(" "),t("td",[s._v("node.master")]),s._v(" "),t("td",[s._v("true")])]),s._v(" "),t("tr",[t("td",[s._v("Data Node")]),s._v(" "),t("td",[s._v("node.data")]),s._v(" "),t("td",[s._v("true")])]),s._v(" "),t("tr",[t("td",[s._v("Ingest Node")]),s._v(" "),t("td",[s._v("node.ingest")]),s._v(" "),t("td",[s._v("true")])]),s._v(" "),t("tr",[t("td",[s._v("Coordinating Node")]),s._v(" "),t("td",[s._v("不需要配置")]),s._v(" "),t("td",[s._v("默认就是coordinating，所以需要设置单一角色时，设置其他类型全部为false")])])])]),s._v(" "),t("p",[s._v("在新版的 ES 中，这个配置方式就做出了改变，使用 "),t("code",[s._v("node.roles")]),s._v(" 参数来指定一个节点的角色。其示例如下：")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("node.roles: "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" master, data "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" //设置节点为 master 候选节点和数据节点\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("如上示例，"),t("code",[s._v("node.roles")]),s._v(" 的值是一个数组，说明一个节点可以有多个角色。"),t("code",[s._v("node.roles")]),s._v(" 的可选项如下：")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("master")]),s._v("，master 候选节点，master 将会从这些节点中选取出来。")]),s._v(" "),t("li",[t("strong",[s._v("voting_only")]),s._v("，参与 master 选举的节点，其只有投票权限，当不会成为 master。")]),s._v(" "),t("li",[t("strong",[s._v("data")]),s._v("，我们最熟悉的一类数据节点。保存文档数据的 shard 将分配到 data 节点中保存。")]),s._v(" "),t("li",[t("strong",[s._v("data_content")]),s._v("，此角色的节点会处理用户创建的文档内容，如书本信息，歌曲信息这类数据。可以处理 CRUD、数据搜索和聚合等。")]),s._v(" "),t("li",[t("strong",[s._v("data_hot")]),s._v("，此角色的节点会根据数据写入 ES 的时间存储时序数据，例如日志数据，data_hot 节点对数据读写要求快速，应当使用 SSD 存储。")]),s._v(" "),t("li",[t("strong",[s._v("data_warm")]),s._v("，data_warm 节点会存储不会经常更新但是仍然被查询的数据，相对于 data_hot，其查询的频率要低。")]),s._v(" "),t("li",[t("strong",[s._v("data_cold")]),s._v("，很少再被读取的数据可以存储在 data_cold，"),t("strong",[s._v("此类节点的数据是只读的")]),s._v("。")]),s._v(" "),t("li",[t("strong",[s._v("data_frozen")]),s._v("，专门用于存储 partially mounted indices 的数据节点。")]),s._v(" "),t("li",[t("strong",[s._v("ingest，")]),s._v("  预处理数据的节点。")]),s._v(" "),t("li",[t("strong",[s._v("ml，")]),s._v("  提供机器学习的功能，此类节点运行作业并处理机器学习 API 请求。")]),s._v(" "),t("li",[t("strong",[s._v("remote_cluster_client")]),s._v("，充当跨集群客户端并连接到其他集群。")]),s._v(" "),t("li",[t("strong",[s._v("transform")]),s._v("，运行 transforms 并处理 transform API 请求。")])]),s._v(" "),t("blockquote",[t("p",[s._v("注意，上述类型中并没有协调节点的类型选项，那怎么设置一个节点为协调节点呢？其实每个节点本身就是一个协调节点，一定要指定一个节点为协调节点的话，可以这样设置：")])]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("node.roles: "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" //就是啥都不写\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("在生产环境中建议将节点分层部署，使用专门的节点类型来处理相应的业务需求。")]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_1-3-分片"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-分片"}},[s._v("#")]),s._v(" 1.3 分片")]),s._v(" "),t("p",[s._v("在 Elasticsearch 的世界中，索引的概念超越了单个节点的硬件限制，允许存储大量数据。举例来说，一个包含 10 亿文档的索引可能占据 1TB 的磁盘空间，而单一节点可能无法满足如此庞大的存储需求，甚至可能因处理搜索请求而变得过于缓慢。为了解决这些问题，Elasticsearch 引入了索引分片的概念，使得索引可以划分成多个部分，每个部分即为一个分片。当您创建一个索引时，可以指定所需的分片数量。每个分片本身都具备独立且完备的索引功能，而这些“子索引”则可以分布在集群中的任意节点上。")]),s._v(" "),t("p",[t("strong",[s._v("索引分片带来的优势：")])]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("水平扩容：")]),s._v(" 通过分片，Elasticsearch 允许索引在需要时进行水平扩容，解决了存储容量和性能瓶颈的问题。")]),s._v(" "),t("li",[t("strong",[s._v("分布式和并行计算：")]),s._v(" 每个分片可以被分布式地、并行地处理，从而实现了高性能和高吞吐量的搜索、聚合等操作。")])]),s._v(" "),t("p",[s._v("分片的分布、文档的聚合以及搜索请求的处理，都由 Elasticsearch 自动管理，作为用户的您无需过分关心这些内部细节，因为它们都在后台透明地运作。")]),s._v(" "),t("p",[s._v("值得一提的是，Lucene 索引在 Elasticsearch 中被称为分片。Elasticsearch 索引实际上是由多个分片构成的集合。当 Elasticsearch 执行索引中的搜索操作时，它会将查询发送到每个属于该索引的分片（即 Lucene 索引），然后将每个分片的结果合并为一个全局结果集。")]),s._v(" "),t("p",[s._v("通过这种巧妙的分片设计，Elasticsearch 实现了高效的数据存储、管理和查询，在用户层面为您提供了无缝的体验。")]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_1-4-副本"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-副本"}},[s._v("#")]),s._v(" 1.4 副本")]),s._v(" "),t("p",[s._v("在 Elasticsearch 中，您有权利创建分片的单个或多个拷贝，这些拷贝称为复制分片（副本）。")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("提供高可用性：")]),s._v(" 复制分片的一个主要用途是在分片或节点故障时保障高可用性。这是为何将复制分片与原始/主分片分配到不同节点上如此重要的原因所在。")]),s._v(" "),t("li",[t("strong",[s._v("扩展搜索量/吞吐量：")]),s._v(" 通过在所有复制分片上并行执行搜索操作，Elasticsearch 实现了搜索量和吞吐量的扩展。这种并行性允许更多的搜索请求同时进行，提高了系统的整体性能。")])]),s._v(" "),t("p",[s._v("每个索引可以被分成多个分片，且可以进行 0 次（即无复制）或多次的复制。一旦启用复制，每个索引将具备主分片（原始分片的来源）和复制分片（主分片的拷贝）。分片和副本的数量可以在索引创建时进行指定。尽管您可以在索引创建后动态调整副本数量，但是分片的数量在创建后无法修改。")]),s._v(" "),t("p",[s._v("通常情况下，默认情况下每个索引在 Elasticsearch 中具有 1 个主分片和 1 个副本，这意味着在具有至少两个节点的集群中，每个索引将包含 1 个主分片和其对应的 1 个复制分片，即总共 2 个分片。然而，根据索引的需求，您可以灵活地确定适当的分片数量。")]),s._v(" "),t("p",[s._v("通过配置分片和复制分片，Elasticsearch 在不同层面上实现了高可用性和性能的优化，为您的数据管理和查询提供了更大的灵活性和控制。")]),s._v(" "),t("p",[s._v("在kibana中设置分片数&副本数。")]),s._v(" "),t("div",{staticClass:"language-json line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-json"}},[t("code",[s._v("## 创建 mapping 的时候定义好分片和副本数量。\nPUT order\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"mappings"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"properties"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"order_id"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"keyword"')]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"name"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"settings"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"number_of_shards"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ## 定义了 "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" 个分片\n    "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"number_of_replicas"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" ## 定义了每个分片 "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" 个副分片\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br")])]),t("hr"),s._v(" "),t("h3",{attrs:{id:"_1-5-集群健康状态"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-5-集群健康状态"}},[s._v("#")]),s._v(" 1.5 集群健康状态")]),s._v(" "),t("p",[s._v("透过集群的健康状态，我们能够迅速了解集群是否出现问题。集群的健康状态可以分为以下三种：")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("Green（绿色）：")]),s._v(" 表示集群处于健康状态，所有主分片和副本分片都在正常运行中，数据的完整性和可用性得到保障。")]),s._v(" "),t("li",[t("strong",[s._v("Yellow（黄色）：")]),s._v(" 主分片全部正常，但部分副本分片可能出现异常。这可能暗示存在单点故障的风险，尤其是在主分片没有足够的备份情况下。例如，当集群拥有三个数据节点但为每个索引分配了四个副本时，可能会出现一个副本分片无法分配到节点的情况，因为相同数据的两个副本不应位于同一节点上。")]),s._v(" "),t("li",[t("strong",[s._v("Red（红色）：")]),s._v(" 表示有一些主分片无法正常运行，可能是因为节点故障或其他问题。此状态可能导致数据的丢失或不可用，需要及时处理以恢复集群正常运行。")])]),s._v(" "),t("p",[s._v("需要强调的是，每个索引也具有这三种状态。若某个索引失去一个副本分片，该索引及集群状态将变为黄色，但其他索引仍可能保持绿色状态。")]),s._v(" "),t("p",[s._v("集群健康状态的监控为管理员提供了重要的指标，帮助您实时了解集群的可靠性和健康程度，从而及时采取措施防范潜在的风险。")]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_1-6-分配"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-6-分配"}},[s._v("#")]),s._v(" 1.6 分配")]),s._v(" "),t("p",[s._v("将分片分配给特定节点是一个涵盖主分片和副本的过程。对于副本，它还涵盖了从主分片复制数据的过程。这个复杂的过程由集群中的主节点（master节点）来完成。")]),s._v(" "),t("p",[s._v("在这个过程中，主节点扮演着协调者的角色，负责管理和监督分片的分配和数据的复制。当创建索引或者出现节点故障时，主节点将考虑集群的健康状况、数据均衡和副本的分布情况，然后决定将主分片和副本分片分配给哪些节点。")]),s._v(" "),t("p",[s._v("对于主分片，主节点会选择一个节点并将主分片分配给它，该节点负责管理和维护主分片中的数据。")]),s._v(" "),t("p",[s._v("对于副本分片，主节点首先选择一个节点作为副本的目标节点，然后将主分片中的数据复制到该目标节点上。这确保了数据的冗余和高可用性，以及在主节点或主分片发生故障时的数据恢复能力。")]),s._v(" "),t("p",[s._v("这个分片分配和数据复制的过程是集群管理的关键部分，它确保了数据的可靠性、高可用性和负载均衡。通过主节点的智能协调，Elasticsearch 能够优化分片分配，确保集群的整体健康和性能。")]),s._v(" "),t("hr"),s._v(" "),t("h2",{attrs:{id:"_2-从数据层面看"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-从数据层面看"}},[s._v("#")]),s._v(" 2.从数据层面看")]),s._v(" "),t("h3",{attrs:{id:"_2-1-索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-索引"}},[s._v("#")]),s._v(" 2.1 索引")]),s._v(" "),t("p",[s._v("一个索引代表了一组具有相似特征的文档集合，可以是客户数据、产品目录、订单数据等。每个索引由一个标识名称（必须全为小写字母）来唯一标识。这个名称在进行索引、搜索、更新和删除等操作时都会被用到。在一个集群中，您可以定义任意数量的索引。")]),s._v(" "),t("p",[s._v("索引在实现数据搜索中起着关键作用，对数据进行索引可以显著提升查询速度，这正是 Elasticsearch 设计的精髓。以下是一个示例索引的图示，该索引拥有三个主分片（P1、P2、P3）以及相应的副本分片（R1、R2、R3），它们分布在三个节点中。\n"),t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/elasticsearch/202311042055491.png",alt:"image.png"}}),s._v("\n主分片和副本分片不会同时分配在同一个节点上，这种分配策略旨在确保数据的高可用性。当一个节点上的主分片因故障无法正常工作时，其他节点上的副本分片可以晋升为主分片，从而保障数据的可靠性和可用性。")]),s._v(" "),t("p",[s._v("通过这种分片和副本的组织方式，Elasticsearch 在保证数据冗余和高可用的同时，也充分利用了集群中的多节点资源，实现了数据的分布式存储和处理，从而提供了高性能、高可扩展性的搜索和查询功能。")]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_2-2-映射"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-映射"}},[s._v("#")]),s._v(" 2.2 映射")]),s._v(" "),t("p",[s._v("映射（Mapping）在Elasticsearch中是用来定义数据处理方式和规则的重要工具，它决定了数据在索引中的结构和属性。映射包括诸多设置，例如字段的数据类型、默认值、分析器、是否索引等，这些设置能够对数据的存储、检索和分析产生深远影响。除此之外，映射还涵盖了一系列处理Elasticsearch数据的最佳实践，旨在优化性能。")]),s._v(" "),t("p",[s._v("在映射中，你可以定义每个字段的具体数据类型，例如文本、数字、日期等，还可以为字段设置默认值，指定如何进行文本分析和分词，以及是否将字段索引以支持高效的搜索操作等。这些设置不仅决定了数据如何存储在索引中，还影响了查询的速度、准确性和效率。")]),s._v(" "),t("p",[s._v("借助映射，你可以根据数据的特性和业务需求，制定最佳的数据处理策略。通过精心构建映射，可以大幅提升性能，优化搜索和分析操作。因此，映射的设计是一个关键的步骤，需要仔细思考如何为数据建立最优的映射，以获得最佳的性能和效果。")]),s._v(" "),t("p",[s._v("综上所述，映射是一种关键的配置，它不仅规定了数据的结构和规则，还为数据处理提供了最佳实践，通过合理设置映射，可以显著提升Elasticsearch的性能和效率。")]),s._v(" "),t("p",[t("strong",[s._v("Mapping 一旦定义后，已经定义的字段的类型是不能更改的")]),s._v("。")]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_2-3-文档"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-文档"}},[s._v("#")]),s._v(" 2.3 文档")]),s._v(" "),t("p",[s._v("一个文档是Elasticsearch中可被索引的基本信息单元，通常对应于一条数据记录。文档以JSON（JavaScript Object Notation）格式来表示，这是一种在互联网数据交互中广泛使用的标准格式。在Elasticsearch中，文档是数据的最小存储单元，它可以包含各种字段和值，以表达数据的不同属性。")]),s._v(" "),t("p",[s._v("每个文档都被分配到特定的索引中，索引可以看作是一种逻辑上的数据容器，用于组织和存储相关的文档。在一个索引内，你可以存储任意数量的文档，这些文档可以来自不同的数据源，代表不同类型的实体或信息。例如，一个电子商务应用可能会有一个商品索引，其中包含多个商品文档，每个文档代表一个商品的信息。")]),s._v(" "),t("p",[s._v("JSON格式的文档具有灵活性，你可以根据需求自由地定义字段和结构，从而适应不同类型的数据。这种灵活性使得Elasticsearch成为了一个强大的数据存储和搜索引擎，能够应对各种复杂的数据处理需求。")]),s._v(" "),t("p",[s._v("我们通过kibana的devTool插入索引一条数据：")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("POST huidong_order/_doc/1\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"id"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"1"')]),s._v(",\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"618 ElasticSearch book"')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("p",[s._v("在kibana中查询这条数据")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("POST huidong_order/_search\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"query"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"match_phrase"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"id"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"1"')]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br")])]),t("p",[s._v("查询结果")]),s._v(" "),t("div",{staticClass:"language-json line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-json"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"took"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"timed_out"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"_shards"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"total"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"successful"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"skipped"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"failed"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"hits"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"total"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"value"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"relation"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"eq"')]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"max_score"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2876821")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"hits"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"_index"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"huidong_order"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"_type"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"_doc"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"_id"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"1"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"_score"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2876821")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"_source"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"id"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"1"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token property"}},[s._v('"name"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"618 ElasticSearch book"')]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br")])]),t("p",[s._v("通过上述结果，我们可以观察到插入的数据被存储在 "),t("code",[s._v("_source")]),s._v(" 字段中，同时结果中还包含了其他一些字段，这些额外字段是Elasticsearch为文档添加的元数据。以下是这些字段的详细解释：")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("_index")]),s._v("：文档所属的索引名称，如在上述例子中是 "),t("code",[s._v("huidong_order")]),s._v("。")]),s._v(" "),t("li",[t("code",[s._v("_type")]),s._v("：文档所属的类型名称，在现代的ES 7.x版本中，所有文档类型统一为 "),t("code",[s._v("_doc")]),s._v("。")]),s._v(" "),t("li",[t("code",[s._v("_id")]),s._v("：文档的唯一标识符。如果在插入数据时未指定文档ID，Elasticsearch会自动生成一个随机的ID，这有助于将数据均匀地分布到不同的分片中。")]),s._v(" "),t("li",[t("code",[s._v("_version")]),s._v("：文档的版本信息，用于解决并发读写时的文档冲突问题。")]),s._v(" "),t("li",[t("code",[s._v("_score")]),s._v("：相关性评分，表示查询结果的匹配程度，可用于结果排序。")]),s._v(" "),t("li",[t("code",[s._v("seq_no")]),s._v(" 和 "),t("code",[s._v("primary_term")]),s._v("：这两个字段是Elasticsearch内部用来确保主分片和副本之间数据一致性的。每当索引选择一个主分片时，都会有一个序列号 "),t("code",[s._v("_primary_term")]),s._v("，每次写入数据时也会有一个顺序号 "),t("code",[s._v("_seq_no")]),s._v("，这两者都是递增的。"),t("code",[s._v("**primary_term**")]),s._v("** 和 "),t("strong",[t("code",[s._v("**seq_no**")])]),s._v(" 在逻辑上共同构成了文档写入的唯一位置。**")])]),s._v(" "),t("p",[s._v("这些元数据字段提供了关于文档的重要信息，包括其存储位置、版本控制、匹配性评分以及数据一致性等方面的信息。通过这些字段，Elasticsearch能够高效地管理文档和处理查询请求，从而实现高性能的搜索和分析功能。")]),s._v(" "),t("blockquote",[t("p",[s._v("每个文档在Elasticsearch中都拥有唯一的标识符，即文档ID。当我们插入文档时，如果没有显式指定文档ID，Elasticsearch会自动为文档生成一个唯一的ID。这种自动生成ID的方式在某些情况下可以提供更好的性能，因为系统无需进行额外的判断来确定是否已经存在该ID。")])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_2-4-字段"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-字段"}},[s._v("#")]),s._v(" 2.4 字段")]),s._v(" "),t("p",[s._v("字段在Elasticsearch中类似于关系型数据库中的表字段，用于对文档数据进行基于不同属性的分类和标识。")]),s._v(" "),t("p",[s._v("每个字段都必须指定特定的数据类型，这些类型常见的有：")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("keyword")]),s._v("：适用于存储短、结构化的字符串，例如产品ID、产品名称等。这种类型通常用于精确匹配和聚合操作。")]),s._v(" "),t("li",[t("code",[s._v("text")]),s._v("：适用于存储全文本数据，如短信内容、邮件内容等。"),t("code",[s._v("text")]),s._v(" 类型的字段会进行全文本分析，允许模糊匹配、搜索和高亮等操作。")]),s._v(" "),t("li",[s._v("数字类型：包括 "),t("code",[s._v("integer")]),s._v("、"),t("code",[s._v("long")]),s._v("、"),t("code",[s._v("float")]),s._v("、"),t("code",[s._v("double")]),s._v(" 等。用于存储数值数据，可以进行数值范围查询和聚合计算。")]),s._v(" "),t("li",[s._v("对象类型：这类字段的值本身是一个JSON对象，可以包含更复杂的结构化数据。例如，可以在一个文档中存储一个嵌套的JSON对象，表示用户的详细信息。")])]),s._v(" "),t("p",[s._v("选择正确的字段类型对于索引性能和查询效果至关重要。通过选择合适的类型，可以充分利用Elasticsearch的索引和搜索功能，从而提高系统的性能和可用性。在设计索引时，需要根据数据的性质和使用场景来选择最适合的字段类型，以便在不同的操作中获取最佳的性能和结果。")]),s._v(" "),t("p",[s._v("For Example:")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("PUT huidong_order\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"mappings"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"properties"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"id"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"keyword"')]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"product"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" \n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"properties"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"last"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br")])]),t("hr"),s._v(" "),t("h3",{attrs:{id:"_2-5-词项-term"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-词项-term"}},[s._v("#")]),s._v(" 2.5 词项（Term）")]),s._v(" "),t("p",[s._v('全文本内容在Elasticsearch中经过分词处理后生成词项。词项是文本内容被分割、标准化并提取后的结果，它们是搜索引擎索引和检索的基本单元。以一句话 "Programmers Love Cat" 为例，经过标准分词器的处理后会得到以下三个词项：[programmer, love, cat]。')]),s._v(" "),t("p",[s._v("在全文搜索中，词项起到关键作用，它们构成了文本的基本构成单元，使搜索引擎能够理解和处理文本数据。分词器根据一定的规则将文本拆分成词项，通常包括将文本转换为小写形式、去除标点符号、提取词根等操作，以便在后续的搜索过程中能够准确地匹配查询关键词。")]),s._v(" "),t("p",[s._v("对于搜索查询，Elasticsearch会将查询字符串进行相同的分词处理，生成相应的词项，然后与索引中的词项进行匹配，从而实现高效的全文搜索功能。理解词项的概念有助于更好地设计索引和查询，以达到更准确、快速的搜索结果。")]),s._v(" "),t("blockquote",[t("p",[s._v("分词器除了进行分词外还会进行大小写转换等其他操作。")])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_2-6-倒排索引-正排索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-6-倒排索引-正排索引"}},[s._v("#")]),s._v(" 2.6 倒排索引&正排索引")]),s._v(" "),t("p",[s._v('在Elasticsearch中，采用一种名为"倒排索引"的结构，这种结构在实现快速的全文搜索方面表现出色。倒排索引与正向索引是对应的概念。通常，倒排索引也以反向索引（inverted index）为其更熟悉的称呼。')]),s._v(" "),t("p",[s._v("在正向索引中，搜索引擎会为每个待搜索的文件分配一个文件ID，然后在搜索过程中将这个文件ID与搜索关键字建立关联，形成键值对。接着，搜索引擎会对这些关键字进行统计计数。\n"),t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/elasticsearch/202311042056875.png",alt:"image.png"}}),s._v("\n然而，互联网上搜索引擎收录的文档数量是一个天文数字级别的数量，传统的正向索引结构无法满足实时返回排名结果的要求。因此，搜索引擎会采用一种策略，将正向索引转化为倒排索引的结构。")]),s._v(" "),t("p",[s._v("在倒排索引中，将文件ID与关键词的映射转变为关键词与文件ID的映射。每个关键词都会对应一系列的文件，这些文件中都包含了该关键词。这种转换使得搜索引擎能够更高效地执行全文搜索，快速找到包含特定关键词的文档。\n"),t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/elasticsearch/202311042057875.png",alt:"image.png"}}),s._v('\n简单的说，一个倒排索引由文档中所有不重复的词构成，对于每个词，都有一个包含它的文档列表。举例来说，假设我们有两个文档，每个文档的 "content" 字段包含如下内容：')]),s._v(" "),t("div",{staticClass:"language-latex line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-latex"}},[t("code",[s._v("The quick brown fox jumped over the lazy dog\n\nQuick brown foxes leap over lazy dogs in summer\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("为了创建倒排索引,我们首先将每个文档的 content 域拆分成单独的 词(我们称它为 词条或 tokens ),创建一个包含所有不重复词条的排序列表,然后列出每个词条出现在哪个文档。结果如下所示:")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("Term")]),s._v(" "),t("th",[s._v("Doc_1")]),s._v(" "),t("th",[s._v("Doc_2")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("Quick")]),s._v(" "),t("td"),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("The")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("brown")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("dog")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("dogs")]),s._v(" "),t("td"),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("fox")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("foxes")]),s._v(" "),t("td"),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("in")]),s._v(" "),t("td"),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("jumped")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("lazy")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("leap")]),s._v(" "),t("td"),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("over")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("quick")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("summer")]),s._v(" "),t("td"),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("the")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")])])]),s._v(" "),t("p",[s._v("现在,如果我们想搜索 "),t("code",[s._v("quick brown")]),s._v(" ,我们只需要查找包含每个词条的文档:")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("Term")]),s._v(" "),t("th",[s._v("Doc_1")]),s._v(" "),t("th",[s._v("Doc_2")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("brown")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("quick")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("Total")]),s._v(" "),t("td",[s._v("2")]),s._v(" "),t("td",[s._v("1")])])])]),s._v(" "),t("p",[s._v("两个文档都匹配,但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单相似性算法,那么我们可以说,对于我们查询的相关性来讲,第一个文档比第二个文档更佳。")]),s._v(" "),t("p",[s._v("目前的倒排索引有一些问题:")]),s._v(" "),t("ul",[t("li",[s._v("Quick 和 quick 以独立的词条出现,然而用户可能认为它们是相同的词。")]),s._v(" "),t("li",[s._v("fox 和 foxes 非常相似, 就像 dog 和 dogs ;他们有相同的词根。")]),s._v(" "),t("li",[s._v("jumped 和 leap, 尽管没有相同的词根,但他们的意思很相近。他们是同义词。")])]),s._v(" "),t("p",[s._v("使用前面的索引搜索 "),t("code",[s._v("+Quick +fox")]),s._v(" 不会得到任何匹配文档。(记住,+ 前缀表明这个词必须存在。)只有同时出现 Quick 和 fox 的文档才满足这个查询条件,但是第一个文档包含"),t("code",[s._v("quick fox")]),s._v(" ,第二个文档包含 "),t("code",[s._v("Quick foxes")]),s._v("。")]),s._v(" "),t("p",[s._v("我们的用户可以合理的期望两个文档与查询匹配。我们可以做的更好。")]),s._v(" "),t("p",[s._v("如果我们将词条规范为标准模式,那么我们可以找到与用户搜索的词条不完全一致,但具有足够相关性的文档。例如:")]),s._v(" "),t("ul",[t("li",[s._v("Quick 可以小写化为 quick 。")]),s._v(" "),t("li",[s._v("foxes 可以 词干提取 --变为词根的格式-- 为 fox 。类似的, dogs 可以为提取为 dog 。")]),s._v(" "),t("li",[s._v("jumped 和 leap 是同义词,可以索引为相同的单词 jump 。")])]),s._v(" "),t("p",[s._v("现在索引看上去像这样:")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("Term")]),s._v(" "),t("th",[s._v("Doc_1")]),s._v(" "),t("th",[s._v("Doc_2")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("brown")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("dog")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("fox")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("in")]),s._v(" "),t("td"),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("jumped")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("lazy")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("over")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("quick")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("summer")]),s._v(" "),t("td"),s._v(" "),t("td",[s._v("X")])]),s._v(" "),t("tr",[t("td",[s._v("the")]),s._v(" "),t("td",[s._v("X")]),s._v(" "),t("td")])])]),s._v(" "),t("p",[s._v("这还远远不够。我们搜索 "),t("code",[s._v("+Quick +fox")]),s._v(" 仍然 会失败,因为在我们的索引中,已经没有 Quick了。但是,如果我们对搜索的字符串使用与 content 域相同的标准化规则,会变成查询"),t("code",[s._v("+quick +fox")]),s._v(",这样两个文档都会匹配.分词和标准化的过程称为分析。")]),s._v(" "),t("p",[s._v("你只能搜索在索引中出现的词条,所以索引文本和查询字符串必须标准化为相同的格式。")]),s._v(" "),t("hr"),s._v(" "),t("h2",{attrs:{id:"_3-从业务层面看"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-从业务层面看"}},[s._v("#")]),s._v(" 3. 从业务层面看")]),s._v(" "),t("h3",{attrs:{id:"_3-1-准实时"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-准实时"}},[s._v("#")]),s._v(" 3.1 准实时")]),s._v(" "),t("p",[t("strong",[s._v("Elasticsearch是一个近实时系统，写入的数据默认情况下会在大约1秒钟后才能被查询到")]),s._v("。这是因为Elasticsearch每秒都会将缓存中的数据写入到段（Segment）文件中，只有在数据被写入到段中后才能被检索。此外，Elasticsearch还会根据特定规则进行刷盘操作，以及对段进行合并。因此，在数据写入成功后立即进行查询可能导致查询不到数据或者获取到旧数据的情况。")]),s._v(" "),t("p",[s._v("这种延迟是为了确保数据的一致性和可靠性，以及提高性能和吞吐量。在实际使用中，用户需要留意这个近实时的特性，确保在进行查询操作时考虑到数据的同步和更新过程。可以使用刷新（refresh）操作来主动触发数据写入到段中并使其可查询，但也需要注意刷新操作会对性能产生一定影响。")]),s._v(" "),t("p",[s._v("了解Elasticsearch的写入和刷新机制有助于合理规划数据操作和查询操作的时机，以获得更好的查询性能和数据可用性。")]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_3-2-lucene-es"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-lucene-es"}},[s._v("#")]),s._v(" 3.2 Lucene&Es")]),s._v(" "),t("p",[s._v("Lucene并非一款完整的搜索引擎产品，而是一个搜索内核。它的功能集中在搜索过程的核心部分，包括文档创建、文本分析以及构建底层索引的过程。Lucene在这些方面提供了强大的支持，特别是通过分析（分词）结果来构建索引。")]),s._v(" "),t("p",[s._v("除此之外，Lucene还支持多样的查询方式，包括但不限于基于词的查询、范围查询、前缀匹配查询、组合查询、短语查询、通配符查询、模糊查询等等。")]),s._v(" "),t("p",[s._v("在Elasticsearch中，一个Lucene索引通常被称作一个分片。而一个Elasticsearch索引实际上是由多个分片组成的集合。当Elasticsearch执行搜索操作时，它会将查询发送到属于该索引的每个分片（即Lucene索引），然后将每个分片的结果合并成一个全局结果集。")]),s._v(" "),t("p",[s._v("这种分片和合并的架构有助于提高搜索的性能和并发处理能力，同时也能保障数据的分布和可用性。深入理解Lucene和Elasticsearch之间的关系，有助于更好地设计和优化搜索应用，从而获得更高效的数据检索和查询体验。")]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_3-3-相关性打分"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-相关性打分"}},[s._v("#")]),s._v(" 3.3 相关性打分")]),s._v(" "),t("p",[s._v("在Elasticsearch中，相关性打分是一种用于搜索查询的特性，它根据文档与查询的匹配程度来计算每个文档的得分，从而确定搜索结果的排序顺序，将最相关的文档排在前面。")]),s._v(" "),t("p",[s._v("这种相关性打分是基于倒排索引和词频统计等信息进行计算的。以下是一些常见的相关性打分算法和概念：")]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("TF-IDF（Term Frequency-Inverse Document Frequency）")]),s._v("：这是一种常用的相关性打分算法，结合了词频和逆文档频率两个因素。词频表示一个词在文档中出现的次数，逆文档频率表示该词在整个文集中的重要性。高TF-IDF得分意味着词在文档中频繁出现，但在整个文集中相对稀有，因此与查询的相关性更高。")]),s._v(" "),t("li",[t("strong",[s._v("BM25（Best Match 25）")]),s._v("：这是一种基于概率模型的相关性打分算法，考虑了词频、文档长度和查询词项的重要性等因素。BM25在Elasticsearch中广泛应用，通常作为默认的相关性打分算法。")]),s._v(" "),t("li",[t("strong",[s._v("向量空间模型（Vector Space Model）")]),s._v("：这种模型基于向量空间，将文档和查询表示为向量，并计算它们之间的相似度。常见的相似度计算方法包括余弦相似度和欧氏距离等。")])]),s._v(" "),t("p",[s._v("这些相关性打分算法基于不同的原理和计算方式来衡量文档与查询的匹配程度。它们在Elasticsearch中以可插拔的方式实现，用户可以根据需要选择适合的打分算法或自定义打分插件。")]),s._v(" "),t("p",[s._v("在查询结果中，每个文档都会被分配一个相关性得分，得分越高表示与查询的匹配程度越高。Elasticsearch默认按照相关性得分进行排序，以便将最相关的文档排在前面。通过自定义查询和打分参数，我们可以调整相关性得分的计算方式，以满足不同的搜索需求。这使得Elasticsearch能够根据查询的目的提供更加精准的搜索结果。")]),s._v(" "),t("hr")])}),[],!1,null,null,null);t.default=r.exports}}]);