(window.webpackJsonp=window.webpackJsonp||[]).push([[130],{472:function(e,t,o){"use strict";o.r(t);var _=o(4),s=Object(_.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[e._v("Kafka自定义了一组基于TCP的二进制协议,只要遵守这组协议的格式,就可以向 Kafka发送消息,也可以从Kafka中拉取消息,或者做一些其他的事情,比如提交消费位移等。")]),e._v(" "),t("p",[e._v("在目前的Kafka2.0.0中,一共包含了43种协议类型,每种协议类型都有对应的请求(Request)和响应( Response),它们都遵守特定的协议模式。每种类型的 Request都包含相同结构的协议请求头(RequestHeader)和不同结构的协议请求体(RequestBody),如图所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311222230188.png",alt:""}})]),e._v(" "),t("p",[e._v("协议请求头中包含4个域(Field): "),t("code",[e._v("api_key")]),e._v("、 "),t("code",[e._v("api_version")]),e._v("、 "),t("code",[e._v("correlation_id")]),e._v("和"),t("code",[e._v("client_d")]),e._v("。")]),e._v(" "),t("p",[e._v("每种类型的 Response也包含相同结构的协议响应头(ResponseHeader)和不同结构的响应体(ResponseBody),如图所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311222231732.png",alt:""}})]),e._v(" "),t("p",[e._v("下面就以最常见的消息发送和消息拉取的两种协议类型做分析。首先要讲述的是消息发送的协议类型,即 "),t("strong",[e._v("ProduceRequest/ProduceResponse")]),e._v(",对应的 "),t("code",[e._v("api_key=0")]),e._v(",表示 "),t("strong",[e._v("PRODUCE")]),e._v("。从 Kafka建立之初,其所支持的协议类型就一直在增加,并且对特定的协议类型而言,内部的组织结构也并非一成不变。以 "),t("strong",[e._v("ProduceRequest/ProduceResponse")]),e._v("为例,截至目前就经历了7个版本(V0~V6)的变迁。下面就以最新版本(V6,即 api_version=6)的结构为例来做细致的讲解。 ProduceRequest的组织结构如图所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311222231617.png",alt:""}})]),e._v(" "),t("p",[e._v("消息累加器"),t("strong",[e._v("RecordAccumulator")]),e._v("中的消息是以"),t("code",[e._v("<分区,DequeProducerBatch>")]),e._v("的形式进行缓存的,之后由"),t("strong",[e._v("Sender")]),e._v("线程转变成"),t("code",[e._v("<Node,List<ProducerBatch>>")]),e._v("的形式,针对每个"),t("strong",[e._v("Node")]),e._v(", "),t("strong",[e._v("Sender")]),e._v("线程在发送消息前会将对应的"),t("code",[e._v("List<ProducerBatch>")]),e._v("形式的内容转变成 "),t("strong",[e._v("ProduceRequest")]),e._v(" 的具体结构。"),t("code",[e._v("List<ProducerBatch>")]),e._v("中的内容首先会按照主题名称进行分类(对应 "),t("strong",[e._v("ProduceRequest")]),e._v("中的域 "),t("code",[e._v("topic")]),e._v("),然后按照分区编号进行分类(对应 "),t("strong",[e._v("ProduceRequest")]),e._v(" 中的域 "),t("code",[e._v("partition")]),e._v("),分类之后的 "),t("strong",[e._v("ProducerBatch")]),e._v(" 集合就对应 "),t("strong",[e._v("ProduceRequest")]),e._v(" 中的域 "),t("code",[e._v("record_set")]),e._v("从另一个角度来讲,每个分区中的消息是顺序追加的,那么在客户端中按照分区归纳好之后就可以省去在服务端中转换的操作了,这样将负载的压力分摊给了客户端,从而使服务端可以专注于它的分内之事,如此也可以提升整体的性能。")]),e._v(" "),t("p",[e._v("如果参数acks设置非0值,那么生产者客户端在发送 "),t("strong",[e._v("ProduceRequest")]),e._v(" 请求之后就需要(异步)等待服务端的响应"),t("strong",[e._v("ProduceResponse")]),e._v("。对 "),t("strong",[e._v("ProduceResponse")]),e._v(" 而言,V6版本中 "),t("strong",[e._v("ProduceResponse")]),e._v("的组织结构如图所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311222231164.png",alt:""}})]),e._v(" "),t("p",[e._v("消息追加是针对单个分区而言的,那么响应也是针对分区粒度来进行划分的,这样"),t("strong",[e._v("ProduceRequest")]),e._v("和 "),t("strong",[e._v("ProduceResponse")]),e._v(" 做到了一一对应。")]),e._v(" "),t("p",[e._v("我们再来了解一下拉取消息的协议类型,即 "),t("strong",[e._v("FetchRequest/FetchResponse")]),e._v(",对应的 "),t("code",[e._v("api_key=1")]),e._v(",表示 FETCH。截至目前,"),t("strong",[e._v("FetchRequest/FetchResponse")]),e._v("一共历经了9个版本(V0~V8)的变迁,下面就以最新版本(V8)的结构为例来做细致的讲解。 "),t("strong",[e._v("FetchRequest")]),e._v("的组织结构如图所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311222231134.png",alt:""}})]),e._v(" "),t("p",[e._v("不管是 follower副本还是普通的消费者客户端,如果要拉取某个分区中的消息,就需要指定详细的拉取信息,也就是需要设定 "),t("code",[e._v("partition、 fetch_offset、log_start_offset和 max_bytes")]),e._v("这4个域的具体值,那么对每个分区而言,就需要占用"),t("code",[e._v("4B+8B+8B+4B=24B")]),e._v("的空间。一般情况下,不管是 follower副本还是普通的消费者,它们的订阅信息是长期固定的也就是说, FetchRequest中的 "),t("code",[e._v("topics")]),e._v(" 域的内容是长期固定的,只有在拉取开始时或发生某些异常时会有所变动。 FetchRequest请求是一个非常频繁的请求,如果要拉取的分区数有很多,比如有1000个分区,那么在网络上频繁交互 FetchRequest时就会有固定的"),t("code",[e._v("1000×24B≈24KB")]),e._v("的字节的内容在传动,如果可以将这24KB的状态保存起来,那么就可以节省这部分所占用的带宽。")]),e._v(" "),t("p",[e._v("Kafka从1.1.0版本开始针对 FetchRequest引入了 "),t("code",[e._v("session_id、 epoch和 forgotten_topics_data")]),e._v("等域, "),t("code",[e._v("session_id和 epoch")]),e._v("确定一条拉取链路的 "),t("code",[e._v("fetch session")]),e._v(",当 "),t("code",[e._v("session")]),e._v("建立或变更时会发送全量式的 FetchRequest,所谓的全量式就是指请求体中包含所有需要拉取的分区信息;当 "),t("code",[e._v("session")]),e._v("稳定时则会发送增量式的 FetchRequest请求,里面的 "),t("code",[e._v("topics")]),e._v("域为空,因为 "),t("code",[e._v("topics")]),e._v("域的内容已经被缓存在了 "),t("code",[e._v("session")]),e._v("链路的两侧。如果需要从当前 "),t("code",[e._v("fetch session")]),e._v("中取消对某些分区的拉取订阅,则可以使用 "),t("code",[e._v("forgotten topics data")]),e._v("字段来实现。")]),e._v(" "),t("p",[e._v("这个改进在大规模(有大量的分区副本需要及时同步)的 Kafka集群中非常有用,它可以提升集群间的网络带宽的有效使用率。不过对客户端而言效果不是那么明显,一般情况下单个客户端不会订阅太多的分区,不过总体上这也是一个很好的优化改进。与 FetchRequest对应的 FetchResponse的组织结构(V8版本)如图所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311222232887.png",alt:""}})]),e._v(" "),t("p",[e._v("FetchResponse结构中的域也很多,它主要分为4层,第1层包含 "),t("code",[e._v("throttle_time_ms、error_code、 session_id和 responses")]),e._v(",前面3个域都见过,其中 "),t("code",[e._v("session_id")]),e._v("和FetchRequest中的 "),t("code",[e._v("session_id")]),e._v("对应。 "),t("code",[e._v("responses")]),e._v("是一个数组类型,表示响应的具体内容,也就是 FetchResponse结构中的第2层,具体地细化到每个分区的响应。第3层中包含分区的元数据信息("),t("code",[e._v("partition、 error_code")]),e._v("等)及具体的消息内容("),t("code",[e._v("record_set")]),e._v(")，"),t("code",[e._v("aborted_transactions")]),e._v("和事务相关。")]),e._v(" "),t("p",[e._v("除了Kafka客户端开发人员,绝大多数的其他开发人员基本接触不到或不需要接触具体的协议,那么我们为什么还要了解它们呢?其实,协议的具体定义可以让我们从另一个角度来了解Kafka的本质。以 PRODUCE和 FETCH为例,从协议结构中就可以看出消息的写入和拉取消费都是细化到每一个分区层级的。并且,通过了解各个协议版本变迁的细节也能够从侧面了解 Kafka变迁的历史,在变迁的过程中遇到过哪方面的瓶颈,又采取哪种优化手段,比如FetchRequest中的 "),t("code",[e._v("session_id")]),e._v("的引入。")]),e._v(" "),t("hr")])}),[],!1,null,null,null);t.default=s.exports}}]);