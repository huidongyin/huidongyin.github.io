(window.webpackJsonp=window.webpackJsonp||[]).push([[125],{467:function(e,n,t){"use strict";t.r(n);var s=t(4),a=Object(s.a)({},(function(){var e=this,n=e._self._c;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("p",[e._v("如果分区规则设置得合理，那么所有的消息可以均匀地分布到不同的分区中，这样就可以实现水平扩展。不考虑多副本的情况，一个分区对应一个日志 (Log)。为了防止 Log 过大,Kafka 又引入了日志分段(LogSegment)的概念，将 Log 切分为多个 LogSegment，相当于一个巨型文件被平均分配为多个相对较小的文件，这样也便于消息的维护和清理。事实上，Log 和LogSegment 也不是纯粹物理意义上的概念，Log 在物理上只以文件夹的形式存储，而每个LogSegment 对应于磁盘上的一个日志文件和两个索引文件，以及可能的其他文件 (比如以"),n("code",[e._v(".txnindex")]),e._v("为后缀的事务索引文件)。下图描绘了主题、分区与副本之间的关系和 Log，LogSegment的关系。")]),e._v(" "),n("p",[n("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311190925773.png",alt:""}})]),e._v(" "),n("p",[e._v("向 Log 中追加消息时是顺序写入的，只有最后一个 LogSegment 才能执行写入操作，在之前所有的 LogSegment 都不能写入数据。为了方便描述，我们将最后一个 LogSegment 称"),n("code",[e._v("activeSegment")]),e._v("，即表示当前活跃的日志分段。随着消息的不断写入，当 "),n("code",[e._v("activeSegment")]),e._v(" 满足一定的条件时，就需要创建新的 "),n("code",[e._v("activeSegment")]),e._v("，之后追加的消息将写入新的 "),n("code",[e._v("activeSegment")]),e._v("。")]),e._v(" "),n("p",[e._v("为了便于消息的检索，每个 LogSegment 中的日志文件 (以"),n("code",[e._v(".log")]),e._v("为文件后缀)都有对应的两个索引文件:偏移量索引文件(以"),n("code",[e._v(".index")]),e._v("为文件后缀)和时间戳索引文件(以"),n("code",[e._v(".timeindex")]),e._v("为文件后缀)。每个 LogSegment 都有一个基准偏移量 "),n("code",[e._v("baseOffset")]),e._v("，用来表示当前 LogSegment中第一条消息的 offset。偏移量是一个 64 位的长整型数，日志文件和两个索引文件都是根据基准偏移量 (baseOffset)命名的，名称固定为 20 位数字，没有达到的位数则用 0 填充。比如第一个 LogSegment 的基准偏移量为0，对应的日志文件为 "),n("code",[e._v("00000000000000000000.log")]),e._v("。")]),e._v(" "),n("p",[e._v("向主题"),n("code",[e._v("topic-log")]),e._v("中发送一定量的消息，某一时刻"),n("code",[e._v("topic-log-0")]),e._v("目录中的布局如下所示。")]),e._v(" "),n("div",{staticClass:"language-text line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("00000000000000000000.index\n00000000000000000000.log\n00000000000000000000.timeindex\n00000000000000000133.index\n00000000000000000133.log\n00000000000000000133.timeindex\n00000000000000000251.index\n00000000000000000251.log\n00000000000000000251.timeindex\n")])]),e._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[e._v("1")]),n("br"),n("span",{staticClass:"line-number"},[e._v("2")]),n("br"),n("span",{staticClass:"line-number"},[e._v("3")]),n("br"),n("span",{staticClass:"line-number"},[e._v("4")]),n("br"),n("span",{staticClass:"line-number"},[e._v("5")]),n("br"),n("span",{staticClass:"line-number"},[e._v("6")]),n("br"),n("span",{staticClass:"line-number"},[e._v("7")]),n("br"),n("span",{staticClass:"line-number"},[e._v("8")]),n("br"),n("span",{staticClass:"line-number"},[e._v("9")]),n("br")])]),n("p",[e._v("示例中第2个 LogSegment 对应的基准位移是 133，也说明了该 LogSegment 中的第一条消息的偏移量为 133，同时可以反映出第一个 LogSegment 中共有 133 条消息 (偏移量从0至 132的消息)。")]),e._v(" "),n("blockquote",[n("p",[e._v("每个 LogSegment 中不只包含"),n("code",[e._v(".log .index .timeindex")]),e._v("这3种文件，还可能包含"),n("code",[e._v(".deleted .cleaned .swap")]),e._v("等临时文件，以及可能的"),n("code",[e._v(".snapshot .txnindex leader-epoch-checkpoint")]),e._v("等文件。")])]),e._v(" "),n("p",[e._v("从更加宏观的视角上讲，Kafka中的文件不只上面提及的这些文件，比如还有一些检查点文件，当一个Kafka服务器第一次启动的时候，默认的根目录下就会创建以下5个文件。")]),e._v(" "),n("div",{staticClass:"language-text line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("cleaner-offset-checkpoint\nlog-start-offset-checkpoint\nmeta.properties\nrecovery-point-offset-checkpoint\nreplication-offset-checkpoint\n")])]),e._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[e._v("1")]),n("br"),n("span",{staticClass:"line-number"},[e._v("2")]),n("br"),n("span",{staticClass:"line-number"},[e._v("3")]),n("br"),n("span",{staticClass:"line-number"},[e._v("4")]),n("br"),n("span",{staticClass:"line-number"},[e._v("5")]),n("br")])]),n("p",[e._v("消费者提交的位点是保存在Kafka内部的主题"),n("code",[e._v("__consumer_offsets")]),e._v("中的，初始情况下这个主题并不存在，当第一次有消费者消费消息时会自动创建这个主题。")]),e._v(" "),n("p",[e._v("在某一时刻，Kafka中的文件目录布局如下图。每一个根目录都会包含最基本的4个检查点文件。在创建主题的时候，如果当前broker中不止配置了一个根目录，那么会挑选分区数最少的那个根目录完成本次创建任务。")]),e._v(" "),n("p",[n("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311190937193.png",alt:""}})]),e._v(" "),n("hr")])}),[],!1,null,null,null);n.default=a.exports}}]);