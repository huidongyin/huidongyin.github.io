(window.webpackJsonp=window.webpackJsonp||[]).push([[185],{566:function(s,t,a){"use strict";a.r(t);var n=a(4),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("p",[s._v("当涉及到强大的搜索引擎如 Elasticsearch 7.x 时，深入了解其核心概念是理解其强大功能的关键。在本文中，我们将探索与 Elasticsearch 7.x 相关性打分和分词器相关的一系列精彩话题。从设计相关性打分模型，深入研究 TF-IDF 和 BM25 模型，一直到分词器的概念及其组成，我们将为您揭开这个引人入胜的世界的面纱。您将了解到 analyze API 的内部运作方式，探索 Elasticsearch 内置分词器的不同特点，以及特别深入地研究中文分词器的实用性。通过这篇文章，您将获得更深入的理解，让您能够更加充分地利用 Elasticsearch 7.x 的强大搜索和分析功能。")]),s._v(" "),t("hr"),s._v(" "),t("h2",{attrs:{id:"_1-如何设计相关性打分模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-如何设计相关性打分模型"}},[s._v("#")]),s._v(" 1.如何设计相关性打分模型")]),s._v(" "),t("p",[s._v("对于搜索引擎而言，排序搜索结果是至关重要的功能。全文检索无法直接将搜索视为精确的等于查询并进行排序。相反，搜索引擎利用搜索相关度（相关性打分）来决定最终返回的结果。")]),s._v(" "),t("p",[s._v("相关性指的是搜索内容与查询结果之间的关联程度，用于衡量查询语句与文档匹配的程度。通过定义精确的相关性计算公式，可以得出最终的打分，然后根据这些分数对查询结果进行排序，以呈现出最符合用户搜索条件的数据。这个过程确保了搜索引擎能够提供高度个性化和准确的搜索结果。")]),s._v(" "),t("blockquote",[t("p",[s._v("这个问题在天猫一面的时候被面试官问到过，当时就ElasticSearch聊了一个多小时，问到了很多开放性知识，比如如何对Es的文档进行打分？如何设计一款分词器，，，等等。")])]),s._v(" "),t("hr"),s._v(" "),t("p",[s._v("无论是在日常方案设计还是面对开放性问题时，我们都应该培养充分思考的能力。举例来说，考虑如何设计一个相关性打分模型。我们知道，Elasticsearch会将文档进行分词，将其转化为一系列单独的词语（terms）。这引发一个问题：我们是否可以将用户输入的搜索内容同样进行分词，得到一组terms，然后分析这些terms在不同文档中的分布情况，以及它们在文档中的出现频率？")]),s._v(" "),t("p",[s._v("然而，我们可以进一步深入思考：从用户输入的搜索条件中拆分出来的terms是否都具有相同的重要性？举例来说，像“的”、“啊”这类常见词汇的意义可能相对较弱，尽管它们在文本中频繁出现。这可能会对最终的相关性打分产生影响。因此，我们应该考虑是否需要对这些词汇进行优先级排序或者忽略，以保证最终的相关性打分更加准确。这种深入思考的过程有助于我们在方案设计和开放性问题回答中做出更为明智的决策。\nFor example:")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("Term")]),s._v(" "),t("th",[s._v("文档ID列表")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("赋能")]),s._v(" "),t("td",[s._v("1,2,3")])]),s._v(" "),t("tr",[t("td",[s._v("闭环")]),s._v(" "),t("td",[s._v("1,3")])]),s._v(" "),t("tr",[t("td",[s._v("啊")]),s._v(" "),t("td",[s._v("1,2,3,4,5,6,7,8,9")])])])]),s._v(" "),t("p",[s._v('如果我们搜索内容是 "赋能 闭环 啊" ，将输入内容拆分成上述term，那么按照上面的思考这个查询最终可以命中的文档为1，2，3，接下来开始对查询结果排序：')]),s._v(" "),t("ol",[t("li",[s._v('列出 "赋能" 和 "闭环" 这两个term分别在文档1，2，3出现的频率。')]),s._v(" "),t("li",[s._v("根据这两个词的权重✖️每一个词出现的频率，得出最终的打分。")])]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("## 假设两个term权重都是1：\nsorce(doc 1) = (赋能)在文档1的出现次数/文档总词语数*1 + (闭环)在文档1的出现次数/文档总词语数*1\nsorce(doc 2) = (赋能)在文档2的出现次数/文档总词语数*1 + (闭环)在文档2的出现次数/文档总词语数*1\nsorce(doc 3) = (赋能)在文档3的出现次数/文档总词语数*1 + (闭环)在文档3的出现次数/文档总词语数*1\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("在我们设计的打分模型中，我们考虑了term 的权重和频率，事实上，很多算法都是基于概率统计的，比如：TF-IDF，BM25.")]),s._v(" "),t("hr"),s._v(" "),t("h2",{attrs:{id:"_2-现有的打分模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-现有的打分模型"}},[s._v("#")]),s._v(" 2.现有的打分模型")]),s._v(" "),t("h3",{attrs:{id:"_2-1-tf-idf打分模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-tf-idf打分模型"}},[s._v("#")]),s._v(" 2.1 TF-IDF打分模型")]),s._v(" "),t("p",[s._v("TF-IDF是一种关键词统计方法，用来反映一个词在一个文档集合或者资料库中的重要程度。它的核心思想就是"),t("strong",[s._v("一个词的重要程度和它在一个文档中出现的频率成正比，和它在整个索引里面出现的频率成反比")]),s._v("。\n"),t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/elasticsearch/202311042134057.png",alt:"TF-IDF.png"}}),s._v(" "),t("strong",[s._v("一个词项在一篇文档中出现得越多，其对于这篇文档来说越重要，同时这个词项在整个语料库中的稀有性影响着它对某篇文档的重要程度。tf-idf 本质上是对 TF 进行了加权计算，而这个权重就是 IDF。")])]),s._v(" "),t("blockquote",[t("p",[s._v("Lucene 对于 TF-IDF 公式有着一定的调整，具体的细节请参考："),t("a",{attrs:{href:"https://lucene.apache.org/core/6_6_6/core/org/apache/lucene/search/similarities/TFIDFSimilarity.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("官方文档"),t("OutboundLink")],1),s._v("。")])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_2-2-bm25算分模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-bm25算分模型"}},[s._v("#")]),s._v(" 2.2 BM25算分模型")]),s._v(" "),t("p",[s._v('"BM"是"Best Matching"的缩写，它基于词频进行打分，但并不考虑多个搜索词项在文档中的距离关系，仅关注各自在文档中出现的频次。而"BM25"则是一组打分函数，这些函数在形式和参数个数上存在一些差异，但都共同关注于对文档的相关性进行打分。\n'),t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/elasticsearch/202311042135913.png",alt:"BM25.png"}}),s._v("\n相对于 TF-IDF 来说，BM25 降低了 TF 对算分的影响力。当 TF 无限增加时，TF-IDF 模型的算分也会无限增加，而 BM25 则会趋于一个值。"),t("strong",[s._v("如果不考虑文档长度的影响（|D|/avgdl = 1 了），BM25 的 TF 算分的公式为：（tf * （k1 + 1）/ (tf + k1)）")]),s._v(" 。\n"),t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/elasticsearch/202311042135615.png",alt:"image.png"}}),s._v("\n在 ES 5.0 的版本后，ES 默认使用了 BM25 的算分模型，相对 TF-IDF 来说，其优化点在于降低 TF 对算分结果的影响力，并且引入了可以自定义的参数：k1 和 b，其中"),t("strong",[s._v("k1 的作用是用来调节词频的影响力的")]),s._v("；"),t("strong",[s._v("b 控制了文档篇幅对于得分的影响程度。")])]),s._v(" "),t("p",[s._v("可以使用 explain API 来查看算分的过程：")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v('GET order/_search\n{\n    "explain": true, ## 开启 explain\n    "query": .....\n}\n')])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("hr"),s._v(" "),t("h2",{attrs:{id:"_3-分词-分词器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-分词-分词器"}},[s._v("#")]),s._v(" 3.分词&分词器")]),s._v(" "),t("h3",{attrs:{id:"_3-1-什么是分词"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-什么是分词"}},[s._v("#")]),s._v(" 3.1 什么是分词")]),s._v(" "),t("p",[s._v("我们将数据存储到ES时，通常可以划分为两类：全文本字段和精确值字段。在查询中，针对精确值字段，我们会对其二进制进行比较，结果仅涉及相等或不相等。而对于全文本字段，通常会运用相关性打分来决定匹配程度。这种打分依赖于在将文档存入ES时进行的分词处理，将全文本转化为词项（term）的过程。")]),s._v(" "),t("p",[s._v("分词是通过分词器实现的，其目的是将全文本分解为词项。ES内置了一系列常用的分词器，如果需要更特定的功能，您可以选择使用第三方分词器，甚至根据需求定制专属分词器。")]),s._v(" "),t("p",[s._v("此外，在进行全文本查询时，不仅需要在数据写入时进行分词，还需要在查询过程中使用相同的分词器对检索内容进行分词。")]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_3-2-分词器的组成"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-分词器的组成"}},[s._v("#")]),s._v(" 3.2 分词器的组成")]),s._v(" "),t("p",[s._v("分词器主要包括三部分：")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("Character Filter")]),s._v("：主要对原文本进行格式处理，如去除 html 标签等。")]),s._v(" "),t("li",[t("strong",[s._v("Tokenizer")]),s._v("：按照指定的规则对文本进行切分，比如按空格来切分单词，同时也负责标记出每个单词的顺序、位置以及单词在原文本中开始和结束的偏移量。")]),s._v(" "),t("li",[t("strong",[s._v("Token Filter")]),s._v("：对切分后的单词进行处理，如转换为小写、删除停用词、增加同义词、词干化等。")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/elasticsearch/202311042135589.png",alt:"分词器的处理流程.png"}})]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_3-3-analyze-api"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-analyze-api"}},[s._v("#")]),s._v(" 3.3 _analyze API")]),s._v(" "),t("p",[t("code",[s._v("_analyze API")]),s._v(" 可以"),t("strong",[s._v("查看分词器是如何工作的")]),s._v("。"),t("code",[s._v("_analyze API")]),s._v(" 提供了 3 种方式来查看分词器是如何工作的。")]),s._v(" "),t("ol",[t("li",[s._v("使用 "),t("code",[s._v("_analyze API")]),s._v(" 时可以直接指定 Analyzer 来进行测试")])]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("GET _analyze\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"analyzer"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"standard"')]),s._v(",\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Your cluster could be accessible to anyone."')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 结果")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tokens"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"token"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"your"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"start_offset"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"end_offset"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<ALPHANUM>"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"position"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"token"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cluster"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"start_offset"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"end_offset"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<ALPHANUM>"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"position"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br")])]),t("blockquote",[t("p",[s._v("在这段代码中可以看到它将 text 的内容用 standard 分词器进行分词，text 的内容按单词进行了切分并且 Your 转为了小写。")])]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("对指定的索引进行测试。")])]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 创建和设置索引")]),s._v("\nPUT my-index\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"mappings"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"properties"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"my_text"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),s._v(",\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"analyzer"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"standard"')]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## my_text字段使用了standard分词器")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\nGET my-index/_analyze \n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"field"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"my_text"')]),s._v(", "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 直接使用my_text字段已经设置的分词器")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Is this déjà vu?"')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 结果：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tokens"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"token"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"is"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"start_offset"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"end_offset"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<ALPHANUM>"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"position"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br")])]),t("blockquote",[t("p",[s._v("text 字段的内容使用了 my-index 索引设置的 standard 分词器来进行分词。")])]),s._v(" "),t("ol",{attrs:{start:"3"}},[t("li",[s._v("组合 tokenizer、filters、character filters 进行测试。")])]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("GET _analyze \n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tokenizer"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"standard"')]),s._v(", \n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"filter"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lowercase"')]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"asciifolding"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", \n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#"char_filter":["html_strip"], ')]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"java app <a></a>"')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br")])]),t("blockquote",[t("p",[s._v("从上面的示例可以看到，tokenizer 使用了 standard 而 token filter 使用了 lowercase 和 asciifolding 来对 text 的内容进行切分。用户可以组合一个 tokenizer、零个或多个 token filter、零个或多个 character filter。")])]),s._v(" "),t("blockquote",[t("p",[s._v("["),t("a",{attrs:{href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/test-analyzer.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("更多内容->官方文档"),t("OutboundLink")],1),s._v("]")])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_3-4-es内置分词器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-es内置分词器"}},[s._v("#")]),s._v(" 3.4 ES内置分词器")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("分词器")]),s._v(" "),t("th",[s._v("简介")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[t("strong",[s._v("Standard Analyzer")])]),s._v(" "),t("td",[s._v("默认的分词器，使用 Unicode 文本分割算法，将文本按单词切分并且转为小写。")])]),s._v(" "),t("tr",[t("td",[t("strong",[s._v("Simple Analyzer")])]),s._v(" "),t("td",[s._v("按照非字母切分并且进行小写处理。")])]),s._v(" "),t("tr",[t("td",[t("strong",[s._v("Stop Analyzer")])]),s._v(" "),t("td",[s._v("与 Simple Analyzer 类似，但增加了停用词过滤（如 a、an、and、are、as、at、be、but 等）。")])]),s._v(" "),t("tr",[t("td",[t("strong",[s._v("Whitespace Analyzer")])]),s._v(" "),t("td",[s._v("使用空格对文本进行切分，并不进行小写转换。")])]),s._v(" "),t("tr",[t("td",[t("strong",[s._v("Patter")]),s._v(" "),t("strong",[s._v("n")]),s._v(" "),t("strong",[s._v("Analyzer")])]),s._v(" "),t("td",[s._v("使用正则表达式切分，默认使用 \\W+ (非字符分隔)。支持小写转换和停用词删除。")])]),s._v(" "),t("tr",[t("td",[t("strong",[s._v("Keyword Analyzer")])]),s._v(" "),t("td",[s._v("不进行分词。")])]),s._v(" "),t("tr",[t("td",[t("strong",[s._v("Language Analyzer")])]),s._v(" "),t("td",[s._v("提供了多种常见语言的分词器。如 Irish、Italian、Latvian 等。")])]),s._v(" "),t("tr",[t("td",[t("strong",[s._v("Customer Analyzer")])]),s._v(" "),t("td",[s._v("自定义分词器。")])])])]),s._v(" "),t("hr"),s._v(" "),t("h4",{attrs:{id:"_1-standard-analyzer"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-standard-analyzer"}},[s._v("#")]),s._v(" 1）"),t("strong",[s._v("Standard Analyzer")])]),s._v(" "),t("p",[s._v("下面以Standard Analyzer分词器为例来进一步熟悉分词器的工作流程。Standard Analyzer 是 ES 默认的分词器，它会将输入的内容按词切分，并且将切分后的词进行小写转换，默认情况下停用词（Stop Word）过滤功能是关闭的。")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("GET _analyze\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"analyzer"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"standard"')]),s._v(", "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 设定分词器为 standard")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Your cluster could be accessible to anyone."')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 结果")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tokens"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"token"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"your"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"start_offset"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"end_offset"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<ALPHANUM>"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"position"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"token"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cluster"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"start_offset"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"end_offset"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<ALPHANUM>"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"position"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br")])]),t("p",[s._v("从上面的结果可以看出，单词 You 做了小写转换，停用词 be 没有被去掉，并且返回结果里记录了这个单词在原文本中的开始偏移、结束偏移以及这个词出现的位置。\n其他内置分词器的使用与 Standard Analyzer 没有太多的差异，但各有各的特点，["),t("a",{attrs:{href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-analyzers.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("更多内容->官方文档"),t("OutboundLink")],1),s._v("]。")]),s._v(" "),t("hr"),s._v(" "),t("h4",{attrs:{id:"_2-自定义分词器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-自定义分词器"}},[s._v("#")]),s._v(" 2）自定义分词器")]),s._v(" "),t("p",[s._v("除了使用内置的分词器外，我们还可以通过组合 Tokenizer、Filters、Character Filters 来自定义分词器。For Example：")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("PUT my-index-001\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"settings"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"analysis"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"char_filter"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 自定义char_filter")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"and_char_filter"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"mapping"')]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"mappings"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"& => and"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 将 '&' 转换为 'and'")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"filter"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 自定义 filter")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"an_stop_filter"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"stop"')]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"stopwords"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"an"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('## 设置 "an" 为停用词')]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"analyzer"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 自定义分词器为 custom_analyzer")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"custom_analyzer"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"custom"')]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 使用内置的html标签过滤和自定义的my_char_filter")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"char_filter"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"html_strip"')]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"and_char_filter"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tokenizer"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"standard"')]),s._v(",\n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 使用内置的lowercase filter和自定义的my_filter")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"filter"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lowercase"')]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"an_stop_filter"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\nGET my-index-001/_analyze\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"analyzer"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"custom_analyzer"')]),s._v(",\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Tom & Gogo bought an orange <span> at an orange shop"')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br")])]),t("p",[s._v("Tom 和 Gogo 将会变成小写，而 & 会转为 and，an 这个停用词和"),t("code",[s._v("<span>")]),s._v("这个 html 标签将会被处理掉，但 at 不会。")]),s._v(" "),t("blockquote",[t("p",[s._v("ES 的内置分词器可以很方便地处理英文字符，但对于中文却并不那么好使，一般我们需要依赖第三方的分词器插件才能满足日常需求。")])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"_3-5-中文分词器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-5-中文分词器"}},[s._v("#")]),s._v(" 3.5 中文分词器")]),s._v(" "),t("p",[s._v("中文分词不像英文分词那样可以简单地以空格来分隔，而是要分成有含义的词汇，但相同的词汇在不同的语境下有不同的含义。")]),s._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Felastic%2Felasticsearch%2Ftree%2Fmaster%2Fplugins%2Fanalysis-icu",target:"_blank",rel:"noopener noreferrer"}},[s._v("analysis-icu"),t("OutboundLink")],1),s._v("：这是官方的插件，其将 Lucene ICU module 融入了 ES 中，使用 ICU 函数库来提供处理 Unicode 的工具。")]),s._v(" "),t("li",[t("a",{attrs:{href:"https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmedcl%2Felasticsearch-analysis-ik",target:"_blank",rel:"noopener noreferrer"}},[s._v("IK"),t("OutboundLink")],1),s._v("：支持自定义词典和词典热更新。")])]),s._v(" "),t("hr"),s._v(" "),t("h4",{attrs:{id:"_1-analysis-icu-分词器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-analysis-icu-分词器"}},[s._v("#")]),s._v(" 1）analysis-icu 分词器")]),s._v(" "),t("p",[s._v("安装：")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("到 es 的plugins目录下 执行：\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("wget")]),s._v(" https://artifacts.elastic.co/downloads/elasticsearch-plugins/analysis-icu/analysis-icu-7.17.0.zip\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("使用：")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("POST _analyze\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("  \n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"analyzer"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"icu_analyzer"')]),s._v(",\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Linus 在90年代开发出了linux操作系统"')]),s._v("  \n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 结果")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tokens"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"token"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"开发"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"start_offset"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"end_offset"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<IDEOGRAPHIC>"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"position"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"token"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"出了"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"start_offset"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"end_offset"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<IDEOGRAPHIC>"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"position"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(",\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"token"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"linux"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"start_offset"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"end_offset"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"<ALPHANUM>"')]),s._v(",\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"position"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br")])]),t("blockquote",[t("p",[s._v("["),t("a",{attrs:{href:"https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-icu-analyzer.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("更多内容->官方文档"),t("OutboundLink")],1),s._v("]")])]),s._v(" "),t("hr"),s._v(" "),t("h4",{attrs:{id:"_2-ik分词器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-ik分词器"}},[s._v("#")]),s._v(" 2)ik分词器")]),s._v(" "),t("p",[s._v("安装在前面的文章有介绍过，不再赘述。")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("POST _analyze\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("  \n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"analyzer"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"ik_max_word"')]),s._v(",\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Linus 在90年代开发出了linux操作系统"')]),s._v("  \n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\nPOST _analyze\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("  \n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"analyzer"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"ik_smart"')]),s._v(",\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"text"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Linus 在90年代开发出了linux操作系统"')]),s._v("  \n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br")])]),t("p",[t("strong",[s._v("IK 有两种模式：ik_max_word 和 ik_smart")]),s._v("，它们的区别可总结为如下：")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("ik_max_word：")]),s._v(" 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国、中华人民、中华、华人、人民共和国、人民、人、民、共和国、共和、和、国国、国歌”，会穷尽各种可能的组合，适合 Term Query。")]),s._v(" "),t("li",[t("strong",[s._v("ik_smart：")]),s._v(" 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国、国歌”，适合 Phrase 查询。")])]),s._v(" "),t("blockquote",[t("p",[s._v("["),t("a",{attrs:{href:"https://github.com/medcl/elasticsearch-analysis-ik/tree/v7.13.0",target:"_blank",rel:"noopener noreferrer"}},[s._v("更多内容->官方文档"),t("OutboundLink")],1),s._v("]")])]),s._v(" "),t("hr")])}),[],!1,null,null,null);t.default=e.exports}}]);