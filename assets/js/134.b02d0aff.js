(window.webpackJsonp=window.webpackJsonp||[]).push([[134],{476:function(e,r,o){"use strict";o.r(r);var v=o(4),_=Object(v.a)({},(function(){var e=this,r=e._self._c;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("p",[e._v("如果 broker端没有显式配置"),r("code",[e._v("listeners(或 advertised.listeners)")]),e._v("使用IP地址,那么最好将"),r("code",[e._v("bootstrap.server")]),e._v("配置成主机名而不要使用IP地址,因为 Kafka内部使用的是全称域名(Fully Qualified Domain Name)。如果不统一,则会出现无法获取元数据的异常。")]),e._v(" "),r("hr"),e._v(" "),r("h2",{attrs:{id:"_1-broker-id"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-broker-id"}},[e._v("#")]),e._v(" 1."),r("code",[e._v("broker.id")])]),e._v(" "),r("p",[r("code",[e._v("broker.id")]),e._v("是 broker在启动之前必须设定的参数之一,在 Kafka集群中,每个broker都有唯一的id(也可以记作 brokerId)值用来区分彼此。 broker在启动时会在 ZooKeeper中的"),r("code",[e._v("/brokers/ids")]),e._v("路径下创建一个以当前brokerId为名称的虚节点,broker的健康状态检查就依赖于此虚节点。当 broker下线时,该虚节点会自动删除,其他 broker节点或客户端通过判断"),r("code",[e._v("/brokers/ids")]),e._v("路径下是否有此 broker的 brokerId节点来确定该 broker的健康状态。")]),e._v(" "),r("p",[e._v("可以通过 broker端的配置文件 "),r("code",[e._v("config/server.properties")]),e._v("里的 broker.id参数来配置brokerId,默认情况下 "),r("code",[e._v("broker.id")]),e._v("值为-1。在 Kafka中, brokerId值必须大于等于0才有可能正常启动,但这里并不是只能通过配置文件 "),r("code",[e._v("config/server.properties")]),e._v("来设定这个值,还可以通过"),r("code",[e._v("meta.properties")]),e._v("文件或自动生成功能来实现。")]),e._v(" "),r("p",[e._v("首先了解一下 "),r("code",[e._v("meta.properties")]),e._v("文件, "),r("code",[e._v("meta.properties")]),e._v("文件中的内容参考如下:")]),e._v(" "),r("div",{staticClass:"language-text line-numbers-mode"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v("# Sun May2723:03:04csT2018\nversion=0\nbroker.id=0\n")])]),e._v(" "),r("div",{staticClass:"line-numbers-wrapper"},[r("span",{staticClass:"line-number"},[e._v("1")]),r("br"),r("span",{staticClass:"line-number"},[e._v("2")]),r("br"),r("span",{staticClass:"line-number"},[e._v("3")]),r("br")])]),r("p",[r("code",[e._v("meta.properties")]),e._v("文件中记录了与当前Kafka版本对应的一个version字段,不过目前只有一个为0的固定值。还有一个"),r("code",[e._v("broker.id")]),e._v(",即brokerId值。 broker在成功启动之后在每个日志根目录下都会有一个 "),r("code",[e._v("meta.properties")]),e._v("文件。"),r("code",[e._v("meta.properties")]),e._v("文件与 "),r("code",[e._v("broker.id")]),e._v("的关联如下:")]),e._v(" "),r("ol",[r("li",[e._v("如果"),r("code",[e._v("log.dir或log.dirs")]),e._v("中配置了多个日志根目录,这些日志根目录中的"),r("code",[e._v("meta.properties")]),e._v("文件所配置的 "),r("code",[e._v("broker.id")]),e._v("不一致则会抛出 InconsistentBrokerIdException的异常。")]),e._v(" "),r("li",[e._v("如果 "),r("code",[e._v("config/server.properties")]),e._v("配置文件里配置的"),r("code",[e._v("broker.id")]),e._v("的值和"),r("code",[e._v("meta.properties")]),e._v("文件里的"),r("code",[e._v("broker.id")]),e._v("值不一致,那么同样会抛出 InconsistentBrokerldException的异常。")]),e._v(" "),r("li",[e._v("如果 "),r("code",[e._v("config/server.properties")]),e._v("配置文件中并未配置 "),r("code",[e._v("broker.id")]),e._v("的值,那么就以"),r("code",[e._v("meta.properties")]),e._v("文件中的"),r("code",[e._v("broker.id")]),e._v("值为准。")]),e._v(" "),r("li",[e._v("如果没有"),r("code",[e._v("meta.properties")]),e._v("文件,那么在获取合适的"),r("code",[e._v("broker.id")]),e._v("值之后会创建一个新的"),r("code",[e._v("meta.properties")]),e._v("文件并将"),r("code",[e._v("broker.id")]),e._v("值存入其中。")])]),e._v(" "),r("p",[e._v("如果 "),r("code",[e._v("config/server.properties")]),e._v("配置文件中并未配置 "),r("code",[e._v("broker.id")]),e._v(",并且日志根目录中也没有任何 "),r("code",[e._v("meta.properties")]),e._v("文件(比如第一次启动时),那么应该如何处理呢?")]),e._v(" "),r("p",[e._v("Kafka还提供了另外两个 broker端参数: "),r("code",[e._v("broker.id.generation.enable")]),e._v("和"),r("code",[e._v("reserved.broker.max.id")]),e._v("来配合生成新的"),r("code",[e._v("brokerId")]),e._v("。"),r("code",[e._v("broker.id.generation.enable")]),e._v("参数用来配置是否开启自动生成 brokerId的功能,默认情况下为true,即开启此功能。自动生成的brokerId有一个基准值,即自动生成的 brokerId必须超过这个基准值,这个基准值通过"),r("code",[e._v("reserverd.broker.max.id")]),e._v("参数配置,默认值为1000。也就是说,默认情况下自动生成的brokerId从1001开始。")]),e._v(" "),r("p",[e._v("自动生成的 brokerId的原理是先往 ZooKeeper中的"),r("code",[e._v("/brokers/said")]),e._v("节点中写入一个空字符串,然后获取返回的Stat信息中的 version值,进而将 version的值和"),r("code",[e._v("reserved.broker.max.id")]),e._v("参数配置的值相加。先往节点中写入数据再获取Stat信息,这样可以确保返回的 version值大于0,进而就可以确保生成的 brokerId值大于"),r("code",[e._v("reserved.broker.max.id")]),e._v("参数配置的值,符合非自动生成的 "),r("code",[e._v("broker.id")]),e._v("的值在"),r("code",[e._v("[0,reserved.broker.max.id)")]),e._v("区间设定。")]),e._v(" "),r("p",[e._v("初始化时 ZooKeeper中"),r("code",[e._v("/brokers/seqid")]),e._v("节点的状态如下:")]),e._v(" "),r("div",{staticClass:"language-text line-numbers-mode"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v("[zk: localhost:2181(CONNECTED) 1] get /kafka/brokers/seqid\nnull\n")])]),e._v(" "),r("div",{staticClass:"line-numbers-wrapper"},[r("span",{staticClass:"line-number"},[e._v("1")]),r("br"),r("span",{staticClass:"line-number"},[e._v("2")]),r("br")])]),r("p",[e._v("可以看到 "),r("code",[e._v("dataVersion=0")]),e._v(",这个就是前面所说的 version。在插入一个空字符串之后,dataVersion就自增1,表示数据发生了变更,这样通过 ZooKeeper的这个功能来实现集群层面的序号递增,整体上相当于一个发号器。")]),e._v(" "),r("p",[e._v("大多数情况下我们一般通过并且习惯于用最普通的 "),r("code",[e._v("config/server.properties")]),e._v("配置文件的方式来设定 brokerId的值,如果知晓其中的细枝末节,那么在遇到诸如 "),r("strong",[e._v("InconsistentBrokerldException")]),e._v("异常时就可以处理得游刃有余,也可以通过自动生成 brokerId的功能来实现一些另类的功能。")]),e._v(" "),r("hr"),e._v(" "),r("h2",{attrs:{id:"_2-bootstrap-servers"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-bootstrap-servers"}},[e._v("#")]),e._v(" 2."),r("code",[e._v("bootstrap.servers")])]),e._v(" "),r("p",[r("code",[e._v("bootstrap.servers")]),e._v("不仅是 "),r("code",[e._v("Kafka Producer")]),e._v("、 "),r("code",[e._v("Kafka Consumer")]),e._v(" 客户端中的必备参数,而且在 "),r("code",[e._v("Kafka Connect")]),e._v("、 "),r("code",[e._v("Kafka streams")]),e._v("和 "),r("code",[e._v("KafkaAdminClient")]),e._v("中都有涉及,是一个至关重要的参数。")]),e._v(" "),r("p",[e._v("一般可以简单地认为 "),r("code",[e._v("bootstrap.servers")]),e._v("这个参数所要指定的就是将要连接的Kafka集群的broker地址列表。不过从深层次的意义上来讲,这个参数配置的是用来发现 Kafka集群元数据信息的服务地址。为了更加形象地说明问题,我们先来看下图。")]),e._v(" "),r("p",[r("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311240911984.png",alt:""}})]),e._v(" "),r("p",[e._v("客户端KafkaProducer1与KafkaCluster直连,这是客户端给我们的既定印象,而事实上客户端连接Kafka集群要经历以下3个过程,如上图中的右边所示。")]),e._v(" "),r("ol",[r("li",[e._v("客户端 KafkaProducer2与 "),r("code",[e._v("bootstrap.servers")]),e._v("参数所指定的 Server连接,并发送MetadataRequest请求来获取集群的元数据信息。")]),e._v(" "),r("li",[e._v("Server在收到 MetadataRequest请求之后,返回MetadataResponse给KafkaProducer2,在MetadataResponse中包含了集群的元数据信息。")]),e._v(" "),r("li",[e._v("客户端KafkaProducer2收到的MetadataResponse之后解析出其中包含的集群元数据信息,然后与集群中的各个节点建立连接,之后就可以发送消息了。")])]),e._v(" "),r("p",[e._v("在绝大多数情况下, Kafka本身就扮演着第一步和第二步中的 Server角色,我们完全可以将这个 Server的角色从Kafka中剥离出来。我们可以在这个 Server的角色上大做文章,比如添加一些路由的功能、负载均衡的功能。")]),e._v(" "),r("hr"),e._v(" "),r("h2",{attrs:{id:"_3-服务端参数列表"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-服务端参数列表"}},[e._v("#")]),e._v(" 3.服务端参数列表")]),e._v(" "),r("p",[e._v("下表列出了部分服务端重要参数。")]),e._v(" "),r("p",[r("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311240913682.png",alt:""}})]),e._v(" "),r("hr")])}),[],!1,null,null,null);r.default=_.exports}}]);