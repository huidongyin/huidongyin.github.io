(window.webpackJsonp=window.webpackJsonp||[]).push([[132],{475:function(e,_,o){"use strict";o.r(_);var v=o(4),d=Object(v.a)({},(function(){var e=this,_=e._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[_("p",[e._v("如果在使用生产者客户端发送消息的时候将"),_("code",[e._v("acks")]),e._v("参数设置为-1,那么就意味着需要等待ISR集合中的所有副本都确认收到消息之后才能正确地收到响应的结果,或者捕获超时异常。")]),e._v(" "),_("p",[e._v("如图所示,假设某个分区有3个副本: "),_("code",[e._v("leader")]),e._v("、"),_("code",[e._v("follower1")]),e._v("和 "),_("code",[e._v("follower2")]),e._v(",它们都在分区的ISR集合中。为了简化说明,这里我们不考虑ISR集合伸缩的情况。 Kafka在收到客户端的生产请求(ProduceRequest)后,将消息3和消息4写入 "),_("code",[e._v("leader")]),e._v(" 副本的本地日志文件。由于客户端设置了"),_("code",[e._v("acks")]),e._v("为-1,那么需要等到 "),_("code",[e._v("follower1")]),e._v(" 和 "),_("code",[e._v("follower2")]),e._v(" 两个副本都收到消息3和消息4后才能告知客户端正确地接收了所发送的消息。如果在一定的时间内, "),_("code",[e._v("follower1")]),e._v(" 副本或 "),_("code",[e._v("follower2")]),e._v(" 副本没能够完全拉取到消息3和消息4,那么就需要返回超时异常给客户端。生产请求的超时时间由参数 "),_("code",[e._v("request.timeout.ms")]),e._v(" 配置,默认值为3000,即30s。")]),e._v(" "),_("p",[e._v("那么这里等待消息3和消息4写入 "),_("code",[e._v("follower1")]),e._v(" 副本和 "),_("code",[e._v("follower2")]),e._v(" 副本,并返回相应的响应结果给客户端的动作是由谁来执行的呢?在将消息写入 "),_("code",[e._v("leader")]),e._v(" 副本的本地日志文件之后, Kafka会创建一个延时的生产操作(DelayedProduce),用来处理消息正常写入所有副本或超时的情况,以返回相应的响应结果给客户端。")]),e._v(" "),_("p",[_("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311240911509.png",alt:""}})]),e._v(" "),_("p",[e._v("在Kafka中有多种延时操作,比如前面提及的延时生产,还有延时拉取(DelayedFetch)、延时数据删除(DelayedDeleteRecords)等。延时操作需要延时返回响应的结果,首先它必须有个超时时间(delayMs),如果在这个超时时间内没有完成既定的任务,那么就需要强制完成以返回响应结果给客户端。其次,延时操作不同于定时操作,定时操作是指在特定时间之后执行的操作,而延时操作可以在所设定的超时时间之前完成,所以延时操作能够支持外部事件的触发。就延时生产操作而言,它的外部事件是所要写入消息的某个分区的HW(高水位)发生增长。也就是说,随着 "),_("code",[e._v("follower")]),e._v(" 副本不断地与 "),_("code",[e._v("leader")]),e._v(" 副本进行消息同步,进而促使HW进一步增长,HW每増长一次都会检测是否能够完成此次延时生产操作,如果可以就执行以此返回响应结果给客户端;如果在超时时间内始终无法完成,则强制执行。")]),e._v(" "),_("p",[e._v("延时操作创建之后会被加入延时操作管理器("),_("strong",[e._v("DelayedOperationPurgatory")]),e._v(")来做专门的处理。延时操作有可能会超时,每个延时操作管理器都会配备一个定时器(SystemTimer)来做超时管理,定时器的底层就是采用时间轮(Timing Wheel)实现的。时间轮的轮转是靠“收割机”线程"),_("code",[e._v("ExpiredOperationReaper")]),e._v("来驱动的,这里的“收割机”线程就是由延时操作管理器启动的。也就是说,定时器、“收割机”线程和延时操作管理器都是一一对应的。延时操作需要支持外部事件的触发,所以还要配备一个监听池来负责监听每个分区的外部事件一一查看是否有分区的HW发生了增长。另外需要补充的是, "),_("code",[e._v("ExpiredOperationReaper")]),e._v(" 不仅可以推进时间轮,还会定期清理监听池中已完成的延时操作。")]),e._v(" "),_("p",[e._v("下图描绘了客户端在请求写入消息到收到响应结果的过程中与延时生产操作相关的细节,在了解相关的概念之后应该比较容易理解:如果客户端设置的"),_("code",[e._v("acκs")]),e._v("参数不为-1,或者没有成功的消息写入,那么就直接返回结果给客户端,否则就需要创建延时生产操作并存入延时操作管理器,最终要么由外部事件触发,要么由超时触发而执行。")]),e._v(" "),_("p",[_("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311240911896.png",alt:""}})]),e._v(" "),_("p",[e._v("有延时生产就有延时拉取。以下图为例,两个 "),_("code",[e._v("follower")]),e._v(" 副本都已经拉取到了 "),_("code",[e._v("leader")]),e._v(" 副本的最新位置,此时又向 "),_("code",[e._v("leader")]),e._v(" 副本发送拉取请求,而 "),_("code",[e._v("leader")]),e._v(" 副本并没有新的消息写入,那么此时 "),_("code",[e._v("leader")]),e._v(" 副本该如何处理呢?可以直接返回空的拉取结果给 "),_("code",[e._v("follower")]),e._v(" 副本,不过在 "),_("code",[e._v("leader")]),e._v(" 副本直没有新消息写入的情况下, "),_("code",[e._v("follower")]),e._v(" 副本会一直发送拉取请求,并且总收到空的拉取结果,这样徒耗资源,显然不太合理。")]),e._v(" "),_("p",[_("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311240911429.png",alt:""}})]),e._v(" "),_("p",[e._v("Kafka选择了延时操作来处理这种情况。 Kafka在处理拉取请求时,会先读取一次日志文件,如果收集不到足够多("),_("code",[e._v("fetchMinBytes")]),e._v(",由参数 "),_("code",[e._v("fetch.min.bytes")]),e._v("配置,默认值为1)的消息,那么就会创建一个延时拉取操作(DelayedFetch)以等待拉取到足够数量的消息。当延时拉取操作执行时,会再读取一次日志文件,然后将拉取结果返回给 "),_("code",[e._v("follower")]),e._v(" 副本。延时拉取操作也会有一个专门的延时操作管理器负责管理,大体的脉络与延时生产操作相同,不再赘述。如果拉取进度一直没有追赶上 "),_("code",[e._v("leader")]),e._v(" 副本,那么在拉取 "),_("code",[e._v("leader")]),e._v(" 副本的消息时一般拉取的消息大小都会不小于 "),_("code",[e._v("fetchMinBytes")]),e._v(",这样Kafka也就不会创建相应的延时拉取操作,而是立即返回拉取结果。")]),e._v(" "),_("p",[e._v("延时拉取操作同样是由超时触发或外部事件触发而被执行的。超时触发很好理解,就是等到超时时间之后触发第二次读取日志文件的操作。外部事件触发就稍复杂了一些,因为拉取请求不单单由 "),_("code",[e._v("follower")]),e._v(" 副本发起,也可以由消费者客户端发起,两种情况所对应的外部事件也是不同的。如果是 "),_("code",[e._v("follower")]),e._v(" 副本的延时拉取,它的外部事件就是消息追加到了 "),_("code",[e._v("leader")]),e._v(" 副本的本地日志文件中;如果是消费者客户端的延时拉取,它的外部事件可以简单地理解为HW的增长,目前版本的Kafka还引入了事务的概念,对于消费者或 "),_("code",[e._v("follower")]),e._v(" 副本而言,其默认的事务隔离级别为"),_("code",[e._v("read_uncommitted")]),e._v("。不过消费者可以通过客户端参数 "),_("code",[e._v("isolation.level")]),e._v("将事务隔离级别设置为"),_("code",[e._v("read_committed")]),e._v("(注意: "),_("code",[e._v("follower")]),e._v("副本不可以将事务隔离级别修改为这个值),这样消费者拉取不到生产者已经写入却尚未提交的消息。对应的消费者的延时拉取,它的外部事件实际上会切换为由LSO(LastStableOffset的增长来触发。LSO是HW之前除去未提交的事务消息的最大偏移量,"),_("code",[e._v("LSO≤HW")]),e._v("。")]),e._v(" "),_("hr")])}),[],!1,null,null,null);_.default=d.exports}}]);