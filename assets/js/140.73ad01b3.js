(window.webpackJsonp=window.webpackJsonp||[]).push([[140],{521:function(e,l,a){"use strict";a.r(l);var r=a(4),o=Object(r.a)({},(function(){var e=this,l=e._self._c;return l("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[l("p",[e._v("在分布式系统中，日志同步机制既要保证数据的一致性，也要保证数据的顺序性。虽然有许多方式可以实现这些功能， 但最简单高效的方式还是从集群中选出一个leader来负责处理数据写入的顺序性。只要leader还处于存活状态， 那么follower只需按照leader中的写入顺序来进行同步即可。")]),e._v(" "),l("p",[e._v("通常情况下， 只要leader不宕机我们就不需要关心follower的同步问题。不过当leader宕机时， 我们就要从follower中选举出一个新的leader。follower的同步状态可能落后leader很多，甚至还可能处于宕机状态， 所以必须确保选择具有最新日志消息的follower作为新的leader。日志同步机制的一个基本原则就是：如果告知客户端已经成功提交了某条消息， 那么即使leader宕机， 也要保证新选举出来的leader中能够包含这条消息。这里就有一个需要权衡(tradeoff)的地方， 如果leader在消息被提交前需要等待更多的follower确认， 那么在它宕机之后就可以有更多的follower替代它， 不过这也会造成性能的下降。")]),e._v(" "),l("p",[e._v("对于这种tradeoff， 一种常见的做法是"),l("strong",[e._v("少数服从多数")]),e._v("， 它可以用来负责提交决策和选举决策。虽然Kafka不采用这种方式， 但可以拿来探讨和理解tradeoff的艺术。在这种方式下， 如果我们有2f+1个副本，那么在提交之前必须保证有f+1个副本同步完消息。同时为了保证能正确选举出新的leader， 至少要保证有f+1个副本节点完成日志同步并从同步完成的副本中选举出新的leader节点。并且在不超过f个副本节点失败的情况下， 新的leader需要保证不会丢失已经提交过的全部消息。这样在任意组合的f+1个副本中，理论上可以确保至少有一个副本能够包含已提交的全部消息， 这个副本的日志拥有最全的消息， 因此会有资格被选举为新的leader来对外提供服务。")]),e._v(" "),l("p",[l("strong",[e._v("少数服从多数")]),e._v("的方式有一个很大的优势，系统的延迟取决于最快的几个节点，比如副本数为3， 那么延迟就取决于最快的那个follower而不是最慢的那个(除了leader， 只需要另一个follower确认即可) 。不过它也有一些劣势， 为了保证leader选举的正常进行， 它所能容忍的失败follower数比较少， 如果要容忍1个follower失败， 那么至少要有3个副本， 如果要容忍2个follower失败， 必须要有5个副本。也就是说， 在生产环境下为了保证较高的容错率，必须要有大量的副本，而大量的副本又会在大数据量下导致性能的急剧下降。这也就是"),l("strong",[e._v("少数服从多数")]),e._v("的这种Quorum模型常被用作共享集群配置(比如ZooKeeper) ， 而很少用于主流的数据存储中的原因。")]),e._v(" "),l("p",[e._v("与"),l("strong",[e._v("少数服从多数")]),e._v("相关的一致性协议有很多， 比如Zab、Raft和Viewstamped Replication等。而Kafka使用的更像是微软的PacificA算法。")]),e._v(" "),l("p",[e._v("在Kafka中动态维护着一个ISR集合， 处于ISR集合内的节点保持与leader相同的高水位(HW) ， 只有位列其中的副本("),l("code",[e._v("unclean.leader.election.enable")]),e._v("配置为false) 才有资格被选为新的leader。写入消息时只有等到所有ISR集合中的副本都确认收到之后才能被认为已经提交。位于ISR中的任何副本节点都有资格成为leader， 选举过程简单 、开销低， 这也是Kafka选用此模型的重要因素。Kafka中包含大量的分区， leader副本的均衡保障了整体负载的均衡， 所以这一因素也极大地影响Kafka的性能指标。")]),e._v(" "),l("p",[e._v("在采用ISR模型和(f+1) 个副本数的配置下，一个Kafka分区能够容忍最大f个节点失败，相比于"),l("strong",[e._v("少数服从多数")]),e._v("的方式所需的节点数大幅减少。实际上，为了能够容忍f个节点失败，"),l("strong",[e._v("少数服从多数")]),e._v("的方式和ISR的方式都需要相同数量副本的确认信息才能提交消息。比如，为了容忍1个节点失败， "),l("strong",[e._v("少数服从多数")]),e._v("需要3个副本和1个follower的确认信息， 采用ISR的方式需要2个副本和1个follower的确认信息。在需要相同确认信息数的情况下， 采用ISR的方式所需要的副本总数变少，复制带来的集群开销也就更低，"),l("strong",[e._v("少数服从多数")]),e._v("的优势在于它可以绕开最慢副本的确认信息， 降低提交的延迟， 而对Kafka而言， 这种能力可以交由客户端自己去选择。")]),e._v(" "),l("p",[e._v("另外，一般的同步策略依赖于稳定的存储系统来做数据恢复，也就是说，在数据恢复时日志文件不可丢失且不能有数据上的冲突。不过它们忽视了两个问题：首先，磁盘故障是会经常发生的，在持久化数据的过程中并不能完全保证数据的完整性；其次，即使不存在硬件级别的故障， 我们也不希望在每次写入数据时执行同步刷盘(fsync) 的动作来保证数据的完整性， 这样会极大地影响性能。而Kafka不需要宕机节点必须从本地数据日志中进行恢复， Kafka的同步方式允许宕机副本重新加入ISR集合， 但在进入ISR之前必须保证自己能够重新同步完leader中的所有数据。")]),e._v(" "),l("hr")])}),[],!1,null,null,null);l.default=o.exports}}]);