(window.webpackJsonp=window.webpackJsonp||[]).push([[126],{468:function(e,v,_){"use strict";_.r(v);var a=_(4),t=Object(a.a)({},(function(){var e=this,v=e._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[v("p",[e._v("随着Kafka的发展，其消息格式也在不断升级改造，从"),v("code",[e._v("0.8.x")]),e._v("版本开始到"),v("code",[e._v("2.0.0")]),e._v("版本，Kafka的消息格式也经历了三个版本："),v("code",[e._v("v0版本")]),e._v("，"),v("code",[e._v("v1版本")]),e._v("，"),v("code",[e._v("v2版本")]),e._v("。")]),e._v(" "),v("p",[e._v("每个分区由内部的每一条消息组成，如果消息格式设计得不够精炼，那么其功能和性能者会大打折扣。比如有冗余字段，势必会不必要地增加分区的占用空间，进而不仅使存储的开销变大、网络传输的开销变大，也会使 Kafka 的性能下降。反观如果缺少字段，比如在最初的 Kafka 消息版本中没有 timestamp 字段，对内部而言，其影响了日志保存、切分策略，对外部而言其影响了消息审计、端到端延迟、大数据应用等功能的扩展。虽然可以在消息体内部添加一个时间戳，但解析变长的消息体会带来额外的开销，而存储在消息体(参考下图中的 value字段)前面可以通过指针偏移量获取其值而容易解析，进而减少了开销(可以查看 v1 版本)，虽然相比于没有 timestamp 字段的开销会大一点。由此可见，仅在一个字段的一增一减之间有这么多门道，那么 Kafka 具体是怎么做的呢? 本节只针对 Kafka "),v("code",[e._v("0.8.x")]),e._v(" 之上(包含)的版本做相应说明，对于之前的版本不做陈述。")]),e._v(" "),v("hr"),e._v(" "),v("h2",{attrs:{id:"_1-v0版本"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1-v0版本"}},[e._v("#")]),e._v(" 1.V0版本")]),e._v(" "),v("p",[e._v("Kafka 消息格式的第一个版本通常称为v0版本，在 Kafka "),v("code",[e._v("0.10.0")]),e._v(" 之前都采用的这个消息格式，在 "),v("code",[e._v("0.8.x")]),e._v(" 版本之前，Kafka 还使用过一个更古老的消息格式，不过对目前的 Kafka 而言，我们也不需要了解这个版本的消息格式。如无特殊说明，只讨论消息未压缩的情形。")]),e._v(" "),v("p",[e._v("下图中左边的"),v("code",[e._v("RECORD")]),e._v("部分就是 v0 版本的消息格式，大多数人会把图中左边的整体(即包括 "),v("code",[e._v("offset")]),e._v(" 和 "),v("code",[e._v("message size")]),e._v(" 字段)都看作消息，因为每个 "),v("code",[e._v("RECORD")]),e._v(" (v0 和 vl版)必定对应一个 "),v("code",[e._v("offset")]),e._v(" 和 "),v("code",[e._v("message size")]),e._v("。每条消息都有一个 "),v("code",[e._v("offset")]),e._v(" 用来标志它在分区中的偏移量，这个 "),v("code",[e._v("offset")]),e._v(" 是逻辑值，而非实际物理偏移值，"),v("code",[e._v("message size")]),e._v(" 表示消息的大小，这两者在一起被称为日志头部("),v("code",[e._v("LOG OVERHEAD")]),e._v(")，固定为 12B。"),v("code",[e._v("LOG OVERHEAD")]),e._v(" 和"),v("code",[e._v("RECORD")]),e._v(" 一起用来描述一条消息，为了配合陈述的语境，在讲述具体消息格式时会偏向于将单纯的 "),v("code",[e._v("RECORD")]),e._v(" 看作消息，而在其他地方则偏向于将 "),v("code",[e._v("LOG OVERHEAD")]),e._v(" 和 "),v("code",[e._v("RECORD")]),e._v(" 的整体看作消息。与消息对应的还有消息集的概念，消息集中包含一条或多条消息，消息集不仅是存储于磁盘及在网络上传输("),v("code",[e._v("Produce & Fetch")]),e._v(")的基本形式，而且是 Kafka中压缩的基本单元，详细结构参考下图中的右边部分。")]),e._v(" "),v("p",[v("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311190950613.png",alt:""}})]),e._v(" "),v("p",[e._v("v0 版本中一个消息的最小长度("),v("code",[e._v("RECORD_OVERHEAD_V0")]),e._v(")为 "),v("code",[e._v("crc32 + magic + attributes + key length + value length = 4B + 1B + 1B + 4B + 4B = 14B")]),e._v("。也就是说，v0 版本中一条消息的最小长度为 14B，如果小于这个值，那么这就是一条破损的消息而不被接收。")]),e._v(" "),v("hr"),e._v(" "),v("h2",{attrs:{id:"_2-v1版本"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2-v1版本"}},[e._v("#")]),e._v(" 2.V1版本")]),e._v(" "),v("p",[e._v("Kafka从"),v("code",[e._v("0.10.0")]),e._v("版本开始到"),v("code",[e._v("0.11.0")]),e._v("版本之前所使用的消息格式版本为V1，比V0版本就多了一个timestamp字段，表示消息的时间戳。V1版本的消息结构如下：")]),e._v(" "),v("p",[v("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311190955637.png",alt:""}})]),e._v(" "),v("p",[e._v("v1 版本的 magic 字段的值为1。v1 版本的 attributes 字段中的低3位和v0版本的一样,还是表示压缩类型,而第4个位(bit)也被利用了起来:0表示timestamp类型为"),v("code",[e._v("CreateTime")]),e._v(",而1表示 timestamp 类型为 "),v("code",[e._v("LogAppendTime")]),e._v("，其他位保留。timestamp 类型由 broker 端参数"),v("code",[e._v("log.message.timestamp.type")]),e._v(" 来配置，默认值为 "),v("code",[e._v("CreateTime")]),e._v("，即采用生产者创建消息时的时间戳。如果在创建 "),v("code",[e._v("ProducerRecord")]),e._v(" 时没有显式指定消息的时间戳，那么 "),v("code",[e._v("KafkaProducer")]),e._v(" 也会在发送这条消息前自动添加上。下面是 "),v("code",[e._v("KafkaProducer")]),e._v(" 中与此对应的一句关键代码:")]),e._v(" "),v("div",{staticClass:"language-text line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("long timestamp = record.timestamp() == null ? time.milliseconds () : record.timestamp () ;\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("blockquote",[v("p",[e._v("v1 版本的消息的最小长度 ("),v("code",[e._v("RECORD_OVERHEAD_V1")]),e._v(")要比 v0 版本的大 8 个字节，即22B。")])]),e._v(" "),v("hr"),e._v(" "),v("h2",{attrs:{id:"_3-消息压缩"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3-消息压缩"}},[e._v("#")]),e._v(" 3.消息压缩")]),e._v(" "),v("p",[e._v("常见的压缩算法是数据量越大压缩效果越好，一条消息通常不会太大，这就导致压缩效果不是太好，而 Kafka 实现的压缩方式是将多条消息一起进行压缩，这样可以保证较好的压缩效果，通常，生产者发送的压缩数据在 broker 中也是保持压缩状态进行存储的，消费者从服务端获取的也是压缩的消息，消费者在处理消息之前才会解压消息，这样保持了端到端的压缩。")]),e._v(" "),v("p",[e._v("Kafka 日志中使用哪种压缩方式是通过参数 "),v("code",[e._v("compression.type")]),e._v(" 来配置的，默认值"),v("code",[e._v("producer")]),e._v("，表示保留生产者使用的压缩方式。这个参数还可以配置为"),v("code",[e._v("gzip,snapy,lz4")]),e._v("分别对应 GZIP、SNAPPY、LZ4 这3种压缩算法。如果参数 "),v("code",[e._v("compression.type")]),e._v(" 配置为"),v("code",[e._v("uncompressed")]),e._v("，则表示不压缩。")]),e._v(" "),v("blockquote",[v("p",[e._v("压缩率是压缩后的大小与压缩前的对比。例如:把 100MB 的文件压缩后是9OMB压缩率为 "),v("code",[e._v("90/100x100%=90%")]),e._v("，压缩率越小，压缩效果越好。")])]),e._v(" "),v("p",[e._v("以上都是针对消息未压缩的情况，而当消息压缩时是将整个消息集进行压缩作为内层消(inner message)，内层消息整体作为外层 (wrapper message)的 value，其结构如下图所示。")]),e._v(" "),v("p",[e._v("压缩后的外层消息 (wrapper message)中的 key 为 null，所以下图左半部分没有画出key字段，value 字段中保存的是多条压缩消息 (inner message，内层消息)，其中 Record表示是从 crc32 到 value 的消息格式。当生产者创建压缩消息的时候，对内部压缩消息设置的offset 从0 开始为每个内部消息分配 offset。")]),e._v(" "),v("p",[v("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311191045427.png",alt:""}}),e._v(" "),v("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311191005911.png",alt:""}})]),e._v(" "),v("p",[e._v("其实每个从生产者发出的消息集中的消息 offset 都是从0开始的，当然这个 offset 不能直接存储在日志文件中，对 offset 的转换是在服务端进行的，客户端不需要做这个工作。外层消息保存了内层消息中最后一条消息的绝对位移 (absolute offset)，绝对位移是相对于整个分区而言的。参考上图，对于未压缩的情形，图右内层消息中最后一条的 offset 理应是 1030，但被压缩之后就变成了 5，而这个 1030 被赋予给了外层的 offset。当消费者消费这个消息集的时候,首先解压缩整个消息集，然后找到内层消息中最后一条消息的 inner offset，根据如下公式找到内层消息中最后一条消息前面的消息的 absolute offset (RO 表示 Relative Offset，IO 表示 InnerOffset，而 AO 表示 Absolute Offset):")]),e._v(" "),v("div",{staticClass:"language-text line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("RO = IO_of a message - IO_of_the_last message\nAO = AO_Of Last Inner_Message + RO\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br"),v("span",{staticClass:"line-number"},[e._v("2")]),v("br")])]),v("p",[e._v("这里的 RO 是前面的消息相对最后一条消息的 IO 而言的，所以其值小于等于 0，0 表示最后一条消息自身。")]),e._v(" "),v("blockquote",[v("p",[e._v("压缩消息，英文是 "),v("code",[e._v("compress message")]),e._v("，Kafka 中还有一个 "),v("code",[e._v("compact message")]),e._v("，常常被直译成压缩消息，需要注意两者的区别。"),v("code",[e._v("compact message")]),e._v(" 是针对日志清理策略而言的("),v("code",[e._v("cleanup.policy= compact")]),e._v(")，是指日志压缩("),v("code",[e._v("Log Compaction")]),e._v(")后的消息。")])]),e._v(" "),v("hr"),e._v(" "),v("h2",{attrs:{id:"_4-变长字段"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_4-变长字段"}},[e._v("#")]),e._v(" 4.变长字段")]),e._v(" "),v("p",[e._v("Kafka从 "),v("code",[e._v("0.11.0")]),e._v(" 版本开始所使用的消息格式版本为v2，这个版本的消息相比v0 和v1 的版本而言改动很大，同时还参考了"),v("code",[e._v("Protocol Buffer")]),e._v("而引入了变长整型("),v("code",[e._v("Varints")]),e._v(")和ZigZag编码。")]),e._v(" "),v("p",[e._v("回顾 Kafka v0 和v1 版本的消息格式，如果消息本身没有 key，那么 "),v("code",[e._v("key length")]),e._v(" 字段为-1,int类型的需要 4 个字节来保存，而如果采用 "),v("code",[e._v("Varints")]),e._v(" 来编码则只需要 1个字节。根据 "),v("code",[e._v("Varints")]),e._v(" 的规则可以推导出0~63之间的数字占1个字节,64~8191之间的数字占2个字节，8192~1048575之间的数字占3 个字节。而 Kafka broker 端配置 "),v("code",[e._v("message.max.bytes")]),e._v(" 的默认大小为 1000012("),v("code",[e._v("Varints")]),e._v(" 编码占3 个字节)，如果消息格式中与长度有关的字段采用 "),v("code",[e._v("Varints")]),e._v(" 的编码，那么绝大多数情况下都会节省空间，而v2 版本的消息格式也正是这样做的。")]),e._v(" "),v("blockquote",[v("p",[v("code",[e._v("Varints")]),e._v(" 并非一直会节省空间，一个 int32 最长会占用 5 个字节 (大于默认的 4个字节)，一个 int64 最长会占用 10 个字节 (大于默认的 8 个字节)。")])]),e._v(" "),v("hr"),e._v(" "),v("h2",{attrs:{id:"_5-v2版本"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5-v2版本"}},[e._v("#")]),e._v(" 5.V2版本")]),e._v(" "),v("p",[e._v("v2 版本中消息集称为 "),v("code",[e._v("Record Batch")]),e._v("，而不是先前的 "),v("code",[e._v("Message Set")]),e._v("，其内部也包含了一条或多条消息，消息的格式参见下图的中部和右部。在消息压缩的情形下，"),v("code",[e._v("Record Batch Header")]),e._v("部分(参见下图左部，从 "),v("code",[e._v("first offset")]),e._v(" 到 "),v("code",[e._v("records count")]),e._v(" 字段)是不被压缩的，而被压缩的是records字段中的所有内容。生产者客户端中的ProducerBatch对应这里的RecordBatch,而 ProducerRecord 对应这里的 Record。")]),e._v(" "),v("p",[v("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311191019459.png",alt:""}})]),e._v(" "),v("p",[e._v("V2版本的消息不仅提供了更多的功能，比如事务，幂等性等等，某些情况下还减少了消息的空间占用，总体性能提升很大。")]),e._v(" "),v("hr")])}),[],!1,null,null,null);v.default=t.exports}}]);