(window.webpackJsonp=window.webpackJsonp||[]).push([[141],{522:function(e,v,_){"use strict";_.r(v);var a=_(4),o=Object(a.a)({},(function(){var e=this,v=e._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[v("p",[e._v("就可靠性本身而言，它并不是一个可以用简单的"),v("strong",[e._v("是")]),e._v("或"),v("strong",[e._v("否")]),e._v("来衡量的一个指标，而一般是采用几个9来衡量的。任何东西不可能做到完全的可靠，即使能应付单机故障，也难以应付集群、数据中心等集体故障，即使躲得过天灾也未必躲得过人祸。就可靠性而言，我们可以基于一定的假设前提来做分析。本节要讲述的是：在只考虑 Kafka 本身使用方式的前提下如何最大程度地提高可靠性。")]),e._v(" "),v("p",[e._v("就 Kafka 而言，越多的副本数越能够保证数据的可靠性，副本数可以在创建主题时配置，也可以在后期修改，不过副本数越多也会引起磁盘、网络带宽的浪费，同时会引起性能的下降。一般而言，设置副本数为3即可满足绝大多数场景对可靠性的要求，而对可靠性要求更高的场景下 ，可以适当增大这个数值，比如国内部分银行在使用 Kafka 时就会设置副本数为5。 与此同时，如果能够在分配分区副本的时候引入基架信息 （"),v("code",[e._v("broker.rack")]),e._v(" 参数） ，那么还要应对机架整体宕机的风险。")]),e._v(" "),v("p",[e._v("仅依靠副本数来支撑可靠性是远远不够的，大多数人还会想到生产者客户端参数 "),v("code",[e._v("acks")]),e._v("。相比于 "),v("code",[e._v("acks = -1")]),e._v(" （客户端还可以配置为all ，它的含义与-1 一样，以下只以-1 来进行陈述)可以最大程度地提高消息的可靠性。")]),e._v(" "),v("p",[e._v("对于 "),v("code",[e._v("acks = 1")]),e._v("的配置，生产者将消息发送到 leader 副本， leader 副本在成功写入本地日志之后会告知生产者己经成功提交，如图所示 如果此时 ISR 集合的 follower 副本还没来得及拉取到 leader 中新写入的消息， leader 就宕机了，那么此次发送的消息就会丢失。")]),e._v(" "),v("p",[v("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202312031522022.png",alt:"8-24"}})]),e._v(" "),v("p",[e._v("对于 "),v("code",[e._v("ack = -1")]),e._v("配置，生产者将消息发送到 leader 副本， leader 副本在成功写入本地日志之后还要等待 ISR 中的 follower 副本全部同步完成才能够告知生产者已经成功提交，即使此时leader 副本宕机，消息也不会丢失，如图所示。")]),e._v(" "),v("p",[v("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202312031523743.png",alt:"8-25"}})]),e._v(" "),v("p",[e._v("同样对于 "),v("code",[e._v("acks = -1")]),e._v("的配置 ，如果在消息成功写入 leader 副本之后，并且在被 ISR 中的所有副本同步之前 leader 副本宕机了，那么生产者会收到异常以此告知此次发送失败，如图所示。")]),e._v(" "),v("p",[v("img",{attrs:{src:"https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202312031523313.png",alt:"8-26"}})]),e._v(" "),v("p",[e._v("消息发送的3种模式，即发后即忘、同步和异步。对于发后即忘的模式，不管消息有没有被成功写入，生产者都不会收到通知，那么即使消息写入失败也无从得知，因此发后即忘的模式不适合高可靠性要求的场景。如果要提升可靠性，那么生产者可以采用同步或异步的模式，在出现异常情况时可以及时获得通知，以便可以做相应的补救措施，比如选择重试发送(可能会引起消息重复)。")]),e._v(" "),v("p",[e._v("有些发送异常属于可重试异常， 比如"),v("strong",[e._v("Network Exception")]),e._v("， 这个可能是由瞬时的网络故障而导致的，一般通过重试就可以解决。对于这类异常，如果直接抛给客户端的使用方也未免过于兴师动众，客户端内部本身提供了重试机制来应对这种类型的异常，通过"),v("code",[e._v("retries")]),e._v("参数即可配置。默认情况下，"),v("code",[e._v("retries")]),e._v("参数设置为0， 即不进行重试， 对于高可靠性要求的场景， 需要将这个值设置为大于0的值，与"),v("code",[e._v("retries")]),e._v("参数相关的还有一个"),v("code",[e._v("retry.back off.ms")]),e._v("参数， 它用来设定两次重试之间的时间间隔， 以此避免无效的频繁重试。在配置"),v("code",[e._v("retries")]),e._v("和"),v("code",[e._v("retry.back off.ms")]),e._v("之前， 最好先估算一下可能的异常恢复时间， 这样可以设定总的重试时间大于这个异常恢复时间，以此来避免生产者过早地放弃重试。如果不知道"),v("code",[e._v("retries")]),e._v("参数应该配置为多少， 则可以参考"),v("strong",[e._v("KafkaAdminClient")]),e._v("， 在"),v("strong",[e._v("KafkaAdminClient")]),e._v("中"),v("code",[e._v("retries")]),e._v("参数的默认值为5。")]),e._v(" "),v("blockquote",[v("p",[e._v("如果配置的"),v("code",[e._v("retries")]),e._v("参数值大于0， 则可能引起一些负面的影响。由于默认的"),v("code",[e._v("max.in.flight.requests.per.connection")]),e._v("参数值为5， 这样可能会影响消息的顺序性，对此要么放弃客户端内部的重试功能，要么将"),v("code",[e._v("max.in.flight.requests.per.connection")]),e._v("参数设置为1， 这样也就放弃了吞吐。其次，有些应用对于时延的要求很高， 很多时候都是需要快速失败的， 设置"),v("code",[e._v("retries>0")]),e._v("会增加客户端对于异常的反馈时延，如此可能会对应用造成不良的影响。")])]),e._v(" "),v("p",[e._v("我们回头再来看一下"),v("code",[e._v("acks=-1")]),e._v("的情形， 它要求ISR中所有的副本都收到相关的消息之后才能够告知生产者已经成功提交。试想一下这样的情形， leader副本的消息流入速度很快， 而follower副本的同步速度很慢， 在某个临界点时所有的follower副本都被剔除出了ISR集合， 那么ISR中只有一个leader副本， 最终"),v("code",[e._v("acks=-1")]),e._v("演变为"),v("code",[e._v("acks=1")]),e._v("的情形， 如此也就加大了消息丢失的风险。Kafka也考虑到了这种情况， 并为此提供了"),v("code",[e._v("min.insync.replicas")]),e._v("参数(默认值为1) 来作为辅助(配合"),v("code",[e._v("acks=-1")]),e._v("来使用) ， 这个参数指定了ISR集合中最小的副本数， 如果不满足条件就会抛出"),v("strong",[e._v("NotEnoughReplicasException")]),e._v("或"),v("strong",[e._v("NotEnoughReplicasAfterAppendException")]),e._v("。在正常的配置下， 需要满足副本数 > "),v("code",[e._v("min.insync.replicas")]),e._v("参数的值。一个典型的配置方案为：副本数配置为3， "),v("code",[e._v("min.insync.replicas")]),e._v("参数值配置为2。注意"),v("code",[e._v("min.insync.replicas")]),e._v("参数在提升可靠性的时候会从侧面影响可用性。试想如果ISR中只有一个leader副本， 那么最起码还可以使用， 而此时如果配置"),v("code",[e._v("min.insync.replicas>1")]),e._v("， 则会使消息无法写入。")]),e._v(" "),v("p",[e._v("与可靠性和ISR集合有关的还有一个参数——"),v("code",[e._v("unclean.leader.election.enable")]),e._v("。这个参数的默认值为false， 如果设置为true就意味着当leader下线时候可以从非ISR集合中选举出新的leader， 这样有可能造成数据的丢失。如果这个参数设置为false， 那么也会影响可用性， 非ISR集合中的副本虽然没能及时同步所有的消息， 但最起码还是存活的可用副本。随着Kafka版本的变更， 有的参数被淘汰， 也有新的参数加入进来， 而传承下来的参数一般都很少会修改既定的默认值，而"),v("code",[e._v("unclean.leader.election.enable")]),e._v("就是这样一个反例， 从"),v("code",[e._v("0.11.0.0")]),e._v("版本开始， "),v("code",[e._v("unclean.leader.election.enable")]),e._v("的默认值由原来的true改为了false， 可以看出Kafka的设计者愈发地偏向于可靠性的提升。")]),e._v(" "),v("p",[e._v("在broker端还有两个参数"),v("code",[e._v("log.flush.interval.messages")]),e._v("和"),v("code",[e._v("log.flush.interval.ms")]),e._v("，用来调整同步刷盘的策略，默认是不做控制而交由操作系统本身来进行处理。同步刷盘是增强一个组件可靠性的有效方式， Kafka也不例外， 但绝大多数情景下，一个组件(尤其是大数据量的组件)的可靠性不应该由同步刷盘这种极其损耗性能的操作来保障，而应该采用多副本的机制来保障。")]),e._v(" "),v("p",[e._v("对于消息的可靠性， 很多人都会忽视消费端的重要性， 如果一条消息成功地写入Kafka，并且也被Kafka完好地保存， 而在消费时由于某些疏忽造成没有消费到这条消息， 那么对于应用来说，这条消息也是丢失的。")]),e._v(" "),v("p",[v("code",[e._v("enable.auto.commit")]),e._v("参数的默认值为true， 即开启自动位点提交的功能， 虽然这种方式非常简便，但它会带来重复消费和消息丢失的问题，对于高可靠性要求的应用来说显然不可取，所以需要将"),v("code",[e._v("enable.auto.commit")]),e._v("参数设置为false来执行手动位点提交。在执行手动位点提交的时候也要遵循一个原则：如果消息没有被成功消费，那么就不能提交所对应的消费位点。对于高可靠要求的应用来说，宁愿重复消费也不应该因为消费异常而导致消息丢失。有时候，由于应用解析消息的异常，可能导致部分消息一直不能够成功被消费，那么这个时候为了不影响整体消费的进度，可以将这类消息暂存到死信队列中，以便后续的故障排除。")]),e._v(" "),v("p",[e._v("对于消费端， Kafka还提供了一个可以兜底的功能， 即回溯消费， 通过这个功能可以让我们能够有机会对漏掉的消息相应地进行回补，进而可以进一步提高可靠性。")]),e._v(" "),v("hr")])}),[],!1,null,null,null);v.default=o.exports}}]);