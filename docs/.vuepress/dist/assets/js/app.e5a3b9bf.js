(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var r,a,s=e[0],c=e[1],l=e[2],u=0,d=[];u<s.length;u++)a=s[u],Object.prototype.hasOwnProperty.call(o,a)&&o[a]&&d.push(o[a][0]),o[a]=0;for(r in c)Object.prototype.hasOwnProperty.call(c,r)&&(n[r]=c[r]);for(p&&p(e);d.length;)d.shift()();return i.push.apply(i,l||[]),t()}function t(){for(var n,e=0;e<i.length;e++){for(var t=i[e],r=!0,s=1;s<t.length;s++){var c=t[s];0!==o[c]&&(r=!1)}r&&(i.splice(e--,1),n=a(a.s=t[0]))}return n}var r={},o={8:0},i=[];function a(e){if(r[e])return r[e].exports;var t=r[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,a),t.l=!0,t.exports}a.e=function(n){var e=[],t=o[n];if(0!==t)if(t)e.push(t[2]);else{var r=new Promise((function(e,r){t=o[n]=[e,r]}));e.push(t[2]=r);var i,s=document.createElement("script");s.charset="utf-8",s.timeout=120,a.nc&&s.setAttribute("nonce",a.nc),s.src=function(n){return a.p+"assets/js/"+({9:"vendors~docsearch"}[n]||n)+"."+{1:"b082846a",2:"35a98e22",3:"fe526cea",4:"030d6107",5:"03731fd0",6:"57334820",7:"58037876",9:"c5803104",10:"127dd8b7",11:"febab2cf",12:"3d1d22b1",13:"0ccaf0ba",14:"8034294b",15:"11f4dc6d",16:"96fd44ee",17:"7fce6d6a",18:"868aac91",19:"7f3a1613",20:"a60b3e2c",21:"d3bf577d",22:"1293318b",23:"3049023c",24:"163d8ece",25:"35403ab4",26:"66625813",27:"59b36eb3",28:"5062e054",29:"5a6db58b",30:"96cc883a",31:"021ce3b6",32:"5d607fb8",33:"76cc5e43",34:"bce34f02",35:"ea32a5a2",36:"264845b1",37:"26953601",38:"0d3ab892",39:"61619d74",40:"dd25f8a4",41:"c1b06cb3",42:"9bd3fa8a",43:"035f8c98",44:"9fb02b8a",45:"0717ab57",46:"f6ce981e",47:"c7593769",48:"a2ea3bea",49:"3fe55807",50:"31d60483",51:"fca46a13",52:"4188fd9d",53:"ce8cea49",54:"3ce3ab2f",55:"cc2400ce",56:"ea30dd6f",57:"f90fbd39",58:"65ba472c",59:"64cfd6f4",60:"b87d7e71",61:"7e76595c",62:"63913359",63:"1c58eb8b",64:"34acb1fe",65:"2b713cfd",66:"e612971b",67:"a85f50fa",68:"f24b8ee6",69:"a387a76a",70:"b5d92790",71:"73912c6a",72:"d1495374",73:"a6a61975",74:"421f5d99",75:"c209038d",76:"f5be4120",77:"33906931",78:"1303fe53",79:"230d5814",80:"f48aeb13",81:"dfad09b6",82:"fc9b7010",83:"d1e1a8c6",84:"cd0262ed",85:"a497e6ed",86:"7349d259",87:"0a3729cf",88:"5816307c",89:"64e96c37",90:"a9e0cd67",91:"779952b9",92:"02167158"}[n]+".js"}(n);var c=new Error;i=function(e){s.onerror=s.onload=null,clearTimeout(l);var t=o[n];if(0!==t){if(t){var r=e&&("load"===e.type?"missing":e.type),i=e&&e.target&&e.target.src;c.message="Loading chunk "+n+" failed.\n("+r+": "+i+")",c.name="ChunkLoadError",c.type=r,c.request=i,t[1](c)}o[n]=void 0}};var l=setTimeout((function(){i({type:"timeout",target:s})}),12e4);s.onerror=s.onload=i,document.head.appendChild(s)}return Promise.all(e)},a.m=n,a.c=r,a.d=function(n,e,t){a.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},a.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},a.t=function(n,e){if(1&e&&(n=a(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(a.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var r in n)a.d(t,r,function(e){return n[e]}.bind(null,r));return t},a.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return a.d(e,"a",e),e},a.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},a.p="/",a.oe=function(n){throw console.error(n),n};var s=window.webpackJsonp=window.webpackJsonp||[],c=s.push.bind(s);s.push=e,s=s.slice();for(var l=0;l<s.length;l++)e(s[l]);var p=c;i.push([108,0]),t()}([function(n,e,t){"use strict";var r=function(n){return n&&n.Math===Math&&n};n.exports=r("object"==typeof globalThis&&globalThis)||r("object"==typeof window&&window)||r("object"==typeof self&&self)||r("object"==typeof global&&global)||function(){return this}()||this||Function("return this")()},function(n,e,t){"use strict";var r=t(56),o=r.all;n.exports=r.IS_HTMLDDA?function(n){return"function"==typeof n||n===o}:function(n){return"function"==typeof n}},function(n,e,t){"use strict";var r=t(29),o=Function.prototype,i=o.call,a=r&&o.bind.bind(i,i);n.exports=r?a:function(n){return function(){return i.apply(n,arguments)}}},function(n,e,t){"use strict";n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e,t){"use strict";function r(n,e,t,r,o,i,a,s){var c,l="function"==typeof n?n.options:n;if(e&&(l.render=e,l.staticRenderFns=t,l._compiled=!0),r&&(l.functional=!0),i&&(l._scopeId="data-v-"+i),a?(c=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),o&&o.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(a)},l._ssrRegister=c):o&&(c=s?function(){o.call(this,(l.functional?this.parent:this).$root.$options.shadowRoot)}:o),c)if(l.functional){l._injectStyles=c;var p=l.render;l.render=function(n,e){return c.call(e),p(n,e)}}else{var u=l.beforeCreate;l.beforeCreate=u?[].concat(u,c):[c]}return{exports:n,options:l}}t.d(e,"a",(function(){return r}))},function(n,e,t){"use strict";var r=t(3);n.exports=!r((function(){return 7!==Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){"use strict";var r=t(2),o=t(33),i=r({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return i(o(n),e)}},function(n,e,t){var r=t(70),o="object"==typeof self&&self&&self.Object===Object&&self,i=r||o||Function("return this")();n.exports=i},function(n,e,t){"use strict";var r=t(1),o=t(56),i=o.all;n.exports=o.IS_HTMLDDA?function(n){return"object"==typeof n?null!==n:r(n)||n===i}:function(n){return"object"==typeof n?null!==n:r(n)}},function(n,e,t){var r=t(166),o=t(169);n.exports=function(n,e){var t=o(n,e);return r(t)?t:void 0}},function(n,e,t){"use strict";t.d(e,"e",(function(){return r})),t.d(e,"b",(function(){return i})),t.d(e,"j",(function(){return a})),t.d(e,"g",(function(){return c})),t.d(e,"h",(function(){return l})),t.d(e,"i",(function(){return p})),t.d(e,"c",(function(){return u})),t.d(e,"f",(function(){return d})),t.d(e,"l",(function(){return f})),t.d(e,"m",(function(){return m})),t.d(e,"d",(function(){return g})),t.d(e,"k",(function(){return k})),t.d(e,"n",(function(){return b})),t.d(e,"a",(function(){return y}));t(17);const r=/#.*$/,o=/\.(md|html)$/,i=/\/$/,a=/^[a-z]+:/i;function s(n){return decodeURI(n).replace(r,"").replace(o,"")}function c(n){return a.test(n)}function l(n){return/^mailto:/.test(n)}function p(n){return/^tel:/.test(n)}function u(n){if(c(n))return n;if(!n)return"404";const e=n.match(r),t=e?e[0]:"",o=s(n);return i.test(o)?n:o+".html"+t}function d(n,e){const t=n.hash,o=function(n){const e=n&&n.match(r);if(e)return e[0]}(e);if(o&&t!==o)return!1;return s(n.path)===s(e)}function f(n,e,t){if(c(e))return{type:"external",path:e};t&&(e=function(n,e,t){const r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;const o=e.split("/");t&&o[o.length-1]||o.pop();const i=n.replace(/^\//,"").split("/");for(let n=0;n<i.length;n++){const e=i[n];".."===e?o.pop():"."!==e&&o.push(e)}""!==o[0]&&o.unshift("");return o.join("/")}(e,t));const r=s(e);for(let e=0;e<n.length;e++)if(s(n[e].regularPath)===r)return Object.assign({},n[e],{type:"page",path:u(n[e].path)});return console.error(`[vuepress] No matching page found for sidebar item "${e}"`),{}}function m(n,e,t,r){const{pages:o,themeConfig:i}=t,a=r&&i.locales&&i.locales[r]||i;if("auto"===(n.frontmatter.sidebar||a.sidebar||i.sidebar))return h(n);const s=a.sidebar||i.sidebar;if(s){const{base:t,config:r}=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(const r in e)if(0===(t=n,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(r)))return{base:r,config:e[r]};var t;return{}}(e,s);return"auto"===r?h(n):r?r.map(n=>function n(e,t,r,o=1){if("string"==typeof e)return f(t,e,r);if(Array.isArray(e))return Object.assign(f(t,e[0],r),{title:e[1]});{o>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const i=e.children||[];return 0===i.length&&e.path?Object.assign(f(t,e.path,r),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:i.map(e=>n(e,t,r,o+1)),collapsable:!1!==e.collapsable}}}(n,o,t)):[]}return[]}function h(n){const e=g(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map(e=>({type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}))}]}function g(n){let e;return(n=n.map(n=>Object.assign({},n))).forEach(n=>{2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)}),n.filter(n=>2===n.level)}function k(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function b(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function v(n){let e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function y(n,e){return v(e)-v(n)}},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){"use strict";var r=t(5),o=t(65),i=t(105),a=t(28),s=t(55),c=TypeError,l=Object.defineProperty,p=Object.getOwnPropertyDescriptor;e.f=r?i?function(n,e,t){if(a(n),e=s(e),a(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var r=p(n,e);r&&r.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:r.configurable,enumerable:"enumerable"in t?t.enumerable:r.enumerable,writable:!1})}return l(n,e,t)}:l:function(n,e,t){if(a(n),e=s(e),a(t),o)try{return l(n,e,t)}catch(n){}if("get"in t||"set"in t)throw new c("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var r=t(16),o=t(151),i=t(152),a=r?r.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":a&&a in Object(n)?o(n):i(n)}},function(n,e,t){"use strict";var r=t(5),o=t(13),i=t(36);n.exports=r?function(n,e,t){return o.f(n,e,i(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){var r=t(8).Symbol;n.exports=r},function(n,e,t){"use strict";var r=t(18),o=t(33),i=t(34),a=t(131),s=t(133);r({target:"Array",proto:!0,arity:1,forced:t(3)((function(){return 4294967297!==[].push.call({length:4294967296},1)}))||!function(){try{Object.defineProperty([],"length",{writable:!1}).push()}catch(n){return n instanceof TypeError}}()},{push:function(n){var e=o(this),t=i(e),r=arguments.length;s(t+r);for(var c=0;c<r;c++)e[t]=arguments[c],t++;return a(e,t),t}})},function(n,e,t){"use strict";var r=t(0),o=t(52).f,i=t(15),a=t(99),s=t(38),c=t(66),l=t(127);n.exports=function(n,e){var t,p,u,d,f,m=n.target,h=n.global,g=n.stat;if(t=h?r:g?r[m]||s(m,{}):(r[m]||{}).prototype)for(p in e){if(d=e[p],u=n.dontCallGetSet?(f=o(t,p))&&f.value:t[p],!l(h?p:m+(g?".":"#")+p,n.forced)&&void 0!==u){if(typeof d==typeof u)continue;c(d,u)}(n.sham||u&&u.sham)&&i(d,"sham",!0),a(t,p,d,n)}}},function(n,e,t){"use strict";var r=t(2),o=r({}.toString),i=r("".slice);n.exports=function(n){return i(o(n),8,-1)}},function(n,e,t){"use strict";var r=t(0),o=t(62),i=t(7),a=t(64),s=t(60),c=t(59),l=r.Symbol,p=o("wks"),u=c?l.for||l:l&&l.withoutSetter||a;n.exports=function(n){return i(p,n)||(p[n]=s&&i(l,n)?l[n]:u("Symbol."+n)),p[n]}},function(n,e,t){var r=t(156),o=t(157),i=t(158),a=t(159),s=t(160);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=o,c.prototype.get=i,c.prototype.has=a,c.prototype.set=s,n.exports=c},function(n,e,t){var r=t(72);n.exports=function(n,e){for(var t=n.length;t--;)if(r(n[t][0],e))return t;return-1}},function(n,e,t){var r=t(10)(Object,"create");n.exports=r},function(n,e,t){var r=t(178);n.exports=function(n,e){var t=n.__data__;return r(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var r=t(46);n.exports=function(n){if("string"==typeof n||r(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var r,o;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(o="function"==typeof(r=function(){var n,e,t={version:"0.2.0"},r=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function o(n,e,t){return n<e?e:n>t?t:n}function i(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(r[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=o(n,r.minimum,1),t.status=1===n?null:n;var c=t.render(!e),l=c.querySelector(r.barSelector),p=r.speed,u=r.easing;return c.offsetWidth,a((function(e){""===r.positionUsing&&(r.positionUsing=t.getPositioningCSS()),s(l,function(n,e,t){var o;return(o="translate3d"===r.positionUsing?{transform:"translate3d("+i(n)+"%,0,0)"}:"translate"===r.positionUsing?{transform:"translate("+i(n)+"%,0)"}:{"margin-left":i(n)+"%"}).transition="all "+e+"ms "+t,o}(n,p,u)),1===n?(s(c,{transition:"none",opacity:1}),c.offsetWidth,setTimeout((function(){s(c,{transition:"all "+p+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),p)}),p)):setTimeout(e,p)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),r.trickleSpeed)};return r.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*o(Math.random()*e,.1,.95)),e=o(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*r.trickleRate)},n=0,e=0,t.promise=function(r){return r&&"resolved"!==r.state()?(0===e&&t.start(),n++,e++,r.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");l(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=r.template;var o,a=e.querySelector(r.barSelector),c=n?"-100":i(t.status||0),p=document.querySelector(r.parent);return s(a,{transition:"all 0 linear",transform:"translate3d("+c+"%,0,0)"}),r.showSpinner||(o=e.querySelector(r.spinnerSelector))&&d(o),p!=document.body&&l(p,"nprogress-custom-parent"),p.appendChild(e),e},t.remove=function(){p(document.documentElement,"nprogress-busy"),p(document.querySelector(r.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&d(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var a=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),s=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var r,o=n.length,i=e.charAt(0).toUpperCase()+e.slice(1);o--;)if((r=n[o]+i)in t)return r;return e}(t))}function r(n,e,r){e=t(e),n.style[e]=r}return function(n,e){var t,o,i=arguments;if(2==i.length)for(t in e)void 0!==(o=e[t])&&e.hasOwnProperty(t)&&r(n,t,o);else r(n,i[1],i[2])}}();function c(n,e){return("string"==typeof n?n:u(n)).indexOf(" "+e+" ")>=0}function l(n,e){var t=u(n),r=t+e;c(t,e)||(n.className=r.substring(1))}function p(n,e){var t,r=u(n);c(n,e)&&(t=r.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function u(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function d(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?r.call(e,t,e,n):r)||(n.exports=o)},function(n){n.exports=JSON.parse('{"name":"vuepress-plugin-comment","version":"0.7.3","description":"Comment plugin in vuepress, such as Gitalk, Valine...","main":"index.js","scripts":{"test":"echo \\"Error: no test specified\\" && exit 1"},"repository":{"type":"git","url":"git+ssh://git@github.com/dongyuanxin/vuepress-plugin-comment.git"},"keywords":["vuepress","comment","plugin","vue","gitalk","valine"],"author":"dongyuanxin","license":"MIT","bugs":{"url":"https://github.com/dongyuanxin/vuepress-plugin-comment/issues"},"homepage":"https://github.com/dongyuanxin/vuepress-plugin-comment#readme","dependencies":{"ejs":"^2.6.1","gitalk":"^1.5.0","gitalk-fix":"^1.5.2","i":"^0.3.6","npm":"^6.9.0","valine":"^1.3.9"}}')},function(n,e,t){"use strict";var r=t(9),o=String,i=TypeError;n.exports=function(n){if(r(n))return n;throw new i(o(n)+" is not an object")}},function(n,e,t){"use strict";var r=t(3);n.exports=!r((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e,t){"use strict";var r=t(49),o=t(53);n.exports=function(n){return r(o(n))}},function(n,e,t){"use strict";var r=t(0),o=t(1),i=function(n){return o(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?i(r[n]):r[n]&&r[n][e]}},function(n,e,t){"use strict";var r=t(1),o=t(114),i=TypeError;n.exports=function(n){if(r(n))return n;throw new i(o(n)+" is not a function")}},function(n,e,t){"use strict";var r=t(53),o=Object;n.exports=function(n){return o(r(n))}},function(n,e,t){"use strict";var r=t(125);n.exports=function(n){return r(n.length)}},function(n,e,t){"use strict";var r=t(29),o=Function.prototype.call;n.exports=r?o.bind(o):function(){return o.apply(o,arguments)}},function(n,e,t){"use strict";n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){"use strict";var r=t(0),o=t(38),i=r["__core-js_shared__"]||o("__core-js_shared__",{});n.exports=i},function(n,e,t){"use strict";var r=t(0),o=Object.defineProperty;n.exports=function(n,e){try{o(r,n,{value:e,configurable:!0,writable:!0})}catch(t){r[n]=e}return e}},function(n,e,t){var r=t(150),o=t(12),i=Object.prototype,a=i.hasOwnProperty,s=i.propertyIsEnumerable,c=r(function(){return arguments}())?r:function(n){return o(n)&&a.call(n,"callee")&&!s.call(n,"callee")};n.exports=c},function(n,e,t){var r=t(10)(t(8),"Map");n.exports=r},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var r=t(170),o=t(177),i=t(179),a=t(180),s=t(181);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=o,c.prototype.get=i,c.prototype.has=a,c.prototype.set=s,n.exports=c},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var r=t(6),o=t(46),i=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,a=/^\w*$/;n.exports=function(n,e){if(r(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!o(n))||(a.test(n)||!i.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var r=t(14),o=t(12);n.exports=function(n){return"symbol"==typeof n||o(n)&&"[object Symbol]"==r(n)}},function(n,e){n.exports=function(n){return n}},function(n,e){var t=/^\s+|\s+$/g,r=/^[-+]0x[0-9a-f]+$/i,o=/^0b[01]+$/i,i=/^0o[0-7]+$/i,a=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,c="object"==typeof self&&self&&self.Object===Object&&self,l=s||c||Function("return this")(),p=Object.prototype.toString,u=Math.max,d=Math.min,f=function(){return l.Date.now()};function m(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function h(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==p.call(n)}(n))return NaN;if(m(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=m(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var s=o.test(n);return s||i.test(n)?a(n.slice(2),s?2:8):r.test(n)?NaN:+n}n.exports=function(n,e,t){var r,o,i,a,s,c,l=0,p=!1,g=!1,k=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function b(e){var t=r,i=o;return r=o=void 0,l=e,a=n.apply(i,t)}function v(n){return l=n,s=setTimeout(x,e),p?b(n):a}function y(n){var t=n-c;return void 0===c||t>=e||t<0||g&&n-l>=i}function x(){var n=f();if(y(n))return _(n);s=setTimeout(x,function(n){var t=e-(n-c);return g?d(t,i-(n-l)):t}(n))}function _(n){return s=void 0,k&&r?b(n):(r=o=void 0,a)}function S(){var n=f(),t=y(n);if(r=arguments,o=this,c=n,t){if(void 0===s)return v(c);if(g)return s=setTimeout(x,e),b(c)}return void 0===s&&(s=setTimeout(x,e)),a}return e=h(e)||0,m(t)&&(p=!!t.leading,i=(g="maxWait"in t)?u(h(t.maxWait)||0,e):i,k="trailing"in t?!!t.trailing:k),S.cancel=function(){void 0!==s&&clearTimeout(s),l=0,r=c=o=s=void 0},S.flush=function(){return void 0===s?a:_(f())},S}},function(n,e,t){"use strict";var r=t(2),o=t(3),i=t(19),a=Object,s=r("".split);n.exports=o((function(){return!a("z").propertyIsEnumerable(0)}))?function(n){return"String"===i(n)?s(n,""):a(n)}:a},function(n,e,t){"use strict";n.exports={}},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e,t){"use strict";var r=t(5),o=t(35),i=t(110),a=t(36),s=t(30),c=t(55),l=t(7),p=t(65),u=Object.getOwnPropertyDescriptor;e.f=r?u:function(n,e){if(n=s(n),e=c(e),p)try{return u(n,e)}catch(n){}if(l(n,e))return a(!o(i.f,n,e),n[e])}},function(n,e,t){"use strict";var r=t(54),o=TypeError;n.exports=function(n){if(r(n))throw new o("Can't call method on "+n);return n}},function(n,e,t){"use strict";n.exports=function(n){return null==n}},function(n,e,t){"use strict";var r=t(111),o=t(57);n.exports=function(n){var e=r(n,"string");return o(e)?e:e+""}},function(n,e,t){"use strict";var r="object"==typeof document&&document.all,o=void 0===r&&void 0!==r;n.exports={all:r,IS_HTMLDDA:o}},function(n,e,t){"use strict";var r=t(31),o=t(1),i=t(58),a=t(59),s=Object;n.exports=a?function(n){return"symbol"==typeof n}:function(n){var e=r("Symbol");return o(e)&&i(e.prototype,s(n))}},function(n,e,t){"use strict";var r=t(2);n.exports=r({}.isPrototypeOf)},function(n,e,t){"use strict";var r=t(60);n.exports=r&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){"use strict";var r=t(61),o=t(3),i=t(0).String;n.exports=!!Object.getOwnPropertySymbols&&!o((function(){var n=Symbol("symbol detection");return!i(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&r&&r<41}))},function(n,e,t){"use strict";var r,o,i=t(0),a=t(112),s=i.process,c=i.Deno,l=s&&s.versions||c&&c.version,p=l&&l.v8;p&&(o=(r=p.split("."))[0]>0&&r[0]<4?1:+(r[0]+r[1])),!o&&a&&(!(r=a.match(/Edge\/(\d+)/))||r[1]>=74)&&(r=a.match(/Chrome\/(\d+)/))&&(o=+r[1]),n.exports=o},function(n,e,t){"use strict";var r=t(63),o=t(37);(n.exports=function(n,e){return o[n]||(o[n]=void 0!==e?e:{})})("versions",[]).push({version:"3.33.2",mode:r?"pure":"global",copyright:"© 2014-2023 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.33.2/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e,t){"use strict";n.exports=!1},function(n,e,t){"use strict";var r=t(2),o=0,i=Math.random(),a=r(1..toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+a(++o+i,36)}},function(n,e,t){"use strict";var r=t(5),o=t(3),i=t(104);n.exports=!r&&!o((function(){return 7!==Object.defineProperty(i("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){"use strict";var r=t(7),o=t(120),i=t(52),a=t(13);n.exports=function(n,e,t){for(var s=o(e),c=a.f,l=i.f,p=0;p<s.length;p++){var u=s[p];r(n,u)||t&&r(t,u)||c(n,u,l(e,u))}}},function(n,e,t){"use strict";var r=t(124);n.exports=function(n){var e=+n;return e!=e||0===e?0:r(e)}},function(n,e,t){"use strict";var r=t(137),o=t(28),i=t(138);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=r(Object.prototype,"__proto__","set"))(t,[]),e=t instanceof Array}catch(n){}return function(t,r){return o(t),i(r),e?n(t,r):t.__proto__=r,t}}():void 0)},function(n,e){n.exports=function(n,e){for(var t=-1,r=e.length,o=n.length;++t<r;)n[o+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var r=t(21),o=t(161),i=t(162),a=t(163),s=t(164),c=t(165);function l(n){var e=this.__data__=new r(n);this.size=e.size}l.prototype.clear=o,l.prototype.delete=i,l.prototype.get=a,l.prototype.has=s,l.prototype.set=c,n.exports=l},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var r=t(14),o=t(41);n.exports=function(n){if(!o(n))return!1;var e=r(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var r=t(182),o=t(12);n.exports=function n(e,t,i,a,s){return e===t||(null==e||null==t||!o(e)&&!o(t)?e!=e&&t!=t:r(e,t,i,a,n,s))}},function(n,e,t){var r=t(77),o=t(185),i=t(78);n.exports=function(n,e,t,a,s,c){var l=1&t,p=n.length,u=e.length;if(p!=u&&!(l&&u>p))return!1;var d=c.get(n),f=c.get(e);if(d&&f)return d==e&&f==n;var m=-1,h=!0,g=2&t?new r:void 0;for(c.set(n,e),c.set(e,n);++m<p;){var k=n[m],b=e[m];if(a)var v=l?a(b,k,m,e,n,c):a(k,b,m,n,e,c);if(void 0!==v){if(v)continue;h=!1;break}if(g){if(!o(e,(function(n,e){if(!i(g,e)&&(k===n||s(k,n,t,a,c)))return g.push(e)}))){h=!1;break}}else if(k!==b&&!s(k,b,t,a,c)){h=!1;break}}return c.delete(n),c.delete(e),h}},function(n,e,t){var r=t(42),o=t(183),i=t(184);function a(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new r;++e<t;)this.add(n[e])}a.prototype.add=a.prototype.push=o,a.prototype.has=i,n.exports=a},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var r=t(195),o=t(201),i=t(83);n.exports=function(n){return i(n)?r(n):o(n)}},function(n,e,t){(function(n){var r=t(8),o=t(197),i=e&&!e.nodeType&&e,a=i&&"object"==typeof n&&n&&!n.nodeType&&n,s=a&&a.exports===i?r.Buffer:void 0,c=(s?s.isBuffer:void 0)||o;n.exports=c}).call(this,t(51)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var r=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==r||"symbol"!=r&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var r=t(198),o=t(199),i=t(200),a=i&&i.isTypedArray,s=a?o(a):r;n.exports=s},function(n,e,t){var r=t(73),o=t(44);n.exports=function(n){return null!=n&&o(n.length)&&!r(n)}},function(n,e,t){var r=t(10)(t(8),"Set");n.exports=r},function(n,e,t){var r=t(41);n.exports=function(n){return n==n&&!r(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var r=t(88),o=t(25);n.exports=function(n,e){for(var t=0,i=(e=r(e,n)).length;null!=n&&t<i;)n=n[o(e[t++])];return t&&t==i?n:void 0}},function(n,e,t){var r=t(6),o=t(45),i=t(212),a=t(215);n.exports=function(n,e){return r(n)?n:o(n,e)?[n]:i(a(n))}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(148),o=t(153),i=t(224),a=t(232),s=t(241),c=t(101),l=i((function(n){var e=c(n);return s(e)&&(e=void 0),a(r(n,1,s,!0),o(e,2))}));n.exports=l},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var r=/["'&<>]/;n.exports=function(n){var e,t=""+n,o=r.exec(t);if(!o)return t;var i="",a=0,s=0;for(a=o.index;a<t.length;a++){switch(t.charCodeAt(a)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}s!==a&&(i+=t.substring(s,a)),s=a+1,i+=e}return s!==a?i+t.substring(s,a):i}},function(n,e,t){!function(){"use strict";n.exports={polyfill:function(){var n=window,e=document;if(!("scrollBehavior"in e.documentElement.style)||!0===n.__forceSmoothScrollPolyfill__){var t,r=n.HTMLElement||n.Element,o={scroll:n.scroll||n.scrollTo,scrollBy:n.scrollBy,elementScroll:r.prototype.scroll||s,scrollIntoView:r.prototype.scrollIntoView},i=n.performance&&n.performance.now?n.performance.now.bind(n.performance):Date.now,a=(t=n.navigator.userAgent,new RegExp(["MSIE ","Trident/","Edge/"].join("|")).test(t)?1:0);n.scroll=n.scrollTo=function(){void 0!==arguments[0]&&(!0!==c(arguments[0])?m.call(n,e.body,void 0!==arguments[0].left?~~arguments[0].left:n.scrollX||n.pageXOffset,void 0!==arguments[0].top?~~arguments[0].top:n.scrollY||n.pageYOffset):o.scroll.call(n,void 0!==arguments[0].left?arguments[0].left:"object"!=typeof arguments[0]?arguments[0]:n.scrollX||n.pageXOffset,void 0!==arguments[0].top?arguments[0].top:void 0!==arguments[1]?arguments[1]:n.scrollY||n.pageYOffset))},n.scrollBy=function(){void 0!==arguments[0]&&(c(arguments[0])?o.scrollBy.call(n,void 0!==arguments[0].left?arguments[0].left:"object"!=typeof arguments[0]?arguments[0]:0,void 0!==arguments[0].top?arguments[0].top:void 0!==arguments[1]?arguments[1]:0):m.call(n,e.body,~~arguments[0].left+(n.scrollX||n.pageXOffset),~~arguments[0].top+(n.scrollY||n.pageYOffset)))},r.prototype.scroll=r.prototype.scrollTo=function(){if(void 0!==arguments[0])if(!0!==c(arguments[0])){var n=arguments[0].left,e=arguments[0].top;m.call(this,this,void 0===n?this.scrollLeft:~~n,void 0===e?this.scrollTop:~~e)}else{if("number"==typeof arguments[0]&&void 0===arguments[1])throw new SyntaxError("Value could not be converted");o.elementScroll.call(this,void 0!==arguments[0].left?~~arguments[0].left:"object"!=typeof arguments[0]?~~arguments[0]:this.scrollLeft,void 0!==arguments[0].top?~~arguments[0].top:void 0!==arguments[1]?~~arguments[1]:this.scrollTop)}},r.prototype.scrollBy=function(){void 0!==arguments[0]&&(!0!==c(arguments[0])?this.scroll({left:~~arguments[0].left+this.scrollLeft,top:~~arguments[0].top+this.scrollTop,behavior:arguments[0].behavior}):o.elementScroll.call(this,void 0!==arguments[0].left?~~arguments[0].left+this.scrollLeft:~~arguments[0]+this.scrollLeft,void 0!==arguments[0].top?~~arguments[0].top+this.scrollTop:~~arguments[1]+this.scrollTop))},r.prototype.scrollIntoView=function(){if(!0!==c(arguments[0])){var t=d(this),r=t.getBoundingClientRect(),i=this.getBoundingClientRect();t!==e.body?(m.call(this,t,t.scrollLeft+i.left-r.left,t.scrollTop+i.top-r.top),"fixed"!==n.getComputedStyle(t).position&&n.scrollBy({left:r.left,top:r.top,behavior:"smooth"})):n.scrollBy({left:i.left,top:i.top,behavior:"smooth"})}else o.scrollIntoView.call(this,void 0===arguments[0]||arguments[0])}}function s(n,e){this.scrollLeft=n,this.scrollTop=e}function c(n){if(null===n||"object"!=typeof n||void 0===n.behavior||"auto"===n.behavior||"instant"===n.behavior)return!0;if("object"==typeof n&&"smooth"===n.behavior)return!1;throw new TypeError("behavior member of ScrollOptions "+n.behavior+" is not a valid value for enumeration ScrollBehavior.")}function l(n,e){return"Y"===e?n.clientHeight+a<n.scrollHeight:"X"===e?n.clientWidth+a<n.scrollWidth:void 0}function p(e,t){var r=n.getComputedStyle(e,null)["overflow"+t];return"auto"===r||"scroll"===r}function u(n){var e=l(n,"Y")&&p(n,"Y"),t=l(n,"X")&&p(n,"X");return e||t}function d(n){for(;n!==e.body&&!1===u(n);)n=n.parentNode||n.host;return n}function f(e){var t,r,o,a,s=(i()-e.startTime)/468;a=s=s>1?1:s,t=.5*(1-Math.cos(Math.PI*a)),r=e.startX+(e.x-e.startX)*t,o=e.startY+(e.y-e.startY)*t,e.method.call(e.scrollable,r,o),r===e.x&&o===e.y||n.requestAnimationFrame(f.bind(n,e))}function m(t,r,a){var c,l,p,u,d=i();t===e.body?(c=n,l=n.scrollX||n.pageXOffset,p=n.scrollY||n.pageYOffset,u=o.scroll):(c=t,l=t.scrollLeft,p=t.scrollTop,u=s),f({scrollable:c,method:u,startTime:d,startX:l,startY:p,x:r,y:a})}}}}()},function(n,e,t){"use strict";
/**
 * @file Embedded JavaScript templating engine. {@link http://ejs.co}
 * @author Matthew Eernisse <mde@fleegix.org>
 * @author Tiancheng "Timothy" Gu <timothygu99@gmail.com>
 * @project EJS
 * @license {@link http://www.apache.org/licenses/LICENSE-2.0 Apache License, Version 2.0}
 */var r=t(251),o=t(252),i=t(253),a=!1,s=t(254).version,c=["delimiter","scope","context","debug","compileDebug","client","_with","rmWhitespace","strict","filename","async"],l=c.concat("cache"),p=/^\uFEFF/,u=/^[a-zA-Z_$][0-9a-zA-Z_$]*$/;function d(n,t){var o;if(t.some((function(t){return o=e.resolveInclude(n,t,!0),r.existsSync(o)})))return o}function f(n,t){var r,o=n.filename,i=arguments.length>1;if(n.cache){if(!o)throw new Error("cache option requires a filename");if(r=e.cache.get(o))return r;i||(t=h(o).toString().replace(p,""))}else if(!i){if(!o)throw new Error("Internal EJS error: no file name or template provided");t=h(o).toString().replace(p,"")}return r=e.compile(t,n),n.cache&&e.cache.set(o,r),r}function m(n,t,r){var o;if(!r){if("function"==typeof e.promiseImpl)return new e.promiseImpl((function(e,r){try{e(o=f(n)(t))}catch(n){r(n)}}));throw new Error("Please provide a callback function")}try{o=f(n)(t)}catch(n){return r(n)}r(null,o)}function h(n){return e.fileLoader(n)}function g(n,t){var o=i.shallowCopy(i.createNullProtoObjWherePossible(),t);if(o.filename=function(n,t){var o,i,a=t.views,s=/^[A-Za-z]+:\\|^\//.exec(n);if(s&&s.length)n=n.replace(/^\/*/,""),o=Array.isArray(t.root)?d(n,t.root):e.resolveInclude(n,t.root||"/",!0);else if(t.filename&&(i=e.resolveInclude(n,t.filename),r.existsSync(i)&&(o=i)),!o&&Array.isArray(a)&&(o=d(n,a)),!o&&"function"!=typeof t.includer)throw new Error('Could not find the include file "'+t.escapeFunction(n)+'"');return o}(n,o),"function"==typeof t.includer){var a=t.includer(n,o.filename);if(a&&(a.filename&&(o.filename=a.filename),a.template))return f(o,a.template)}return f(o)}function k(n,e,t,r,o){var i=e.split("\n"),a=Math.max(r-3,0),s=Math.min(i.length,r+3),c=o(t),l=i.slice(a,s).map((function(n,e){var t=e+a+1;return(t==r?" >> ":"    ")+t+"| "+n})).join("\n");throw n.path=c,n.message=(c||"ejs")+":"+r+"\n"+l+"\n\n"+n.message,n}function b(n){return n.replace(/;(\s*$)/,"$1")}function v(n,t){t=t||i.createNullProtoObjWherePossible();var r=i.createNullProtoObjWherePossible();this.templateText=n,this.mode=null,this.truncate=!1,this.currentLine=1,this.source="",r.client=t.client||!1,r.escapeFunction=t.escape||t.escapeFunction||i.escapeXML,r.compileDebug=!1!==t.compileDebug,r.debug=!!t.debug,r.filename=t.filename,r.openDelimiter=t.openDelimiter||e.openDelimiter||"<",r.closeDelimiter=t.closeDelimiter||e.closeDelimiter||">",r.delimiter=t.delimiter||e.delimiter||"%",r.strict=t.strict||!1,r.context=t.context,r.cache=t.cache||!1,r.rmWhitespace=t.rmWhitespace,r.root=t.root,r.includer=t.includer,r.outputFunctionName=t.outputFunctionName,r.localsName=t.localsName||e.localsName||"locals",r.views=t.views,r.async=t.async,r.destructuredLocals=t.destructuredLocals,r.legacyInclude=void 0===t.legacyInclude||!!t.legacyInclude,r.strict?r._with=!1:r._with=void 0===t._with||t._with,this.opts=r,this.regex=this.createRegex()}e.cache=i.cache,e.fileLoader=r.readFileSync,e.localsName="locals",e.promiseImpl=new Function("return this;")().Promise,e.resolveInclude=function(n,e,t){var r=o.dirname,i=o.extname,a=(0,o.resolve)(t?e:r(e),n);return i(n)||(a+=".ejs"),a},e.compile=function(n,e){return e&&e.scope&&(a||(console.warn("`scope` option is deprecated and will be removed in EJS 3"),a=!0),e.context||(e.context=e.scope),delete e.scope),new v(n,e).compile()},e.render=function(n,e,t){var r=e||i.createNullProtoObjWherePossible(),o=t||i.createNullProtoObjWherePossible();return 2==arguments.length&&i.shallowCopyFromList(o,r,c),f(o,n)(r)},e.renderFile=function(){var n,e,t,r=Array.prototype.slice.call(arguments),o=r.shift(),a={filename:o};return"function"==typeof arguments[arguments.length-1]&&(n=r.pop()),r.length?(e=r.shift(),r.length?i.shallowCopy(a,r.pop()):(e.settings&&(e.settings.views&&(a.views=e.settings.views),e.settings["view cache"]&&(a.cache=!0),(t=e.settings["view options"])&&i.shallowCopy(a,t)),i.shallowCopyFromList(a,e,l)),a.filename=o):e=i.createNullProtoObjWherePossible(),m(a,e,n)},e.Template=v,e.clearCache=function(){e.cache.reset()},v.modes={EVAL:"eval",ESCAPED:"escaped",RAW:"raw",COMMENT:"comment",LITERAL:"literal"},v.prototype={createRegex:function(){var n="(<%%|%%>|<%=|<%-|<%_|<%#|<%|%>|-%>|_%>)",e=i.escapeRegExpChars(this.opts.delimiter),t=i.escapeRegExpChars(this.opts.openDelimiter),r=i.escapeRegExpChars(this.opts.closeDelimiter);return n=n.replace(/%/g,e).replace(/</g,t).replace(/>/g,r),new RegExp(n)},compile:function(){var n,e,t,r=this.opts,a="",s="",c=r.escapeFunction,l=r.filename?JSON.stringify(r.filename):"undefined";if(!this.source){if(this.generateSource(),a+='  var __output = "";\n  function __append(s) { if (s !== undefined && s !== null) __output += s }\n',r.outputFunctionName){if(!u.test(r.outputFunctionName))throw new Error("outputFunctionName is not a valid JS identifier.");a+="  var "+r.outputFunctionName+" = __append;\n"}if(r.localsName&&!u.test(r.localsName))throw new Error("localsName is not a valid JS identifier.");if(r.destructuredLocals&&r.destructuredLocals.length){for(var p="  var __locals = ("+r.localsName+" || {}),\n",d=0;d<r.destructuredLocals.length;d++){var f=r.destructuredLocals[d];if(!u.test(f))throw new Error("destructuredLocals["+d+"] is not a valid JS identifier.");d>0&&(p+=",\n  "),p+=f+" = __locals."+f}a+=p+";\n"}!1!==r._with&&(a+="  with ("+r.localsName+" || {}) {\n",s+="  }\n"),s+="  return __output;\n",this.source=a+this.source+s}n=r.compileDebug?"var __line = 1\n  , __lines = "+JSON.stringify(this.templateText)+"\n  , __filename = "+l+";\ntry {\n"+this.source+"} catch (e) {\n  rethrow(e, __lines, __filename, __line, escapeFn);\n}\n":this.source,r.client&&(n="escapeFn = escapeFn || "+c.toString()+";\n"+n,r.compileDebug&&(n="rethrow = rethrow || "+k.toString()+";\n"+n)),r.strict&&(n='"use strict";\n'+n),r.debug&&console.log(n),r.compileDebug&&r.filename&&(n=n+"\n//# sourceURL="+l+"\n");try{if(r.async)try{t=new Function("return (async function(){}).constructor;")()}catch(n){throw n instanceof SyntaxError?new Error("This environment does not support async/await"):n}else t=Function;e=new t(r.localsName+", escapeFn, include, rethrow",n)}catch(n){throw n instanceof SyntaxError&&(r.filename&&(n.message+=" in "+r.filename),n.message+=" while compiling ejs\n\n",n.message+="If the above error is not helpful, you may want to try EJS-Lint:\n",n.message+="https://github.com/RyanZim/EJS-Lint",r.async||(n.message+="\n",n.message+="Or, if you meant to create an async function, pass `async: true` as an option.")),n}var m=r.client?e:function(n){return e.apply(r.context,[n||i.createNullProtoObjWherePossible(),c,function(e,t){var o=i.shallowCopy(i.createNullProtoObjWherePossible(),n);return t&&(o=i.shallowCopy(o,t)),g(e,r)(o)},k])};if(r.filename&&"function"==typeof Object.defineProperty){var h=r.filename,b=o.basename(h,o.extname(h));try{Object.defineProperty(m,"name",{value:b,writable:!1,enumerable:!1,configurable:!0})}catch(n){}}return m},generateSource:function(){this.opts.rmWhitespace&&(this.templateText=this.templateText.replace(/[\r\n]+/g,"\n").replace(/^\s+|\s+$/gm,"")),this.templateText=this.templateText.replace(/[ \t]*<%_/gm,"<%_").replace(/_%>[ \t]*/gm,"_%>");var n=this,e=this.parseTemplateText(),t=this.opts.delimiter,r=this.opts.openDelimiter,o=this.opts.closeDelimiter;e&&e.length&&e.forEach((function(i,a){var s;if(0===i.indexOf(r+t)&&0!==i.indexOf(r+t+t)&&(s=e[a+2])!=t+o&&s!="-"+t+o&&s!="_"+t+o)throw new Error('Could not find matching close tag for "'+i+'".');n.scanLine(i)}))},parseTemplateText:function(){for(var n,e=this.templateText,t=this.regex,r=t.exec(e),o=[];r;)0!==(n=r.index)&&(o.push(e.substring(0,n)),e=e.slice(n)),o.push(r[0]),e=e.slice(r[0].length),r=t.exec(e);return e&&o.push(e),o},_addOutput:function(n){if(this.truncate&&(n=n.replace(/^(?:\r\n|\r|\n)/,""),this.truncate=!1),!n)return n;n=(n=(n=(n=n.replace(/\\/g,"\\\\")).replace(/\n/g,"\\n")).replace(/\r/g,"\\r")).replace(/"/g,'\\"'),this.source+='    ; __append("'+n+'")\n'},scanLine:function(n){var e,t=this.opts.delimiter,r=this.opts.openDelimiter,o=this.opts.closeDelimiter;switch(e=n.split("\n").length-1,n){case r+t:case r+t+"_":this.mode=v.modes.EVAL;break;case r+t+"=":this.mode=v.modes.ESCAPED;break;case r+t+"-":this.mode=v.modes.RAW;break;case r+t+"#":this.mode=v.modes.COMMENT;break;case r+t+t:this.mode=v.modes.LITERAL,this.source+='    ; __append("'+n.replace(r+t+t,r+t)+'")\n';break;case t+t+o:this.mode=v.modes.LITERAL,this.source+='    ; __append("'+n.replace(t+t+o,t+o)+'")\n';break;case t+o:case"-"+t+o:case"_"+t+o:this.mode==v.modes.LITERAL&&this._addOutput(n),this.mode=null,this.truncate=0===n.indexOf("-")||0===n.indexOf("_");break;default:if(this.mode){switch(this.mode){case v.modes.EVAL:case v.modes.ESCAPED:case v.modes.RAW:n.lastIndexOf("//")>n.lastIndexOf("\n")&&(n+="\n")}switch(this.mode){case v.modes.EVAL:this.source+="    ; "+n+"\n";break;case v.modes.ESCAPED:this.source+="    ; __append(escapeFn("+b(n)+"))\n";break;case v.modes.RAW:this.source+="    ; __append("+b(n)+")\n";break;case v.modes.COMMENT:break;case v.modes.LITERAL:this._addOutput(n)}}else this._addOutput(n)}this.opts.compileDebug&&e&&(this.currentLine+=e,this.source+="    ; __line = "+this.currentLine+"\n")}},e.escapeXML=i.escapeXML,e.__express=e.renderFile,e.VERSION=s,e.name="ejs","undefined"!=typeof window&&(window.ejs=e)},function(n,e,t){"use strict";t.r(e);var r={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},o=(t(244),t(4)),i=Object(o.a)(r,(function(){return(0,this._self._c)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);e.default=i.exports},function(n,e,t){"use strict";t.r(e);var r={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(n){this.codeTabs.forEach(n=>{n.elm.classList.remove("theme-code-block__active")}),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(n=>Boolean(n.componentOptions)).map((n,e)=>(""===n.componentOptions.propsData.active&&(this.activeCodeTabIndex=e),{title:n.componentOptions.propsData.title,elm:n.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(n){this.activeCodeTabIndex=n}}},o=(t(245),t(4)),i=Object(o.a)(r,(function(){var n=this,e=n._self._c;return e("div",{staticClass:"theme-code-group"},[e("div",{staticClass:"theme-code-group__nav"},[e("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(t,r){return e("li",{key:t.title,staticClass:"theme-code-group__li"},[e("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":r===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(r)}}},[n._v("\n            "+n._s(t.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?e("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"2f5f1757",null);e.default=i.exports},function(n,e,t){"use strict";var r=t(1),o=t(13),i=t(102),a=t(38);n.exports=function(n,e,t,s){s||(s={});var c=s.enumerable,l=void 0!==s.name?s.name:e;if(r(t)&&i(t,l,s),s.global)c?n[e]=t:a(e,t);else{try{s.unsafe?n[e]&&(c=!0):delete n[e]}catch(n){}c?n[e]=t:o.f(n,e,{value:t,enumerable:!1,configurable:!s.nonConfigurable,writable:!s.nonWritable})}return n}},function(n,e,t){"use strict";var r=t(142),o=String;n.exports=function(n){if("Symbol"===r(n))throw new TypeError("Cannot convert a Symbol value to a string");return o(n)}},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){"use strict";var r=t(2),o=t(3),i=t(1),a=t(7),s=t(5),c=t(116).CONFIGURABLE,l=t(117),p=t(118),u=p.enforce,d=p.get,f=String,m=Object.defineProperty,h=r("".slice),g=r("".replace),k=r([].join),b=s&&!o((function(){return 8!==m((function(){}),"length",{value:8}).length})),v=String(String).split("String"),y=n.exports=function(n,e,t){"Symbol("===h(f(e),0,7)&&(e="["+g(f(e),/^Symbol\(([^)]*)\)/,"$1")+"]"),t&&t.getter&&(e="get "+e),t&&t.setter&&(e="set "+e),(!a(n,"name")||c&&n.name!==e)&&(s?m(n,"name",{value:e,configurable:!0}):n.name=e),b&&t&&a(t,"arity")&&n.length!==t.arity&&m(n,"length",{value:t.arity});try{t&&a(t,"constructor")&&t.constructor?s&&m(n,"prototype",{writable:!1}):n.prototype&&(n.prototype=void 0)}catch(n){}var r=u(n);return a(r,"source")||(r.source=k(v,"string"==typeof e?e:"")),n};Function.prototype.toString=y((function(){return i(this)&&d(this).source||l(this)}),"toString")},function(n,e,t){"use strict";n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){"use strict";var r=t(0),o=t(9),i=r.document,a=o(i)&&o(i.createElement);n.exports=function(n){return a?i.createElement(n):{}}},function(n,e,t){"use strict";var r=t(5),o=t(3);n.exports=r&&o((function(){return 42!==Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){"use strict";var r=t(62),o=t(64),i=r("keys");n.exports=function(n){return i[n]||(i[n]=o(n))}},function(n,e,t){"use strict";var r=t(2),o=t(7),i=t(30),a=t(122).indexOf,s=t(50),c=r([].push);n.exports=function(n,e){var t,r=i(n),l=0,p=[];for(t in r)!o(s,t)&&o(r,t)&&c(p,t);for(;e.length>l;)o(r,t=e[l++])&&(~a(p,t)||c(p,t));return p}},function(n,e,t){n.exports=t(257)},function(n,e,t){"use strict";var r=t(18),o=t(128).left,i=t(129),a=t(61);r({target:"Array",proto:!0,forced:!t(130)&&a>79&&a<83||!i("reduce")},{reduce:function(n){var e=arguments.length;return o(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r={}.propertyIsEnumerable,o=Object.getOwnPropertyDescriptor,i=o&&!r.call({1:2},1);e.f=i?function(n){var e=o(this,n);return!!e&&e.enumerable}:r},function(n,e,t){"use strict";var r=t(35),o=t(9),i=t(57),a=t(113),s=t(115),c=t(20),l=TypeError,p=c("toPrimitive");n.exports=function(n,e){if(!o(n)||i(n))return n;var t,c=a(n,p);if(c){if(void 0===e&&(e="default"),t=r(c,n,e),!o(t)||i(t))return t;throw new l("Can't convert object to primitive value")}return void 0===e&&(e="number"),s(n,e)}},function(n,e,t){"use strict";n.exports="undefined"!=typeof navigator&&String(navigator.userAgent)||""},function(n,e,t){"use strict";var r=t(32),o=t(54);n.exports=function(n,e){var t=n[e];return o(t)?void 0:r(t)}},function(n,e,t){"use strict";var r=String;n.exports=function(n){try{return r(n)}catch(n){return"Object"}}},function(n,e,t){"use strict";var r=t(35),o=t(1),i=t(9),a=TypeError;n.exports=function(n,e){var t,s;if("string"===e&&o(t=n.toString)&&!i(s=r(t,n)))return s;if(o(t=n.valueOf)&&!i(s=r(t,n)))return s;if("string"!==e&&o(t=n.toString)&&!i(s=r(t,n)))return s;throw new a("Can't convert object to primitive value")}},function(n,e,t){"use strict";var r=t(5),o=t(7),i=Function.prototype,a=r&&Object.getOwnPropertyDescriptor,s=o(i,"name"),c=s&&"something"===function(){}.name,l=s&&(!r||r&&a(i,"name").configurable);n.exports={EXISTS:s,PROPER:c,CONFIGURABLE:l}},function(n,e,t){"use strict";var r=t(2),o=t(1),i=t(37),a=r(Function.toString);o(i.inspectSource)||(i.inspectSource=function(n){return a(n)}),n.exports=i.inspectSource},function(n,e,t){"use strict";var r,o,i,a=t(119),s=t(0),c=t(9),l=t(15),p=t(7),u=t(37),d=t(106),f=t(50),m=s.TypeError,h=s.WeakMap;if(a||u.state){var g=u.state||(u.state=new h);g.get=g.get,g.has=g.has,g.set=g.set,r=function(n,e){if(g.has(n))throw new m("Object already initialized");return e.facade=n,g.set(n,e),e},o=function(n){return g.get(n)||{}},i=function(n){return g.has(n)}}else{var k=d("state");f[k]=!0,r=function(n,e){if(p(n,k))throw new m("Object already initialized");return e.facade=n,l(n,k,e),e},o=function(n){return p(n,k)?n[k]:{}},i=function(n){return p(n,k)}}n.exports={set:r,get:o,has:i,enforce:function(n){return i(n)?o(n):r(n,{})},getterFor:function(n){return function(e){var t;if(!c(e)||(t=o(e)).type!==n)throw new m("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){"use strict";var r=t(0),o=t(1),i=r.WeakMap;n.exports=o(i)&&/native code/.test(String(i))},function(n,e,t){"use strict";var r=t(31),o=t(2),i=t(121),a=t(126),s=t(28),c=o([].concat);n.exports=r("Reflect","ownKeys")||function(n){var e=i.f(s(n)),t=a.f;return t?c(e,t(n)):e}},function(n,e,t){"use strict";var r=t(107),o=t(103).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return r(n,o)}},function(n,e,t){"use strict";var r=t(30),o=t(123),i=t(34),a=function(n){return function(e,t,a){var s,c=r(e),l=i(c),p=o(a,l);if(n&&t!=t){for(;l>p;)if((s=c[p++])!=s)return!0}else for(;l>p;p++)if((n||p in c)&&c[p]===t)return n||p||0;return!n&&-1}};n.exports={includes:a(!0),indexOf:a(!1)}},function(n,e,t){"use strict";var r=t(67),o=Math.max,i=Math.min;n.exports=function(n,e){var t=r(n);return t<0?o(t+e,0):i(t,e)}},function(n,e,t){"use strict";var r=Math.ceil,o=Math.floor;n.exports=Math.trunc||function(n){var e=+n;return(e>0?o:r)(e)}},function(n,e,t){"use strict";var r=t(67),o=Math.min;n.exports=function(n){return n>0?o(r(n),9007199254740991):0}},function(n,e,t){"use strict";e.f=Object.getOwnPropertySymbols},function(n,e,t){"use strict";var r=t(3),o=t(1),i=/#|\.prototype\./,a=function(n,e){var t=c[s(n)];return t===p||t!==l&&(o(e)?r(e):!!e)},s=a.normalize=function(n){return String(n).replace(i,".").toLowerCase()},c=a.data={},l=a.NATIVE="N",p=a.POLYFILL="P";n.exports=a},function(n,e,t){"use strict";var r=t(32),o=t(33),i=t(49),a=t(34),s=TypeError,c=function(n){return function(e,t,c,l){r(t);var p=o(e),u=i(p),d=a(p),f=n?d-1:0,m=n?-1:1;if(c<2)for(;;){if(f in u){l=u[f],f+=m;break}if(f+=m,n?f<0:d<=f)throw new s("Reduce of empty array with no initial value")}for(;n?f>=0:d>f;f+=m)f in u&&(l=t(l,u[f],f,p));return l}};n.exports={left:c(!1),right:c(!0)}},function(n,e,t){"use strict";var r=t(3);n.exports=function(n,e){var t=[][n];return!!t&&r((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){"use strict";var r=t(0),o=t(19);n.exports="process"===o(r.process)},function(n,e,t){"use strict";var r=t(5),o=t(132),i=TypeError,a=Object.getOwnPropertyDescriptor,s=r&&!function(){if(void 0!==this)return!0;try{Object.defineProperty([],"length",{writable:!1}).length=1}catch(n){return n instanceof TypeError}}();n.exports=s?function(n,e){if(o(n)&&!a(n,"length").writable)throw new i("Cannot set read only .length");return n.length=e}:function(n,e){return n.length=e}},function(n,e,t){"use strict";var r=t(19);n.exports=Array.isArray||function(n){return"Array"===r(n)}},function(n,e,t){"use strict";var r=TypeError;n.exports=function(n){if(n>9007199254740991)throw r("Maximum allowed index exceeded");return n}},function(n,e,t){"use strict";var r=t(18),o=t(0),i=t(135),a=t(136),s=o.WebAssembly,c=7!==new Error("e",{cause:7}).cause,l=function(n,e){var t={};t[n]=a(n,e,c),r({global:!0,constructor:!0,arity:1,forced:c},t)},p=function(n,e){if(s&&s[n]){var t={};t[n]=a("WebAssembly."+n,e,c),r({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:c},t)}};l("Error",(function(n){return function(e){return i(n,this,arguments)}})),l("EvalError",(function(n){return function(e){return i(n,this,arguments)}})),l("RangeError",(function(n){return function(e){return i(n,this,arguments)}})),l("ReferenceError",(function(n){return function(e){return i(n,this,arguments)}})),l("SyntaxError",(function(n){return function(e){return i(n,this,arguments)}})),l("TypeError",(function(n){return function(e){return i(n,this,arguments)}})),l("URIError",(function(n){return function(e){return i(n,this,arguments)}})),p("CompileError",(function(n){return function(e){return i(n,this,arguments)}})),p("LinkError",(function(n){return function(e){return i(n,this,arguments)}})),p("RuntimeError",(function(n){return function(e){return i(n,this,arguments)}}))},function(n,e,t){"use strict";var r=t(29),o=Function.prototype,i=o.apply,a=o.call;n.exports="object"==typeof Reflect&&Reflect.apply||(r?a.bind(i):function(){return a.apply(i,arguments)})},function(n,e,t){"use strict";var r=t(31),o=t(7),i=t(15),a=t(58),s=t(68),c=t(66),l=t(139),p=t(140),u=t(141),d=t(144),f=t(145),m=t(5),h=t(63);n.exports=function(n,e,t,g){var k=g?2:1,b=n.split("."),v=b[b.length-1],y=r.apply(null,b);if(y){var x=y.prototype;if(!h&&o(x,"cause")&&delete x.cause,!t)return y;var _=r("Error"),S=e((function(n,e){var t=u(g?e:n,void 0),r=g?new y(n):new y;return void 0!==t&&i(r,"message",t),f(r,S,r.stack,2),this&&a(x,this)&&p(r,this,S),arguments.length>k&&d(r,arguments[k]),r}));if(S.prototype=x,"Error"!==v?s?s(S,_):c(S,_,{name:!0}):m&&"stackTraceLimit"in y&&(l(S,y,"stackTraceLimit"),l(S,y,"prepareStackTrace")),c(S,y),!h)try{x.name!==v&&i(x,"name",v),x.constructor=S}catch(n){}return S}}},function(n,e,t){"use strict";var r=t(2),o=t(32);n.exports=function(n,e,t){try{return r(o(Object.getOwnPropertyDescriptor(n,e)[t]))}catch(n){}}},function(n,e,t){"use strict";var r=t(1),o=String,i=TypeError;n.exports=function(n){if("object"==typeof n||r(n))return n;throw new i("Can't set "+o(n)+" as a prototype")}},function(n,e,t){"use strict";var r=t(13).f;n.exports=function(n,e,t){t in n||r(n,t,{configurable:!0,get:function(){return e[t]},set:function(n){e[t]=n}})}},function(n,e,t){"use strict";var r=t(1),o=t(9),i=t(68);n.exports=function(n,e,t){var a,s;return i&&r(a=e.constructor)&&a!==t&&o(s=a.prototype)&&s!==t.prototype&&i(n,s),n}},function(n,e,t){"use strict";var r=t(100);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:r(n)}},function(n,e,t){"use strict";var r=t(143),o=t(1),i=t(19),a=t(20)("toStringTag"),s=Object,c="Arguments"===i(function(){return arguments}());n.exports=r?i:function(n){var e,t,r;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=s(n),a))?t:c?i(e):"Object"===(r=i(e))&&o(e.callee)?"Arguments":r}},function(n,e,t){"use strict";var r={};r[t(20)("toStringTag")]="z",n.exports="[object z]"===String(r)},function(n,e,t){"use strict";var r=t(9),o=t(15);n.exports=function(n,e){r(e)&&"cause"in e&&o(n,"cause",e.cause)}},function(n,e,t){"use strict";var r=t(15),o=t(146),i=t(147),a=Error.captureStackTrace;n.exports=function(n,e,t,s){i&&(a?a(n,e):r(n,"stack",o(t,s)))}},function(n,e,t){"use strict";var r=t(2),o=Error,i=r("".replace),a=String(new o("zxcasd").stack),s=/\n\s*at [^:]*:[^\n]*/,c=s.test(a);n.exports=function(n,e){if(c&&"string"==typeof n&&!o.prepareStackTrace)for(;e--;)n=i(n,s,"");return n}},function(n,e,t){"use strict";var r=t(3),o=t(36);n.exports=!r((function(){var n=new Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",o(1,7)),7!==n.stack)}))},function(n,e,t){var r=t(69),o=t(149);n.exports=function n(e,t,i,a,s){var c=-1,l=e.length;for(i||(i=o),s||(s=[]);++c<l;){var p=e[c];t>0&&i(p)?t>1?n(p,t-1,i,a,s):r(s,p):a||(s[s.length]=p)}return s}},function(n,e,t){var r=t(16),o=t(39),i=t(6),a=r?r.isConcatSpreadable:void 0;n.exports=function(n){return i(n)||o(n)||!!(a&&n&&n[a])}},function(n,e,t){var r=t(14),o=t(12);n.exports=function(n){return o(n)&&"[object Arguments]"==r(n)}},function(n,e,t){var r=t(16),o=Object.prototype,i=o.hasOwnProperty,a=o.toString,s=r?r.toStringTag:void 0;n.exports=function(n){var e=i.call(n,s),t=n[s];try{n[s]=void 0;var r=!0}catch(n){}var o=a.call(n);return r&&(e?n[s]=t:delete n[s]),o}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var r=t(154),o=t(210),i=t(47),a=t(6),s=t(221);n.exports=function(n){return"function"==typeof n?n:null==n?i:"object"==typeof n?a(n)?o(n[0],n[1]):r(n):s(n)}},function(n,e,t){var r=t(155),o=t(209),i=t(86);n.exports=function(n){var e=o(n);return 1==e.length&&e[0][2]?i(e[0][0],e[0][1]):function(t){return t===n||r(t,n,e)}}},function(n,e,t){var r=t(71),o=t(75);n.exports=function(n,e,t,i){var a=t.length,s=a,c=!i;if(null==n)return!s;for(n=Object(n);a--;){var l=t[a];if(c&&l[2]?l[1]!==n[l[0]]:!(l[0]in n))return!1}for(;++a<s;){var p=(l=t[a])[0],u=n[p],d=l[1];if(c&&l[2]){if(void 0===u&&!(p in n))return!1}else{var f=new r;if(i)var m=i(u,d,p,n,e,f);if(!(void 0===m?o(d,u,3,i,f):m))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var r=t(22),o=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=r(e,n);return!(t<0)&&(t==e.length-1?e.pop():o.call(e,t,1),--this.size,!0)}},function(n,e,t){var r=t(22);n.exports=function(n){var e=this.__data__,t=r(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var r=t(22);n.exports=function(n){return r(this.__data__,n)>-1}},function(n,e,t){var r=t(22);n.exports=function(n,e){var t=this.__data__,o=r(t,n);return o<0?(++this.size,t.push([n,e])):t[o][1]=e,this}},function(n,e,t){var r=t(21);n.exports=function(){this.__data__=new r,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var r=t(21),o=t(40),i=t(42);n.exports=function(n,e){var t=this.__data__;if(t instanceof r){var a=t.__data__;if(!o||a.length<199)return a.push([n,e]),this.size=++t.size,this;t=this.__data__=new i(a)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var r=t(73),o=t(167),i=t(41),a=t(74),s=/^\[object .+?Constructor\]$/,c=Function.prototype,l=Object.prototype,p=c.toString,u=l.hasOwnProperty,d=RegExp("^"+p.call(u).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!i(n)||o(n))&&(r(n)?d:s).test(a(n))}},function(n,e,t){var r,o=t(168),i=(r=/[^.]+$/.exec(o&&o.keys&&o.keys.IE_PROTO||""))?"Symbol(src)_1."+r:"";n.exports=function(n){return!!i&&i in n}},function(n,e,t){var r=t(8)["__core-js_shared__"];n.exports=r},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var r=t(171),o=t(21),i=t(40);n.exports=function(){this.size=0,this.__data__={hash:new r,map:new(i||o),string:new r}}},function(n,e,t){var r=t(172),o=t(173),i=t(174),a=t(175),s=t(176);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=o,c.prototype.get=i,c.prototype.has=a,c.prototype.set=s,n.exports=c},function(n,e,t){var r=t(23);n.exports=function(){this.__data__=r?r(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var r=t(23),o=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(r){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return o.call(e,n)?e[n]:void 0}},function(n,e,t){var r=t(23),o=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return r?void 0!==e[n]:o.call(e,n)}},function(n,e,t){var r=t(23);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=r&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var r=t(24);n.exports=function(n){var e=r(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var r=t(24);n.exports=function(n){return r(this,n).get(n)}},function(n,e,t){var r=t(24);n.exports=function(n){return r(this,n).has(n)}},function(n,e,t){var r=t(24);n.exports=function(n,e){var t=r(this,n),o=t.size;return t.set(n,e),this.size+=t.size==o?0:1,this}},function(n,e,t){var r=t(71),o=t(76),i=t(186),a=t(189),s=t(205),c=t(6),l=t(80),p=t(82),u="[object Object]",d=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,f,m,h){var g=c(n),k=c(e),b=g?"[object Array]":s(n),v=k?"[object Array]":s(e),y=(b="[object Arguments]"==b?u:b)==u,x=(v="[object Arguments]"==v?u:v)==u,_=b==v;if(_&&l(n)){if(!l(e))return!1;g=!0,y=!1}if(_&&!y)return h||(h=new r),g||p(n)?o(n,e,t,f,m,h):i(n,e,b,t,f,m,h);if(!(1&t)){var S=y&&d.call(n,"__wrapped__"),E=x&&d.call(e,"__wrapped__");if(S||E){var w=S?n.value():n,C=E?e.value():e;return h||(h=new r),m(w,C,t,f,h)}}return!!_&&(h||(h=new r),a(n,e,t,f,m,h))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length;++t<r;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var r=t(16),o=t(187),i=t(72),a=t(76),s=t(188),c=t(43),l=r?r.prototype:void 0,p=l?l.valueOf:void 0;n.exports=function(n,e,t,r,l,u,d){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!u(new o(n),new o(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return i(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var f=s;case"[object Set]":var m=1&r;if(f||(f=c),n.size!=e.size&&!m)return!1;var h=d.get(n);if(h)return h==e;r|=2,d.set(n,e);var g=a(f(n),f(e),r,l,u,d);return d.delete(n),g;case"[object Symbol]":if(p)return p.call(n)==p.call(e)}return!1}},function(n,e,t){var r=t(8).Uint8Array;n.exports=r},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,r){t[++e]=[r,n]})),t}},function(n,e,t){var r=t(190),o=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,i,a,s){var c=1&t,l=r(n),p=l.length;if(p!=r(e).length&&!c)return!1;for(var u=p;u--;){var d=l[u];if(!(c?d in e:o.call(e,d)))return!1}var f=s.get(n),m=s.get(e);if(f&&m)return f==e&&m==n;var h=!0;s.set(n,e),s.set(e,n);for(var g=c;++u<p;){var k=n[d=l[u]],b=e[d];if(i)var v=c?i(b,k,d,e,n,s):i(k,b,d,n,e,s);if(!(void 0===v?k===b||a(k,b,t,i,s):v)){h=!1;break}g||(g="constructor"==d)}if(h&&!g){var y=n.constructor,x=e.constructor;y==x||!("constructor"in n)||!("constructor"in e)||"function"==typeof y&&y instanceof y&&"function"==typeof x&&x instanceof x||(h=!1)}return s.delete(n),s.delete(e),h}},function(n,e,t){var r=t(191),o=t(192),i=t(79);n.exports=function(n){return r(n,i,o)}},function(n,e,t){var r=t(69),o=t(6);n.exports=function(n,e,t){var i=e(n);return o(n)?i:r(i,t(n))}},function(n,e,t){var r=t(193),o=t(194),i=Object.prototype.propertyIsEnumerable,a=Object.getOwnPropertySymbols,s=a?function(n){return null==n?[]:(n=Object(n),r(a(n),(function(e){return i.call(n,e)})))}:o;n.exports=s},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,o=0,i=[];++t<r;){var a=n[t];e(a,t,n)&&(i[o++]=a)}return i}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var r=t(196),o=t(39),i=t(6),a=t(80),s=t(81),c=t(82),l=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=i(n),p=!t&&o(n),u=!t&&!p&&a(n),d=!t&&!p&&!u&&c(n),f=t||p||u||d,m=f?r(n.length,String):[],h=m.length;for(var g in n)!e&&!l.call(n,g)||f&&("length"==g||u&&("offset"==g||"parent"==g)||d&&("buffer"==g||"byteLength"==g||"byteOffset"==g)||s(g,h))||m.push(g);return m}},function(n,e){n.exports=function(n,e){for(var t=-1,r=Array(n);++t<n;)r[t]=e(t);return r}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var r=t(14),o=t(44),i=t(12),a={};a["[object Float32Array]"]=a["[object Float64Array]"]=a["[object Int8Array]"]=a["[object Int16Array]"]=a["[object Int32Array]"]=a["[object Uint8Array]"]=a["[object Uint8ClampedArray]"]=a["[object Uint16Array]"]=a["[object Uint32Array]"]=!0,a["[object Arguments]"]=a["[object Array]"]=a["[object ArrayBuffer]"]=a["[object Boolean]"]=a["[object DataView]"]=a["[object Date]"]=a["[object Error]"]=a["[object Function]"]=a["[object Map]"]=a["[object Number]"]=a["[object Object]"]=a["[object RegExp]"]=a["[object Set]"]=a["[object String]"]=a["[object WeakMap]"]=!1,n.exports=function(n){return i(n)&&o(n.length)&&!!a[r(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var r=t(70),o=e&&!e.nodeType&&e,i=o&&"object"==typeof n&&n&&!n.nodeType&&n,a=i&&i.exports===o&&r.process,s=function(){try{var n=i&&i.require&&i.require("util").types;return n||a&&a.binding&&a.binding("util")}catch(n){}}();n.exports=s}).call(this,t(51)(n))},function(n,e,t){var r=t(202),o=t(203),i=Object.prototype.hasOwnProperty;n.exports=function(n){if(!r(n))return o(n);var e=[];for(var t in Object(n))i.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var r=t(204)(Object.keys,Object);n.exports=r},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var r=t(206),o=t(40),i=t(207),a=t(84),s=t(208),c=t(14),l=t(74),p=l(r),u=l(o),d=l(i),f=l(a),m=l(s),h=c;(r&&"[object DataView]"!=h(new r(new ArrayBuffer(1)))||o&&"[object Map]"!=h(new o)||i&&"[object Promise]"!=h(i.resolve())||a&&"[object Set]"!=h(new a)||s&&"[object WeakMap]"!=h(new s))&&(h=function(n){var e=c(n),t="[object Object]"==e?n.constructor:void 0,r=t?l(t):"";if(r)switch(r){case p:return"[object DataView]";case u:return"[object Map]";case d:return"[object Promise]";case f:return"[object Set]";case m:return"[object WeakMap]"}return e}),n.exports=h},function(n,e,t){var r=t(10)(t(8),"DataView");n.exports=r},function(n,e,t){var r=t(10)(t(8),"Promise");n.exports=r},function(n,e,t){var r=t(10)(t(8),"WeakMap");n.exports=r},function(n,e,t){var r=t(85),o=t(79);n.exports=function(n){for(var e=o(n),t=e.length;t--;){var i=e[t],a=n[i];e[t]=[i,a,r(a)]}return e}},function(n,e,t){var r=t(75),o=t(211),i=t(218),a=t(45),s=t(85),c=t(86),l=t(25);n.exports=function(n,e){return a(n)&&s(e)?c(l(n),e):function(t){var a=o(t,n);return void 0===a&&a===e?i(t,n):r(e,a,3)}}},function(n,e,t){var r=t(87);n.exports=function(n,e,t){var o=null==n?void 0:r(n,e);return void 0===o?t:o}},function(n,e,t){var r=t(213),o=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,i=/\\(\\)?/g,a=r((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(o,(function(n,t,r,o){e.push(r?o.replace(i,"$1"):t||n)})),e}));n.exports=a},function(n,e,t){var r=t(214);n.exports=function(n){var e=r(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var r=t(42);function o(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var r=arguments,o=e?e.apply(this,r):r[0],i=t.cache;if(i.has(o))return i.get(o);var a=n.apply(this,r);return t.cache=i.set(o,a)||i,a};return t.cache=new(o.Cache||r),t}o.Cache=r,n.exports=o},function(n,e,t){var r=t(216);n.exports=function(n){return null==n?"":r(n)}},function(n,e,t){var r=t(16),o=t(217),i=t(6),a=t(46),s=r?r.prototype:void 0,c=s?s.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(i(e))return o(e,n)+"";if(a(e))return c?c.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,o=Array(r);++t<r;)o[t]=e(n[t],t,n);return o}},function(n,e,t){var r=t(219),o=t(220);n.exports=function(n,e){return null!=n&&o(n,e,r)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var r=t(88),o=t(39),i=t(6),a=t(81),s=t(44),c=t(25);n.exports=function(n,e,t){for(var l=-1,p=(e=r(e,n)).length,u=!1;++l<p;){var d=c(e[l]);if(!(u=null!=n&&t(n,d)))break;n=n[d]}return u||++l!=p?u:!!(p=null==n?0:n.length)&&s(p)&&a(d,p)&&(i(n)||o(n))}},function(n,e,t){var r=t(222),o=t(223),i=t(45),a=t(25);n.exports=function(n){return i(n)?r(a(n)):o(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var r=t(87);n.exports=function(n){return function(e){return r(e,n)}}},function(n,e,t){var r=t(47),o=t(225),i=t(227);n.exports=function(n,e){return i(o(n,e,r),n+"")}},function(n,e,t){var r=t(226),o=Math.max;n.exports=function(n,e,t){return e=o(void 0===e?n.length-1:e,0),function(){for(var i=arguments,a=-1,s=o(i.length-e,0),c=Array(s);++a<s;)c[a]=i[e+a];a=-1;for(var l=Array(e+1);++a<e;)l[a]=i[a];return l[e]=t(c),r(n,this,l)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var r=t(228),o=t(231)(r);n.exports=o},function(n,e,t){var r=t(229),o=t(230),i=t(47),a=o?function(n,e){return o(n,"toString",{configurable:!0,enumerable:!1,value:r(e),writable:!0})}:i;n.exports=a},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var r=t(10),o=function(){try{var n=r(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=o},function(n,e){var t=Date.now;n.exports=function(n){var e=0,r=0;return function(){var o=t(),i=16-(o-r);if(r=o,i>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var r=t(77),o=t(233),i=t(238),a=t(78),s=t(239),c=t(43);n.exports=function(n,e,t){var l=-1,p=o,u=n.length,d=!0,f=[],m=f;if(t)d=!1,p=i;else if(u>=200){var h=e?null:s(n);if(h)return c(h);d=!1,p=a,m=new r}else m=e?[]:f;n:for(;++l<u;){var g=n[l],k=e?e(g):g;if(g=t||0!==g?g:0,d&&k==k){for(var b=m.length;b--;)if(m[b]===k)continue n;e&&m.push(k),f.push(g)}else p(m,k,t)||(m!==f&&m.push(k),f.push(g))}return f}},function(n,e,t){var r=t(234);n.exports=function(n,e){return!!(null==n?0:n.length)&&r(n,e,0)>-1}},function(n,e,t){var r=t(235),o=t(236),i=t(237);n.exports=function(n,e,t){return e==e?i(n,e,t):r(n,o,t)}},function(n,e){n.exports=function(n,e,t,r){for(var o=n.length,i=t+(r?1:-1);r?i--:++i<o;)if(e(n[i],i,n))return i;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var r=t-1,o=n.length;++r<o;)if(n[r]===e)return r;return-1}},function(n,e){n.exports=function(n,e,t){for(var r=-1,o=null==n?0:n.length;++r<o;)if(t(e,n[r]))return!0;return!1}},function(n,e,t){var r=t(84),o=t(240),i=t(43),a=r&&1/i(new r([,-0]))[1]==1/0?function(n){return new r(n)}:o;n.exports=a},function(n,e){n.exports=function(){}},function(n,e,t){var r=t(83),o=t(12);n.exports=function(n){return o(n)&&r(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(89)},function(n,e,t){"use strict";t(90)},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";var r=t(18),o=t(0),i=t(250);r({global:!0},{Reflect:{}}),i(o.Reflect,"Reflect",!0)},function(n,e,t){"use strict";var r=t(13).f,o=t(7),i=t(20)("toStringTag");n.exports=function(n,e,t){n&&!t&&(n=n.prototype),n&&!o(n,i)&&r(n,i,{configurable:!0,value:e})}},function(n,e){},function(n,e){function t(n,e){for(var t=0,r=n.length-1;r>=0;r--){var o=n[r];"."===o?n.splice(r,1):".."===o?(n.splice(r,1),t++):t&&(n.splice(r,1),t--)}if(e)for(;t--;t)n.unshift("..");return n}function r(n,e){if(n.filter)return n.filter(e);for(var t=[],r=0;r<n.length;r++)e(n[r],r,n)&&t.push(n[r]);return t}e.resolve=function(){for(var n="",e=!1,o=arguments.length-1;o>=-1&&!e;o--){var i=o>=0?arguments[o]:process.cwd();if("string"!=typeof i)throw new TypeError("Arguments to path.resolve must be strings");i&&(n=i+"/"+n,e="/"===i.charAt(0))}return(e?"/":"")+(n=t(r(n.split("/"),(function(n){return!!n})),!e).join("/"))||"."},e.normalize=function(n){var i=e.isAbsolute(n),a="/"===o(n,-1);return(n=t(r(n.split("/"),(function(n){return!!n})),!i).join("/"))||i||(n="."),n&&a&&(n+="/"),(i?"/":"")+n},e.isAbsolute=function(n){return"/"===n.charAt(0)},e.join=function(){var n=Array.prototype.slice.call(arguments,0);return e.normalize(r(n,(function(n,e){if("string"!=typeof n)throw new TypeError("Arguments to path.join must be strings");return n})).join("/"))},e.relative=function(n,t){function r(n){for(var e=0;e<n.length&&""===n[e];e++);for(var t=n.length-1;t>=0&&""===n[t];t--);return e>t?[]:n.slice(e,t-e+1)}n=e.resolve(n).substr(1),t=e.resolve(t).substr(1);for(var o=r(n.split("/")),i=r(t.split("/")),a=Math.min(o.length,i.length),s=a,c=0;c<a;c++)if(o[c]!==i[c]){s=c;break}var l=[];for(c=s;c<o.length;c++)l.push("..");return(l=l.concat(i.slice(s))).join("/")},e.sep="/",e.delimiter=":",e.dirname=function(n){if("string"!=typeof n&&(n+=""),0===n.length)return".";for(var e=n.charCodeAt(0),t=47===e,r=-1,o=!0,i=n.length-1;i>=1;--i)if(47===(e=n.charCodeAt(i))){if(!o){r=i;break}}else o=!1;return-1===r?t?"/":".":t&&1===r?"/":n.slice(0,r)},e.basename=function(n,e){var t=function(n){"string"!=typeof n&&(n+="");var e,t=0,r=-1,o=!0;for(e=n.length-1;e>=0;--e)if(47===n.charCodeAt(e)){if(!o){t=e+1;break}}else-1===r&&(o=!1,r=e+1);return-1===r?"":n.slice(t,r)}(n);return e&&t.substr(-1*e.length)===e&&(t=t.substr(0,t.length-e.length)),t},e.extname=function(n){"string"!=typeof n&&(n+="");for(var e=-1,t=0,r=-1,o=!0,i=0,a=n.length-1;a>=0;--a){var s=n.charCodeAt(a);if(47!==s)-1===r&&(o=!1,r=a+1),46===s?-1===e?e=a:1!==i&&(i=1):-1!==e&&(i=-1);else if(!o){t=a+1;break}}return-1===e||-1===r||0===i||1===i&&e===r-1&&e===t+1?"":n.slice(e,r)};var o="b"==="ab".substr(-1)?function(n,e,t){return n.substr(e,t)}:function(n,e,t){return e<0&&(e=n.length+e),n.substr(e,t)}},function(n,e,t){"use strict";var r=/[|\\{}()[\]^$+*?.]/g,o=Object.prototype.hasOwnProperty,i=function(n,e){return o.apply(n,[e])};e.escapeRegExpChars=function(n){return n?String(n).replace(r,"\\$&"):""};var a={"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&#34;","'":"&#39;"},s=/[&<>'"]/g;function c(n){return a[n]||n}function l(){return Function.prototype.toString.call(this)+';\nvar _ENCODE_HTML_RULES = {\n      "&": "&amp;"\n    , "<": "&lt;"\n    , ">": "&gt;"\n    , \'"\': "&#34;"\n    , "\'": "&#39;"\n    }\n  , _MATCH_HTML = /[&<>\'"]/g;\nfunction encode_char(c) {\n  return _ENCODE_HTML_RULES[c] || c;\n};\n'}e.escapeXML=function(n){return null==n?"":String(n).replace(s,c)};try{"function"==typeof Object.defineProperty?Object.defineProperty(e.escapeXML,"toString",{value:l}):e.escapeXML.toString=l}catch(n){console.warn("Unable to set escapeXML.toString (is the Function prototype frozen?)")}e.shallowCopy=function(n,e){if(e=e||{},null!=n)for(var t in e)i(e,t)&&"__proto__"!==t&&"constructor"!==t&&(n[t]=e[t]);return n},e.shallowCopyFromList=function(n,e,t){if(t=t||[],e=e||{},null!=n)for(var r=0;r<t.length;r++){var o=t[r];if(void 0!==e[o]){if(!i(e,o))continue;if("__proto__"===o||"constructor"===o)continue;n[o]=e[o]}}return n},e.cache={_data:{},set:function(n,e){this._data[n]=e},get:function(n){return this._data[n]},remove:function(n){delete this._data[n]},reset:function(){this._data={}}},e.hyphenToCamel=function(n){return n.replace(/-[a-z]/g,(function(n){return n[1].toUpperCase()}))},e.createNullProtoObjWherePossible="function"==typeof Object.create?function(){return Object.create(null)}:{__proto__:null}instanceof Object?function(){return{}}:function(){return{__proto__:null}}},function(n){n.exports=JSON.parse('{"name":"ejs","description":"Embedded JavaScript templates","keywords":["template","engine","ejs"],"version":"3.1.9","author":"Matthew Eernisse <mde@fleegix.org> (http://fleegix.org)","license":"Apache-2.0","bin":{"ejs":"./bin/cli.js"},"main":"./lib/ejs.js","jsdelivr":"ejs.min.js","unpkg":"ejs.min.js","repository":{"type":"git","url":"git://github.com/mde/ejs.git"},"bugs":"https://github.com/mde/ejs/issues","homepage":"https://github.com/mde/ejs","dependencies":{"jake":"^10.8.5"},"devDependencies":{"browserify":"^16.5.1","eslint":"^6.8.0","git-directory-deploy":"^1.5.1","jsdoc":"^4.0.2","lru-cache":"^4.0.1","mocha":"^10.2.0","uglify-js":"^3.3.16"},"engines":{"node":">=0.10.0"},"scripts":{"test":"mocha -u tdd"}}')},function(n,e,t){"use strict";t(91)},function(n,e,t){"use strict";t(92)},function(n,e,t){"use strict";t.r(e);
/*!
 * Vue.js v2.7.15
 * (c) 2014-2023 Evan You
 * Released under the MIT License.
 */
var r=Object.freeze({}),o=Array.isArray;function i(n){return null==n}function a(n){return null!=n}function s(n){return!0===n}function c(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function l(n){return"function"==typeof n}function p(n){return null!==n&&"object"==typeof n}var u=Object.prototype.toString;function d(n){return"[object Object]"===u.call(n)}function f(n){return"[object RegExp]"===u.call(n)}function m(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function h(n){return a(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function g(n){return null==n?"":Array.isArray(n)||d(n)&&n.toString===u?JSON.stringify(n,null,2):String(n)}function k(n){var e=parseFloat(n);return isNaN(e)?n:e}function b(n,e){for(var t=Object.create(null),r=n.split(","),o=0;o<r.length;o++)t[r[o]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}b("slot,component",!0);var v=b("key,ref,slot,slot-scope,is");function y(n,e){var t=n.length;if(t){if(e===n[t-1])return void(n.length=t-1);var r=n.indexOf(e);if(r>-1)return n.splice(r,1)}}var x=Object.prototype.hasOwnProperty;function _(n,e){return x.call(n,e)}function S(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var E=/-(\w)/g,w=S((function(n){return n.replace(E,(function(n,e){return e?e.toUpperCase():""}))})),C=S((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),T=/\B([A-Z])/g,z=S((function(n){return n.replace(T,"-$1").toLowerCase()}));var A=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var r=arguments.length;return r?r>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function P(n,e){e=e||0;for(var t=n.length-e,r=new Array(t);t--;)r[t]=n[t+e];return r}function O(n,e){for(var t in e)n[t]=e[t];return n}function I(n){for(var e={},t=0;t<n.length;t++)n[t]&&O(e,n[t]);return e}function R(n,e,t){}var M=function(n,e,t){return!1},j=function(n){return n};function L(n,e){if(n===e)return!0;var t=p(n),r=p(e);if(!t||!r)return!t&&!r&&String(n)===String(e);try{var o=Array.isArray(n),i=Array.isArray(e);if(o&&i)return n.length===e.length&&n.every((function(n,t){return L(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(o||i)return!1;var a=Object.keys(n),s=Object.keys(e);return a.length===s.length&&a.every((function(t){return L(n[t],e[t])}))}catch(n){return!1}}function B(n,e){for(var t=0;t<n.length;t++)if(L(n[t],e))return t;return-1}function K(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}function N(n,e){return n===e?0===n&&1/n!=1/e:n==n||e==e}var D=["component","directive","filter"],$=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],F={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:M,isReservedAttr:M,isUnknownElement:M,getTagNamespace:R,parsePlatformTagName:j,mustUseProp:M,async:!0,_lifecycleHooks:$},q=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function U(n){var e=(n+"").charCodeAt(0);return 36===e||95===e}function Q(n,e,t,r){Object.defineProperty(n,e,{value:t,enumerable:!!r,writable:!0,configurable:!0})}var J=new RegExp("[^".concat(q.source,".$_\\d]"));var V="__proto__"in{},Z="undefined"!=typeof window,H=Z&&window.navigator.userAgent.toLowerCase(),G=H&&/msie|trident/.test(H),W=H&&H.indexOf("msie 9.0")>0,X=H&&H.indexOf("edge/")>0;H&&H.indexOf("android");var Y=H&&/iphone|ipad|ipod|ios/.test(H);H&&/chrome\/\d+/.test(H),H&&/phantomjs/.test(H);var nn,en=H&&H.match(/firefox\/(\d+)/),tn={}.watch,rn=!1;if(Z)try{var on={};Object.defineProperty(on,"passive",{get:function(){rn=!0}}),window.addEventListener("test-passive",null,on)}catch(n){}var an=function(){return void 0===nn&&(nn=!Z&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),nn},sn=Z&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function cn(n){return"function"==typeof n&&/native code/.test(n.toString())}var ln,pn="undefined"!=typeof Symbol&&cn(Symbol)&&"undefined"!=typeof Reflect&&cn(Reflect.ownKeys);ln="undefined"!=typeof Set&&cn(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var un=null;function dn(n){void 0===n&&(n=null),n||un&&un._scope.off(),un=n,n&&n._scope.on()}var fn=function(){function n(n,e,t,r,o,i,a,s){this.tag=n,this.data=e,this.children=t,this.text=r,this.elm=o,this.ns=void 0,this.context=i,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=a,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(n.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),n}(),mn=function(n){void 0===n&&(n="");var e=new fn;return e.text=n,e.isComment=!0,e};function hn(n){return new fn(void 0,void 0,void 0,String(n))}function gn(n){var e=new fn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}var kn=0,bn=[],vn=function(){function n(){this._pending=!1,this.id=kn++,this.subs=[]}return n.prototype.addSub=function(n){this.subs.push(n)},n.prototype.removeSub=function(n){this.subs[this.subs.indexOf(n)]=null,this._pending||(this._pending=!0,bn.push(this))},n.prototype.depend=function(e){n.target&&n.target.addDep(this)},n.prototype.notify=function(n){var e=this.subs.filter((function(n){return n}));for(var t=0,r=e.length;t<r;t++){0,e[t].update()}},n}();vn.target=null;var yn=[];function xn(n){yn.push(n),vn.target=n}function _n(){yn.pop(),vn.target=yn[yn.length-1]}var Sn=Array.prototype,En=Object.create(Sn);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=Sn[n];Q(En,n,(function(){for(var t=[],r=0;r<arguments.length;r++)t[r]=arguments[r];var o,i=e.apply(this,t),a=this.__ob__;switch(n){case"push":case"unshift":o=t;break;case"splice":o=t.slice(2)}return o&&a.observeArray(o),a.dep.notify(),i}))}));var wn=Object.getOwnPropertyNames(En),Cn={},Tn=!0;function zn(n){Tn=n}var An={notify:R,depend:R,addSub:R,removeSub:R},Pn=function(){function n(n,e,t){if(void 0===e&&(e=!1),void 0===t&&(t=!1),this.value=n,this.shallow=e,this.mock=t,this.dep=t?An:new vn,this.vmCount=0,Q(n,"__ob__",this),o(n)){if(!t)if(V)n.__proto__=En;else for(var r=0,i=wn.length;r<i;r++){Q(n,s=wn[r],En[s])}e||this.observeArray(n)}else{var a=Object.keys(n);for(r=0;r<a.length;r++){var s;In(n,s=a[r],Cn,void 0,e,t)}}}return n.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)On(n[e],!1,this.mock)},n}();function On(n,e,t){return n&&_(n,"__ob__")&&n.__ob__ instanceof Pn?n.__ob__:!Tn||!t&&an()||!o(n)&&!d(n)||!Object.isExtensible(n)||n.__v_skip||Nn(n)||n instanceof fn?void 0:new Pn(n,e,t)}function In(n,e,t,r,i,a){var s=new vn,c=Object.getOwnPropertyDescriptor(n,e);if(!c||!1!==c.configurable){var l=c&&c.get,p=c&&c.set;l&&!p||t!==Cn&&2!==arguments.length||(t=n[e]);var u=!i&&On(t,!1,a);return Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=l?l.call(n):t;return vn.target&&(s.depend(),u&&(u.dep.depend(),o(e)&&jn(e))),Nn(e)&&!i?e.value:e},set:function(e){var r=l?l.call(n):t;if(N(r,e)){if(p)p.call(n,e);else{if(l)return;if(!i&&Nn(r)&&!Nn(e))return void(r.value=e);t=e}u=!i&&On(e,!1,a),s.notify()}}}),s}}function Rn(n,e,t){if(!Kn(n)){var r=n.__ob__;return o(n)&&m(e)?(n.length=Math.max(n.length,e),n.splice(e,1,t),r&&!r.shallow&&r.mock&&On(t,!1,!0),t):e in n&&!(e in Object.prototype)?(n[e]=t,t):n._isVue||r&&r.vmCount?t:r?(In(r.value,e,t,void 0,r.shallow,r.mock),r.dep.notify(),t):(n[e]=t,t)}}function Mn(n,e){if(o(n)&&m(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||Kn(n)||_(n,e)&&(delete n[e],t&&t.dep.notify())}}function jn(n){for(var e=void 0,t=0,r=n.length;t<r;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),o(e)&&jn(e)}function Ln(n){return Bn(n,!0),Q(n,"__v_isShallow",!0),n}function Bn(n,e){if(!Kn(n)){On(n,e,an());0}}function Kn(n){return!(!n||!n.__v_isReadonly)}function Nn(n){return!(!n||!0!==n.__v_isRef)}function Dn(n,e,t){Object.defineProperty(n,t,{enumerable:!0,configurable:!0,get:function(){var n=e[t];if(Nn(n))return n.value;var r=n&&n.__ob__;return r&&r.dep.depend(),n},set:function(n){var r=e[t];Nn(r)&&!Nn(n)?r.value=n:e[t]=n}})}"".concat("watcher"," callback"),"".concat("watcher"," getter"),"".concat("watcher"," cleanup");var $n;var Fn=function(){function n(n){void 0===n&&(n=!1),this.detached=n,this.active=!0,this.effects=[],this.cleanups=[],this.parent=$n,!n&&$n&&(this.index=($n.scopes||($n.scopes=[])).push(this)-1)}return n.prototype.run=function(n){if(this.active){var e=$n;try{return $n=this,n()}finally{$n=e}}else 0},n.prototype.on=function(){$n=this},n.prototype.off=function(){$n=this.parent},n.prototype.stop=function(n){if(this.active){var e=void 0,t=void 0;for(e=0,t=this.effects.length;e<t;e++)this.effects[e].teardown();for(e=0,t=this.cleanups.length;e<t;e++)this.cleanups[e]();if(this.scopes)for(e=0,t=this.scopes.length;e<t;e++)this.scopes[e].stop(!0);if(!this.detached&&this.parent&&!n){var r=this.parent.scopes.pop();r&&r!==this&&(this.parent.scopes[this.index]=r,r.index=this.index)}this.parent=void 0,this.active=!1}},n}();function qn(n){var e=n._provided,t=n.$parent&&n.$parent._provided;return t===e?n._provided=Object.create(t):e}var Un=S((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),r="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=r?n.slice(1):n,once:t,capture:r,passive:e}}));function Qn(n,e){function t(){var n=t.fns;if(!o(n))return Te(n,null,arguments,e,"v-on handler");for(var r=n.slice(),i=0;i<r.length;i++)Te(r[i],null,arguments,e,"v-on handler")}return t.fns=n,t}function Jn(n,e,t,r,o,a){var c,l,p,u;for(c in n)l=n[c],p=e[c],u=Un(c),i(l)||(i(p)?(i(l.fns)&&(l=n[c]=Qn(l,a)),s(u.once)&&(l=n[c]=o(u.name,l,u.capture)),t(u.name,l,u.capture,u.passive,u.params)):l!==p&&(p.fns=l,n[c]=p));for(c in e)i(n[c])&&r((u=Un(c)).name,e[c],u.capture)}function Vn(n,e,t){var r;n instanceof fn&&(n=n.data.hook||(n.data.hook={}));var o=n[e];function c(){t.apply(this,arguments),y(r.fns,c)}i(o)?r=Qn([c]):a(o.fns)&&s(o.merged)?(r=o).fns.push(c):r=Qn([o,c]),r.merged=!0,n[e]=r}function Zn(n,e,t,r,o){if(a(e)){if(_(e,t))return n[t]=e[t],o||delete e[t],!0;if(_(e,r))return n[t]=e[r],o||delete e[r],!0}return!1}function Hn(n){return c(n)?[hn(n)]:o(n)?function n(e,t){var r,l,p,u,d=[];for(r=0;r<e.length;r++)i(l=e[r])||"boolean"==typeof l||(p=d.length-1,u=d[p],o(l)?l.length>0&&(Gn((l=n(l,"".concat(t||"","_").concat(r)))[0])&&Gn(u)&&(d[p]=hn(u.text+l[0].text),l.shift()),d.push.apply(d,l)):c(l)?Gn(u)?d[p]=hn(u.text+l):""!==l&&d.push(hn(l)):Gn(l)&&Gn(u)?d[p]=hn(u.text+l.text):(s(e._isVList)&&a(l.tag)&&i(l.key)&&a(t)&&(l.key="__vlist".concat(t,"_").concat(r,"__")),d.push(l)));return d}(n):void 0}function Gn(n){return a(n)&&a(n.text)&&!1===n.isComment}function Wn(n,e){var t,r,i,s,c=null;if(o(n)||"string"==typeof n)for(c=new Array(n.length),t=0,r=n.length;t<r;t++)c[t]=e(n[t],t);else if("number"==typeof n)for(c=new Array(n),t=0;t<n;t++)c[t]=e(t+1,t);else if(p(n))if(pn&&n[Symbol.iterator]){c=[];for(var l=n[Symbol.iterator](),u=l.next();!u.done;)c.push(e(u.value,c.length)),u=l.next()}else for(i=Object.keys(n),c=new Array(i.length),t=0,r=i.length;t<r;t++)s=i[t],c[t]=e(n[s],s,t);return a(c)||(c=[]),c._isVList=!0,c}function Xn(n,e,t,r){var o,i=this.$scopedSlots[n];i?(t=t||{},r&&(t=O(O({},r),t)),o=i(t)||(l(e)?e():e)):o=this.$slots[n]||(l(e)?e():e);var a=t&&t.slot;return a?this.$createElement("template",{slot:a},o):o}function Yn(n){return Pt(this.$options,"filters",n,!0)||j}function ne(n,e){return o(n)?-1===n.indexOf(e):n!==e}function ee(n,e,t,r,o){var i=F.keyCodes[e]||t;return o&&r&&!F.keyCodes[e]?ne(o,r):i?ne(i,n):r?z(r)!==e:void 0===n}function te(n,e,t,r,i){if(t)if(p(t)){o(t)&&(t=I(t));var a=void 0,s=function(o){if("class"===o||"style"===o||v(o))a=n;else{var s=n.attrs&&n.attrs.type;a=r||F.mustUseProp(e,s,o)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var c=w(o),l=z(o);c in a||l in a||(a[o]=t[o],i&&((n.on||(n.on={}))["update:".concat(o)]=function(n){t[o]=n}))};for(var c in t)s(c)}else;return n}function re(n,e){var t=this._staticTrees||(this._staticTrees=[]),r=t[n];return r&&!e||ie(r=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,this._c,this),"__static__".concat(n),!1),r}function oe(n,e,t){return ie(n,"__once__".concat(e).concat(t?"_".concat(t):""),!0),n}function ie(n,e,t){if(o(n))for(var r=0;r<n.length;r++)n[r]&&"string"!=typeof n[r]&&ae(n[r],"".concat(e,"_").concat(r),t);else ae(n,e,t)}function ae(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function se(n,e){if(e)if(d(e)){var t=n.on=n.on?O({},n.on):{};for(var r in e){var o=t[r],i=e[r];t[r]=o?[].concat(o,i):i}}else;return n}function ce(n,e,t,r){e=e||{$stable:!t};for(var i=0;i<n.length;i++){var a=n[i];o(a)?ce(a,e,t):a&&(a.proxy&&(a.fn.proxy=!0),e[a.key]=a.fn)}return r&&(e.$key=r),e}function le(n,e){for(var t=0;t<e.length;t+=2){var r=e[t];"string"==typeof r&&r&&(n[e[t]]=e[t+1])}return n}function pe(n,e){return"string"==typeof n?e+n:n}function ue(n){n._o=oe,n._n=k,n._s=g,n._l=Wn,n._t=Xn,n._q=L,n._i=B,n._m=re,n._f=Yn,n._k=ee,n._b=te,n._v=hn,n._e=mn,n._u=ce,n._g=se,n._d=le,n._p=pe}function de(n,e){if(!n||!n.length)return{};for(var t={},r=0,o=n.length;r<o;r++){var i=n[r],a=i.data;if(a&&a.attrs&&a.attrs.slot&&delete a.attrs.slot,i.context!==e&&i.fnContext!==e||!a||null==a.slot)(t.default||(t.default=[])).push(i);else{var s=a.slot,c=t[s]||(t[s]=[]);"template"===i.tag?c.push.apply(c,i.children||[]):c.push(i)}}for(var l in t)t[l].every(fe)&&delete t[l];return t}function fe(n){return n.isComment&&!n.asyncFactory||" "===n.text}function me(n){return n.isComment&&n.asyncFactory}function he(n,e,t,o){var i,a=Object.keys(t).length>0,s=e?!!e.$stable:!a,c=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(s&&o&&o!==r&&c===o.$key&&!a&&!o.$hasNormal)return o;for(var l in i={},e)e[l]&&"$"!==l[0]&&(i[l]=ge(n,t,l,e[l]))}else i={};for(var p in t)p in i||(i[p]=ke(t,p));return e&&Object.isExtensible(e)&&(e._normalized=i),Q(i,"$stable",s),Q(i,"$key",c),Q(i,"$hasNormal",a),i}function ge(n,e,t,r){var i=function(){var e=un;dn(n);var t=arguments.length?r.apply(null,arguments):r({}),i=(t=t&&"object"==typeof t&&!o(t)?[t]:Hn(t))&&t[0];return dn(e),t&&(!i||1===t.length&&i.isComment&&!me(i))?void 0:t};return r.proxy&&Object.defineProperty(e,t,{get:i,enumerable:!0,configurable:!0}),i}function ke(n,e){return function(){return n[e]}}function be(n){return{get attrs(){if(!n._attrsProxy){var e=n._attrsProxy={};Q(e,"_v_attr_proxy",!0),ve(e,n.$attrs,r,n,"$attrs")}return n._attrsProxy},get listeners(){n._listenersProxy||ve(n._listenersProxy={},n.$listeners,r,n,"$listeners");return n._listenersProxy},get slots(){return function(n){n._slotsProxy||xe(n._slotsProxy={},n.$scopedSlots);return n._slotsProxy}(n)},emit:A(n.$emit,n),expose:function(e){e&&Object.keys(e).forEach((function(t){return Dn(n,e,t)}))}}}function ve(n,e,t,r,o){var i=!1;for(var a in e)a in n?e[a]!==t[a]&&(i=!0):(i=!0,ye(n,a,r,o));for(var a in n)a in e||(i=!0,delete n[a]);return i}function ye(n,e,t,r){Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){return t[r][e]}})}function xe(n,e){for(var t in e)n[t]=e[t];for(var t in n)t in e||delete n[t]}var _e=null;function Se(n,e){return(n.__esModule||pn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),p(n)?e.extend(n):n}function Ee(n){if(o(n))for(var e=0;e<n.length;e++){var t=n[e];if(a(t)&&(a(t.componentOptions)||me(t)))return t}}function we(n,e,t,r,u,d){return(o(t)||c(t))&&(u=r,r=t,t=void 0),s(d)&&(u=2),function(n,e,t,r,c){if(a(t)&&a(t.__ob__))return mn();a(t)&&a(t.is)&&(e=t.is);if(!e)return mn();0;o(r)&&l(r[0])&&((t=t||{}).scopedSlots={default:r[0]},r.length=0);2===c?r=Hn(r):1===c&&(r=function(n){for(var e=0;e<n.length;e++)if(o(n[e]))return Array.prototype.concat.apply([],n);return n}(r));var u,d;if("string"==typeof e){var f=void 0;d=n.$vnode&&n.$vnode.ns||F.getTagNamespace(e),u=F.isReservedTag(e)?new fn(F.parsePlatformTagName(e),t,r,void 0,void 0,n):t&&t.pre||!a(f=Pt(n.$options,"components",e))?new fn(e,t,r,void 0,void 0,n):yt(f,t,n,r,e)}else u=yt(e,t,n,r);return o(u)?u:a(u)?(a(d)&&function n(e,t,r){e.ns=t,"foreignObject"===e.tag&&(t=void 0,r=!0);if(a(e.children))for(var o=0,c=e.children.length;o<c;o++){var l=e.children[o];a(l.tag)&&(i(l.ns)||s(r)&&"svg"!==l.tag)&&n(l,t,r)}}(u,d),a(t)&&function(n){p(n.style)&&Fe(n.style);p(n.class)&&Fe(n.class)}(t),u):mn()}(n,e,t,r,u)}function Ce(n,e,t){xn();try{if(e)for(var r=e;r=r.$parent;){var o=r.$options.errorCaptured;if(o)for(var i=0;i<o.length;i++)try{if(!1===o[i].call(r,n,e,t))return}catch(n){ze(n,r,"errorCaptured hook")}}ze(n,e,t)}finally{_n()}}function Te(n,e,t,r,o){var i;try{(i=t?n.apply(e,t):n.call(e))&&!i._isVue&&h(i)&&!i._handled&&(i.catch((function(n){return Ce(n,r,o+" (Promise/async)")})),i._handled=!0)}catch(n){Ce(n,r,o)}return i}function ze(n,e,t){if(F.errorHandler)try{return F.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Ae(e,null,"config.errorHandler")}Ae(n,e,t)}function Ae(n,e,t){if(!Z||"undefined"==typeof console)throw n;console.error(n)}var Pe,Oe=!1,Ie=[],Re=!1;function Me(){Re=!1;var n=Ie.slice(0);Ie.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&cn(Promise)){var je=Promise.resolve();Pe=function(){je.then(Me),Y&&setTimeout(R)},Oe=!0}else if(G||"undefined"==typeof MutationObserver||!cn(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Pe="undefined"!=typeof setImmediate&&cn(setImmediate)?function(){setImmediate(Me)}:function(){setTimeout(Me,0)};else{var Le=1,Be=new MutationObserver(Me),Ke=document.createTextNode(String(Le));Be.observe(Ke,{characterData:!0}),Pe=function(){Le=(Le+1)%2,Ke.data=String(Le)},Oe=!0}function Ne(n,e){var t;if(Ie.push((function(){if(n)try{n.call(e)}catch(n){Ce(n,e,"nextTick")}else t&&t(e)})),Re||(Re=!0,Pe()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}function De(n){return function(e,t){if(void 0===t&&(t=un),t)return function(n,e,t){var r=n.$options;r[e]=Ct(r[e],t)}(t,n,e)}}De("beforeMount"),De("mounted"),De("beforeUpdate"),De("updated"),De("beforeDestroy"),De("destroyed"),De("activated"),De("deactivated"),De("serverPrefetch"),De("renderTracked"),De("renderTriggered"),De("errorCaptured");var $e=new ln;function Fe(n){return function n(e,t){var r,i,a=o(e);if(!a&&!p(e)||e.__v_skip||Object.isFrozen(e)||e instanceof fn)return;if(e.__ob__){var s=e.__ob__.dep.id;if(t.has(s))return;t.add(s)}if(a)for(r=e.length;r--;)n(e[r],t);else if(Nn(e))n(e.value,t);else for(i=Object.keys(e),r=i.length;r--;)n(e[i[r]],t)}(n,$e),$e.clear(),n}var qe,Ue=0,Qe=function(){function n(n,e,t,r,o){var i,a;i=this,void 0===(a=$n&&!$n._vm?$n:n?n._scope:void 0)&&(a=$n),a&&a.active&&a.effects.push(i),(this.vm=n)&&o&&(n._watcher=this),r?(this.deep=!!r.deep,this.user=!!r.user,this.lazy=!!r.lazy,this.sync=!!r.sync,this.before=r.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++Ue,this.active=!0,this.post=!1,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new ln,this.newDepIds=new ln,this.expression="",l(e)?this.getter=e:(this.getter=function(n){if(!J.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=R)),this.value=this.lazy?void 0:this.get()}return n.prototype.get=function(){var n;xn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;Ce(n,e,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&Fe(n),_n(),this.cleanupDeps()}return n},n.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},n.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},n.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():dt(this)},n.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||p(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'.concat(this.expression,'"');Te(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},n.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},n.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},n.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&y(this.vm._scope.effects,this),this.active){for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},n}();function Je(n,e){qe.$on(n,e)}function Ve(n,e){qe.$off(n,e)}function Ze(n,e){var t=qe;return function r(){var o=e.apply(null,arguments);null!==o&&t.$off(n,r)}}function He(n,e,t){qe=n,Jn(e,t||{},Je,Ve,Ze,n),qe=void 0}var Ge=null;function We(n){var e=Ge;return Ge=n,function(){Ge=e}}function Xe(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function Ye(n,e){if(e){if(n._directInactive=!1,Xe(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)Ye(n.$children[t]);nt(n,"activated")}}function nt(n,e,t,r){void 0===r&&(r=!0),xn();var o=un,i=$n;r&&dn(n);var a=n.$options[e],s="".concat(e," hook");if(a)for(var c=0,l=a.length;c<l;c++)Te(a[c],n,t||null,n,s);n._hasHookEvent&&n.$emit("hook:"+e),r&&(dn(o),i&&i.on()),_n()}var et=[],tt=[],rt={},ot=!1,it=!1,at=0;var st=0,ct=Date.now;if(Z&&!G){var lt=window.performance;lt&&"function"==typeof lt.now&&ct()>document.createEvent("Event").timeStamp&&(ct=function(){return lt.now()})}var pt=function(n,e){if(n.post){if(!e.post)return 1}else if(e.post)return-1;return n.id-e.id};function ut(){var n,e;for(st=ct(),it=!0,et.sort(pt),at=0;at<et.length;at++)(n=et[at]).before&&n.before(),e=n.id,rt[e]=null,n.run();var t=tt.slice(),r=et.slice();at=et.length=tt.length=0,rt={},ot=it=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,Ye(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],r=t.vm;r&&r._watcher===t&&r._isMounted&&!r._isDestroyed&&nt(r,"updated")}}(r),function(){for(var n=0;n<bn.length;n++){var e=bn[n];e.subs=e.subs.filter((function(n){return n})),e._pending=!1}bn.length=0}(),sn&&F.devtools&&sn.emit("flush")}function dt(n){var e=n.id;if(null==rt[e]&&(n!==vn.target||!n.noRecurse)){if(rt[e]=!0,it){for(var t=et.length-1;t>at&&et[t].id>n.id;)t--;et.splice(t+1,0,n)}else et.push(n);ot||(ot=!0,Ne(ut))}}function ft(n,e){if(n){for(var t=Object.create(null),r=pn?Reflect.ownKeys(n):Object.keys(n),o=0;o<r.length;o++){var i=r[o];if("__ob__"!==i){var a=n[i].from;if(a in e._provided)t[i]=e._provided[a];else if("default"in n[i]){var s=n[i].default;t[i]=l(s)?s.call(e):s}else 0}}return t}}function mt(n,e,t,i,a){var c,l=this,p=a.options;_(i,"_uid")?(c=Object.create(i))._original=i:(c=i,i=i._original);var u=s(p._compiled),d=!u;this.data=n,this.props=e,this.children=t,this.parent=i,this.listeners=n.on||r,this.injections=ft(p.inject,i),this.slots=function(){return l.$slots||he(i,n.scopedSlots,l.$slots=de(t,i)),l.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return he(i,n.scopedSlots,this.slots())}}),u&&(this.$options=p,this.$slots=this.slots(),this.$scopedSlots=he(i,n.scopedSlots,this.$slots)),p._scopeId?this._c=function(n,e,t,r){var a=we(c,n,e,t,r,d);return a&&!o(a)&&(a.fnScopeId=p._scopeId,a.fnContext=i),a}:this._c=function(n,e,t,r){return we(c,n,e,t,r,d)}}function ht(n,e,t,r,o){var i=gn(n);return i.fnContext=t,i.fnOptions=r,e.slot&&((i.data||(i.data={})).slot=e.slot),i}function gt(n,e){for(var t in e)n[w(t)]=e[t]}function kt(n){return n.name||n.__name||n._componentTag}ue(mt.prototype);var bt={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;bt.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},r=n.data.inlineTemplate;a(r)&&(t.render=r.render,t.staticRenderFns=r.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,Ge)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,o,i){var a=o.data.scopedSlots,s=n.$scopedSlots,c=!!(a&&!a.$stable||s!==r&&!s.$stable||a&&n.$scopedSlots.$key!==a.$key||!a&&n.$scopedSlots.$key),l=!!(i||n.$options._renderChildren||c),p=n.$vnode;n.$options._parentVnode=o,n.$vnode=o,n._vnode&&(n._vnode.parent=o),n.$options._renderChildren=i;var u=o.data.attrs||r;n._attrsProxy&&ve(n._attrsProxy,u,p.data&&p.data.attrs||r,n,"$attrs")&&(l=!0),n.$attrs=u,t=t||r;var d=n.$options._parentListeners;if(n._listenersProxy&&ve(n._listenersProxy,t,d||r,n,"$listeners"),n.$listeners=n.$options._parentListeners=t,He(n,t,d),e&&n.$options.props){zn(!1);for(var f=n._props,m=n.$options._propKeys||[],h=0;h<m.length;h++){var g=m[h],k=n.$options.props;f[g]=Ot(g,k,e,n)}zn(!0),n.$options.propsData=e}l&&(n.$slots=de(i,o.context),n.$forceUpdate())}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,r=n.componentInstance;r._isMounted||(r._isMounted=!0,nt(r,"mounted")),n.data.keepAlive&&(t._isMounted?((e=r)._inactive=!1,tt.push(e)):Ye(r,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(!(t&&(e._directInactive=!0,Xe(e))||e._inactive)){e._inactive=!0;for(var r=0;r<e.$children.length;r++)n(e.$children[r]);nt(e,"deactivated")}}(e,!0):e.$destroy())}},vt=Object.keys(bt);function yt(n,e,t,c,l){if(!i(n)){var u=t.$options._base;if(p(n)&&(n=u.extend(n)),"function"==typeof n){var d;if(i(n.cid)&&void 0===(n=function(n,e){if(s(n.error)&&a(n.errorComp))return n.errorComp;if(a(n.resolved))return n.resolved;var t=_e;if(t&&a(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t),s(n.loading)&&a(n.loadingComp))return n.loadingComp;if(t&&!a(n.owners)){var r=n.owners=[t],o=!0,c=null,l=null;t.$on("hook:destroyed",(function(){return y(r,t)}));var u=function(n){for(var e=0,t=r.length;e<t;e++)r[e].$forceUpdate();n&&(r.length=0,null!==c&&(clearTimeout(c),c=null),null!==l&&(clearTimeout(l),l=null))},d=K((function(t){n.resolved=Se(t,e),o?r.length=0:u(!0)})),f=K((function(e){a(n.errorComp)&&(n.error=!0,u(!0))})),m=n(d,f);return p(m)&&(h(m)?i(n.resolved)&&m.then(d,f):h(m.component)&&(m.component.then(d,f),a(m.error)&&(n.errorComp=Se(m.error,e)),a(m.loading)&&(n.loadingComp=Se(m.loading,e),0===m.delay?n.loading=!0:c=setTimeout((function(){c=null,i(n.resolved)&&i(n.error)&&(n.loading=!0,u(!1))}),m.delay||200)),a(m.timeout)&&(l=setTimeout((function(){l=null,i(n.resolved)&&f(null)}),m.timeout)))),o=!1,n.loading?n.loadingComp:n.resolved}}(d=n,u)))return function(n,e,t,r,o){var i=mn();return i.asyncFactory=n,i.asyncMeta={data:e,context:t,children:r,tag:o},i}(d,e,t,c,l);e=e||{},Qt(n),a(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",r=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var i=e.on||(e.on={}),s=i[r],c=e.model.callback;a(s)?(o(s)?-1===s.indexOf(c):s!==c)&&(i[r]=[c].concat(s)):i[r]=c}(n.options,e);var f=function(n,e,t){var r=e.options.props;if(!i(r)){var o={},s=n.attrs,c=n.props;if(a(s)||a(c))for(var l in r){var p=z(l);Zn(o,c,l,p,!0)||Zn(o,s,l,p,!1)}return o}}(e,n);if(s(n.options.functional))return function(n,e,t,i,s){var c=n.options,l={},p=c.props;if(a(p))for(var u in p)l[u]=Ot(u,p,e||r);else a(t.attrs)&&gt(l,t.attrs),a(t.props)&&gt(l,t.props);var d=new mt(t,l,s,i,n),f=c.render.call(null,d._c,d);if(f instanceof fn)return ht(f,t,d.parent,c,d);if(o(f)){for(var m=Hn(f)||[],h=new Array(m.length),g=0;g<m.length;g++)h[g]=ht(m[g],t,d.parent,c,d);return h}}(n,f,e,t,c);var m=e.on;if(e.on=e.nativeOn,s(n.options.abstract)){var g=e.slot;e={},g&&(e.slot=g)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<vt.length;t++){var r=vt[t],o=e[r],i=bt[r];o===i||o&&o._merged||(e[r]=o?xt(i,o):i)}}(e);var k=kt(n.options)||l;return new fn("vue-component-".concat(n.cid).concat(k?"-".concat(k):""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:f,listeners:m,tag:l,children:c},d)}}}function xt(n,e){var t=function(t,r){n(t,r),e(t,r)};return t._merged=!0,t}var _t=R,St=F.optionMergeStrategies;function Et(n,e,t){if(void 0===t&&(t=!0),!e)return n;for(var r,o,i,a=pn?Reflect.ownKeys(e):Object.keys(e),s=0;s<a.length;s++)"__ob__"!==(r=a[s])&&(o=n[r],i=e[r],t&&_(n,r)?o!==i&&d(o)&&d(i)&&Et(o,i):Rn(n,r,i));return n}function wt(n,e,t){return t?function(){var r=l(e)?e.call(t,t):e,o=l(n)?n.call(t,t):n;return r?Et(r,o):o}:e?n?function(){return Et(l(e)?e.call(this,this):e,l(n)?n.call(this,this):n)}:e:n}function Ct(n,e){var t=e?n?n.concat(e):o(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function Tt(n,e,t,r){var o=Object.create(n||null);return e?O(o,e):o}St.data=function(n,e,t){return t?wt(n,e,t):e&&"function"!=typeof e?n:wt(n,e)},$.forEach((function(n){St[n]=Ct})),D.forEach((function(n){St[n+"s"]=Tt})),St.watch=function(n,e,t,r){if(n===tn&&(n=void 0),e===tn&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var i={};for(var a in O(i,n),e){var s=i[a],c=e[a];s&&!o(s)&&(s=[s]),i[a]=s?s.concat(c):o(c)?c:[c]}return i},St.props=St.methods=St.inject=St.computed=function(n,e,t,r){if(!n)return e;var o=Object.create(null);return O(o,n),e&&O(o,e),o},St.provide=function(n,e){return n?function(){var t=Object.create(null);return Et(t,l(n)?n.call(this):n),e&&Et(t,l(e)?e.call(this):e,!1),t}:e};var zt=function(n,e){return void 0===e?n:e};function At(n,e,t){if(l(e)&&(e=e.options),function(n,e){var t=n.props;if(t){var r,i,a={};if(o(t))for(r=t.length;r--;)"string"==typeof(i=t[r])&&(a[w(i)]={type:null});else if(d(t))for(var s in t)i=t[s],a[w(s)]=d(i)?i:{type:i};else 0;n.props=a}}(e),function(n,e){var t=n.inject;if(t){var r=n.inject={};if(o(t))for(var i=0;i<t.length;i++)r[t[i]]={from:t[i]};else if(d(t))for(var a in t){var s=t[a];r[a]=d(s)?O({from:a},s):{from:s}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var r=e[t];l(r)&&(e[t]={bind:r,update:r})}}(e),!e._base&&(e.extends&&(n=At(n,e.extends,t)),e.mixins))for(var r=0,i=e.mixins.length;r<i;r++)n=At(n,e.mixins[r],t);var a,s={};for(a in n)c(a);for(a in e)_(n,a)||c(a);function c(r){var o=St[r]||zt;s[r]=o(n[r],e[r],t,r)}return s}function Pt(n,e,t,r){if("string"==typeof t){var o=n[e];if(_(o,t))return o[t];var i=w(t);if(_(o,i))return o[i];var a=C(i);return _(o,a)?o[a]:o[t]||o[i]||o[a]}}function Ot(n,e,t,r){var o=e[n],i=!_(t,n),a=t[n],s=jt(Boolean,o.type);if(s>-1)if(i&&!_(o,"default"))a=!1;else if(""===a||a===z(n)){var c=jt(String,o.type);(c<0||s<c)&&(a=!0)}if(void 0===a){a=function(n,e,t){if(!_(e,"default"))return;var r=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return l(r)&&"Function"!==Rt(e.type)?r.call(n):r}(r,o,n);var p=Tn;zn(!0),On(a),zn(p)}return a}var It=/^\s*function (\w+)/;function Rt(n){var e=n&&n.toString().match(It);return e?e[1]:""}function Mt(n,e){return Rt(n)===Rt(e)}function jt(n,e){if(!o(e))return Mt(e,n)?0:-1;for(var t=0,r=e.length;t<r;t++)if(Mt(e[t],n))return t;return-1}var Lt={enumerable:!0,configurable:!0,get:R,set:R};function Bt(n,e,t){Lt.get=function(){return this[e][t]},Lt.set=function(n){this[e][t]=n},Object.defineProperty(n,t,Lt)}function Kt(n){var e=n.$options;if(e.props&&function(n,e){var t=n.$options.propsData||{},r=n._props=Ln({}),o=n.$options._propKeys=[];n.$parent&&zn(!1);var i=function(i){o.push(i);var a=Ot(i,e,t,n);In(r,i,a),i in n||Bt(n,"_props",i)};for(var a in e)i(a);zn(!0)}(n,e.props),function(n){var e=n.$options,t=e.setup;if(t){var r=n._setupContext=be(n);dn(n),xn();var o=Te(t,null,[n._props||Ln({}),r],n,"setup");if(_n(),dn(),l(o))e.render=o;else if(p(o))if(n._setupState=o,o.__sfc){var i=n._setupProxy={};for(var a in o)"__sfc"!==a&&Dn(i,o,a)}else for(var a in o)U(a)||Dn(n,o,a);else 0}}(n),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?R:A(e[t],n)}(n,e.methods),e.data)!function(n){var e=n.$options.data;d(e=n._data=l(e)?function(n,e){xn();try{return n.call(e,e)}catch(n){return Ce(n,e,"data()"),{}}finally{_n()}}(e,n):e||{})||(e={});var t=Object.keys(e),r=n.$options.props,o=(n.$options.methods,t.length);for(;o--;){var i=t[o];0,r&&_(r,i)||U(i)||Bt(n,"_data",i)}var a=On(e);a&&a.vmCount++}(n);else{var t=On(n._data={});t&&t.vmCount++}e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),r=an();for(var o in e){var i=e[o],a=l(i)?i:i.get;0,r||(t[o]=new Qe(n,a||R,R,Nt)),o in n||Dt(n,o,i)}}(n,e.computed),e.watch&&e.watch!==tn&&function(n,e){for(var t in e){var r=e[t];if(o(r))for(var i=0;i<r.length;i++)qt(n,t,r[i]);else qt(n,t,r)}}(n,e.watch)}var Nt={lazy:!0};function Dt(n,e,t){var r=!an();l(t)?(Lt.get=r?$t(e):Ft(t),Lt.set=R):(Lt.get=t.get?r&&!1!==t.cache?$t(e):Ft(t.get):R,Lt.set=t.set||R),Object.defineProperty(n,e,Lt)}function $t(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),vn.target&&e.depend(),e.value}}function Ft(n){return function(){return n.call(this,this)}}function qt(n,e,t,r){return d(t)&&(r=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,r)}var Ut=0;function Qt(n){var e=n.options;if(n.super){var t=Qt(n.super);if(t!==n.superOptions){n.superOptions=t;var r=function(n){var e,t=n.options,r=n.sealedOptions;for(var o in t)t[o]!==r[o]&&(e||(e={}),e[o]=t[o]);return e}(n);r&&O(n.extendOptions,r),(e=n.options=At(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function Jt(n){this._init(n)}function Vt(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,r=t.cid,o=n._Ctor||(n._Ctor={});if(o[r])return o[r];var i=kt(n)||kt(t.options);var a=function(n){this._init(n)};return(a.prototype=Object.create(t.prototype)).constructor=a,a.cid=e++,a.options=At(t.options,n),a.super=t,a.options.props&&function(n){var e=n.options.props;for(var t in e)Bt(n.prototype,"_props",t)}(a),a.options.computed&&function(n){var e=n.options.computed;for(var t in e)Dt(n.prototype,t,e[t])}(a),a.extend=t.extend,a.mixin=t.mixin,a.use=t.use,D.forEach((function(n){a[n]=t[n]})),i&&(a.options.components[i]=a),a.superOptions=t.options,a.extendOptions=n,a.sealedOptions=O({},a.options),o[r]=a,a}}function Zt(n){return n&&(kt(n.Ctor.options)||n.tag)}function Ht(n,e){return o(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!f(n)&&n.test(e)}function Gt(n,e){var t=n.cache,r=n.keys,o=n._vnode;for(var i in t){var a=t[i];if(a){var s=a.name;s&&!e(s)&&Wt(t,i,r,o)}}}function Wt(n,e,t,r){var o=n[e];!o||r&&o.tag===r.tag||o.componentInstance.$destroy(),n[e]=null,y(t,e)}Jt.prototype._init=function(n){var e=this;e._uid=Ut++,e._isVue=!0,e.__v_skip=!0,e._scope=new Fn(!0),e._scope._vm=!0,n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),r=e._parentVnode;t.parent=e.parent,t._parentVnode=r;var o=r.componentOptions;t.propsData=o.propsData,t._parentListeners=o.listeners,t._renderChildren=o.children,t._componentTag=o.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=At(Qt(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._provided=t?t._provided:Object.create(null),n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&He(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,o=t&&t.context;n.$slots=de(e._renderChildren,o),n.$scopedSlots=t?he(n.$parent,t.data.scopedSlots,n.$slots):r,n._c=function(e,t,r,o){return we(n,e,t,r,o,!1)},n.$createElement=function(e,t,r,o){return we(n,e,t,r,o,!0)};var i=t&&t.data;In(n,"$attrs",i&&i.attrs||r,null,!0),In(n,"$listeners",e._parentListeners||r,null,!0)}(e),nt(e,"beforeCreate",void 0,!1),function(n){var e=ft(n.$options.inject,n);e&&(zn(!1),Object.keys(e).forEach((function(t){In(n,t,e[t])})),zn(!0))}(e),Kt(e),function(n){var e=n.$options.provide;if(e){var t=l(e)?e.call(n):e;if(!p(t))return;for(var r=qn(n),o=pn?Reflect.ownKeys(t):Object.keys(t),i=0;i<o.length;i++){var a=o[i];Object.defineProperty(r,a,Object.getOwnPropertyDescriptor(t,a))}}}(e),nt(e,"created"),e.$options.el&&e.$mount(e.$options.el)},function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=Rn,n.prototype.$delete=Mn,n.prototype.$watch=function(n,e,t){if(d(e))return qt(this,n,e,t);(t=t||{}).user=!0;var r=new Qe(this,n,e,t);if(t.immediate){var o='callback for immediate watcher "'.concat(r.expression,'"');xn(),Te(e,this,[r.value],this,o),_n()}return function(){r.teardown()}}}(Jt),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var r=this;if(o(n))for(var i=0,a=n.length;i<a;i++)r.$on(n[i],t);else(r._events[n]||(r._events[n]=[])).push(t),e.test(n)&&(r._hasHookEvent=!0);return r},n.prototype.$once=function(n,e){var t=this;function r(){t.$off(n,r),e.apply(t,arguments)}return r.fn=e,t.$on(n,r),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(o(n)){for(var r=0,i=n.length;r<i;r++)t.$off(n[r],e);return t}var a,s=t._events[n];if(!s)return t;if(!e)return t._events[n]=null,t;for(var c=s.length;c--;)if((a=s[c])===e||a.fn===e){s.splice(c,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?P(t):t;for(var r=P(arguments,1),o='event handler for "'.concat(n,'"'),i=0,a=t.length;i<a;i++)Te(t[i],e,r,e,o)}return e}}(Jt),function(n){n.prototype._update=function(n,e){var t=this,r=t.$el,o=t._vnode,i=We(t);t._vnode=n,t.$el=o?t.__patch__(o,n):t.__patch__(t.$el,n,e,!1),i(),r&&(r.__vue__=null),t.$el&&(t.$el.__vue__=t);for(var a=t;a&&a.$vnode&&a.$parent&&a.$vnode===a.$parent._vnode;)a.$parent.$el=a.$el,a=a.$parent},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){nt(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||y(e.$children,n),n._scope.stop(),n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),nt(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}(Jt),function(n){ue(n.prototype),n.prototype.$nextTick=function(n){return Ne(n,this)},n.prototype._render=function(){var n,e=this,t=e.$options,r=t.render,i=t._parentVnode;i&&e._isMounted&&(e.$scopedSlots=he(e.$parent,i.data.scopedSlots,e.$slots,e.$scopedSlots),e._slotsProxy&&xe(e._slotsProxy,e.$scopedSlots)),e.$vnode=i;try{dn(e),_e=e,n=r.call(e._renderProxy,e.$createElement)}catch(t){Ce(t,e,"render"),n=e._vnode}finally{_e=null,dn()}return o(n)&&1===n.length&&(n=n[0]),n instanceof fn||(n=mn()),n.parent=i,n}}(Jt);var Xt=[String,RegExp,Array],Yt={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Xt,exclude:Xt,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,r=this.keyToCache;if(t){var o=t.tag,i=t.componentInstance,a=t.componentOptions;n[r]={name:Zt(a),tag:o,componentInstance:i},e.push(r),this.max&&e.length>parseInt(this.max)&&Wt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Wt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Gt(n,(function(n){return Ht(e,n)}))})),this.$watch("exclude",(function(e){Gt(n,(function(n){return!Ht(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=Ee(n),t=e&&e.componentOptions;if(t){var r=Zt(t),o=this.include,i=this.exclude;if(o&&(!r||!Ht(o,r))||i&&r&&Ht(i,r))return e;var a=this.cache,s=this.keys,c=null==e.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):e.key;a[c]?(e.componentInstance=a[c].componentInstance,y(s,c),s.push(c)):(this.vnodeToCache=e,this.keyToCache=c),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return F}};Object.defineProperty(n,"config",e),n.util={warn:_t,extend:O,mergeOptions:At,defineReactive:In},n.set=Rn,n.delete=Mn,n.nextTick=Ne,n.observable=function(n){return On(n),n},n.options=Object.create(null),D.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,O(n.options.components,Yt),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=P(arguments,1);return t.unshift(this),l(n.install)?n.install.apply(n,t):l(n)&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=At(this.options,n),this}}(n),Vt(n),function(n){D.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&d(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&l(t)&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}(Jt),Object.defineProperty(Jt.prototype,"$isServer",{get:an}),Object.defineProperty(Jt.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Jt,"FunctionalRenderContext",{value:mt}),Jt.version="2.7.15";var nr=b("style,class"),er=b("input,textarea,option,select,progress"),tr=b("contenteditable,draggable,spellcheck"),rr=b("events,caret,typing,plaintext-only"),or=b("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),ir="http://www.w3.org/1999/xlink",ar=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},sr=function(n){return ar(n)?n.slice(6,n.length):""},cr=function(n){return null==n||!1===n};function lr(n){for(var e=n.data,t=n,r=n;a(r.componentInstance);)(r=r.componentInstance._vnode)&&r.data&&(e=pr(r.data,e));for(;a(t=t.parent);)t&&t.data&&(e=pr(e,t.data));return function(n,e){if(a(n)||a(e))return ur(n,dr(e));return""}(e.staticClass,e.class)}function pr(n,e){return{staticClass:ur(n.staticClass,e.staticClass),class:a(n.class)?[n.class,e.class]:e.class}}function ur(n,e){return n?e?n+" "+e:n:e||""}function dr(n){return Array.isArray(n)?function(n){for(var e,t="",r=0,o=n.length;r<o;r++)a(e=dr(n[r]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):p(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var fr={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},mr=b("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),hr=b("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),gr=function(n){return mr(n)||hr(n)};var kr=Object.create(null);var br=b("text,number,password,search,email,tel,url");var vr=Object.freeze({__proto__:null,createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(fr[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),yr={create:function(n,e){xr(e)},update:function(n,e){n.data.ref!==e.data.ref&&(xr(n,!0),xr(e))},destroy:function(n){xr(n,!0)}};function xr(n,e){var t=n.data.ref;if(a(t)){var r=n.context,i=n.componentInstance||n.elm,s=e?null:i,c=e?void 0:i;if(l(t))Te(t,r,[s],r,"template ref function");else{var p=n.data.refInFor,u="string"==typeof t||"number"==typeof t,d=Nn(t),f=r.$refs;if(u||d)if(p){var m=u?f[t]:t.value;e?o(m)&&y(m,i):o(m)?m.includes(i)||m.push(i):u?(f[t]=[i],_r(r,t,f[t])):t.value=[i]}else if(u){if(e&&f[t]!==i)return;f[t]=c,_r(r,t,s)}else if(d){if(e&&t.value!==i)return;t.value=s}else 0}}}function _r(n,e,t){var r=n._setupState;r&&_(r,e)&&(Nn(r[e])?r[e].value=t:r[e]=t)}var Sr=new fn("",{},[]),Er=["create","activate","update","remove","destroy"];function wr(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&a(n.data)===a(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,r=a(t=n.data)&&a(t=t.attrs)&&t.type,o=a(t=e.data)&&a(t=t.attrs)&&t.type;return r===o||br(r)&&br(o)}(n,e)||s(n.isAsyncPlaceholder)&&i(e.asyncFactory.error))}function Cr(n,e,t){var r,o,i={};for(r=e;r<=t;++r)a(o=n[r].key)&&(i[o]=r);return i}var Tr={create:zr,update:zr,destroy:function(n){zr(n,Sr)}};function zr(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,r,o,i=n===Sr,a=e===Sr,s=Pr(n.data.directives,n.context),c=Pr(e.data.directives,e.context),l=[],p=[];for(t in c)r=s[t],o=c[t],r?(o.oldValue=r.value,o.oldArg=r.arg,Ir(o,"update",e,n),o.def&&o.def.componentUpdated&&p.push(o)):(Ir(o,"bind",e,n),o.def&&o.def.inserted&&l.push(o));if(l.length){var u=function(){for(var t=0;t<l.length;t++)Ir(l[t],"inserted",e,n)};i?Vn(e,"insert",u):u()}p.length&&Vn(e,"postpatch",(function(){for(var t=0;t<p.length;t++)Ir(p[t],"componentUpdated",e,n)}));if(!i)for(t in s)c[t]||Ir(s[t],"unbind",n,n,a)}(n,e)}var Ar=Object.create(null);function Pr(n,e){var t,r,o=Object.create(null);if(!n)return o;for(t=0;t<n.length;t++){if((r=n[t]).modifiers||(r.modifiers=Ar),o[Or(r)]=r,e._setupState&&e._setupState.__sfc){var i=r.def||Pt(e,"_setupState","v-"+r.name);r.def="function"==typeof i?{bind:i,update:i}:i}r.def=r.def||Pt(e.$options,"directives",r.name)}return o}function Or(n){return n.rawName||"".concat(n.name,".").concat(Object.keys(n.modifiers||{}).join("."))}function Ir(n,e,t,r,o){var i=n.def&&n.def[e];if(i)try{i(t.elm,n,t,r,o)}catch(r){Ce(r,t.context,"directive ".concat(n.name," ").concat(e," hook"))}}var Rr=[yr,Tr];function Mr(n,e){var t=e.componentOptions;if(!(a(t)&&!1===t.Ctor.options.inheritAttrs||i(n.data.attrs)&&i(e.data.attrs))){var r,o,c=e.elm,l=n.data.attrs||{},p=e.data.attrs||{};for(r in(a(p.__ob__)||s(p._v_attr_proxy))&&(p=e.data.attrs=O({},p)),p)o=p[r],l[r]!==o&&jr(c,r,o,e.data.pre);for(r in(G||X)&&p.value!==l.value&&jr(c,"value",p.value),l)i(p[r])&&(ar(r)?c.removeAttributeNS(ir,sr(r)):tr(r)||c.removeAttribute(r))}}function jr(n,e,t,r){r||n.tagName.indexOf("-")>-1?Lr(n,e,t):or(e)?cr(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):tr(e)?n.setAttribute(e,function(n,e){return cr(e)||"false"===e?"false":"contenteditable"===n&&rr(e)?e:"true"}(e,t)):ar(e)?cr(t)?n.removeAttributeNS(ir,sr(e)):n.setAttributeNS(ir,e,t):Lr(n,e,t)}function Lr(n,e,t){if(cr(t))n.removeAttribute(e);else{if(G&&!W&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var r=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",r)};n.addEventListener("input",r),n.__ieph=!0}n.setAttribute(e,t)}}var Br={create:Mr,update:Mr};function Kr(n,e){var t=e.elm,r=e.data,o=n.data;if(!(i(r.staticClass)&&i(r.class)&&(i(o)||i(o.staticClass)&&i(o.class)))){var s=lr(e),c=t._transitionClasses;a(c)&&(s=ur(s,dr(c))),s!==t._prevClass&&(t.setAttribute("class",s),t._prevClass=s)}}var Nr,Dr={create:Kr,update:Kr};function $r(n,e,t){var r=Nr;return function o(){var i=e.apply(null,arguments);null!==i&&Ur(n,o,t,r)}}var Fr=Oe&&!(en&&Number(en[1])<=53);function qr(n,e,t,r){if(Fr){var o=st,i=e;e=i._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=o||n.timeStamp<=0||n.target.ownerDocument!==document)return i.apply(this,arguments)}}Nr.addEventListener(n,e,rn?{capture:t,passive:r}:t)}function Ur(n,e,t,r){(r||Nr).removeEventListener(n,e._wrapper||e,t)}function Qr(n,e){if(!i(n.data.on)||!i(e.data.on)){var t=e.data.on||{},r=n.data.on||{};Nr=e.elm||n.elm,function(n){if(a(n.__r)){var e=G?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}a(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),Jn(t,r,qr,Ur,$r,e.context),Nr=void 0}}var Jr,Vr={create:Qr,update:Qr,destroy:function(n){return Qr(n,Sr)}};function Zr(n,e){if(!i(n.data.domProps)||!i(e.data.domProps)){var t,r,o=e.elm,c=n.data.domProps||{},l=e.data.domProps||{};for(t in(a(l.__ob__)||s(l._v_attr_proxy))&&(l=e.data.domProps=O({},l)),c)t in l||(o[t]="");for(t in l){if(r=l[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),r===c[t])continue;1===o.childNodes.length&&o.removeChild(o.childNodes[0])}if("value"===t&&"PROGRESS"!==o.tagName){o._value=r;var p=i(r)?"":String(r);Hr(o,p)&&(o.value=p)}else if("innerHTML"===t&&hr(o.tagName)&&i(o.innerHTML)){(Jr=Jr||document.createElement("div")).innerHTML="<svg>".concat(r,"</svg>");for(var u=Jr.firstChild;o.firstChild;)o.removeChild(o.firstChild);for(;u.firstChild;)o.appendChild(u.firstChild)}else if(r!==c[t])try{o[t]=r}catch(n){}}}}function Hr(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,r=n._vModifiers;if(a(r)){if(r.number)return k(t)!==k(e);if(r.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Gr={create:Zr,update:Zr},Wr=S((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var r=n.split(t);r.length>1&&(e[r[0].trim()]=r[1].trim())}})),e}));function Xr(n){var e=Yr(n.style);return n.staticStyle?O(n.staticStyle,e):e}function Yr(n){return Array.isArray(n)?I(n):"string"==typeof n?Wr(n):n}var no,eo=/^--/,to=/\s*!important$/,ro=function(n,e,t){if(eo.test(e))n.style.setProperty(e,t);else if(to.test(t))n.style.setProperty(z(e),t.replace(to,""),"important");else{var r=io(e);if(Array.isArray(t))for(var o=0,i=t.length;o<i;o++)n.style[r]=t[o];else n.style[r]=t}},oo=["Webkit","Moz","ms"],io=S((function(n){if(no=no||document.createElement("div").style,"filter"!==(n=w(n))&&n in no)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<oo.length;t++){var r=oo[t]+e;if(r in no)return r}}));function ao(n,e){var t=e.data,r=n.data;if(!(i(t.staticStyle)&&i(t.style)&&i(r.staticStyle)&&i(r.style))){var o,s,c=e.elm,l=r.staticStyle,p=r.normalizedStyle||r.style||{},u=l||p,d=Yr(e.data.style)||{};e.data.normalizedStyle=a(d.__ob__)?O({},d):d;var f=function(n,e){var t,r={};if(e)for(var o=n;o.componentInstance;)(o=o.componentInstance._vnode)&&o.data&&(t=Xr(o.data))&&O(r,t);(t=Xr(n.data))&&O(r,t);for(var i=n;i=i.parent;)i.data&&(t=Xr(i.data))&&O(r,t);return r}(e,!0);for(s in u)i(f[s])&&ro(c,s,"");for(s in f)(o=f[s])!==u[s]&&ro(c,s,null==o?"":o)}}var so={create:ao,update:ao},co=/\s+/;function lo(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(co).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" ".concat(n.getAttribute("class")||""," ");t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function po(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(co).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" ".concat(n.getAttribute("class")||""," "),r=" "+e+" ";t.indexOf(r)>=0;)t=t.replace(r," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function uo(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&O(e,fo(n.name||"v")),O(e,n),e}return"string"==typeof n?fo(n):void 0}}var fo=S((function(n){return{enterClass:"".concat(n,"-enter"),enterToClass:"".concat(n,"-enter-to"),enterActiveClass:"".concat(n,"-enter-active"),leaveClass:"".concat(n,"-leave"),leaveToClass:"".concat(n,"-leave-to"),leaveActiveClass:"".concat(n,"-leave-active")}})),mo=Z&&!W,ho="transition",go="transitionend",ko="animation",bo="animationend";mo&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(ho="WebkitTransition",go="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(ko="WebkitAnimation",bo="webkitAnimationEnd"));var vo=Z?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function yo(n){vo((function(){vo(n)}))}function xo(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),lo(n,e))}function _o(n,e){n._transitionClasses&&y(n._transitionClasses,e),po(n,e)}function So(n,e,t){var r=wo(n,e),o=r.type,i=r.timeout,a=r.propCount;if(!o)return t();var s="transition"===o?go:bo,c=0,l=function(){n.removeEventListener(s,p),t()},p=function(e){e.target===n&&++c>=a&&l()};setTimeout((function(){c<a&&l()}),i+1),n.addEventListener(s,p)}var Eo=/\b(transform|all)(,|$)/;function wo(n,e){var t,r=window.getComputedStyle(n),o=(r[ho+"Delay"]||"").split(", "),i=(r[ho+"Duration"]||"").split(", "),a=Co(o,i),s=(r[ko+"Delay"]||"").split(", "),c=(r[ko+"Duration"]||"").split(", "),l=Co(s,c),p=0,u=0;return"transition"===e?a>0&&(t="transition",p=a,u=i.length):"animation"===e?l>0&&(t="animation",p=l,u=c.length):u=(t=(p=Math.max(a,l))>0?a>l?"transition":"animation":null)?"transition"===t?i.length:c.length:0,{type:t,timeout:p,propCount:u,hasTransform:"transition"===t&&Eo.test(r[ho+"Property"])}}function Co(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return To(e)+To(n[t])})))}function To(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function zo(n,e){var t=n.elm;a(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var r=uo(n.data.transition);if(!i(r)&&!a(t._enterCb)&&1===t.nodeType){for(var o=r.css,s=r.type,c=r.enterClass,u=r.enterToClass,d=r.enterActiveClass,f=r.appearClass,m=r.appearToClass,h=r.appearActiveClass,g=r.beforeEnter,b=r.enter,v=r.afterEnter,y=r.enterCancelled,x=r.beforeAppear,_=r.appear,S=r.afterAppear,E=r.appearCancelled,w=r.duration,C=Ge,T=Ge.$vnode;T&&T.parent;)C=T.context,T=T.parent;var z=!C._isMounted||!n.isRootInsert;if(!z||_||""===_){var A=z&&f?f:c,P=z&&h?h:d,O=z&&m?m:u,I=z&&x||g,R=z&&l(_)?_:b,M=z&&S||v,j=z&&E||y,L=k(p(w)?w.enter:w);0;var B=!1!==o&&!W,N=Oo(R),D=t._enterCb=K((function(){B&&(_o(t,O),_o(t,P)),D.cancelled?(B&&_o(t,A),j&&j(t)):M&&M(t),t._enterCb=null}));n.data.show||Vn(n,"insert",(function(){var e=t.parentNode,r=e&&e._pending&&e._pending[n.key];r&&r.tag===n.tag&&r.elm._leaveCb&&r.elm._leaveCb(),R&&R(t,D)})),I&&I(t),B&&(xo(t,A),xo(t,P),yo((function(){_o(t,A),D.cancelled||(xo(t,O),N||(Po(L)?setTimeout(D,L):So(t,s,D)))}))),n.data.show&&(e&&e(),R&&R(t,D)),B||N||D()}}}function Ao(n,e){var t=n.elm;a(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var r=uo(n.data.transition);if(i(r)||1!==t.nodeType)return e();if(!a(t._leaveCb)){var o=r.css,s=r.type,c=r.leaveClass,l=r.leaveToClass,u=r.leaveActiveClass,d=r.beforeLeave,f=r.leave,m=r.afterLeave,h=r.leaveCancelled,g=r.delayLeave,b=r.duration,v=!1!==o&&!W,y=Oo(f),x=k(p(b)?b.leave:b);0;var _=t._leaveCb=K((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),v&&(_o(t,l),_o(t,u)),_.cancelled?(v&&_o(t,c),h&&h(t)):(e(),m&&m(t)),t._leaveCb=null}));g?g(S):S()}function S(){_.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),d&&d(t),v&&(xo(t,c),xo(t,u),yo((function(){_o(t,c),_.cancelled||(xo(t,l),y||(Po(x)?setTimeout(_,x):So(t,s,_)))}))),f&&f(t,_),v||y||_())}}function Po(n){return"number"==typeof n&&!isNaN(n)}function Oo(n){if(i(n))return!1;var e=n.fns;return a(e)?Oo(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function Io(n,e){!0!==e.data.show&&zo(e)}var Ro=function(n){var e,t,r={},l=n.modules,p=n.nodeOps;for(e=0;e<Er.length;++e)for(r[Er[e]]=[],t=0;t<l.length;++t)a(l[t][Er[e]])&&r[Er[e]].push(l[t][Er[e]]);function u(n){var e=p.parentNode(n);a(e)&&p.removeChild(e,n)}function d(n,e,t,o,i,c,l){if(a(n.elm)&&a(c)&&(n=c[l]=gn(n)),n.isRootInsert=!i,!function(n,e,t,o){var i=n.data;if(a(i)){var c=a(n.componentInstance)&&i.keepAlive;if(a(i=i.hook)&&a(i=i.init)&&i(n,!1),a(n.componentInstance))return f(n,e),m(t,n.elm,o),s(c)&&function(n,e,t,o){var i,s=n;for(;s.componentInstance;)if(s=s.componentInstance._vnode,a(i=s.data)&&a(i=i.transition)){for(i=0;i<r.activate.length;++i)r.activate[i](Sr,s);e.push(s);break}m(t,n.elm,o)}(n,e,t,o),!0}}(n,e,t,o)){var u=n.data,d=n.children,g=n.tag;a(g)?(n.elm=n.ns?p.createElementNS(n.ns,g):p.createElement(g,n),v(n),h(n,d,e),a(u)&&k(n,e),m(t,n.elm,o)):s(n.isComment)?(n.elm=p.createComment(n.text),m(t,n.elm,o)):(n.elm=p.createTextNode(n.text),m(t,n.elm,o))}}function f(n,e){a(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,g(n)?(k(n,e),v(n)):(xr(n),e.push(n))}function m(n,e,t){a(n)&&(a(t)?p.parentNode(t)===n&&p.insertBefore(n,e,t):p.appendChild(n,e))}function h(n,e,t){if(o(e)){0;for(var r=0;r<e.length;++r)d(e[r],t,n.elm,null,!0,e,r)}else c(n.text)&&p.appendChild(n.elm,p.createTextNode(String(n.text)))}function g(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return a(n.tag)}function k(n,t){for(var o=0;o<r.create.length;++o)r.create[o](Sr,n);a(e=n.data.hook)&&(a(e.create)&&e.create(Sr,n),a(e.insert)&&t.push(n))}function v(n){var e;if(a(e=n.fnScopeId))p.setStyleScope(n.elm,e);else for(var t=n;t;)a(e=t.context)&&a(e=e.$options._scopeId)&&p.setStyleScope(n.elm,e),t=t.parent;a(e=Ge)&&e!==n.context&&e!==n.fnContext&&a(e=e.$options._scopeId)&&p.setStyleScope(n.elm,e)}function y(n,e,t,r,o,i){for(;r<=o;++r)d(t[r],i,n,e,!1,t,r)}function x(n){var e,t,o=n.data;if(a(o))for(a(e=o.hook)&&a(e=e.destroy)&&e(n),e=0;e<r.destroy.length;++e)r.destroy[e](n);if(a(e=n.children))for(t=0;t<n.children.length;++t)x(n.children[t])}function _(n,e,t){for(;e<=t;++e){var r=n[e];a(r)&&(a(r.tag)?(S(r),x(r)):u(r.elm))}}function S(n,e){if(a(e)||a(n.data)){var t,o=r.remove.length+1;for(a(e)?e.listeners+=o:e=function(n,e){function t(){0==--t.listeners&&u(n)}return t.listeners=e,t}(n.elm,o),a(t=n.componentInstance)&&a(t=t._vnode)&&a(t.data)&&S(t,e),t=0;t<r.remove.length;++t)r.remove[t](n,e);a(t=n.data.hook)&&a(t=t.remove)?t(n,e):e()}else u(n.elm)}function E(n,e,t,r){for(var o=t;o<r;o++){var i=e[o];if(a(i)&&wr(n,i))return o}}function w(n,e,t,o,c,l){if(n!==e){a(e.elm)&&a(o)&&(e=o[c]=gn(e));var u=e.elm=n.elm;if(s(n.isAsyncPlaceholder))a(e.asyncFactory.resolved)?z(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(s(e.isStatic)&&s(n.isStatic)&&e.key===n.key&&(s(e.isCloned)||s(e.isOnce)))e.componentInstance=n.componentInstance;else{var f,m=e.data;a(m)&&a(f=m.hook)&&a(f=f.prepatch)&&f(n,e);var h=n.children,k=e.children;if(a(m)&&g(e)){for(f=0;f<r.update.length;++f)r.update[f](n,e);a(f=m.hook)&&a(f=f.update)&&f(n,e)}i(e.text)?a(h)&&a(k)?h!==k&&function(n,e,t,r,o){var s,c,l,u=0,f=0,m=e.length-1,h=e[0],g=e[m],k=t.length-1,b=t[0],v=t[k],x=!o;for(0;u<=m&&f<=k;)i(h)?h=e[++u]:i(g)?g=e[--m]:wr(h,b)?(w(h,b,r,t,f),h=e[++u],b=t[++f]):wr(g,v)?(w(g,v,r,t,k),g=e[--m],v=t[--k]):wr(h,v)?(w(h,v,r,t,k),x&&p.insertBefore(n,h.elm,p.nextSibling(g.elm)),h=e[++u],v=t[--k]):wr(g,b)?(w(g,b,r,t,f),x&&p.insertBefore(n,g.elm,h.elm),g=e[--m],b=t[++f]):(i(s)&&(s=Cr(e,u,m)),i(c=a(b.key)?s[b.key]:E(b,e,u,m))?d(b,r,n,h.elm,!1,t,f):wr(l=e[c],b)?(w(l,b,r,t,f),e[c]=void 0,x&&p.insertBefore(n,l.elm,h.elm)):d(b,r,n,h.elm,!1,t,f),b=t[++f]);u>m?y(n,i(t[k+1])?null:t[k+1].elm,t,f,k,r):f>k&&_(e,u,m)}(u,h,k,t,l):a(k)?(a(n.text)&&p.setTextContent(u,""),y(u,null,k,0,k.length-1,t)):a(h)?_(h,0,h.length-1):a(n.text)&&p.setTextContent(u,""):n.text!==e.text&&p.setTextContent(u,e.text),a(m)&&a(f=m.hook)&&a(f=f.postpatch)&&f(n,e)}}}function C(n,e,t){if(s(t)&&a(n.parent))n.parent.data.pendingInsert=e;else for(var r=0;r<e.length;++r)e[r].data.hook.insert(e[r])}var T=b("attrs,class,staticClass,staticStyle,key");function z(n,e,t,r){var o,i=e.tag,c=e.data,l=e.children;if(r=r||c&&c.pre,e.elm=n,s(e.isComment)&&a(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(a(c)&&(a(o=c.hook)&&a(o=o.init)&&o(e,!0),a(o=e.componentInstance)))return f(e,t),!0;if(a(i)){if(a(l))if(n.hasChildNodes())if(a(o=c)&&a(o=o.domProps)&&a(o=o.innerHTML)){if(o!==n.innerHTML)return!1}else{for(var p=!0,u=n.firstChild,d=0;d<l.length;d++){if(!u||!z(u,l[d],t,r)){p=!1;break}u=u.nextSibling}if(!p||u)return!1}else h(e,l,t);if(a(c)){var m=!1;for(var g in c)if(!T(g)){m=!0,k(e,t);break}!m&&c.class&&Fe(c.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,o){if(!i(e)){var c,l=!1,u=[];if(i(n))l=!0,d(e,u);else{var f=a(n.nodeType);if(!f&&wr(n,e))w(n,e,u,null,null,o);else{if(f){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),s(t)&&z(n,e,u))return C(e,u,!0),n;c=n,n=new fn(p.tagName(c).toLowerCase(),{},[],void 0,c)}var m=n.elm,h=p.parentNode(m);if(d(e,u,m._leaveCb?null:h,p.nextSibling(m)),a(e.parent))for(var k=e.parent,b=g(e);k;){for(var v=0;v<r.destroy.length;++v)r.destroy[v](k);if(k.elm=e.elm,b){for(var y=0;y<r.create.length;++y)r.create[y](Sr,k);var S=k.data.hook.insert;if(S.merged)for(var E=S.fns.slice(1),T=0;T<E.length;T++)E[T]()}else xr(k);k=k.parent}a(h)?_([n],0,0):a(n.tag)&&x(n)}}return C(e,u,l),e.elm}a(n)&&x(n)}}({nodeOps:vr,modules:[Br,Dr,Vr,Gr,so,Z?{create:Io,activate:Io,remove:function(n,e){!0!==n.data.show?Ao(n,e):e()}}:{}].concat(Rr)});W&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&$o(n,"input")}));var Mo={inserted:function(n,e,t,r){"select"===t.tag?(r.elm&&!r.elm._vOptions?Vn(t,"postpatch",(function(){Mo.componentUpdated(n,e,t)})):jo(n,e,t.context),n._vOptions=[].map.call(n.options,Ko)):("textarea"===t.tag||br(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",No),n.addEventListener("compositionend",Do),n.addEventListener("change",Do),W&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){jo(n,e,t.context);var r=n._vOptions,o=n._vOptions=[].map.call(n.options,Ko);if(o.some((function(n,e){return!L(n,r[e])})))(n.multiple?e.value.some((function(n){return Bo(n,o)})):e.value!==e.oldValue&&Bo(e.value,o))&&$o(n,"change")}}};function jo(n,e,t){Lo(n,e,t),(G||X)&&setTimeout((function(){Lo(n,e,t)}),0)}function Lo(n,e,t){var r=e.value,o=n.multiple;if(!o||Array.isArray(r)){for(var i,a,s=0,c=n.options.length;s<c;s++)if(a=n.options[s],o)i=B(r,Ko(a))>-1,a.selected!==i&&(a.selected=i);else if(L(Ko(a),r))return void(n.selectedIndex!==s&&(n.selectedIndex=s));o||(n.selectedIndex=-1)}}function Bo(n,e){return e.every((function(e){return!L(e,n)}))}function Ko(n){return"_value"in n?n._value:n.value}function No(n){n.target.composing=!0}function Do(n){n.target.composing&&(n.target.composing=!1,$o(n.target,"input"))}function $o(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function Fo(n){return!n.componentInstance||n.data&&n.data.transition?n:Fo(n.componentInstance._vnode)}var qo={model:Mo,show:{bind:function(n,e,t){var r=e.value,o=(t=Fo(t)).data&&t.data.transition,i=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;r&&o?(t.data.show=!0,zo(t,(function(){n.style.display=i}))):n.style.display=r?i:"none"},update:function(n,e,t){var r=e.value;!r!=!e.oldValue&&((t=Fo(t)).data&&t.data.transition?(t.data.show=!0,r?zo(t,(function(){n.style.display=n.__vOriginalDisplay})):Ao(t,(function(){n.style.display="none"}))):n.style.display=r?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,r,o){o||(n.style.display=n.__vOriginalDisplay)}}},Uo={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Qo(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?Qo(Ee(e.children)):n}function Jo(n){var e={},t=n.$options;for(var r in t.propsData)e[r]=n[r];var o=t._parentListeners;for(var r in o)e[w(r)]=o[r];return e}function Vo(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Zo=function(n){return n.tag||me(n)},Ho=function(n){return"show"===n.name},Go={name:"transition",props:Uo,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Zo)).length){0;var r=this.mode;0;var o=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return o;var i=Qo(o);if(!i)return o;if(this._leaving)return Vo(n,o);var a="__transition-".concat(this._uid,"-");i.key=null==i.key?i.isComment?a+"comment":a+i.tag:c(i.key)?0===String(i.key).indexOf(a)?i.key:a+i.key:i.key;var s=(i.data||(i.data={})).transition=Jo(this),l=this._vnode,p=Qo(l);if(i.data.directives&&i.data.directives.some(Ho)&&(i.data.show=!0),p&&p.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(i,p)&&!me(p)&&(!p.componentInstance||!p.componentInstance._vnode.isComment)){var u=p.data.transition=O({},s);if("out-in"===r)return this._leaving=!0,Vn(u,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Vo(n,o);if("in-out"===r){if(me(i))return l;var d,f=function(){d()};Vn(s,"afterEnter",f),Vn(s,"enterCancelled",f),Vn(u,"delayLeave",(function(n){d=n}))}}return o}}},Wo=O({tag:String,moveClass:String},Uo);function Xo(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function Yo(n){n.data.newPos=n.elm.getBoundingClientRect()}function ni(n){var e=n.data.pos,t=n.data.newPos,r=e.left-t.left,o=e.top-t.top;if(r||o){n.data.moved=!0;var i=n.elm.style;i.transform=i.WebkitTransform="translate(".concat(r,"px,").concat(o,"px)"),i.transitionDuration="0s"}}delete Wo.mode;var ei={Transition:Go,TransitionGroup:{props:Wo,beforeMount:function(){var n=this,e=this._update;this._update=function(t,r){var o=We(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,o(),e.call(n,t,r)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),r=this.prevChildren=this.children,o=this.$slots.default||[],i=this.children=[],a=Jo(this),s=0;s<o.length;s++){if((p=o[s]).tag)if(null!=p.key&&0!==String(p.key).indexOf("__vlist"))i.push(p),t[p.key]=p,(p.data||(p.data={})).transition=a;else;}if(r){var c=[],l=[];for(s=0;s<r.length;s++){var p;(p=r[s]).data.transition=a,p.data.pos=p.elm.getBoundingClientRect(),t[p.key]?c.push(p):l.push(p)}this.kept=n(e,null,c),this.removed=l}return n(e,null,i)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Xo),n.forEach(Yo),n.forEach(ni),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,r=t.style;xo(t,e),r.transform=r.WebkitTransform=r.transitionDuration="",t.addEventListener(go,t._moveCb=function n(r){r&&r.target!==t||r&&!/transform$/.test(r.propertyName)||(t.removeEventListener(go,n),t._moveCb=null,_o(t,e))})}})))},methods:{hasMove:function(n,e){if(!mo)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){po(t,n)})),lo(t,e),t.style.display="none",this.$el.appendChild(t);var r=wo(t);return this.$el.removeChild(t),this._hasMove=r.hasTransform}}}};function ti(n,e){for(var t in e)n[t]=e[t];return n}Jt.config.mustUseProp=function(n,e,t){return"value"===t&&er(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},Jt.config.isReservedTag=gr,Jt.config.isReservedAttr=nr,Jt.config.getTagNamespace=function(n){return hr(n)?"svg":"math"===n?"math":void 0},Jt.config.isUnknownElement=function(n){if(!Z)return!0;if(gr(n))return!1;if(n=n.toLowerCase(),null!=kr[n])return kr[n];var e=document.createElement(n);return n.indexOf("-")>-1?kr[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:kr[n]=/HTMLUnknownElement/.test(e.toString())},O(Jt.options.directives,qo),O(Jt.options.components,ei),Jt.prototype.__patch__=Z?Ro:R,Jt.prototype.$mount=function(n,e){return function(n,e,t){var r;n.$el=e,n.$options.render||(n.$options.render=mn),nt(n,"beforeMount"),r=function(){n._update(n._render(),t)},new Qe(n,r,R,{before:function(){n._isMounted&&!n._isDestroyed&&nt(n,"beforeUpdate")}},!0),t=!1;var o=n._preWatchers;if(o)for(var i=0;i<o.length;i++)o[i].run();return null==n.$vnode&&(n._isMounted=!0,nt(n,"mounted")),n}(this,n=n&&Z?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},Z&&setTimeout((function(){F.devtools&&sn&&sn.emit("init",Jt)}),0);var ri=/[!'()*]/g,oi=function(n){return"%"+n.charCodeAt(0).toString(16)},ii=/%2C/g,ai=function(n){return encodeURIComponent(n).replace(ri,oi).replace(ii,",")};function si(n){try{return decodeURIComponent(n)}catch(n){0}return n}var ci=function(n){return null==n||"object"==typeof n?n:String(n)};function li(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),r=si(t.shift()),o=t.length>0?si(t.join("=")):null;void 0===e[r]?e[r]=o:Array.isArray(e[r])?e[r].push(o):e[r]=[e[r],o]})),e):e}function pi(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return ai(e);if(Array.isArray(t)){var r=[];return t.forEach((function(n){void 0!==n&&(null===n?r.push(ai(e)):r.push(ai(e)+"="+ai(n)))})),r.join("&")}return ai(e)+"="+ai(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var ui=/\/?$/;function di(n,e,t,r){var o=r&&r.options.stringifyQuery,i=e.query||{};try{i=fi(i)}catch(n){}var a={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:i,params:e.params||{},fullPath:gi(e,o),matched:n?hi(n):[]};return t&&(a.redirectedFrom=gi(t,o)),Object.freeze(a)}function fi(n){if(Array.isArray(n))return n.map(fi);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=fi(n[t]);return e}return n}var mi=di(null,{path:"/"});function hi(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function gi(n,e){var t=n.path,r=n.query;void 0===r&&(r={});var o=n.hash;return void 0===o&&(o=""),(t||"/")+(e||pi)(r)+o}function ki(n,e,t){return e===mi?n===e:!!e&&(n.path&&e.path?n.path.replace(ui,"")===e.path.replace(ui,"")&&(t||n.hash===e.hash&&bi(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&bi(n.query,e.query)&&bi(n.params,e.params))))}function bi(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),r=Object.keys(e).sort();return t.length===r.length&&t.every((function(t,o){var i=n[t];if(r[o]!==t)return!1;var a=e[t];return null==i||null==a?i===a:"object"==typeof i&&"object"==typeof a?bi(i,a):String(i)===String(a)}))}function vi(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var r in t.instances){var o=t.instances[r],i=t.enteredCbs[r];if(o&&i){delete t.enteredCbs[r];for(var a=0;a<i.length;a++)o._isBeingDestroyed||i[a](o)}}}}var yi={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,r=e.children,o=e.parent,i=e.data;i.routerView=!0;for(var a=o.$createElement,s=t.name,c=o.$route,l=o._routerViewCache||(o._routerViewCache={}),p=0,u=!1;o&&o._routerRoot!==o;){var d=o.$vnode?o.$vnode.data:{};d.routerView&&p++,d.keepAlive&&o._directInactive&&o._inactive&&(u=!0),o=o.$parent}if(i.routerViewDepth=p,u){var f=l[s],m=f&&f.component;return m?(f.configProps&&xi(m,i,f.route,f.configProps),a(m,i,r)):a()}var h=c.matched[p],g=h&&h.components[s];if(!h||!g)return l[s]=null,a();l[s]={component:g},i.registerRouteInstance=function(n,e){var t=h.instances[s];(e&&t!==n||!e&&t===n)&&(h.instances[s]=e)},(i.hook||(i.hook={})).prepatch=function(n,e){h.instances[s]=e.componentInstance},i.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==h.instances[s]&&(h.instances[s]=n.componentInstance),vi(c)};var k=h.props&&h.props[s];return k&&(ti(l[s],{route:c,configProps:k}),xi(g,i,c,k)),a(g,i,r)}};function xi(n,e,t,r){var o=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,r);if(o){o=e.props=ti({},o);var i=e.attrs=e.attrs||{};for(var a in o)n.props&&a in n.props||(i[a]=o[a],delete o[a])}}function _i(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var o=e.split("/");t&&o[o.length-1]||o.pop();for(var i=n.replace(/^\//,"").split("/"),a=0;a<i.length;a++){var s=i[a];".."===s?o.pop():"."!==s&&o.push(s)}return""!==o[0]&&o.unshift(""),o.join("/")}function Si(n){return n.replace(/\/(?:\s*\/)+/g,"/")}var Ei=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},wi=Ni,Ci=Oi,Ti=function(n,e){return Ri(Oi(n,e),e)},zi=Ri,Ai=Ki,Pi=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function Oi(n,e){for(var t,r=[],o=0,i=0,a="",s=e&&e.delimiter||"/";null!=(t=Pi.exec(n));){var c=t[0],l=t[1],p=t.index;if(a+=n.slice(i,p),i=p+c.length,l)a+=l[1];else{var u=n[i],d=t[2],f=t[3],m=t[4],h=t[5],g=t[6],k=t[7];a&&(r.push(a),a="");var b=null!=d&&null!=u&&u!==d,v="+"===g||"*"===g,y="?"===g||"*"===g,x=t[2]||s,_=m||h;r.push({name:f||o++,prefix:d||"",delimiter:x,optional:y,repeat:v,partial:b,asterisk:!!k,pattern:_?ji(_):k?".*":"[^"+Mi(x)+"]+?"})}}return i<n.length&&(a+=n.substr(i)),a&&r.push(a),r}function Ii(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function Ri(n,e){for(var t=new Array(n.length),r=0;r<n.length;r++)"object"==typeof n[r]&&(t[r]=new RegExp("^(?:"+n[r].pattern+")$",Bi(e)));return function(e,r){for(var o="",i=e||{},a=(r||{}).pretty?Ii:encodeURIComponent,s=0;s<n.length;s++){var c=n[s];if("string"!=typeof c){var l,p=i[c.name];if(null==p){if(c.optional){c.partial&&(o+=c.prefix);continue}throw new TypeError('Expected "'+c.name+'" to be defined')}if(Ei(p)){if(!c.repeat)throw new TypeError('Expected "'+c.name+'" to not repeat, but received `'+JSON.stringify(p)+"`");if(0===p.length){if(c.optional)continue;throw new TypeError('Expected "'+c.name+'" to not be empty')}for(var u=0;u<p.length;u++){if(l=a(p[u]),!t[s].test(l))throw new TypeError('Expected all "'+c.name+'" to match "'+c.pattern+'", but received `'+JSON.stringify(l)+"`");o+=(0===u?c.prefix:c.delimiter)+l}}else{if(l=c.asterisk?encodeURI(p).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):a(p),!t[s].test(l))throw new TypeError('Expected "'+c.name+'" to match "'+c.pattern+'", but received "'+l+'"');o+=c.prefix+l}}else o+=c}return o}}function Mi(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function ji(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function Li(n,e){return n.keys=e,n}function Bi(n){return n&&n.sensitive?"":"i"}function Ki(n,e,t){Ei(e)||(t=e||t,e=[]);for(var r=(t=t||{}).strict,o=!1!==t.end,i="",a=0;a<n.length;a++){var s=n[a];if("string"==typeof s)i+=Mi(s);else{var c=Mi(s.prefix),l="(?:"+s.pattern+")";e.push(s),s.repeat&&(l+="(?:"+c+l+")*"),i+=l=s.optional?s.partial?c+"("+l+")?":"(?:"+c+"("+l+"))?":c+"("+l+")"}}var p=Mi(t.delimiter||"/"),u=i.slice(-p.length)===p;return r||(i=(u?i.slice(0,-p.length):i)+"(?:"+p+"(?=$))?"),i+=o?"$":r&&u?"":"(?="+p+"|$)",Li(new RegExp("^"+i,Bi(t)),e)}function Ni(n,e,t){return Ei(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var r=0;r<t.length;r++)e.push({name:r,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return Li(n,e)}(n,e):Ei(n)?function(n,e,t){for(var r=[],o=0;o<n.length;o++)r.push(Ni(n[o],e,t).source);return Li(new RegExp("(?:"+r.join("|")+")",Bi(t)),e)}(n,e,t):function(n,e,t){return Ki(Oi(n,t),e,t)}(n,e,t)}wi.parse=Ci,wi.compile=Ti,wi.tokensToFunction=zi,wi.tokensToRegExp=Ai;var Di=Object.create(null);function $i(n,e,t){e=e||{};try{var r=Di[n]||(Di[n]=wi.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),r(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function Fi(n,e,t,r){var o="string"==typeof n?{path:n}:n;if(o._normalized)return o;if(o.name){var i=(o=ti({},n)).params;return i&&"object"==typeof i&&(o.params=ti({},i)),o}if(!o.path&&o.params&&e){(o=ti({},o))._normalized=!0;var a=ti(ti({},e.params),o.params);if(e.name)o.name=e.name,o.params=a;else if(e.matched.length){var s=e.matched[e.matched.length-1].path;o.path=$i(s,a,e.path)}else 0;return o}var c=function(n){var e="",t="",r=n.indexOf("#");r>=0&&(e=n.slice(r),n=n.slice(0,r));var o=n.indexOf("?");return o>=0&&(t=n.slice(o+1),n=n.slice(0,o)),{path:n,query:t,hash:e}}(o.path||""),l=e&&e.path||"/",p=c.path?_i(c.path,l,t||o.append):l,u=function(n,e,t){void 0===e&&(e={});var r,o=t||li;try{r=o(n||"")}catch(n){r={}}for(var i in e){var a=e[i];r[i]=Array.isArray(a)?a.map(ci):ci(a)}return r}(c.query,o.query,r&&r.options.parseQuery),d=o.hash||c.hash;return d&&"#"!==d.charAt(0)&&(d="#"+d),{_normalized:!0,path:p,query:u,hash:d}}var qi,Ui=function(){},Qi={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,r=this.$route,o=t.resolve(this.to,r,this.append),i=o.location,a=o.route,s=o.href,c={},l=t.options.linkActiveClass,p=t.options.linkExactActiveClass,u=null==l?"router-link-active":l,d=null==p?"router-link-exact-active":p,f=null==this.activeClass?u:this.activeClass,m=null==this.exactActiveClass?d:this.exactActiveClass,h=a.redirectedFrom?di(null,Fi(a.redirectedFrom),null,t):a;c[m]=ki(r,h,this.exactPath),c[f]=this.exact||this.exactPath?c[m]:function(n,e){return 0===n.path.replace(ui,"/").indexOf(e.path.replace(ui,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(r,h);var g=c[m]?this.ariaCurrentValue:null,k=function(n){Ji(n)&&(e.replace?t.replace(i,Ui):t.push(i,Ui))},b={click:Ji};Array.isArray(this.event)?this.event.forEach((function(n){b[n]=k})):b[this.event]=k;var v={class:c},y=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:s,route:a,navigate:k,isActive:c[f],isExactActive:c[m]});if(y){if(1===y.length)return y[0];if(y.length>1||!y.length)return 0===y.length?n():n("span",{},y)}if("a"===this.tag)v.on=b,v.attrs={href:s,"aria-current":g};else{var x=function n(e){var t;if(e)for(var r=0;r<e.length;r++){if("a"===(t=e[r]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(x){x.isStatic=!1;var _=x.data=ti({},x.data);for(var S in _.on=_.on||{},_.on){var E=_.on[S];S in b&&(_.on[S]=Array.isArray(E)?E:[E])}for(var w in b)w in _.on?_.on[w].push(b[w]):_.on[w]=k;var C=x.data.attrs=ti({},x.data.attrs);C.href=s,C["aria-current"]=g}else v.on=b}return n(this.tag,v,this.$slots.default)}};function Ji(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Vi="undefined"!=typeof window;function Zi(n,e,t,r,o){var i=e||[],a=t||Object.create(null),s=r||Object.create(null);n.forEach((function(n){!function n(e,t,r,o,i,a){var s=o.path,c=o.name;0;var l=o.pathToRegexpOptions||{},p=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return Si(e.path+"/"+n)}(s,i,l.strict);"boolean"==typeof o.caseSensitive&&(l.sensitive=o.caseSensitive);var u={path:p,regex:Hi(p,l),components:o.components||{default:o.component},alias:o.alias?"string"==typeof o.alias?[o.alias]:o.alias:[],instances:{},enteredCbs:{},name:c,parent:i,matchAs:a,redirect:o.redirect,beforeEnter:o.beforeEnter,meta:o.meta||{},props:null==o.props?{}:o.components?o.props:{default:o.props}};o.children&&o.children.forEach((function(o){var i=a?Si(a+"/"+o.path):void 0;n(e,t,r,o,u,i)}));t[u.path]||(e.push(u.path),t[u.path]=u);if(void 0!==o.alias)for(var d=Array.isArray(o.alias)?o.alias:[o.alias],f=0;f<d.length;++f){0;var m={path:d[f],children:o.children};n(e,t,r,m,i,u.path||"/")}c&&(r[c]||(r[c]=u))}(i,a,s,n,o)}));for(var c=0,l=i.length;c<l;c++)"*"===i[c]&&(i.push(i.splice(c,1)[0]),l--,c--);return{pathList:i,pathMap:a,nameMap:s}}function Hi(n,e){return wi(n,[],e)}function Gi(n,e){var t=Zi(n),r=t.pathList,o=t.pathMap,i=t.nameMap;function a(n,t,a){var s=Fi(n,t,!1,e),l=s.name;if(l){var p=i[l];if(!p)return c(null,s);var u=p.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var d in t.params)!(d in s.params)&&u.indexOf(d)>-1&&(s.params[d]=t.params[d]);return s.path=$i(p.path,s.params),c(p,s,a)}if(s.path){s.params={};for(var f=0;f<r.length;f++){var m=r[f],h=o[m];if(Wi(h.regex,s.path,s.params))return c(h,s,a)}}return c(null,s)}function s(n,t){var r=n.redirect,o="function"==typeof r?r(di(n,t,null,e)):r;if("string"==typeof o&&(o={path:o}),!o||"object"!=typeof o)return c(null,t);var s=o,l=s.name,p=s.path,u=t.query,d=t.hash,f=t.params;if(u=s.hasOwnProperty("query")?s.query:u,d=s.hasOwnProperty("hash")?s.hash:d,f=s.hasOwnProperty("params")?s.params:f,l){i[l];return a({_normalized:!0,name:l,query:u,hash:d,params:f},void 0,t)}if(p){var m=function(n,e){return _i(n,e.parent?e.parent.path:"/",!0)}(p,n);return a({_normalized:!0,path:$i(m,f),query:u,hash:d},void 0,t)}return c(null,t)}function c(n,t,r){return n&&n.redirect?s(n,r||t):n&&n.matchAs?function(n,e,t){var r=a({_normalized:!0,path:$i(t,e.params)});if(r){var o=r.matched,i=o[o.length-1];return e.params=r.params,c(i,e)}return c(null,e)}(0,t,n.matchAs):di(n,t,r,e)}return{match:a,addRoute:function(n,e){var t="object"!=typeof n?i[n]:void 0;Zi([e||n],r,o,i,t),t&&t.alias.length&&Zi(t.alias.map((function(n){return{path:n,children:[e]}})),r,o,i,t)},getRoutes:function(){return r.map((function(n){return o[n]}))},addRoutes:function(n){Zi(n,r,o,i)}}}function Wi(n,e,t){var r=e.match(n);if(!r)return!1;if(!t)return!0;for(var o=1,i=r.length;o<i;++o){var a=n.keys[o-1];a&&(t[a.name||"pathMatch"]="string"==typeof r[o]?si(r[o]):r[o])}return!0}var Xi=Vi&&window.performance&&window.performance.now?window.performance:Date;function Yi(){return Xi.now().toFixed(3)}var na=Yi();function ea(){return na}function ta(n){return na=n}var ra=Object.create(null);function oa(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=ti({},window.history.state);return t.key=ea(),window.history.replaceState(t,"",e),window.addEventListener("popstate",sa),function(){window.removeEventListener("popstate",sa)}}function ia(n,e,t,r){if(n.app){var o=n.options.scrollBehavior;o&&n.app.$nextTick((function(){var i=function(){var n=ea();if(n)return ra[n]}(),a=o.call(n,e,t,r?i:null);a&&("function"==typeof a.then?a.then((function(n){da(n,i)})).catch((function(n){0})):da(a,i))}))}}function aa(){var n=ea();n&&(ra[n]={x:window.pageXOffset,y:window.pageYOffset})}function sa(n){aa(),n.state&&n.state.key&&ta(n.state.key)}function ca(n){return pa(n.x)||pa(n.y)}function la(n){return{x:pa(n.x)?n.x:window.pageXOffset,y:pa(n.y)?n.y:window.pageYOffset}}function pa(n){return"number"==typeof n}var ua=/^#\d/;function da(n,e){var t,r="object"==typeof n;if(r&&"string"==typeof n.selector){var o=ua.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(o){var i=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),r=n.getBoundingClientRect();return{x:r.left-t.left-e.x,y:r.top-t.top-e.y}}(o,i={x:pa((t=i).x)?t.x:0,y:pa(t.y)?t.y:0})}else ca(n)&&(e=la(n))}else r&&ca(n)&&(e=la(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var fa,ma=Vi&&((-1===(fa=window.navigator.userAgent).indexOf("Android 2.")&&-1===fa.indexOf("Android 4.0")||-1===fa.indexOf("Mobile Safari")||-1!==fa.indexOf("Chrome")||-1!==fa.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function ha(n,e){aa();var t=window.history;try{if(e){var r=ti({},t.state);r.key=ea(),t.replaceState(r,"",n)}else t.pushState({key:ta(Yi())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function ga(n){ha(n,!0)}var ka={redirected:2,aborted:4,cancelled:8,duplicated:16};function ba(n,e){return ya(n,e,ka.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return xa.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function va(n,e){return ya(n,e,ka.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function ya(n,e,t,r){var o=new Error(r);return o._isRouter=!0,o.from=n,o.to=e,o.type=t,o}var xa=["params","query","hash"];function _a(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function Sa(n,e){return _a(n)&&n._isRouter&&(null==e||n.type===e)}function Ea(n,e,t){var r=function(o){o>=n.length?t():n[o]?e(n[o],(function(){r(o+1)})):r(o+1)};r(0)}function wa(n){return function(e,t,r){var o=!1,i=0,a=null;Ca(n,(function(n,e,t,s){if("function"==typeof n&&void 0===n.cid){o=!0,i++;var c,l=Aa((function(e){var o;((o=e).__esModule||za&&"Module"===o[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:qi.extend(e),t.components[s]=e,--i<=0&&r()})),p=Aa((function(n){var e="Failed to resolve async component "+s+": "+n;a||(a=_a(n)?n:new Error(e),r(a))}));try{c=n(l,p)}catch(n){p(n)}if(c)if("function"==typeof c.then)c.then(l,p);else{var u=c.component;u&&"function"==typeof u.then&&u.then(l,p)}}})),o||r()}}function Ca(n,e){return Ta(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function Ta(n){return Array.prototype.concat.apply([],n)}var za="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Aa(n){var e=!1;return function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];if(!e)return e=!0,n.apply(this,t)}}var Pa=function(n,e){this.router=n,this.base=function(n){if(!n)if(Vi){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=mi,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Oa(n,e,t,r){var o=Ca(n,(function(n,r,o,i){var a=function(n,e){"function"!=typeof n&&(n=qi.extend(n));return n.options[e]}(n,e);if(a)return Array.isArray(a)?a.map((function(n){return t(n,r,o,i)})):t(a,r,o,i)}));return Ta(r?o.reverse():o)}function Ia(n,e){if(e)return function(){return n.apply(e,arguments)}}Pa.prototype.listen=function(n){this.cb=n},Pa.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},Pa.prototype.onError=function(n){this.errorCbs.push(n)},Pa.prototype.transitionTo=function(n,e,t){var r,o=this;try{r=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var i=this.current;this.confirmTransition(r,(function(){o.updateRoute(r),e&&e(r),o.ensureURL(),o.router.afterHooks.forEach((function(n){n&&n(r,i)})),o.ready||(o.ready=!0,o.readyCbs.forEach((function(n){n(r)})))}),(function(n){t&&t(n),n&&!o.ready&&(Sa(n,ka.redirected)&&i===mi||(o.ready=!0,o.readyErrorCbs.forEach((function(e){e(n)}))))}))},Pa.prototype.confirmTransition=function(n,e,t){var r=this,o=this.current;this.pending=n;var i,a,s=function(n){!Sa(n)&&_a(n)&&(r.errorCbs.length?r.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},c=n.matched.length-1,l=o.matched.length-1;if(ki(n,o)&&c===l&&n.matched[c]===o.matched[l])return this.ensureURL(),n.hash&&ia(this.router,o,n,!1),s(((a=ya(i=o,n,ka.duplicated,'Avoided redundant navigation to current location: "'+i.fullPath+'".')).name="NavigationDuplicated",a));var p=function(n,e){var t,r=Math.max(n.length,e.length);for(t=0;t<r&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),u=p.updated,d=p.deactivated,f=p.activated,m=[].concat(function(n){return Oa(n,"beforeRouteLeave",Ia,!0)}(d),this.router.beforeHooks,function(n){return Oa(n,"beforeRouteUpdate",Ia)}(u),f.map((function(n){return n.beforeEnter})),wa(f)),h=function(e,t){if(r.pending!==n)return s(va(o,n));try{e(n,o,(function(e){!1===e?(r.ensureURL(!0),s(function(n,e){return ya(n,e,ka.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(o,n))):_a(e)?(r.ensureURL(!0),s(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(s(ba(o,n)),"object"==typeof e&&e.replace?r.replace(e):r.push(e)):t(e)}))}catch(n){s(n)}};Ea(m,h,(function(){Ea(function(n){return Oa(n,"beforeRouteEnter",(function(n,e,t,r){return function(n,e,t){return function(r,o,i){return n(r,o,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),i(n)}))}}(n,t,r)}))}(f).concat(r.router.resolveHooks),h,(function(){if(r.pending!==n)return s(va(o,n));r.pending=null,e(n),r.router.app&&r.router.app.$nextTick((function(){vi(n)}))}))}))},Pa.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},Pa.prototype.setupListeners=function(){},Pa.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=mi,this.pending=null};var Ra=function(n){function e(e,t){n.call(this,e,t),this._startLocation=Ma(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,r=ma&&t;r&&this.listeners.push(oa());var o=function(){var t=n.current,o=Ma(n.base);n.current===mi&&o===n._startLocation||n.transitionTo(o,(function(n){r&&ia(e,n,t,!0)}))};window.addEventListener("popstate",o),this.listeners.push((function(){window.removeEventListener("popstate",o)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){ha(Si(r.base+n.fullPath)),ia(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){ga(Si(r.base+n.fullPath)),ia(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(Ma(this.base)!==this.current.fullPath){var e=Si(this.base+this.current.fullPath);n?ha(e):ga(e)}},e.prototype.getCurrentLocation=function(){return Ma(this.base)},e}(Pa);function Ma(n){var e=window.location.pathname,t=e.toLowerCase(),r=n.toLowerCase();return!n||t!==r&&0!==t.indexOf(Si(r+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var ja=function(n){function e(e,t,r){n.call(this,e,t),r&&function(n){var e=Ma(n);if(!/^\/#/.test(e))return window.location.replace(Si(n+"/#"+e)),!0}(this.base)||La()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=ma&&e;t&&this.listeners.push(oa());var r=function(){var e=n.current;La()&&n.transitionTo(Ba(),(function(r){t&&ia(n.router,r,e,!0),ma||Da(r.fullPath)}))},o=ma?"popstate":"hashchange";window.addEventListener(o,r),this.listeners.push((function(){window.removeEventListener(o,r)}))}},e.prototype.push=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){Na(n.fullPath),ia(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){Da(n.fullPath),ia(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;Ba()!==e&&(n?Na(e):Da(e))},e.prototype.getCurrentLocation=function(){return Ba()},e}(Pa);function La(){var n=Ba();return"/"===n.charAt(0)||(Da("/"+n),!1)}function Ba(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function Ka(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function Na(n){ma?ha(Ka(n)):window.location.hash=n}function Da(n){ma?ga(Ka(n)):window.location.replace(Ka(n))}var $a=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index+1).concat(n),r.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var r=this.stack[t];this.confirmTransition(r,(function(){var n=e.current;e.index=t,e.updateRoute(r),e.router.afterHooks.forEach((function(e){e&&e(r,n)}))}),(function(n){Sa(n,ka.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(Pa),Fa=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Gi(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!ma&&!1!==n.fallback,this.fallback&&(e="hash"),Vi||(e="abstract"),this.mode=e,e){case"history":this.history=new Ra(this,n.base);break;case"hash":this.history=new ja(this,n.base,this.fallback);break;case"abstract":this.history=new $a(this,n.base);break;default:0}},qa={currentRoute:{configurable:!0}};Fa.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},qa.currentRoute.get=function(){return this.history&&this.history.current},Fa.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof Ra||t instanceof ja){var r=function(n){t.setupListeners(),function(n){var r=t.current,o=e.options.scrollBehavior;ma&&o&&"fullPath"in n&&ia(e,n,r,!1)}(n)};t.transitionTo(t.getCurrentLocation(),r,r)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},Fa.prototype.beforeEach=function(n){return Qa(this.beforeHooks,n)},Fa.prototype.beforeResolve=function(n){return Qa(this.resolveHooks,n)},Fa.prototype.afterEach=function(n){return Qa(this.afterHooks,n)},Fa.prototype.onReady=function(n,e){this.history.onReady(n,e)},Fa.prototype.onError=function(n){this.history.onError(n)},Fa.prototype.push=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.push(n,e,t)}));this.history.push(n,e,t)},Fa.prototype.replace=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.replace(n,e,t)}));this.history.replace(n,e,t)},Fa.prototype.go=function(n){this.history.go(n)},Fa.prototype.back=function(){this.go(-1)},Fa.prototype.forward=function(){this.go(1)},Fa.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},Fa.prototype.resolve=function(n,e,t){var r=Fi(n,e=e||this.history.current,t,this),o=this.match(r,e),i=o.redirectedFrom||o.fullPath;return{location:r,route:o,href:function(n,e,t){var r="hash"===t?"#"+e:e;return n?Si(n+"/"+r):r}(this.history.base,i,this.mode),normalizedTo:r,resolved:o}},Fa.prototype.getRoutes=function(){return this.matcher.getRoutes()},Fa.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==mi&&this.history.transitionTo(this.history.getCurrentLocation())},Fa.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==mi&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(Fa.prototype,qa);var Ua=Fa;function Qa(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}Fa.install=function n(e){if(!n.installed||qi!==e){n.installed=!0,qi=e;var t=function(n){return void 0!==n},r=function(n,e){var r=n.$options._parentVnode;t(r)&&t(r=r.data)&&t(r=r.registerRouteInstance)&&r(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,r(this,this)},destroyed:function(){r(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",yi),e.component("RouterLink",Qi);var o=e.config.optionMergeStrategies;o.beforeRouteEnter=o.beforeRouteLeave=o.beforeRouteUpdate=o.created}},Fa.version="3.6.5",Fa.isNavigationFailure=Sa,Fa.NavigationFailureType=ka,Fa.START_LOCATION=mi,Vi&&window.Vue&&window.Vue.use(Fa);t(109);t(17),t(134);var Ja={"components/AlgoliaSearchBox":()=>Promise.all([t.e(0),t.e(14)]).then(t.bind(null,379)),"components/ArchivesPage":()=>Promise.all([t.e(0),t.e(17)]).then(t.bind(null,339)),"components/ArticleInfo":()=>Promise.all([t.e(0),t.e(20)]).then(t.bind(null,340)),"components/BloggerBar":()=>Promise.all([t.e(0),t.e(21)]).then(t.bind(null,341)),"components/BodyBgImg":()=>Promise.all([t.e(0),t.e(22)]).then(t.bind(null,342)),"components/Buttons":()=>Promise.all([t.e(0),t.e(18)]).then(t.bind(null,343)),"components/Catalogue":()=>Promise.all([t.e(0),t.e(23)]).then(t.bind(null,344)),"components/CategoriesBar":()=>Promise.all([t.e(0),t.e(24)]).then(t.bind(null,304)),"components/CategoriesPage":()=>Promise.all([t.e(0),t.e(11)]).then(t.bind(null,345)),"components/DropdownLink":()=>Promise.all([t.e(0),t.e(15)]).then(t.bind(null,282)),"components/DropdownTransition":()=>Promise.all([t.e(0),t.e(25)]).then(t.bind(null,260)),"components/Footer":()=>Promise.all([t.e(0),t.e(26)]).then(t.bind(null,346)),"components/Home":()=>Promise.all([t.e(0),t.e(2),t.e(36)]).then(t.bind(null,372)),"components/MainLayout":()=>Promise.all([t.e(0),t.e(27)]).then(t.bind(null,274)),"components/NavLink":()=>t.e(37).then(t.bind(null,259)),"components/NavLinks":()=>Promise.all([t.e(0),t.e(13)]).then(t.bind(null,306)),"components/Navbar":()=>Promise.all([t.e(0),t.e(1)]).then(t.bind(null,371)),"components/Page":()=>Promise.all([t.e(0),t.e(3),t.e(34)]).then(t.bind(null,373)),"components/PageEdit":()=>Promise.all([t.e(0),t.e(19)]).then(t.bind(null,347)),"components/PageNav":()=>Promise.all([t.e(0),t.e(16)]).then(t.bind(null,348)),"components/Pagination":()=>Promise.all([t.e(0),t.e(28)]).then(t.bind(null,273)),"components/PostList":()=>Promise.all([t.e(0),t.e(29)]).then(t.bind(null,272)),"components/RightMenu":()=>Promise.all([t.e(0),t.e(30)]).then(t.bind(null,349)),"components/Sidebar":()=>Promise.all([t.e(0),t.e(10)]).then(t.bind(null,350)),"components/SidebarButton":()=>Promise.all([t.e(0),t.e(31)]).then(t.bind(null,352)),"components/SidebarGroup":()=>Promise.all([t.e(0),t.e(5)]).then(t.bind(null,307)),"components/SidebarLink":()=>Promise.all([t.e(0),t.e(32)]).then(t.bind(null,283)),"components/SidebarLinks":()=>Promise.all([t.e(0),t.e(5)]).then(t.bind(null,280)),"components/TagsBar":()=>Promise.all([t.e(0),t.e(33)]).then(t.bind(null,305)),"components/TagsPage":()=>Promise.all([t.e(0),t.e(12)]).then(t.bind(null,351)),"components/UpdateArticle":()=>Promise.all([t.e(0),t.e(35)]).then(t.bind(null,310)),"global-components/Badge":()=>Promise.all([t.e(0),t.e(6)]).then(t.bind(null,382)),"global-components/CodeBlock":()=>Promise.resolve().then(t.bind(null,97)),"global-components/CodeGroup":()=>Promise.resolve().then(t.bind(null,98)),"layouts/404":()=>Promise.all([t.e(0),t.e(7)]).then(t.bind(null,380)),"layouts/Layout":()=>Promise.all([t.e(0),t.e(1),t.e(2),t.e(3),t.e(4)]).then(t.bind(null,381)),NotFound:()=>Promise.all([t.e(0),t.e(7)]).then(t.bind(null,380)),Layout:()=>Promise.all([t.e(0),t.e(1),t.e(2),t.e(3),t.e(4)]).then(t.bind(null,381))},Va={"v-7bce3c4c":()=>t.e(38).then(t.bind(null,383)),"v-2828728c":()=>t.e(39).then(t.bind(null,384)),"v-a0d8828e":()=>t.e(40).then(t.bind(null,385)),"v-1b87ba43":()=>t.e(41).then(t.bind(null,386)),"v-11eb3e66":()=>t.e(42).then(t.bind(null,387)),"v-e9974c2e":()=>t.e(43).then(t.bind(null,388)),"v-0a65f29b":()=>t.e(44).then(t.bind(null,389)),"v-6d347c8a":()=>t.e(45).then(t.bind(null,390)),"v-ab895bee":()=>t.e(46).then(t.bind(null,391)),"v-034cab0a":()=>t.e(47).then(t.bind(null,392)),"v-60a1e9f7":()=>t.e(48).then(t.bind(null,393)),"v-46ce60b6":()=>t.e(49).then(t.bind(null,394)),"v-78c75671":()=>t.e(51).then(t.bind(null,395)),"v-65a5217b":()=>t.e(52).then(t.bind(null,396)),"v-e871167a":()=>t.e(50).then(t.bind(null,397)),"v-501486a1":()=>t.e(53).then(t.bind(null,398)),"v-c5d205e2":()=>t.e(54).then(t.bind(null,399)),"v-3e9d649c":()=>t.e(56).then(t.bind(null,400)),"v-688d279e":()=>t.e(57).then(t.bind(null,401)),"v-3dcceb24":()=>t.e(55).then(t.bind(null,402)),"v-c52462c8":()=>t.e(58).then(t.bind(null,403)),"v-2a48cbdf":()=>t.e(59).then(t.bind(null,404)),"v-e6a3f9b4":()=>t.e(60).then(t.bind(null,405)),"v-b4a5b7ac":()=>t.e(61).then(t.bind(null,406)),"v-060d414d":()=>t.e(62).then(t.bind(null,407)),"v-25d46bba":()=>t.e(63).then(t.bind(null,408)),"v-2880c44a":()=>t.e(64).then(t.bind(null,409)),"v-d5a2bdec":()=>t.e(65).then(t.bind(null,410)),"v-a51427f8":()=>t.e(66).then(t.bind(null,411)),"v-336aff4e":()=>t.e(67).then(t.bind(null,412)),"v-63d529e4":()=>t.e(68).then(t.bind(null,413)),"v-44762c24":()=>t.e(69).then(t.bind(null,414)),"v-d1f5af9c":()=>t.e(70).then(t.bind(null,415)),"v-3e055fb4":()=>t.e(71).then(t.bind(null,416)),"v-82ddb1de":()=>t.e(72).then(t.bind(null,417)),"v-27fcd69b":()=>t.e(73).then(t.bind(null,418)),"v-45c57d20":()=>t.e(74).then(t.bind(null,419)),"v-4d97f68d":()=>t.e(75).then(t.bind(null,420)),"v-112a6e78":()=>t.e(76).then(t.bind(null,421)),"v-01bbe51f":()=>t.e(77).then(t.bind(null,422)),"v-787e3e12":()=>t.e(78).then(t.bind(null,423)),"v-c41b9cfa":()=>t.e(79).then(t.bind(null,424)),"v-3c49f337":()=>t.e(80).then(t.bind(null,425)),"v-0b1d5734":()=>t.e(81).then(t.bind(null,426)),"v-535a8cba":()=>t.e(82).then(t.bind(null,427)),"v-0e63a70b":()=>t.e(83).then(t.bind(null,428)),"v-2a6c0621":()=>t.e(84).then(t.bind(null,429)),"v-5fa503ff":()=>t.e(85).then(t.bind(null,430)),"v-240b277f":()=>t.e(88).then(t.bind(null,431)),"v-46ec5342":()=>t.e(87).then(t.bind(null,432)),"v-1bb1d17c":()=>t.e(89).then(t.bind(null,433)),"v-66aca7ff":()=>t.e(86).then(t.bind(null,434))};function Za(n){const e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}const Ha=/-(\w)/g,Ga=Za(n=>n.replace(Ha,(n,e)=>e?e.toUpperCase():"")),Wa=/\B([A-Z])/g,Xa=Za(n=>n.replace(Wa,"-$1").toLowerCase()),Ya=Za(n=>n.charAt(0).toUpperCase()+n.slice(1));function ns(n,e){if(!e)return;if(n(e))return n(e);return e.includes("-")?n(Ya(Ga(e))):n(Ya(e))||n(Xa(e))}const es=Object.assign({},Ja,Va),ts=n=>es[n],rs=n=>Va[n],os=n=>Ja[n],is=n=>Jt.component(n);function as(n){return ns(rs,n)}function ss(n){return ns(os,n)}function cs(n){return ns(ts,n)}function ls(n){return ns(is,n)}function ps(...n){return Promise.all(n.filter(n=>n).map(async n=>{if(!ls(n)&&cs(n)){const e=await cs(n)();Jt.component(n,e.default)}}))}function us(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var ds=t(93),fs=t.n(ds),ms=t(94),hs=t.n(ms),gs={created(){if(this.siteMeta=this.$site.headTags.filter(([n])=>"meta"===n).map(([n,e])=>e),this.$ssrContext){const e=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(n=e)?n.map(n=>{let e="<meta";return Object.keys(n).forEach(t=>{e+=` ${t}="${hs()(n[t])}"`}),e+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=bs(this.$canonicalUrl)}var n},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const n=this.getMergedMetaTags();this.currentMetaTags=vs(n,this.currentMetaTags)},getMergedMetaTags(){const n=this.$page.frontmatter.meta||[];return fs()([{name:"description",content:this.$description}],n,this.siteMeta,ys)},updateCanonicalLink(){ks(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",bs(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){vs(null,this.currentMetaTags),ks()}};function ks(){const n=document.querySelector("link[rel='canonical']");n&&n.remove()}function bs(n=""){return n?`<link href="${n}" rel="canonical" />`:""}function vs(n,e){if(e&&[...e].filter(n=>n.parentNode===document.head).forEach(n=>document.head.removeChild(n)),n)return n.map(n=>{const e=document.createElement("meta");return Object.keys(n).forEach(t=>{e.setAttribute(t,n[t])}),document.head.appendChild(e),e})}function ys(n){for(const e of["name","property","itemprop"])if(n.hasOwnProperty(e))return n[e]+e;return JSON.stringify(n)}var xs=t(48),_s={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(xs)()((function(){this.setActiveHash()}),300),setActiveHash(){const n=[].slice.call(document.querySelectorAll(".sidebar-link")),e=[].slice.call(document.querySelectorAll(".header-anchor")).filter(e=>n.some(n=>n.hash===e.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),r=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),o=window.innerHeight+t;for(let n=0;n<e.length;n++){const i=e[n],a=e[n+1],s=0===n&&0===t||t>=i.parentElement.offsetTop+10&&(!a||t<a.parentElement.offsetTop-10),c=decodeURIComponent(this.$route.hash);if(s&&c!==decodeURIComponent(i.hash)){const t=i;if(o===r)for(let t=n+1;t<e.length;t++)if(c===decodeURIComponent(e[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},Ss=t(26),Es=t.n(Ss),ws={mounted(){Es.a.configure({showSpinner:!1}),this.$router.beforeEach((n,e,t)=>{n.path===e.path||Jt.component(n.name)||Es.a.start(),t()}),this.$router.afterEach(()=>{Es.a.done(),this.isSidebarOpen=!1})}},Cs=t(95),Ts=t.n(Cs),zs={mounted(){Ts.a.polyfill()}};t(242),t(243);class As{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:n="",duration:e=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${n}</div>\n    `,this.containerEl.appendChild(t),e>0&&setTimeout(()=>{this.close(t)},e)}close(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",()=>{n.remove()})}}var Ps={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(n=>{document.querySelectorAll(n).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(n){if(n.classList.contains("codecopy-enabled"))return;const e=document.createElement("i");e.className="code-copy",e.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',e.title="Copy to clipboard",e.addEventListener("click",()=>{this.copyToClipboard(n.innerText)}),n.appendChild(e),n.classList.add("codecopy-enabled")},copyToClipboard(n){const e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy");(new As).show({text:"copy success",duration:1e4}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}},Os="auto",Is="zoom-in",Rs="zoom-out",Ms="grab",js="move";function Ls(n,e,t){var r=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],o={passive:!1};r?n.addEventListener(e,t,o):n.removeEventListener(e,t,o)}function Bs(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function Ks(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function Ns(n,e,t){!function(n){var e=Ds,t=$s;if(n.transition){var r=n.transition;delete n.transition,n[e]=r}if(n.transform){var o=n.transform;delete n.transform,n[t]=o}}(e);var r=n.style,o={};for(var i in e)t&&(o[i]=r[i]||""),r[i]=e[i];return o}var Ds="transition",$s="transform",Fs="transform",qs="transitionend";var Us=function(){},Qs={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:Us,onClose:Us,onGrab:Us,onMove:Us,onRelease:Us,onBeforeOpen:Us,onBeforeClose:Us,onBeforeGrab:Us,onBeforeRelease:Us,onImageLoading:Us,onImageLoaded:Us},Js={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),Zs(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var r=this.lastScrollPosition.x-e,o=this.lastScrollPosition.y-t,i=this.options.scrollThreshold;(Math.abs(o)>=i||Math.abs(r)>=i)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(Vs(n)&&!Zs(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){Vs(n)&&!Zs(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,r=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,r)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,r=e.clientY;this.move(t,r)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function Vs(n){return 0===n.button}function Zs(n){return n.metaKey||n.ctrlKey}var Hs={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,Ns(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),Ls(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){Ns(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},Gs="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},Ws=function(){function n(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}return function(e,t,r){return t&&n(e.prototype,t),r&&n(e,r),e}}(),Xs=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(n[r]=t[r])}return n},Ys={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=Ks(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,r=n.transitionDuration,o=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?Ms:Rs,transition:Fs+"\n        "+r+"s\n        "+o,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Ns(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Ns(this.el,{transform:"none"})},grab:function(n,e,t){var r=nc(),o=r.x-n,i=r.y-e;Ns(this.el,{cursor:js,transform:"translate3d(\n        "+(this.translate.x+o)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var r=nc(),o=r.x-n,i=r.y-e;Ns(this.el,{transition:Fs,transform:"translate3d(\n        "+(this.translate.x+o)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Ns(this.el,this.styleClose)},restoreOpenStyle:function(){Ns(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=nc(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,r=this.instance.options,o=r.customSize,i=r.scaleBase;if(!o&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(o&&"object"===(void 0===o?"undefined":Gs(o)))return{x:o.width/this.rect.width,y:o.height/this.rect.height};var a=this.rect.width/2,s=this.rect.height/2,c=nc(),l={x:c.x-a,y:c.y-s},p=l.x/a,u=l.y/s,d=i+Math.min(p,u);if(o&&"string"==typeof o){var f=t||this.el.naturalWidth,m=e||this.el.naturalHeight,h=parseFloat(o)*f/(100*this.rect.width),g=parseFloat(o)*m/(100*this.rect.height);if(d>h||d>g)return{x:h,y:g}}return{x:d,y:d}}};function nc(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function ec(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(r){Ls(n,r,e[r],t)}))}var tc=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(Ys),this.overlay=Object.create(Hs),this.handler=Object.create(Js),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=Xs({},Qs,e),this.overlay.init(this),this.handler.init(this)}return Ws(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=Is,Ls(n,"click",this.handler.click),this.options.preloadImage&&Bs(Ks(n)));return this}},{key:"config",value:function(n){return n?(Xs(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var r="string"==typeof n?document.querySelector(n):n;if("IMG"===r.tagName){if(this.options.onBeforeOpen(r),this.target.init(r,this),!this.options.preloadImage){var o=this.target.srcOriginal;null!=o&&(this.options.onImageLoading(r),Bs(o,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Ls(document,"scroll",this.handler.scroll),Ls(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Ls(window,"resize",this.handler.resizeWindow);var i=function n(){Ls(r,qs,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&ec(document,e.handler,!0),t(r)};return Ls(r,qs,i),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=Os,this.overlay.fadeOut(),this.target.zoomOut(),Ls(document,"scroll",this.handler.scroll,!1),Ls(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Ls(window,"resize",this.handler.resizeWindow,!1);var r=function r(){Ls(t,qs,r,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&ec(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return Ls(t,qs,r),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var o=this.target.el;this.options.onBeforeGrab(o),this.released=!1,this.target.grab(n,e,t);var i=function n(){Ls(o,qs,n,!1),r(o)};return Ls(o,qs,i),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=js,this.target.move(n,e,t);var o=this.target.el,i=function n(){Ls(o,qs,n,!1),r(o)};return Ls(o,qs,i),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=Os,this.target.restoreOpenStyle();var r=function r(){Ls(t,qs,r,!1),n.lock=!1,n.released=!0,e(t)};return Ls(t,qs,r),this}}}]),n}();const rc=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),oc=Number("500");class ic{constructor(){this.instance=new tc(rc)}update(n=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(n)}updateDelay(n=".theme-vdoing-content img:not(.no-zoom)",e=oc){setTimeout(()=>this.update(n),e)}}var ac=[gs,_s,ws,zs,Ps,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new ic,this.$vuepress.zooming.updateDelay()}}],sc={name:"GlobalLayout",computed:{layout(){const n=this.getLayout();return us("layout",n),Jt.component(n)}},methods:{getLayout(){if(this.$page.path){const n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},cc=t(4),lc=Object(cc.a)(sc,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),n[e].push(...t);break;default:throw new Error("Unknown option name.")}}(lc,"mixins",ac);const pc=[{name:"v-7bce3c4c",path:"/pages/aboutme/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-7bce3c4c").then(t)}},{path:"/pages/aboutme/index.html",redirect:"/pages/aboutme/"},{path:"/00.AboutMe/01.个人简历.html",redirect:"/pages/aboutme/"},{name:"v-2828728c",path:"/pages/a2a9d5e6-b580-3ee0-b2c2-5b1557852fd5/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-2828728c").then(t)}},{path:"/pages/a2a9d5e6-b580-3ee0-b2c2-5b1557852fd5/index.html",redirect:"/pages/a2a9d5e6-b580-3ee0-b2c2-5b1557852fd5/"},{path:"/00.AboutMe/02.项目经验/00.小米新零售BI数据领域建设思考与沉淀.html",redirect:"/pages/a2a9d5e6-b580-3ee0-b2c2-5b1557852fd5/"},{name:"v-a0d8828e",path:"/pages/1/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-a0d8828e").then(t)}},{path:"/pages/1/index.html",redirect:"/pages/1/"},{path:"/01.Java基础/00.JavaSE/01.xxx.html",redirect:"/pages/1/"},{name:"v-1b87ba43",path:"/pages/2/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-1b87ba43").then(t)}},{path:"/pages/2/index.html",redirect:"/pages/2/"},{path:"/01.Java基础/01.并发编程/01.xxx.html",redirect:"/pages/2/"},{name:"v-11eb3e66",path:"/pages/3/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-11eb3e66").then(t)}},{path:"/pages/3/index.html",redirect:"/pages/3/"},{path:"/01.Java基础/02.JavaWeb/01.xxx.html",redirect:"/pages/3/"},{name:"v-e9974c2e",path:"/pages/4/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-e9974c2e").then(t)}},{path:"/pages/4/index.html",redirect:"/pages/4/"},{path:"/01.Java基础/03.版本新特性/01.xxx.html",redirect:"/pages/4/"},{name:"v-0a65f29b",path:"/pages/11/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-0a65f29b").then(t)}},{path:"/pages/11/index.html",redirect:"/pages/11/"},{path:"/02.Spring全家桶/00.Spring/01.xxx.html",redirect:"/pages/11/"},{name:"v-6d347c8a",path:"/pages/12/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-6d347c8a").then(t)}},{path:"/pages/12/index.html",redirect:"/pages/12/"},{path:"/02.Spring全家桶/01.SpringMvc/01.xxx.html",redirect:"/pages/12/"},{name:"v-ab895bee",path:"/pages/13/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-ab895bee").then(t)}},{path:"/pages/13/index.html",redirect:"/pages/13/"},{path:"/02.Spring全家桶/02.Mybatis/01.xxx.html",redirect:"/pages/13/"},{name:"v-034cab0a",path:"/pages/14/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-034cab0a").then(t)}},{path:"/pages/14/index.html",redirect:"/pages/14/"},{path:"/02.Spring全家桶/03.SpringBoot/01.xxx.html",redirect:"/pages/14/"},{name:"v-60a1e9f7",path:"/pages/15/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-60a1e9f7").then(t)}},{path:"/pages/15/index.html",redirect:"/pages/15/"},{path:"/02.Spring全家桶/04.SpringCloud/01.xxx.html",redirect:"/pages/15/"},{name:"v-46ce60b6",path:"/pages/16/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-46ce60b6").then(t)}},{path:"/pages/16/index.html",redirect:"/pages/16/"},{path:"/02.Spring全家桶/05.Dubbo/01.xxx.html",redirect:"/pages/16/"},{name:"v-78c75671",path:"/pages/18/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-78c75671").then(t)}},{path:"/pages/18/index.html",redirect:"/pages/18/"},{path:"/02.Spring全家桶/07.Netty/01.xxx.html",redirect:"/pages/18/"},{name:"v-65a5217b",path:"/pages/19/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-65a5217b").then(t)}},{path:"/pages/19/index.html",redirect:"/pages/19/"},{path:"/02.Spring全家桶/08.Tomcat/01.xxx.html",redirect:"/pages/19/"},{name:"v-e871167a",path:"/pages/17/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-e871167a").then(t)}},{path:"/pages/17/index.html",redirect:"/pages/17/"},{path:"/02.Spring全家桶/06.Zookeeper/01.xxx.html",redirect:"/pages/17/"},{name:"v-501486a1",path:"/pages/c8412896-0c96-3cef-8d32-94dcb1852140/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-501486a1").then(t)}},{path:"/pages/c8412896-0c96-3cef-8d32-94dcb1852140/index.html",redirect:"/pages/c8412896-0c96-3cef-8d32-94dcb1852140/"},{path:"/03.消息队列/00.Kafka/1.Kafka入门.html",redirect:"/pages/c8412896-0c96-3cef-8d32-94dcb1852140/"},{name:"v-c5d205e2",path:"/pages/278cdef6-836b-3904-aa7f-a51df28ee2da/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-c5d205e2").then(t)}},{path:"/pages/278cdef6-836b-3904-aa7f-a51df28ee2da/index.html",redirect:"/pages/278cdef6-836b-3904-aa7f-a51df28ee2da/"},{path:"/03.消息队列/00.Kafka/10.消费者-客户端开发-多线程实现.html",redirect:"/pages/278cdef6-836b-3904-aa7f-a51df28ee2da/"},{name:"v-3e9d649c",path:"/pages/dbe6fcd9-6490-3b92-804a-ea7117ef815d/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-3e9d649c").then(t)}},{path:"/pages/dbe6fcd9-6490-3b92-804a-ea7117ef815d/index.html",redirect:"/pages/dbe6fcd9-6490-3b92-804a-ea7117ef815d/"},{path:"/03.消息队列/00.Kafka/12.主题-主题管理.html",redirect:"/pages/dbe6fcd9-6490-3b92-804a-ea7117ef815d/"},{name:"v-688d279e",path:"/pages/b94bdb82-9532-3582-8bb7-19f2bc7e5c4f/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-688d279e").then(t)}},{path:"/pages/b94bdb82-9532-3582-8bb7-19f2bc7e5c4f/index.html",redirect:"/pages/b94bdb82-9532-3582-8bb7-19f2bc7e5c4f/"},{path:"/03.消息队列/00.Kafka/13.主题-KafkaAdminClient.html",redirect:"/pages/b94bdb82-9532-3582-8bb7-19f2bc7e5c4f/"},{name:"v-3dcceb24",path:"/pages/7ece0102-a50f-3e0c-be18-9f58eb0723e1/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-3dcceb24").then(t)}},{path:"/pages/7ece0102-a50f-3e0c-be18-9f58eb0723e1/index.html",redirect:"/pages/7ece0102-a50f-3e0c-be18-9f58eb0723e1/"},{path:"/03.消息队列/00.Kafka/11.消费者-客户端开发-参数说明.html",redirect:"/pages/7ece0102-a50f-3e0c-be18-9f58eb0723e1/"},{name:"v-c52462c8",path:"/pages/14a08dc7-2466-3341-b742-a0ba9b8b26c3/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-c52462c8").then(t)}},{path:"/pages/14a08dc7-2466-3341-b742-a0ba9b8b26c3/index.html",redirect:"/pages/14a08dc7-2466-3341-b742-a0ba9b8b26c3/"},{path:"/03.消息队列/00.Kafka/14.分区-分区管理.html",redirect:"/pages/14a08dc7-2466-3341-b742-a0ba9b8b26c3/"},{name:"v-2a48cbdf",path:"/pages/bd36a2fb-82ce-3f34-bf5a-91f5703e12a6/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-2a48cbdf").then(t)}},{path:"/pages/bd36a2fb-82ce-3f34-bf5a-91f5703e12a6/index.html",redirect:"/pages/bd36a2fb-82ce-3f34-bf5a-91f5703e12a6/"},{path:"/03.消息队列/00.Kafka/15.分区-如何选择合适的分区数.html",redirect:"/pages/bd36a2fb-82ce-3f34-bf5a-91f5703e12a6/"},{name:"v-e6a3f9b4",path:"/pages/00e44d72-3af4-33ec-95aa-573c4e2603b1/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-e6a3f9b4").then(t)}},{path:"/pages/00e44d72-3af4-33ec-95aa-573c4e2603b1/index.html",redirect:"/pages/00e44d72-3af4-33ec-95aa-573c4e2603b1/"},{path:"/03.消息队列/00.Kafka/2.生产者-客户端开发.html",redirect:"/pages/00e44d72-3af4-33ec-95aa-573c4e2603b1/"},{name:"v-b4a5b7ac",path:"/pages/517a0a21-c440-3dd1-9e5e-a00d7a7fc18a/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-b4a5b7ac").then(t)}},{path:"/pages/517a0a21-c440-3dd1-9e5e-a00d7a7fc18a/index.html",redirect:"/pages/517a0a21-c440-3dd1-9e5e-a00d7a7fc18a/"},{path:"/03.消息队列/00.Kafka/3.生产者-原理分析.html",redirect:"/pages/517a0a21-c440-3dd1-9e5e-a00d7a7fc18a/"},{name:"v-060d414d",path:"/pages/c4ec1b4a-45f6-3fd7-8faf-7af762dfb0ed/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-060d414d").then(t)}},{path:"/pages/c4ec1b4a-45f6-3fd7-8faf-7af762dfb0ed/index.html",redirect:"/pages/c4ec1b4a-45f6-3fd7-8faf-7af762dfb0ed/"},{path:"/03.消息队列/00.Kafka/4.消费者-消费者&消费者组.html",redirect:"/pages/c4ec1b4a-45f6-3fd7-8faf-7af762dfb0ed/"},{name:"v-25d46bba",path:"/pages/6a99e6af-7333-3944-94f1-6a8a3a84a946/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-25d46bba").then(t)}},{path:"/pages/6a99e6af-7333-3944-94f1-6a8a3a84a946/index.html",redirect:"/pages/6a99e6af-7333-3944-94f1-6a8a3a84a946/"},{path:"/03.消息队列/00.Kafka/5.消费者-客户端开发-消费逻辑.html",redirect:"/pages/6a99e6af-7333-3944-94f1-6a8a3a84a946/"},{name:"v-2880c44a",path:"/pages/0768d08c-72ff-34e7-aada-50c4eecb08b5/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-2880c44a").then(t)}},{path:"/pages/0768d08c-72ff-34e7-aada-50c4eecb08b5/index.html",redirect:"/pages/0768d08c-72ff-34e7-aada-50c4eecb08b5/"},{path:"/03.消息队列/00.Kafka/6.消费者-客户端开发-位点提交.html",redirect:"/pages/0768d08c-72ff-34e7-aada-50c4eecb08b5/"},{name:"v-d5a2bdec",path:"/pages/5ab26239-f80c-3f5e-affc-fc2c33f5178f/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-d5a2bdec").then(t)}},{path:"/pages/5ab26239-f80c-3f5e-affc-fc2c33f5178f/index.html",redirect:"/pages/5ab26239-f80c-3f5e-affc-fc2c33f5178f/"},{path:"/03.消息队列/00.Kafka/7.消费者-客户端开发-指定位点消费.html",redirect:"/pages/5ab26239-f80c-3f5e-affc-fc2c33f5178f/"},{name:"v-a51427f8",path:"/pages/2b4b8b25-552c-374f-9419-12d2c51dbeb1/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-a51427f8").then(t)}},{path:"/pages/2b4b8b25-552c-374f-9419-12d2c51dbeb1/index.html",redirect:"/pages/2b4b8b25-552c-374f-9419-12d2c51dbeb1/"},{path:"/03.消息队列/00.Kafka/8.消费者-客户端开发-Rebalance.html",redirect:"/pages/2b4b8b25-552c-374f-9419-12d2c51dbeb1/"},{name:"v-336aff4e",path:"/pages/40f82a04-0969-342d-8b82-bb27281bb7e0/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-336aff4e").then(t)}},{path:"/pages/40f82a04-0969-342d-8b82-bb27281bb7e0/index.html",redirect:"/pages/40f82a04-0969-342d-8b82-bb27281bb7e0/"},{path:"/03.消息队列/00.Kafka/9.消费者-客户端开发-拦截器.html",redirect:"/pages/40f82a04-0969-342d-8b82-bb27281bb7e0/"},{name:"v-63d529e4",path:"/pages/20/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-63d529e4").then(t)}},{path:"/pages/20/index.html",redirect:"/pages/20/"},{path:"/03.消息队列/01.RocketMQ/01.xxx.html",redirect:"/pages/20/"},{name:"v-44762c24",path:"/pages/21/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-44762c24").then(t)}},{path:"/pages/21/index.html",redirect:"/pages/21/"},{path:"/03.消息队列/02.RabbitMQ/01.xxx.html",redirect:"/pages/21/"},{name:"v-d1f5af9c",path:"/pages/22/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-d1f5af9c").then(t)}},{path:"/pages/22/index.html",redirect:"/pages/22/"},{path:"/04.数据库/00.MySQL/01.xxx.html",redirect:"/pages/22/"},{name:"v-3e055fb4",path:"/pages/23/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-3e055fb4").then(t)}},{path:"/pages/23/index.html",redirect:"/pages/23/"},{path:"/04.数据库/01.Redis/01.xxx.html",redirect:"/pages/23/"},{name:"v-82ddb1de",path:"/pages/24/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-82ddb1de").then(t)}},{path:"/pages/24/index.html",redirect:"/pages/24/"},{path:"/05.微服务架构/00.架构演进/01.xxx.html",redirect:"/pages/24/"},{name:"v-27fcd69b",path:"/pages/25/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-27fcd69b").then(t)}},{path:"/pages/25/index.html",redirect:"/pages/25/"},{path:"/05.微服务架构/01.分布式事务/01.xxx.html",redirect:"/pages/25/"},{name:"v-45c57d20",path:"/pages/26/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-45c57d20").then(t)}},{path:"/pages/26/index.html",redirect:"/pages/26/"},{path:"/05.微服务架构/02.设计模式/01.xxx.html",redirect:"/pages/26/"},{name:"v-4d97f68d",path:"/pages/27/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-4d97f68d").then(t)}},{path:"/pages/27/index.html",redirect:"/pages/27/"},{path:"/05.微服务架构/03.领域驱动设计/01.xxx.html",redirect:"/pages/27/"},{name:"v-112a6e78",path:"/pages/28/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-112a6e78").then(t)}},{path:"/pages/28/index.html",redirect:"/pages/28/"},{path:"/06.搜索引擎/00.ElasticSearch/01.xxx.html",redirect:"/pages/28/"},{name:"v-01bbe51f",path:"/pages/29/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-01bbe51f").then(t)}},{path:"/pages/29/index.html",redirect:"/pages/29/"},{path:"/07.JVM/01.xxx.html",redirect:"/pages/29/"},{name:"v-787e3e12",path:"/pages/30/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-787e3e12").then(t)}},{path:"/pages/30/index.html",redirect:"/pages/30/"},{path:"/08.云计算/00.Docker/01.xxx.html",redirect:"/pages/30/"},{name:"v-c41b9cfa",path:"/pages/1c1021ad-9e46-3426-be54-98f2d02a1fa5/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-c41b9cfa").then(t)}},{path:"/pages/1c1021ad-9e46-3426-be54-98f2d02a1fa5/index.html",redirect:"/pages/1c1021ad-9e46-3426-be54-98f2d02a1fa5/"},{path:"/09.日常开发/00.Mac日常使用/00.SublimeText3随手记.html",redirect:"/pages/1c1021ad-9e46-3426-be54-98f2d02a1fa5/"},{name:"v-3c49f337",path:"/pages/6b6ad1f6-ccb5-397f-8ca8-29b053ff97e2/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-3c49f337").then(t)}},{path:"/pages/6b6ad1f6-ccb5-397f-8ca8-29b053ff97e2/index.html",redirect:"/pages/6b6ad1f6-ccb5-397f-8ca8-29b053ff97e2/"},{path:"/09.日常开发/00.Mac日常使用/01.去除桌面的硬盘图标.html",redirect:"/pages/6b6ad1f6-ccb5-397f-8ca8-29b053ff97e2/"},{name:"v-0b1d5734",path:"/pages/b719f0b3-c7e1-303b-ae66-cbd44c17c1c5/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-0b1d5734").then(t)}},{path:"/pages/b719f0b3-c7e1-303b-ae66-cbd44c17c1c5/index.html",redirect:"/pages/b719f0b3-c7e1-303b-ae66-cbd44c17c1c5/"},{path:"/09.日常开发/00.Mac日常使用/02.安装Jprofiler.html",redirect:"/pages/b719f0b3-c7e1-303b-ae66-cbd44c17c1c5/"},{name:"v-535a8cba",path:"/pages/77b8e011-088b-3337-bc78-1694d12258e7/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-535a8cba").then(t)}},{path:"/pages/77b8e011-088b-3337-bc78-1694d12258e7/index.html",redirect:"/pages/77b8e011-088b-3337-bc78-1694d12258e7/"},{path:"/09.日常开发/00.Mac日常使用/03.文件夹显示隐藏文件.html",redirect:"/pages/77b8e011-088b-3337-bc78-1694d12258e7/"},{name:"v-0e63a70b",path:"/pages/64b132ef-4cde-3692-9a03-b3f0e7841561/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-0e63a70b").then(t)}},{path:"/pages/64b132ef-4cde-3692-9a03-b3f0e7841561/index.html",redirect:"/pages/64b132ef-4cde-3692-9a03-b3f0e7841561/"},{path:"/09.日常开发/00.Mac日常使用/04.解决鼠标滚轮上下翻转.html",redirect:"/pages/64b132ef-4cde-3692-9a03-b3f0e7841561/"},{name:"v-2a6c0621",path:"/pages/723e2b0a-de27-32e9-9704-f57ba9e27c73/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-2a6c0621").then(t)}},{path:"/pages/723e2b0a-de27-32e9-9704-f57ba9e27c73/index.html",redirect:"/pages/723e2b0a-de27-32e9-9704-f57ba9e27c73/"},{path:"/09.日常开发/00.Mac日常使用/05.配置ZSH.html",redirect:"/pages/723e2b0a-de27-32e9-9704-f57ba9e27c73/"},{name:"v-5fa503ff",path:"/pages/xxxxxxxxxx/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-5fa503ff").then(t)}},{path:"/pages/xxxxxxxxxx/index.html",redirect:"/pages/xxxxxxxxxx/"},{path:"/09.日常开发/00.Mac日常使用/06.访达隐藏文件显示.html",redirect:"/pages/xxxxxxxxxx/"},{name:"v-240b277f",path:"/tags/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-240b277f").then(t)}},{path:"/tags/index.html",redirect:"/tags/"},{path:"/@pages/tagsPage.html",redirect:"/tags/"},{name:"v-46ec5342",path:"/categories/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-46ec5342").then(t)}},{path:"/categories/index.html",redirect:"/categories/"},{path:"/@pages/categoriesPage.html",redirect:"/categories/"},{name:"v-1bb1d17c",path:"/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-1bb1d17c").then(t)}},{path:"/index.html",redirect:"/"},{name:"v-66aca7ff",path:"/archives/",component:lc,beforeEnter:(n,e,t)=>{ps("Layout","v-66aca7ff").then(t)}},{path:"/archives/index.html",redirect:"/archives/"},{path:"/@pages/archivesPage.html",redirect:"/archives/"},{path:"*",component:lc}],uc={title:"Huidong Blogs",description:"花花世界迷人眼，没有实力别赛脸。",base:"/",headTags:[["link",{rel:"icon",href:"/img/logo.jpg"}],["meta",{name:"keywords",content:"Java essay"}],["meta",{name:"baidu-site-verification",content:"7F55weZDDc"}],["meta",{name:"theme-color",content:"#11a8cd"}],["script",{},'var _hmt = _hmt || [];\n    (function() {\n      var hm = document.createElement("script");\n      hm.src = "https://hm.baidu.com/hm.js?b4efcb3b959fd674ffa886696241c972";\n      var s = document.getElementsByTagName("script")[0];\n      s.parentNode.insertBefore(hm, s);\n    })();\n    ']],pages:[{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/aboutme/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/00.AboutMe/01.%E4%B8%AA%E4%BA%BA%E7%AE%80%E5%8E%86.html",relativePath:"00.AboutMe/01.个人简历.md",key:"v-7bce3c4c",path:"/pages/aboutme/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"小米新零售BI数据领域建设思考与沉淀",frontmatter:{title:"小米新零售BI数据领域建设思考与沉淀",date:"2023-01-01T00:00:00.000Z",tags:["新零售","小米","BI","数仓建模"],categories:["项目"],description:"小米新零售BI数据领域建设思考与沉淀",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/a2a9d5e6-b580-3ee0-b2c2-5b1557852fd5/"},regularPath:"/00.AboutMe/02.%E9%A1%B9%E7%9B%AE%E7%BB%8F%E9%AA%8C/00.%E5%B0%8F%E7%B1%B3%E6%96%B0%E9%9B%B6%E5%94%AEBI%E6%95%B0%E6%8D%AE%E9%A2%86%E5%9F%9F%E5%BB%BA%E8%AE%BE%E6%80%9D%E8%80%83%E4%B8%8E%E6%B2%89%E6%B7%80.html",relativePath:"00.AboutMe/02.项目经验/00.小米新零售BI数据领域建设思考与沉淀.md",key:"v-2828728c",path:"/pages/a2a9d5e6-b580-3ee0-b2c2-5b1557852fd5/",headers:[{level:2,title:"1.零售通数据方案演进",slug:"_1-零售通数据方案演进",normalizedTitle:"1.零售通数据方案演进",charIndex:490},{level:2,title:"2.ADS数据领域建设",slug:"_2-ads数据领域建设",normalizedTitle:"2.ads数据领域建设",charIndex:1888},{level:3,title:"2.1 阵地领域",slug:"_2-1-阵地领域",normalizedTitle:"2.1 阵地领域",charIndex:1948},{level:4,title:"1）阵地领域：分公司",slug:"_1-阵地领域-分公司",normalizedTitle:"1）阵地领域：分公司",charIndex:2004},{level:3,title:"2.2 盈利领域：资金领域",slug:"_2-2-盈利领域-资金领域",normalizedTitle:"2.2 盈利领域：资金领域",charIndex:2107},{level:4,title:"1）盈利：资金领域",slug:"_1-盈利-资金领域",normalizedTitle:"1）盈利：资金领域",charIndex:2124},{level:4,title:"2）盈利：返利领域",slug:"_2-盈利-返利领域",normalizedTitle:"2）盈利：返利领域",charIndex:2223},{level:3,title:"2.3 销售领域",slug:"_2-3-销售领域",normalizedTitle:"2.3 销售领域",charIndex:2317},{level:3,title:"2.4 激活领域",slug:"_2-4-激活领域",normalizedTitle:"2.4 激活领域",charIndex:2374},{level:3,title:"2.5 库存领域",slug:"_2-5-库存领域",normalizedTitle:"2.5 库存领域",charIndex:2458},{level:3,title:"2.6 员工领域",slug:"_2-6-员工领域",normalizedTitle:"2.6 员工领域",charIndex:2580},{level:3,title:"2.7 跨领域宽表",slug:"_2-7-跨领域宽表",normalizedTitle:"2.7 跨领域宽表",charIndex:2675},{level:3,title:"2.8 领域建设全局概览",slug:"_2-8-领域建设全局概览",normalizedTitle:"2.8 领域建设全局概览",charIndex:2774},{level:3,title:"2.9 领域闭环",slug:"_2-9-领域闭环",normalizedTitle:"2.9 领域闭环",charIndex:2835},{level:2,title:"!](/images/Project/小米新零售BI数据领域建设思考与沉淀/19.png)\n![",slug:"images-project-小米新零售bi数据领域建设思考与沉淀-19-png-images-project-小米新零售bi数据领域建设思考与沉淀-20-png",normalizedTitle:"!](/images/project/小米新零售bi数据领域建设思考与沉淀/19.png)\n![",charIndex:null},{level:2,title:"3. 数据领域设计规约",slug:"_3-数据领域设计规约",normalizedTitle:"3. 数据领域设计规约",charIndex:2852},{level:3,title:"3.1 表名规约",slug:"_3-1-表名规约",normalizedTitle:"3.1 表名规约",charIndex:2868},{level:3,title:"3.2 Schema规约",slug:"_3-2-schema规约",normalizedTitle:"3.2 schema规约",charIndex:2925},{level:2,title:"4. 规划 && 展望",slug:"_4-规划-展望",normalizedTitle:"4. 规划 &amp;&amp; 展望",charIndex:null},{level:3,title:"4.1 数据服务建设",slug:"_4-1-数据服务建设",normalizedTitle:"4.1 数据服务建设",charIndex:3002},{level:3,title:"4.2 数据平台服务设想",slug:"_4-2-数据平台服务设想",normalizedTitle:"4.2 数据平台服务设想",charIndex:3247}],headersStr:"1.零售通数据方案演进 2.ADS数据领域建设 2.1 阵地领域 1）阵地领域：分公司 2.2 盈利领域：资金领域 1）盈利：资金领域 2）盈利：返利领域 2.3 销售领域 2.4 激活领域 2.5 库存领域 2.6 员工领域 2.7 跨领域宽表 2.8 领域建设全局概览 2.9 领域闭环 !](/images/Project/小米新零售BI数据领域建设思考与沉淀/19.png)\n![ 3. 数据领域设计规约 3.1 表名规约 3.2 Schema规约 4. 规划 && 展望 4.1 数据服务建设 4.2 数据平台服务设想",content:'小米新零售的管理工具——零售通，是一款专注于B端的功能丰富、信息展示全面、管理高效的应用。其核心目标是借助互联网工具和方法，提高传统零售业务的效率。零售通通过软硬件的协同配合，构建了一套智能实体门店体系，以实现门店业务的高效转化。主要应用模块包括BI数据看板、员工工作台、直播观看与回放，以及个人信息与门店管理，移动收银支付等等。\n\n * BI数据看板：内部跨多个部门的数据源，融合线上线下的所有销售数据，切分成各个的领域，按照不同的维度和视角做数据展示。\n * 员工工作台：主要包括员工日常工作管理，日周月报，入转调离，审批流，零售学院销售技能学习，晨读任务等等。\n * 直播观看与回放：总部不定期对员工进行业务培训，支持录播，回放，评论，点赞等等。\n * 个人信息与门店管理：主要是"我的"页面，个人基础信息管理，在线建店，闭店，消息推送，问题反馈，登录退出，角色切换等等。\n * 移动收银支付：打通了整个履约和仓储配货，调货等流程；同时支持客户扫码支付，智能统计员工个人激励等等。\n\n----------------------------------------\n\n\n# 1.零售通数据方案演进\n\n项目初始阶段着重推动BI数据看板的开发，随着经验的积累，我们经历了四个阶段的调整，逐步将新零售的数据看板从初始的雏形发展成为一个成熟稳定的系统。\n\n 1. 第一阶段：零售通Java上线\n    1. 数据未成建制，来源分散杂乱：业务数据散落在夸部门的各个系统，缺乏统一规划切口径不一致。\n    2. 零售通技术架构面临转换：初版项目采用Go语言开发，面临转向Java生态，Java团队处于初创阶段。\n    3. 业务需求先于数据基础建设：与常规的数据先行模式不同，数据开发滞后，项目推进存在挑战。\n    4. 数据同步更新难度大：早期多数数据采用T+1更新，后期当日数据与T+1数据分离，服务端预留汇总逻辑。\n    5. 数据团队开始收口：多数外部接口不再由零售通服务对接，数据组进行原始数据同步落库。\n    6. 采用Doris方案支持T+1数据：海量原始数据采用原有offline表设计性能无法满足要求，数据团队转向Doris寻求出路。\n    7. 服务端基于Doris+MySQL汇总：主要数据初期均为T+1更新Doris，后期将当日数据进入MySQL，服务端基于相同结构合并不同时段数据。\n 2. 第二阶段：数据预热方案\n    1. 零售通Java整体迁移上线：从Go+Java的泥淖中解脱出来，Java团队全面接管零售通。\n    2. 产品形态简单堆砌：按省、区、商、店视角构建工作台，新老需求堆砌数据楼层，缺乏层级纵深分流。\n    3. Doris在线查询支持能力不足：并发条件下并不能很好的支持即时查询，接口请求超时严重。\n    4. 数据实时性诉求不断提升：项目急需支持业务数据特别是销售数据的实时化查询。\n    5. 数据预热方案紧急上线：各视角各个楼层设计Job+Redis缓存预热，MiSchedule进行调度。\n    6. 数据实时化：通过高频定时任务进行T+0与T+1数据聚合后写入ES，提供近实时查询能力。\n    7. 前后端协同改造数据渲染方案：楼层越来越多，页面越来越长；服务端接口拆分，楼层独立化；客户端尝试按需渲染，异步加载。\n 3. 第三阶段：ADS开始建立\n    1. 推动产品形态开始裂变：数据关注点聚焦，从冗长楼层拆解出来，加强利用纵深展现数据。\n    2. 作战室 隆重登场：业务推进模式更加关注各个视角排名，数据涉及销量、激活、门店数等。\n    3. ADS应用数据层 应运而生：OLAP ？ OLTP；大数据的解决方案；数据领域分层理念开始推行。\n 4. 第四阶段：ADS 2.0时代\n    1. 业务主体框架基本建成：全面建立各职能视角工作台；工作台tab、作战室tab、销售tab 三足鼎立；建店模式清晰化：米家 vs 授权；从系统性需求进入迭代型需求。\n    2. 流式计算方案试点推行：数据仓库内部结合一商一议需求尝试；flink更新数据方案，逐步推广至ADS。\n    3. ADS数据服务进入2.0时代：领域建设全面覆盖业务领域；数据更新方案变更，更新时间更加及时；new-retail-ads 服务退出历史舞台；PDS服务正式上线，推进架构合理化调整。\n\n\n\n现阶段零售通架构\n\n----------------------------------------\n\n\n# 2.ADS数据领域建设\n\n\n\n----------------------------------------\n\n\n# 2.1 阵地领域\n\n\n\n----------------------------------------\n\n# 1）阵地领域：分公司\n\n主要关注点：\n\n 1. 小区数量\n 2. 县区覆盖率\n 3. 分状态，分类型门店数量\n\n\n\n----------------------------------------\n\n\n# 2.2 盈利领域：资金领域\n\n# 1）盈利：资金领域\n\n主要关注点：\n\n 1. 平均保证金\n 2. 近七日销售金额\n 3. 资金周转周期\n\n\n\n----------------------------------------\n\n# 2）盈利：返利领域\n\n主要关注点：\n\n 1. 妥投金额\n 2. 返利金额\n 3. 返利点位\n\n\n\n----------------------------------------\n\n\n# 2.3 销售领域\n\n\n\n----------------------------------------\n\n\n# 2.4 激活领域\n\n主要关注点：\n\n 1. 销售激活\n 2. 合规激活\n\n\n\n----------------------------------------\n\n\n# 2.5 库存领域\n\n主要关注点：\n\n 1. 店间在途\n 2. 店仓店在途\n 3. 店实物\n 4. 样机库存\n 5. N天日均销\n 6. N天DOS\n\n\n\n----------------------------------------\n\n\n# 2.6 员工领域\n\n主要关注点：\n\n 1. 员工画像\n 2. 员工评分\n 3. 员工销售激励\n\n\n\n----------------------------------------\n\n\n# 2.7 跨领域宽表\n\n * 销售额\n * 订单量\n * 客流量\n * 退货\n * 激活\n * NPS\n\n\n\n----------------------------------------\n\n\n# 2.8 领域建设全局概览\n\n\n\n----------------------------------------\n\n\n# 2.9 领域闭环\n\n\n#\n\n\n# 3. 数据领域设计规约\n\n\n# 3.1 表名规约\n\n\n\n----------------------------------------\n\n\n# 3.2 Schema规约\n\n\n\n----------------------------------------\n\n\n# 4. 规划 && 展望\n\n\n# 4.1 数据服务建设\n\n 1. 性能提升：业务逻辑解耦优化；合理设计缓存；并行化、异步化；SQL优化、索引优化等。\n 2. 领域健全：在领域主体框架建立的基础上，持续完善细分领域和关注点，如：返利、员工领域。\n 3. 架构合理化：主从分离，老旧表废弃梳理；垂直拆分系统服务、数据领域、DB实例等。\n 4. 服务切换：全面推进领域服务切换至ADS2.0，工作台实时化，Proretail余留部分等。\n\n----------------------------------------\n\n\n# 4.2 数据平台服务设想\n\n\n\n----------------------------------------',normalizedContent:'小米新零售的管理工具——零售通，是一款专注于b端的功能丰富、信息展示全面、管理高效的应用。其核心目标是借助互联网工具和方法，提高传统零售业务的效率。零售通通过软硬件的协同配合，构建了一套智能实体门店体系，以实现门店业务的高效转化。主要应用模块包括bi数据看板、员工工作台、直播观看与回放，以及个人信息与门店管理，移动收银支付等等。\n\n * bi数据看板：内部跨多个部门的数据源，融合线上线下的所有销售数据，切分成各个的领域，按照不同的维度和视角做数据展示。\n * 员工工作台：主要包括员工日常工作管理，日周月报，入转调离，审批流，零售学院销售技能学习，晨读任务等等。\n * 直播观看与回放：总部不定期对员工进行业务培训，支持录播，回放，评论，点赞等等。\n * 个人信息与门店管理：主要是"我的"页面，个人基础信息管理，在线建店，闭店，消息推送，问题反馈，登录退出，角色切换等等。\n * 移动收银支付：打通了整个履约和仓储配货，调货等流程；同时支持客户扫码支付，智能统计员工个人激励等等。\n\n----------------------------------------\n\n\n# 1.零售通数据方案演进\n\n项目初始阶段着重推动bi数据看板的开发，随着经验的积累，我们经历了四个阶段的调整，逐步将新零售的数据看板从初始的雏形发展成为一个成熟稳定的系统。\n\n 1. 第一阶段：零售通java上线\n    1. 数据未成建制，来源分散杂乱：业务数据散落在夸部门的各个系统，缺乏统一规划切口径不一致。\n    2. 零售通技术架构面临转换：初版项目采用go语言开发，面临转向java生态，java团队处于初创阶段。\n    3. 业务需求先于数据基础建设：与常规的数据先行模式不同，数据开发滞后，项目推进存在挑战。\n    4. 数据同步更新难度大：早期多数数据采用t+1更新，后期当日数据与t+1数据分离，服务端预留汇总逻辑。\n    5. 数据团队开始收口：多数外部接口不再由零售通服务对接，数据组进行原始数据同步落库。\n    6. 采用doris方案支持t+1数据：海量原始数据采用原有offline表设计性能无法满足要求，数据团队转向doris寻求出路。\n    7. 服务端基于doris+mysql汇总：主要数据初期均为t+1更新doris，后期将当日数据进入mysql，服务端基于相同结构合并不同时段数据。\n 2. 第二阶段：数据预热方案\n    1. 零售通java整体迁移上线：从go+java的泥淖中解脱出来，java团队全面接管零售通。\n    2. 产品形态简单堆砌：按省、区、商、店视角构建工作台，新老需求堆砌数据楼层，缺乏层级纵深分流。\n    3. doris在线查询支持能力不足：并发条件下并不能很好的支持即时查询，接口请求超时严重。\n    4. 数据实时性诉求不断提升：项目急需支持业务数据特别是销售数据的实时化查询。\n    5. 数据预热方案紧急上线：各视角各个楼层设计job+redis缓存预热，mischedule进行调度。\n    6. 数据实时化：通过高频定时任务进行t+0与t+1数据聚合后写入es，提供近实时查询能力。\n    7. 前后端协同改造数据渲染方案：楼层越来越多，页面越来越长；服务端接口拆分，楼层独立化；客户端尝试按需渲染，异步加载。\n 3. 第三阶段：ads开始建立\n    1. 推动产品形态开始裂变：数据关注点聚焦，从冗长楼层拆解出来，加强利用纵深展现数据。\n    2. 作战室 隆重登场：业务推进模式更加关注各个视角排名，数据涉及销量、激活、门店数等。\n    3. ads应用数据层 应运而生：olap ？ oltp；大数据的解决方案；数据领域分层理念开始推行。\n 4. 第四阶段：ads 2.0时代\n    1. 业务主体框架基本建成：全面建立各职能视角工作台；工作台tab、作战室tab、销售tab 三足鼎立；建店模式清晰化：米家 vs 授权；从系统性需求进入迭代型需求。\n    2. 流式计算方案试点推行：数据仓库内部结合一商一议需求尝试；flink更新数据方案，逐步推广至ads。\n    3. ads数据服务进入2.0时代：领域建设全面覆盖业务领域；数据更新方案变更，更新时间更加及时；new-retail-ads 服务退出历史舞台；pds服务正式上线，推进架构合理化调整。\n\n\n\n现阶段零售通架构\n\n----------------------------------------\n\n\n# 2.ads数据领域建设\n\n\n\n----------------------------------------\n\n\n# 2.1 阵地领域\n\n\n\n----------------------------------------\n\n# 1）阵地领域：分公司\n\n主要关注点：\n\n 1. 小区数量\n 2. 县区覆盖率\n 3. 分状态，分类型门店数量\n\n\n\n----------------------------------------\n\n\n# 2.2 盈利领域：资金领域\n\n# 1）盈利：资金领域\n\n主要关注点：\n\n 1. 平均保证金\n 2. 近七日销售金额\n 3. 资金周转周期\n\n\n\n----------------------------------------\n\n# 2）盈利：返利领域\n\n主要关注点：\n\n 1. 妥投金额\n 2. 返利金额\n 3. 返利点位\n\n\n\n----------------------------------------\n\n\n# 2.3 销售领域\n\n\n\n----------------------------------------\n\n\n# 2.4 激活领域\n\n主要关注点：\n\n 1. 销售激活\n 2. 合规激活\n\n\n\n----------------------------------------\n\n\n# 2.5 库存领域\n\n主要关注点：\n\n 1. 店间在途\n 2. 店仓店在途\n 3. 店实物\n 4. 样机库存\n 5. n天日均销\n 6. n天dos\n\n\n\n----------------------------------------\n\n\n# 2.6 员工领域\n\n主要关注点：\n\n 1. 员工画像\n 2. 员工评分\n 3. 员工销售激励\n\n\n\n----------------------------------------\n\n\n# 2.7 跨领域宽表\n\n * 销售额\n * 订单量\n * 客流量\n * 退货\n * 激活\n * nps\n\n\n\n----------------------------------------\n\n\n# 2.8 领域建设全局概览\n\n\n\n----------------------------------------\n\n\n# 2.9 领域闭环\n\n\n#\n\n\n# 3. 数据领域设计规约\n\n\n# 3.1 表名规约\n\n\n\n----------------------------------------\n\n\n# 3.2 schema规约\n\n\n\n----------------------------------------\n\n\n# 4. 规划 && 展望\n\n\n# 4.1 数据服务建设\n\n 1. 性能提升：业务逻辑解耦优化；合理设计缓存；并行化、异步化；sql优化、索引优化等。\n 2. 领域健全：在领域主体框架建立的基础上，持续完善细分领域和关注点，如：返利、员工领域。\n 3. 架构合理化：主从分离，老旧表废弃梳理；垂直拆分系统服务、数据领域、db实例等。\n 4. 服务切换：全面推进领域服务切换至ads2.0，工作台实时化，proretail余留部分等。\n\n----------------------------------------\n\n\n# 4.2 数据平台服务设想\n\n\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/1/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/00.JavaSE/01.xxx.html",relativePath:"01.Java基础/00.JavaSE/01.xxx.md",key:"v-a0d8828e",path:"/pages/1/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/2/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/01.%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/01.xxx.html",relativePath:"01.Java基础/01.并发编程/01.xxx.md",key:"v-1b87ba43",path:"/pages/2/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/3/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/02.JavaWeb/01.xxx.html",relativePath:"01.Java基础/02.JavaWeb/01.xxx.md",key:"v-11eb3e66",path:"/pages/3/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/4/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/01.Java%E5%9F%BA%E7%A1%80/03.%E7%89%88%E6%9C%AC%E6%96%B0%E7%89%B9%E6%80%A7/01.xxx.html",relativePath:"01.Java基础/03.版本新特性/01.xxx.md",key:"v-e9974c2e",path:"/pages/4/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/11/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/02.Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/00.Spring/01.xxx.html",relativePath:"02.Spring全家桶/00.Spring/01.xxx.md",key:"v-0a65f29b",path:"/pages/11/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/12/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/02.Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/01.SpringMvc/01.xxx.html",relativePath:"02.Spring全家桶/01.SpringMvc/01.xxx.md",key:"v-6d347c8a",path:"/pages/12/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/13/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/02.Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/02.Mybatis/01.xxx.html",relativePath:"02.Spring全家桶/02.Mybatis/01.xxx.md",key:"v-ab895bee",path:"/pages/13/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/14/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/02.Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/03.SpringBoot/01.xxx.html",relativePath:"02.Spring全家桶/03.SpringBoot/01.xxx.md",key:"v-034cab0a",path:"/pages/14/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/15/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/02.Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/04.SpringCloud/01.xxx.html",relativePath:"02.Spring全家桶/04.SpringCloud/01.xxx.md",key:"v-60a1e9f7",path:"/pages/15/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/16/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/02.Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/05.Dubbo/01.xxx.html",relativePath:"02.Spring全家桶/05.Dubbo/01.xxx.md",key:"v-46ce60b6",path:"/pages/16/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/18/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/02.Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/07.Netty/01.xxx.html",relativePath:"02.Spring全家桶/07.Netty/01.xxx.md",key:"v-78c75671",path:"/pages/18/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/19/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/02.Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/08.Tomcat/01.xxx.html",relativePath:"02.Spring全家桶/08.Tomcat/01.xxx.md",key:"v-65a5217b",path:"/pages/19/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/17/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/02.Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/06.Zookeeper/01.xxx.html",relativePath:"02.Spring全家桶/06.Zookeeper/01.xxx.md",key:"v-e871167a",path:"/pages/17/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"Kafka入门",frontmatter:{title:"Kafka入门",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"Kafka入门",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/c8412896-0c96-3cef-8d32-94dcb1852140/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/1.Kafka%E5%85%A5%E9%97%A8.html",relativePath:"03.消息队列/00.Kafka/1.Kafka入门.md",key:"v-501486a1",path:"/pages/c8412896-0c96-3cef-8d32-94dcb1852140/",headers:[{level:2,title:"1.体系架构",slug:"_1-体系架构",normalizedTitle:"1.体系架构",charIndex:888},{level:2,title:"2.主题分区",slug:"_2-主题分区",normalizedTitle:"2.主题分区",charIndex:1293},{level:2,title:"3.副本机制",slug:"_3-副本机制",normalizedTitle:"3.副本机制",charIndex:1745},{level:2,title:"4.安装配置",slug:"_4-安装配置",normalizedTitle:"4.安装配置",charIndex:2484},{level:2,title:"5.生产消费",slug:"_5-生产消费",normalizedTitle:"5.生产消费",charIndex:5063},{level:3,title:"5.1使用脚本测试",slug:"_5-1使用脚本测试",normalizedTitle:"5.1使用脚本测试",charIndex:5074},{level:3,title:"5.2使用代码测试",slug:"_5-2使用代码测试",normalizedTitle:"5.2使用代码测试",charIndex:6432},{level:2,title:"6.服务端参数说明",slug:"_6-服务端参数说明",normalizedTitle:"6.服务端参数说明",charIndex:8982},{level:3,title:"6.1zookeeper.connect",slug:"_6-1zookeeper-connect",normalizedTitle:"6.1zookeeper.connect",charIndex:8996},{level:3,title:"6.2listeners",slug:"_6-2listeners",normalizedTitle:"6.2listeners",charIndex:10269},{level:3,title:"6.3broker.id",slug:"_6-3broker-id",normalizedTitle:"6.3broker.id",charIndex:10400},{level:3,title:"6.4log.dir & log.dirs",slug:"_6-4log-dir-log-dirs",normalizedTitle:"6.4log.dir &amp; log.dirs",charIndex:null},{level:3,title:"6.5message.max.bytes",slug:"_6-5message-max-bytes",normalizedTitle:"6.5message.max.bytes",charIndex:10760}],headersStr:"1.体系架构 2.主题分区 3.副本机制 4.安装配置 5.生产消费 5.1使用脚本测试 5.2使用代码测试 6.服务端参数说明 6.1zookeeper.connect 6.2listeners 6.3broker.id 6.4log.dir & log.dirs 6.5message.max.bytes",content:'当涉及 Kafka 时，有三个关键方面需要考虑，它们构成了 Kafka 的核心特性，为各种应用场景提供了强大的支持：\n\n 1. 消息系统：Kafka是一个高性能、分布式的消息系统，具有多重关键特性。首先，它支持异步通信，这意味着生产者和消费者不必等待对方的响应，从而提高了系统的吞吐量和响应速度。其次，Kafka能够处理削峰（smoothing）——在瞬时高负载时，它能够暂存消息以确保系统的稳定性。此外，它支持消息的解耦，允许不同组件之间独立开发和部署，提高了系统的可维护性。Kafka还提供卓越的扩展性，能够轻松地适应不断增长的工作负载。同时，Kafka具备出色的恢复性，即使在硬件或网络故障的情况下，消息仍然能够被可靠地传递。此外，Kafka支持顺序性消费，确保消息按照其产生的顺序被消费。最后，它还支持回溯消息，允许消费者重新处理历史消息，这对于分析和数据挖掘非常有用。\n 2. 存储系统：除了作为消息系统，Kafka还可用作强大的分布式数据存储系统。它能够可靠地存储消息，使得这些消息可以被后续应用程序或系统查询、分析和处理。这种存储功能使Kafka成为了一个持久性的、高度可扩展的数据存储引擎，用于存储和管理各种类型的数据，包括事件日志、指标、日志文件、以及其他业务数据。因此，Kafka适用于实时大数据处理、日志存储、监控、以及各种其他数据管理需求。\n 3. 流式处理平台：Kafka不仅仅是一个消息传递系统和数据存储引擎，它还提供了一个流式处理平台，能够为流式处理框架提供数据来源。通过Kafka，数据可以被实时地传递到流处理应用程序，这使得开发者可以构建实时分析、事件驱动型应用、以及复杂的数据处理流程。Kafka还提供了一套完整的流式处理类库，包括窗口处理、连接操作、数据变换以及聚合功能，使开发者能够轻松构建强大的实时数据处理应用。\n\n这三个方面的特性使 Kafka 成为一种强大的工具，适用于各种现代数据处理和数据流应用，从事件驱动架构到实时数据分析和监控。\n\n----------------------------------------\n\n\n# 1.体系架构\n\nKafka 是一个强大的分布式消息传递系统，其核心体系架构包括四个主要组件：Producer、Broker、Consumer 和 ZooKeeper (zk)。\n\n 1. ZooKeeper：Kafka 使用 ZooKeeper 来负责集群元数据的管理、控制器的选举等操作，确保 Kafka 集群的协调和一致性。\n 2. Producer：生产者负责将消息发送到 Kafka 的 Broker 中。\n 3. Broker：Broker 是 Kafka 集群中的消息存储节点，它们接收、存储和分发消息。\n 4. Consumer：消费者从 Broker 订阅并消费消息，采用拉模型（pull-based）来获取消息。\n\n一台部署了 Kafka Broker 的服务器可以看作是一个 Kafka 服务器。\n\n----------------------------------------\n\n\n# 2.主题分区\n\n * Topic：生产者在发送消息时需要指定一个 Topic。Topic 是消息的逻辑分类，用于组织和标识消息。\n * Partition：每个 Topic 可以划分为多个 Partition，每个Partition是一个有序、追加的日志文件，每条消息都会分配一个唯一的偏移量（offset）。偏移量用于保证消息在分区内的顺序。\n\n> Kafka 保证 Partition 内的消息有序，但不保证 Topic 有序。Topic 可能有多个 Partition，它们可以分布在不同的 Broker 上。\n\nTopic的多个分区可以分布在不同的Broker上，消息在发送到Broker之前会首先根据分区规则计算出储存到哪一个分区。如果一个Topic只有一个分区，那么这个Topic的性能瓶颈就是这个分区所在Broker的I/O。创建Topic时可以指定分区的数量，也可以随时增加分区以实现水平扩展。\n\n----------------------------------------\n\n\n# 3.副本机制\n\n * Kafka 引入了副本（Replica）机制用于实现容灾备份。每个 Partition 可能有多个副本。\n * 副本分为三种状态：AR（All Replica，所有副本），ISR（In Sync Replica，同步中的副本），OSR（Out Sync Replica，同步之外的副本）。\n * 在同一时刻，副本之间并非完全一样。Leader 副本负责处理读写请求，而 Follower 副本只负责与 Leader 副本的消息同步。当Leader所在的Broker 出现故障时，从 Follower 副本中重新选举新的 Leader 副本对外提供服务。\n * ISR（In Sync Replica）指的是同步中的副本，它们具备资格被选为 Leader 副本。\n * AR = ISR + OSR。正常情况下 AR = ISR，OSR = 0。\n * 副本有一个重要的概念，即 HW（High Watermark），消费者只能拉取消息直到 HW 位置。HW 是所有 ISR 集合内的副本的LEO（LogEndOffset）的最小值。\n * LEO（Log End Offset）标识当前 Partition 日志文件中下一条待写入的消息的 offset。LEO = 当前日志文件的最后一条消息的偏移量+1。\n * kafka客户端也具备一定的容灾备份能力，消费者使用拉模型从服务端拉消息，并且保存消费的具体位置，当消费者宕机后恢复上线时可以根据之前保存的消费位点重新拉消息。\n\n相比于同步复制的性能损耗和异步复制的不可靠性，ISR的方式在两者之间做了更好的权衡。\n\n----------------------------------------\n\n\n# 4.安装配置\n\nKafka官方下载地址：http://kafka.apache.org/downloads。\n\n> kafka-xx-yy: xx 是scala版本，yy是kafka版本。\n\n下面我们使用docker安装和配置zk和kafka。\n\n 1. 首先创建一个桥接网络，方便zk和kafka因为重启docker导致ip变化时需要重新修正配置的问题。\n\ndocker network create kafka-net\n\n\n1\n\n 2. 拉取zk镜像并安装。\n\ndocker pull zookeeper:3.5.9\n\ndocker run -d --privileged=true  --name kafka-zookeeper  -p 2181:2181  --network kafka-net  --network-alias kafka-zookeeper  -v /Users/huidong/docker/zk/data:/data  -v /Users/huidong/docker/zk/conf:/conf  -v /Users/huidong/docker/zk/logs:/datalog  zookeeper:3.5.9\n\n\n1\n2\n3\n\n\n2888为组成zookeeper服务器之间的通信端口，3888为用来选举leader的端口。如果想要查看zk的运行状态：\n\n# 1. 进入zk容器\ndocker exec -it 容器id /bin/bash\n\n# 2. 找到配置文件位置\ncat /conf/zoo.cfg\n\n# 3. 查看zk状态\nzkServer.sh status\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 3. 拉取kafka镜像并安装。\n\ndocker pull wurstmeister/kafka\n\ndocker run -d  --privileged=true \\\n--name kafka0 -p 9092:9092 \\\n--network kafka-net \\\n--network-alias kafka0 \\\n-e KAFKA_BROKER_ID=0 \\\n-e KAFKA_ZOOKEEPER_CONNECT=kafka-zookeeper:2181 \\\n-e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \\\n-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.1.5:9092 \\\n-e ALLOW_PLAINTEXT_LISTENER=yes \\\nwurstmeister/kafka:latest\n\ndocker run -d  --privileged=true \\\n--name kafka1 -p 9093:9092 \\\n--network kafka-net \\\n--network-alias kafka1 \\\n-e KAFKA_BROKER_ID=1 \\\n-e KAFKA_ZOOKEEPER_CONNECT=kafka-zookeeper:2181 \\\n-e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \\\n-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.1.5:9093 \\\n-e ALLOW_PLAINTEXT_LISTENER=yes \\\nwurstmeister/kafka:latest\n\ndocker run -d  --privileged=true \\\n--name kafka2 -p 9094:9092 \\\n--network kafka-net \\\n--network-alias kafka2 \\\n-e KAFKA_BROKER_ID=2 \\\n-e KAFKA_ZOOKEEPER_CONNECT=kafka-zookeeper:2181 \\\n-e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \\\n-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.1.5:9094 \\\n-e ALLOW_PLAINTEXT_LISTENER=yes \\\nwurstmeister/kafka:latest\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n\n\nKAFKA_LISTENERS 与 KAFKA_ADVERTISED_LISTENERS 是为了区分内网和外网的，如果只有内网访问，就可以只配置 KAFKA_LISTENERS。如果涉及了外网访问，比如要在云服务器上部署使用，就需要配置 KAFKA_ADVERTISED_LISTENERS参数了，在开始时配置了一个 kafka-net 的网络，也就是处于这个网络下的访问才属于内网访问，而 kafka部署完毕后，需要在其他服务器上访问 kafka，这就需要通过外网访问 kafka，所以必须配置 KAFKA_ADVERTISED_LISTENERS，且值为 PLAINTEXT://<服务器ip>:<暴露端口> ，例如我的电脑IP为 192.168.1.5，端口为容器暴露的端口。\n\n * KAFKA_BROKER_ID : broker的ID，这个ID是集群的标识，不能重复。\n * KAFKA_ZOOKEEPER_CONNECT：zookeeper的连接地址。\n * KAFKA_LISTENERS：标识kafka服务运行在容器内的9092端口，因为没有指定host，所以是0.0.0.0标识所有的网络接口。\n * KAFKA_ADVERTISED_LISTENERS：kafka发布到zookeeper供客户端使用的服务地址。\n\n至此，一个单节点的zk和三个broker的kafka集群就安装成功了。\n\n----------------------------------------\n\n\n# 5.生产消费\n\n\n# 5.1使用脚本测试\n\n我们知道生产者将消息发送到Topic,而消费者也是通过订阅Topic来消费消息的。进入kafka-broker所在的docker容器，在 /opt/kafka_2.13-2.8.1/bin 目录下有kafka的一些脚本，我们首先通过脚本来创建Topic并测试生产和消费。\n\n 1. 创建Topic\n\n./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-demo --replication-factor 3 --partitions 4\n\n\n1\n\n * factor：表示topic的副本因子，也就是每一个partition有几个副本。\n * partition：表示分区数。\n * zookeeper：指定kafka连接的zk的地址。\n * topic：指定要创建的主题的名字。\n\n 2. 查看Topic的信息\n\n./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-demo\n\n\n1\n\n\n返回信息如下：\n\n# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-demo\nTopic: topic-demo       TopicId: yCY_qq7XQaaGlYp6Fnod-A PartitionCount: 4       ReplicationFactor: 3    Configs: \n        Topic: topic-demo       Partition: 0    Leader: 0       Replicas: 0,2,1 Isr: 0,2,1\n        Topic: topic-demo       Partition: 1    Leader: 1       Replicas: 1,0,2 Isr: 1,0,2\n        Topic: topic-demo       Partition: 2    Leader: 2       Replicas: 2,1,0 Isr: 2,1,0\n        Topic: topic-demo       Partition: 3    Leader: 0       Replicas: 0,1,2 Isr: 0,1,2\n\n\n1\n2\n3\n4\n5\n6\n\n 3. 生产消息\n\n./kafka-console-producer.sh --bootstrap-server kafka0:9092 --topic topic-demo\n\n\n1\n\n * bootstrap-server：指定连接的kafka集群地址。\n\n 4. 消费消息\n\n./kafka-console-consumer.sh --bootstrap-server kafka0:9092 --topic topic-demo\n\n\n1\n\n\n----------------------------------------\n\n\n# 5.2使用代码测试\n\n我们以Java客户端测试Kafka集群的生产消费。\n\n 1. 首先在项目中引入Kafka客户端的依赖。\n\n  <dependency>\n      <groupId>org.apache.kafka</groupId>\n      <artifactId>kafka-clients</artifactId>\n      <version>2.8.1</version>\n  </dependency>\n\n\n1\n2\n3\n4\n5\n\n 2. 使用kafka消费者消费消息。\n\n * 设置 Kafka 消费者配置：配置 Kafka 消费者，包括指定 Kafka 服务器地址、消费者组、键值反序列化器等。\n * 创建 Kafka 消费者：使用上述配置创建 Kafka 消费者。\n * 订阅主题：使用 subscribe 方法订阅一个或多个主题。\n * 轮询并处理消息：使用 poll 方法轮询 Kafka 主题以获取消息，并处理这些消息。处理逻辑可以根据需求来定制。\n * 关闭 Kafka 消费者：在完成消费后，关闭 Kafka 消费者以释放资源。\n\npublic static void consume() {\n    Properties props = new Properties();\n    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n    props.put(ConsumerConfig.GROUP_ID_CONFIG, groupName);\n    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    consumer.subscribe(Collections.singletonList(topicName));\n\n    while (true) {\n        ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));\n        records.forEach(record -> System.out.println("Received message: key = " + record.key() + ", value = " + record.value()));\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n 3. 使用kafka生产者发送消息。\n\n * 设置 Kafka 生产者配置：首先，配置 Kafka 生产者。这包括指定 Kafka 服务器地址、序列化器、主题名称等。\n * 创建 Kafka 生产者：使用上述配置创建 Kafka 生产者。\n * 发送消息：使用 send 方法向 Kafka 主题发送消息。消息需要指定主题名称、消息键和消息值。\n * 关闭 Kafka 生产者：在完成发送后，记得关闭 Kafka 生产者以释放资源。\n\npublic static void produce() {\n    Properties props = new Properties();\n    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");\n    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");\n\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    ProducerRecord<String, String> record = new ProducerRecord<>(topicName, "key", "value");\n\n    for (int i = 0; i < 100; i++) {\n        producer.send(record, (metadata, exception) -> {\n            if (exception == null) {\n                System.out.println("Message sent to partition " + metadata.partition() + " with offset " + metadata.offset());\n            } else {\n                exception.printStackTrace();\n            }\n        });\n    }\n\n    producer.close();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n----------------------------------------\n\n\n# 6.服务端参数说明\n\n\n# 6.1zookeeper.connect\n\nzookeeper.connect 是 Kafka 配置中的一个重要参数，它用于指定 Kafka与ZooKeeper集群之间的连接信息。以下是关于 zookeeper.connect 参数的详细介绍：\n\n * 参数名称：zookeeper.connect\n * 作用：指定 Kafka 集群与 ZooKeeper 集群之间的连接信息。\n * 格式：zookeeper.connect参数的值通常以逗号分隔的形式列出多个 ZooKeeper 服务器的连接地址。格式如下：\n\nhost1:port1,host2:port2,host3:port3\n\n\n1\n\n\n其中，host1:port1、host2:port2、host3:port3 是 ZooKeeper 服务器的主机名（或 IP地址）和端口号。使用者可以列出多个ZooKeeper服务器以增加可用性和冗余性。Kafka 客户端会自动选择其中一个 ZooKeeper 服务器来进行连接。\n\n * 示例：以下是一个示例 zookeeper.connect 参数的值：\n\nzookeeper.connect=zookeeper1:2181,zookeeper2:2181,zookeeper3:2181\n\n\n1\n\n * 用途：zookeeper.connect 参数用于告知 Kafka客户端如何连接到ZooKeeper集群，以获取元数据、执行领导者选举等操作。ZooKeeper还用于管理消费者组的偏移量（offset）信息，以确保Kafka消费者能够继续从上次停止的地方消费消息。\n * 注意事项：在配置 zookeeper.connect 参数时，确保指定了正确的 ZooKeeper 服务器地址和端口号。同时，也需要确保ZooKeeper集群与 Kafka 集群之间有良好的网络连接，以确保正常的协调和管理功能。\n\nzookeeper.connect 参数也可以配置 ZooKeeper 的 chroot 路径。chroot路径允许在ZooKeeper服务器上创建一个命名空间（类似于文件系统的目录），以便不同的应用程序或服务可以在同一个ZooKeeper集群上维护独立的配置和元数据信息。在Kafka 中，chroot 路径通常用于隔离不同的 Kafka 集群或服务。\n\n以下是关于在 zookeeper.connect 参数中配置 chroot 路径的说明：\n\n * 格式：要配置 chroot 路径，可以将其附加到 zookeeper.connect 的值中，使用斜杠（/）分隔。例如：\n\nzookeeper.connect=zk1:2181,zk2:2181/kafka-chroot\n\n\n1\n\n\n在上述示例中，kafka-chroot 是 chroot 路径，它指定了一个命名空间，Kafka 将在其中执行与 ZooKeeper 相关的操作。\n\n----------------------------------------\n\n\n# 6.2listeners\n\n上面在安装配置小节已经介绍过 listeners 和 advertised.listeners 参数。前者主要是对内网配置，后者是公网配置。\n\n----------------------------------------\n\n\n# 6.3broker.id\n\n该参数用来指定Kafka集群中broker的唯一标识，默认值为-1。如果没有配置，那么kafka会自动生成一个。\n\n----------------------------------------\n\n\n# 6.4log.dir & log.dirs\n\nKafka 把所有的消息都保存在磁盘上，而这两个参数用来配置Kafka日志文件存放的根目录。通常 log.dir用来配置单个根目录，log.dirs 用来配置多个根目录（多个之间用逗号分隔），但是Kafka并没有做强限制。另外 log.dirs的优先级比 log.dir 高，默认只有 log.dir 有默认值 /tmp/kafka-logs 。\n\n----------------------------------------\n\n\n# 6.5message.max.bytes\n\n该参数用来指定broker所能接收的消息的最大值，默认是 1000012B，约等于976KB。如果生产者发送的消息大于这个值，就会抛出 RecordTooLargeException。如果需要修改这个参数还要考虑客户端的参数 max.request.size 和Topic的参数 max.message.bytes 的影响。\n\n----------------------------------------\n\n至此，我们已经对Kafka有了初步的了解，接下来我们继续深入学习Kafka。',normalizedContent:'当涉及 kafka 时，有三个关键方面需要考虑，它们构成了 kafka 的核心特性，为各种应用场景提供了强大的支持：\n\n 1. 消息系统：kafka是一个高性能、分布式的消息系统，具有多重关键特性。首先，它支持异步通信，这意味着生产者和消费者不必等待对方的响应，从而提高了系统的吞吐量和响应速度。其次，kafka能够处理削峰（smoothing）——在瞬时高负载时，它能够暂存消息以确保系统的稳定性。此外，它支持消息的解耦，允许不同组件之间独立开发和部署，提高了系统的可维护性。kafka还提供卓越的扩展性，能够轻松地适应不断增长的工作负载。同时，kafka具备出色的恢复性，即使在硬件或网络故障的情况下，消息仍然能够被可靠地传递。此外，kafka支持顺序性消费，确保消息按照其产生的顺序被消费。最后，它还支持回溯消息，允许消费者重新处理历史消息，这对于分析和数据挖掘非常有用。\n 2. 存储系统：除了作为消息系统，kafka还可用作强大的分布式数据存储系统。它能够可靠地存储消息，使得这些消息可以被后续应用程序或系统查询、分析和处理。这种存储功能使kafka成为了一个持久性的、高度可扩展的数据存储引擎，用于存储和管理各种类型的数据，包括事件日志、指标、日志文件、以及其他业务数据。因此，kafka适用于实时大数据处理、日志存储、监控、以及各种其他数据管理需求。\n 3. 流式处理平台：kafka不仅仅是一个消息传递系统和数据存储引擎，它还提供了一个流式处理平台，能够为流式处理框架提供数据来源。通过kafka，数据可以被实时地传递到流处理应用程序，这使得开发者可以构建实时分析、事件驱动型应用、以及复杂的数据处理流程。kafka还提供了一套完整的流式处理类库，包括窗口处理、连接操作、数据变换以及聚合功能，使开发者能够轻松构建强大的实时数据处理应用。\n\n这三个方面的特性使 kafka 成为一种强大的工具，适用于各种现代数据处理和数据流应用，从事件驱动架构到实时数据分析和监控。\n\n----------------------------------------\n\n\n# 1.体系架构\n\nkafka 是一个强大的分布式消息传递系统，其核心体系架构包括四个主要组件：producer、broker、consumer 和 zookeeper (zk)。\n\n 1. zookeeper：kafka 使用 zookeeper 来负责集群元数据的管理、控制器的选举等操作，确保 kafka 集群的协调和一致性。\n 2. producer：生产者负责将消息发送到 kafka 的 broker 中。\n 3. broker：broker 是 kafka 集群中的消息存储节点，它们接收、存储和分发消息。\n 4. consumer：消费者从 broker 订阅并消费消息，采用拉模型（pull-based）来获取消息。\n\n一台部署了 kafka broker 的服务器可以看作是一个 kafka 服务器。\n\n----------------------------------------\n\n\n# 2.主题分区\n\n * topic：生产者在发送消息时需要指定一个 topic。topic 是消息的逻辑分类，用于组织和标识消息。\n * partition：每个 topic 可以划分为多个 partition，每个partition是一个有序、追加的日志文件，每条消息都会分配一个唯一的偏移量（offset）。偏移量用于保证消息在分区内的顺序。\n\n> kafka 保证 partition 内的消息有序，但不保证 topic 有序。topic 可能有多个 partition，它们可以分布在不同的 broker 上。\n\ntopic的多个分区可以分布在不同的broker上，消息在发送到broker之前会首先根据分区规则计算出储存到哪一个分区。如果一个topic只有一个分区，那么这个topic的性能瓶颈就是这个分区所在broker的i/o。创建topic时可以指定分区的数量，也可以随时增加分区以实现水平扩展。\n\n----------------------------------------\n\n\n# 3.副本机制\n\n * kafka 引入了副本（replica）机制用于实现容灾备份。每个 partition 可能有多个副本。\n * 副本分为三种状态：ar（all replica，所有副本），isr（in sync replica，同步中的副本），osr（out sync replica，同步之外的副本）。\n * 在同一时刻，副本之间并非完全一样。leader 副本负责处理读写请求，而 follower 副本只负责与 leader 副本的消息同步。当leader所在的broker 出现故障时，从 follower 副本中重新选举新的 leader 副本对外提供服务。\n * isr（in sync replica）指的是同步中的副本，它们具备资格被选为 leader 副本。\n * ar = isr + osr。正常情况下 ar = isr，osr = 0。\n * 副本有一个重要的概念，即 hw（high watermark），消费者只能拉取消息直到 hw 位置。hw 是所有 isr 集合内的副本的leo（logendoffset）的最小值。\n * leo（log end offset）标识当前 partition 日志文件中下一条待写入的消息的 offset。leo = 当前日志文件的最后一条消息的偏移量+1。\n * kafka客户端也具备一定的容灾备份能力，消费者使用拉模型从服务端拉消息，并且保存消费的具体位置，当消费者宕机后恢复上线时可以根据之前保存的消费位点重新拉消息。\n\n相比于同步复制的性能损耗和异步复制的不可靠性，isr的方式在两者之间做了更好的权衡。\n\n----------------------------------------\n\n\n# 4.安装配置\n\nkafka官方下载地址：http://kafka.apache.org/downloads。\n\n> kafka-xx-yy: xx 是scala版本，yy是kafka版本。\n\n下面我们使用docker安装和配置zk和kafka。\n\n 1. 首先创建一个桥接网络，方便zk和kafka因为重启docker导致ip变化时需要重新修正配置的问题。\n\ndocker network create kafka-net\n\n\n1\n\n 2. 拉取zk镜像并安装。\n\ndocker pull zookeeper:3.5.9\n\ndocker run -d --privileged=true  --name kafka-zookeeper  -p 2181:2181  --network kafka-net  --network-alias kafka-zookeeper  -v /users/huidong/docker/zk/data:/data  -v /users/huidong/docker/zk/conf:/conf  -v /users/huidong/docker/zk/logs:/datalog  zookeeper:3.5.9\n\n\n1\n2\n3\n\n\n2888为组成zookeeper服务器之间的通信端口，3888为用来选举leader的端口。如果想要查看zk的运行状态：\n\n# 1. 进入zk容器\ndocker exec -it 容器id /bin/bash\n\n# 2. 找到配置文件位置\ncat /conf/zoo.cfg\n\n# 3. 查看zk状态\nzkserver.sh status\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 3. 拉取kafka镜像并安装。\n\ndocker pull wurstmeister/kafka\n\ndocker run -d  --privileged=true \\\n--name kafka0 -p 9092:9092 \\\n--network kafka-net \\\n--network-alias kafka0 \\\n-e kafka_broker_id=0 \\\n-e kafka_zookeeper_connect=kafka-zookeeper:2181 \\\n-e kafka_listeners=plaintext://0.0.0.0:9092 \\\n-e kafka_advertised_listeners=plaintext://192.168.1.5:9092 \\\n-e allow_plaintext_listener=yes \\\nwurstmeister/kafka:latest\n\ndocker run -d  --privileged=true \\\n--name kafka1 -p 9093:9092 \\\n--network kafka-net \\\n--network-alias kafka1 \\\n-e kafka_broker_id=1 \\\n-e kafka_zookeeper_connect=kafka-zookeeper:2181 \\\n-e kafka_listeners=plaintext://0.0.0.0:9092 \\\n-e kafka_advertised_listeners=plaintext://192.168.1.5:9093 \\\n-e allow_plaintext_listener=yes \\\nwurstmeister/kafka:latest\n\ndocker run -d  --privileged=true \\\n--name kafka2 -p 9094:9092 \\\n--network kafka-net \\\n--network-alias kafka2 \\\n-e kafka_broker_id=2 \\\n-e kafka_zookeeper_connect=kafka-zookeeper:2181 \\\n-e kafka_listeners=plaintext://0.0.0.0:9092 \\\n-e kafka_advertised_listeners=plaintext://192.168.1.5:9094 \\\n-e allow_plaintext_listener=yes \\\nwurstmeister/kafka:latest\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n\n\nkafka_listeners 与 kafka_advertised_listeners 是为了区分内网和外网的，如果只有内网访问，就可以只配置 kafka_listeners。如果涉及了外网访问，比如要在云服务器上部署使用，就需要配置 kafka_advertised_listeners参数了，在开始时配置了一个 kafka-net 的网络，也就是处于这个网络下的访问才属于内网访问，而 kafka部署完毕后，需要在其他服务器上访问 kafka，这就需要通过外网访问 kafka，所以必须配置 kafka_advertised_listeners，且值为 plaintext://<服务器ip>:<暴露端口> ，例如我的电脑ip为 192.168.1.5，端口为容器暴露的端口。\n\n * kafka_broker_id : broker的id，这个id是集群的标识，不能重复。\n * kafka_zookeeper_connect：zookeeper的连接地址。\n * kafka_listeners：标识kafka服务运行在容器内的9092端口，因为没有指定host，所以是0.0.0.0标识所有的网络接口。\n * kafka_advertised_listeners：kafka发布到zookeeper供客户端使用的服务地址。\n\n至此，一个单节点的zk和三个broker的kafka集群就安装成功了。\n\n----------------------------------------\n\n\n# 5.生产消费\n\n\n# 5.1使用脚本测试\n\n我们知道生产者将消息发送到topic,而消费者也是通过订阅topic来消费消息的。进入kafka-broker所在的docker容器，在 /opt/kafka_2.13-2.8.1/bin 目录下有kafka的一些脚本，我们首先通过脚本来创建topic并测试生产和消费。\n\n 1. 创建topic\n\n./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-demo --replication-factor 3 --partitions 4\n\n\n1\n\n * factor：表示topic的副本因子，也就是每一个partition有几个副本。\n * partition：表示分区数。\n * zookeeper：指定kafka连接的zk的地址。\n * topic：指定要创建的主题的名字。\n\n 2. 查看topic的信息\n\n./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-demo\n\n\n1\n\n\n返回信息如下：\n\n# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-demo\ntopic: topic-demo       topicid: ycy_qq7xqaaglyp6fnod-a partitioncount: 4       replicationfactor: 3    configs: \n        topic: topic-demo       partition: 0    leader: 0       replicas: 0,2,1 isr: 0,2,1\n        topic: topic-demo       partition: 1    leader: 1       replicas: 1,0,2 isr: 1,0,2\n        topic: topic-demo       partition: 2    leader: 2       replicas: 2,1,0 isr: 2,1,0\n        topic: topic-demo       partition: 3    leader: 0       replicas: 0,1,2 isr: 0,1,2\n\n\n1\n2\n3\n4\n5\n6\n\n 3. 生产消息\n\n./kafka-console-producer.sh --bootstrap-server kafka0:9092 --topic topic-demo\n\n\n1\n\n * bootstrap-server：指定连接的kafka集群地址。\n\n 4. 消费消息\n\n./kafka-console-consumer.sh --bootstrap-server kafka0:9092 --topic topic-demo\n\n\n1\n\n\n----------------------------------------\n\n\n# 5.2使用代码测试\n\n我们以java客户端测试kafka集群的生产消费。\n\n 1. 首先在项目中引入kafka客户端的依赖。\n\n  <dependency>\n      <groupid>org.apache.kafka</groupid>\n      <artifactid>kafka-clients</artifactid>\n      <version>2.8.1</version>\n  </dependency>\n\n\n1\n2\n3\n4\n5\n\n 2. 使用kafka消费者消费消息。\n\n * 设置 kafka 消费者配置：配置 kafka 消费者，包括指定 kafka 服务器地址、消费者组、键值反序列化器等。\n * 创建 kafka 消费者：使用上述配置创建 kafka 消费者。\n * 订阅主题：使用 subscribe 方法订阅一个或多个主题。\n * 轮询并处理消息：使用 poll 方法轮询 kafka 主题以获取消息，并处理这些消息。处理逻辑可以根据需求来定制。\n * 关闭 kafka 消费者：在完成消费后，关闭 kafka 消费者以释放资源。\n\npublic static void consume() {\n    properties props = new properties();\n    props.put(consumerconfig.bootstrap_servers_config, brokerlist);\n    props.put(consumerconfig.group_id_config, groupname);\n    props.put(consumerconfig.key_deserializer_class_config, stringdeserializer.class.getname());\n    props.put(consumerconfig.value_deserializer_class_config, stringdeserializer.class.getname());\n\n    kafkaconsumer<string, string> consumer = new kafkaconsumer<>(props);\n    consumer.subscribe(collections.singletonlist(topicname));\n\n    while (true) {\n        consumerrecords<string, string> records = consumer.poll(duration.ofmillis(100));\n        records.foreach(record -> system.out.println("received message: key = " + record.key() + ", value = " + record.value()));\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n 3. 使用kafka生产者发送消息。\n\n * 设置 kafka 生产者配置：首先，配置 kafka 生产者。这包括指定 kafka 服务器地址、序列化器、主题名称等。\n * 创建 kafka 生产者：使用上述配置创建 kafka 生产者。\n * 发送消息：使用 send 方法向 kafka 主题发送消息。消息需要指定主题名称、消息键和消息值。\n * 关闭 kafka 生产者：在完成发送后，记得关闭 kafka 生产者以释放资源。\n\npublic static void produce() {\n    properties props = new properties();\n    props.put(producerconfig.bootstrap_servers_config, brokerlist);\n    props.put(producerconfig.key_serializer_class_config, "org.apache.kafka.common.serialization.stringserializer");\n    props.put(producerconfig.value_serializer_class_config, "org.apache.kafka.common.serialization.stringserializer");\n\n    kafkaproducer<string, string> producer = new kafkaproducer<>(props);\n\n    producerrecord<string, string> record = new producerrecord<>(topicname, "key", "value");\n\n    for (int i = 0; i < 100; i++) {\n        producer.send(record, (metadata, exception) -> {\n            if (exception == null) {\n                system.out.println("message sent to partition " + metadata.partition() + " with offset " + metadata.offset());\n            } else {\n                exception.printstacktrace();\n            }\n        });\n    }\n\n    producer.close();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n----------------------------------------\n\n\n# 6.服务端参数说明\n\n\n# 6.1zookeeper.connect\n\nzookeeper.connect 是 kafka 配置中的一个重要参数，它用于指定 kafka与zookeeper集群之间的连接信息。以下是关于 zookeeper.connect 参数的详细介绍：\n\n * 参数名称：zookeeper.connect\n * 作用：指定 kafka 集群与 zookeeper 集群之间的连接信息。\n * 格式：zookeeper.connect参数的值通常以逗号分隔的形式列出多个 zookeeper 服务器的连接地址。格式如下：\n\nhost1:port1,host2:port2,host3:port3\n\n\n1\n\n\n其中，host1:port1、host2:port2、host3:port3 是 zookeeper 服务器的主机名（或 ip地址）和端口号。使用者可以列出多个zookeeper服务器以增加可用性和冗余性。kafka 客户端会自动选择其中一个 zookeeper 服务器来进行连接。\n\n * 示例：以下是一个示例 zookeeper.connect 参数的值：\n\nzookeeper.connect=zookeeper1:2181,zookeeper2:2181,zookeeper3:2181\n\n\n1\n\n * 用途：zookeeper.connect 参数用于告知 kafka客户端如何连接到zookeeper集群，以获取元数据、执行领导者选举等操作。zookeeper还用于管理消费者组的偏移量（offset）信息，以确保kafka消费者能够继续从上次停止的地方消费消息。\n * 注意事项：在配置 zookeeper.connect 参数时，确保指定了正确的 zookeeper 服务器地址和端口号。同时，也需要确保zookeeper集群与 kafka 集群之间有良好的网络连接，以确保正常的协调和管理功能。\n\nzookeeper.connect 参数也可以配置 zookeeper 的 chroot 路径。chroot路径允许在zookeeper服务器上创建一个命名空间（类似于文件系统的目录），以便不同的应用程序或服务可以在同一个zookeeper集群上维护独立的配置和元数据信息。在kafka 中，chroot 路径通常用于隔离不同的 kafka 集群或服务。\n\n以下是关于在 zookeeper.connect 参数中配置 chroot 路径的说明：\n\n * 格式：要配置 chroot 路径，可以将其附加到 zookeeper.connect 的值中，使用斜杠（/）分隔。例如：\n\nzookeeper.connect=zk1:2181,zk2:2181/kafka-chroot\n\n\n1\n\n\n在上述示例中，kafka-chroot 是 chroot 路径，它指定了一个命名空间，kafka 将在其中执行与 zookeeper 相关的操作。\n\n----------------------------------------\n\n\n# 6.2listeners\n\n上面在安装配置小节已经介绍过 listeners 和 advertised.listeners 参数。前者主要是对内网配置，后者是公网配置。\n\n----------------------------------------\n\n\n# 6.3broker.id\n\n该参数用来指定kafka集群中broker的唯一标识，默认值为-1。如果没有配置，那么kafka会自动生成一个。\n\n----------------------------------------\n\n\n# 6.4log.dir & log.dirs\n\nkafka 把所有的消息都保存在磁盘上，而这两个参数用来配置kafka日志文件存放的根目录。通常 log.dir用来配置单个根目录，log.dirs 用来配置多个根目录（多个之间用逗号分隔），但是kafka并没有做强限制。另外 log.dirs的优先级比 log.dir 高，默认只有 log.dir 有默认值 /tmp/kafka-logs 。\n\n----------------------------------------\n\n\n# 6.5message.max.bytes\n\n该参数用来指定broker所能接收的消息的最大值，默认是 1000012b，约等于976kb。如果生产者发送的消息大于这个值，就会抛出 recordtoolargeexception。如果需要修改这个参数还要考虑客户端的参数 max.request.size 和topic的参数 max.message.bytes 的影响。\n\n----------------------------------------\n\n至此，我们已经对kafka有了初步的了解，接下来我们继续深入学习kafka。',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"消费者-客户端开发-多线程实现",frontmatter:{title:"消费者-客户端开发-多线程实现",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"消费者-客户端开发-多线程实现",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/278cdef6-836b-3904-aa7f-a51df28ee2da/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/10.%E6%B6%88%E8%B4%B9%E8%80%85-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BC%80%E5%8F%91-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AE%9E%E7%8E%B0.html",relativePath:"03.消息队列/00.Kafka/10.消费者-客户端开发-多线程实现.md",key:"v-c5d205e2",path:"/pages/278cdef6-836b-3904-aa7f-a51df28ee2da/",headersStr:null,content:'KakaProducer 是线程安全的，然而 KafkaConsumer 却是非线程安全的。KafkaConsumer定义了一个acquire()方法，用来检测当前是否只有一个线程在操作，若有其他线程正在操作会抛出 ConcurrentModifcationException 异常。\n\nKafkaConsumer 中的每个公用方法在执行所要执行的动作之前都会调用这个 acquire()方法只有 wakeup()方法是个例外。\n\nprivate final AtomicInteger refcount=new AtomicInteger(0);\nprivate void acquire(){\n        long threadId=Thread.currentThread().getId();\n        if(threadId!=currentThread.get()&&!currentThread.compareAndSet(NO_CURRENT_THREAD,threadId))\n        throw new ConcurrentModificationException("KafkaConsumer is not safe for multi-threaded access");\n        refcount.incrementAndGet();\n        }\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\nacquire()方法和我们通常所说的锁(synchronized、Lock 等)不同，它不会造成阻塞等待，我们可以将其看作一个轻量级锁，它仅通过线程操作计数标记的方式来检测线程是否发生了并发操作，以此保证只有一个线程在操作。acquire()方法和 release()方法成对出现，表示相应的加锁和解锁操作。\n\n  private void release(){\n        if(refcount.decrementAndGet()==0)\n        currentThread.set(NO_CURRENT_THREAD);\n        }\n\n\n1\n2\n3\n4\n\n\nacquire()方法和 release()方法都是私有方法，因此在实际应用中不需要我们显式地调用，但了解其内部的机理之后可以促使我们正确、有效地编写相应的程序逻辑。\n\nKafkaConsumer非线程安全并不意味着我们在消费消息的时候只能以单线程的方式执行，如果生产者发送消息的速度大于消费者处理消息的速度，那么就会有越来越多的消息得不到及时的消费，造成了一定的延迟。除此之外，由于Kaka中消息保留机制的作用，有些消息有可能在被消费之前就被清理了，从而造成消息的丢失。我们可以通过多线程的方式来实现消息消费，多线程的目的就是为了提高整体的消费能力。多线程的实现方式有多种，第一种也是最常见的方式:线程封闭，即为每个线程实例化一个 KakaConsumer 对象，如图：\n\n\n\n一个线程对应一个KafkaConsumer实例，我们可以称之为消费线程。一个消费线程可以消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。这种实现方式的并发度受限于分区的实际个数，当消费线程的个数大于分区数时，就有部分消费线程一直处于空闲的状态。\n\n与此对应的第二种方式是多个消费线程同时消费同一个分区，这个通过 assign()、seek()等方法实现，这样可以打破原有的消费线程的个数不能超过分区数的限制，进一步提高了消费的能力。不过这种实现方式对于位点提交和顺序控制的处理就会变得非常复杂，实际应用中使用得极少。一般而言，分区是消费线程的最小划分单位。下面我们通过实际编码来演示第一种多线程消费实现的方式，\n\npublic class FirstMultiConsumerThreadDemo {\n\n    public static final String brokerList = "localhost:9092";\n\n    public static final String topic = "topic-demo";\n\n    public static final String groupId = "group.demo";\n\n    public static Properties init() {\n        Properties props = new Properties();\n        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);\n        return props;\n    }\n\n    public static void main(String[] args) {\n        Properties props = init();\n        int consumerThreadNum = 4;\n\n        IntStream.range(0, consumerThreadNum).forEach(i -> new KafkaConsumerThread(props, topic).start());\n    }\n\n    public static class KafkaConsumerThread extends Thread {\n        private KafkaConsumer<String, String> kafkaConsumer;\n\n        public KafkaConsumerThread(Properties props, String topic) {\n            this.kafkaConsumer = new KafkaConsumer<>(props);\n            this.kafkaConsumer.subscribe(Collections.singletonList(topic));\n        }\n\n        @Override\n        public void run() {\n            try {\n                ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofMillis(100));\n                for (ConsumerRecord<String, String> record : records) {\n                    // 业务处理逻辑\n                    System.out.println(record.value());\n                }\n            } catch (Exception e) {\n                e.printStackTrace();\n            } finally {\n                kafkaConsumer.close();\n            }\n        }\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n\n\n内部类 KafkaConsumerThread 代表消费线程，其内部包裹着一个独立的 KafkaConsumer 实例。通过外部类的 main()方法来启动多个消费线程，消费线程的数量由 consumerThreadNum 变量指定。一般一个主题的分区数事先可以知晓，可以将 consumerThreadNum 设置成不大于分区数的值，如果不知道主题的分区数，那么也可以通过 KafkaConsumer类的 partitionsFor()方法来间接获取，进而再设置合理的 consumerThreadNum 值。\n\n上面这种多线程的实现方式和开启多个消费进程的方式没有本质上的区别，它的优点是每个线程可以按顺序消费各个分区中的消息。缺点也很明显，每个消费线程都要维护一个独立的TCP连接，如果分区数和consumerThreadNum 的值都很大，那么会造成不小的系统开销。\n\n对于上面代码中的第①行，如果这里对消息的处理非常迅速，那么 poll()拉取的频次也会更高，进而整体消费的性能也会提升;相反，如果在这里对消息的处理缓慢，比如进行一个事务性操作，或者等待一个RPC的同步响应，那么 poll()拉取的频次也会随之下降，进而造成整体消费性能的下降。一般而言， poll()拉取消息的速度是相当快的，而整体消费的瓶颈也正是在处理消息这一块，如果我们通过一定的方式来改进这一部分，那么我们就能带动整体消费性能的提升。参考下图，考虑第三种实现方式，将处理消息模块改成多线程的实现方式。\n\n\n\npublic class FirstMultiConsumerThreadDemo {\n\n    public static final String brokerList = "localhost:9092";\n\n    public static final String topic = "topic-demo";\n\n    public static final String groupId = "group.demo";\n\n    public static Properties init() {\n        Properties props = new Properties();\n        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);\n        return props;\n    }\n\n    public static void main(String[] args) {\n        Properties props = init();\n        KafkaConsumerThread thread = new KafkaConsumerThread(props, topic, Runtime.getRuntime().availableProcessors());\n        thread.start();\n    }\n\n    public static class KafkaConsumerThread extends Thread {\n        private final KafkaConsumer<String, String> kafkaConsumer;\n        private final ExecutorService executorService;\n\n        private final int consumerThreadNum;\n\n        public KafkaConsumerThread(Properties props, String topic, int consumerThreadNum) {\n            this.kafkaConsumer = new KafkaConsumer<>(props);\n            this.kafkaConsumer.subscribe(Collections.singletonList(topic));\n            this.consumerThreadNum = consumerThreadNum;\n            executorService = new ThreadPoolExecutor(consumerThreadNum, consumerThreadNum, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue<>(1000), new ThreadPoolExecutor.CallerRunsPolicy());\n        }\n\n        @Override\n        public void run() {\n            try {\n                while (true) {\n                    ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofMillis(100));\n                    if (!records.isEmpty()) {\n                        executorService.submit(new RecordsHandler(records));\n                    }\n                }\n\n            } catch (Exception e) {\n                e.printStackTrace();\n            } finally {\n                kafkaConsumer.close();\n            }\n        }\n    }\n\n    public static class RecordsHandler extends Thread {\n        private final ConsumerRecords<String, String> records;\n\n        public RecordsHandler(ConsumerRecords<String, String> records) {\n            this.records = records;\n        }\n\n        @Override\n        public void run() {\n            //处理records逻辑\n        }\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n\n\n上面代码中的 RecordHandler 类是用来处理消息的，而 KafkaConsumerThread 类的是一个消费线程，里面通过线程池的方式来调用RecordHandler 处理一批批的消息。注意KakaConsumerThread类中 ThreadPoolExccutor 里的最后一个参数设置的是 CallerRunsPolicy(),这样可以防止线程池的总体消费能力跟不上 poll()拉取的能力，从而导致异常现象的发生。第三种实现方式还可以横向扩展，通过开启多个KafkaConsumerThread 实例来进一步提升整体的消费能力。\n\n第三种实现方式相比第一种实现方式而言，除了横向扩展的能力，还可以减少 TCP 连接对系统资源的消耗，不过缺点就是对于消息的顺序处理就比较困难了。\n\n上面的代码还特别设置了自动提交消费位点。这样旨在说明在具体实现的时候并没有考虑位点提交的情况。对于第一种实现方式而言如果要做具体的位点提交，直接在KafkaConsumerThread中的 run()方法里实现即可。而对于第三种实现方式，这里引入一个共享变量 offsets 来参与提交，如下图：\n\n\n\n每一个处理消息的 RecordHandler 类在处理完消息之后都将对应的消费位点保存到共享变量offsets 中,KafkaConsumerThread在每一次 poll()方法之后都读取 offsets 中的内容并对其进行位点提交。\n\n> 在实现的过程中对 offsets 读写需要加锁处理，防止出现并发问题。并且在写入offsets 的时候需要注意位点覆盖的问题，针对这个问题，可以将RecordHandler 类中的 run()方法实现改为如下内容。\n\n    public static class RecordsHandler extends Thread {\n    private final ConsumerRecords<String, String> records;\n\n    private static final Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\n\n    public RecordsHandler(ConsumerRecords<String, String> records) {\n        this.records = records;\n    }\n\n    @Override\n    public void run() {\n        //处理records逻辑\n        for (TopicPartition tp : records.partitions()) {\n            List<ConsumerRecord<String, String>> tpRecords = records.records(tp);\n            long lastConsumedOffset = tpRecords.get(tpRecords.size() - 1).offset();\n            synchronized (offsets) {\n                if (!offsets.containsKey(tp)) {\n                    offsets.put(tp, new OffsetAndMetadata(lastConsumedOffset + 1));\n                } else {\n                    long position = offsets.get(tp).offset();\n                    if (position < lastConsumedOffset + 1) {\n                        offsets.put(tp, new OffsetAndMetadata(lastConsumedOffset + 1));\n                    }\n                }\n            }\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n对应的位点提交实现可以添加在第三种多线程实现方式的代码中 KafkaConsumerThread 类的第①行代码下方。\n\nsynchronized(offsets){\n        if(offsets.isEmpty()){\n        kafkaConsumer.commitSync(offsets);\n        }\n        }\n\n\n1\n2\n3\n4\n5\n\n\n这样实现是否万无一失?其实这种位点提交的方式会有数据丢失的风险。对于同一个分区中的消息，假设一个处理线程 RecordHandler1正在处理 offset 为 0~99 的消息，而另一个处理线程 RecordHandler2 已经处理完了 offset 为 100~199 的消息并进行了位点提交，此时如果RecordHandler1 发生异常，则之后的消费只能从 200 开始而无法再次消费 0~99的消息，从而造成了消息丢失的现象。这里虽然针对位点覆盖做了一定的处理，但还没有解决异常情况下的位点覆盖问题。对此就要引入更加复杂的处理机制，这里再提供一种解决思路，参考下图，总体结构上是基于滑动窗口实现的。对于第三种实现方式而言，它所呈现的结构是通过消费者拉取分批次的消息，然后提交给多线程进行处理，而这里的滑动窗口式的实现方式是将拉取到的消息暂存起来，多个消费线程可以拉取暂存的消息，这个用于暂存消息的缓存大小即为动窗口的大小，总体上而言没有太多的变化，不同的是对于消费位点的把控。\n\n\n\n如图所示，每一个方格代表一个批次的消息，一个滑动窗口包含若干方格，startOffset标注的是当前滑动窗口的起始位置，endOffset标注的是末尾位置。每当 startOffset指向的方格中的消息被消费完成，就可以提交这部分的位点，与此同时，窗口向前滑动一格，删除原来startOffset所指方格中对应的消息，并且拉取新的消息进入窗口。滑动窗口的大小固定，所对应的用来暂存消息的缓存大小也就固定了，这部分内存开销可控。方格大小和滑动窗口的大小同时决定了消费线程的并发数:**一个方格对应一个消费线程，对于窗口大小固定的情况，方格越小并行度越高;对于方格大小固定的情况，窗口越大并行度越高。**不过，若窗口设置得过大不仅会增大内存的开销，而且在发生异常(比如 Crash)的情况下也会引起大量的重复消费，同时还考虑线程切换的开销，建议根据实际情况设置一个合理的值，不管是对于方格还是窗口而言，过大或过小都不合适。\n\n如果一个方格内的消息无法被标记为消费完成，那么就会造成 startOffset的悬停。为了使窗口能够继续向前滑动，那么就需要设定一个阈值，当 startOffset悬停一定的时间后就对这部分消息进行本地重试消费，如果重试失败就转入重试队列，如果还不奏效就转入死信队列。真实应用中无法消费的情况极少，一般是由业务代码的处理逻辑引起的，比如消息中的内容格式与业务处理的内容格式不符，无法对这条消息进行决断，这种情况可以通过优化代码逻辑或采取丢弃策略来避免。如果需要消息高度可靠，也可以将无法进行业务逻辑的消息 (这类消息可以称为死信)存入磁盘、数据库或Kafka，然后继续消费下一条消息以保证整体消费进度合理推进，之后可以通过一个额外的处理任务来分析死信进而找出异常的原因。\n\n----------------------------------------',normalizedContent:'kakaproducer 是线程安全的，然而 kafkaconsumer 却是非线程安全的。kafkaconsumer定义了一个acquire()方法，用来检测当前是否只有一个线程在操作，若有其他线程正在操作会抛出 concurrentmodifcationexception 异常。\n\nkafkaconsumer 中的每个公用方法在执行所要执行的动作之前都会调用这个 acquire()方法只有 wakeup()方法是个例外。\n\nprivate final atomicinteger refcount=new atomicinteger(0);\nprivate void acquire(){\n        long threadid=thread.currentthread().getid();\n        if(threadid!=currentthread.get()&&!currentthread.compareandset(no_current_thread,threadid))\n        throw new concurrentmodificationexception("kafkaconsumer is not safe for multi-threaded access");\n        refcount.incrementandget();\n        }\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\nacquire()方法和我们通常所说的锁(synchronized、lock 等)不同，它不会造成阻塞等待，我们可以将其看作一个轻量级锁，它仅通过线程操作计数标记的方式来检测线程是否发生了并发操作，以此保证只有一个线程在操作。acquire()方法和 release()方法成对出现，表示相应的加锁和解锁操作。\n\n  private void release(){\n        if(refcount.decrementandget()==0)\n        currentthread.set(no_current_thread);\n        }\n\n\n1\n2\n3\n4\n\n\nacquire()方法和 release()方法都是私有方法，因此在实际应用中不需要我们显式地调用，但了解其内部的机理之后可以促使我们正确、有效地编写相应的程序逻辑。\n\nkafkaconsumer非线程安全并不意味着我们在消费消息的时候只能以单线程的方式执行，如果生产者发送消息的速度大于消费者处理消息的速度，那么就会有越来越多的消息得不到及时的消费，造成了一定的延迟。除此之外，由于kaka中消息保留机制的作用，有些消息有可能在被消费之前就被清理了，从而造成消息的丢失。我们可以通过多线程的方式来实现消息消费，多线程的目的就是为了提高整体的消费能力。多线程的实现方式有多种，第一种也是最常见的方式:线程封闭，即为每个线程实例化一个 kakaconsumer 对象，如图：\n\n\n\n一个线程对应一个kafkaconsumer实例，我们可以称之为消费线程。一个消费线程可以消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。这种实现方式的并发度受限于分区的实际个数，当消费线程的个数大于分区数时，就有部分消费线程一直处于空闲的状态。\n\n与此对应的第二种方式是多个消费线程同时消费同一个分区，这个通过 assign()、seek()等方法实现，这样可以打破原有的消费线程的个数不能超过分区数的限制，进一步提高了消费的能力。不过这种实现方式对于位点提交和顺序控制的处理就会变得非常复杂，实际应用中使用得极少。一般而言，分区是消费线程的最小划分单位。下面我们通过实际编码来演示第一种多线程消费实现的方式，\n\npublic class firstmulticonsumerthreaddemo {\n\n    public static final string brokerlist = "localhost:9092";\n\n    public static final string topic = "topic-demo";\n\n    public static final string groupid = "group.demo";\n\n    public static properties init() {\n        properties props = new properties();\n        props.put(consumerconfig.bootstrap_servers_config, brokerlist);\n        props.put(consumerconfig.group_id_config, groupid);\n        props.put(consumerconfig.key_deserializer_class_config, stringdeserializer.class.getname());\n        props.put(consumerconfig.value_deserializer_class_config, stringdeserializer.class.getname());\n        props.put(consumerconfig.enable_auto_commit_config, true);\n        return props;\n    }\n\n    public static void main(string[] args) {\n        properties props = init();\n        int consumerthreadnum = 4;\n\n        intstream.range(0, consumerthreadnum).foreach(i -> new kafkaconsumerthread(props, topic).start());\n    }\n\n    public static class kafkaconsumerthread extends thread {\n        private kafkaconsumer<string, string> kafkaconsumer;\n\n        public kafkaconsumerthread(properties props, string topic) {\n            this.kafkaconsumer = new kafkaconsumer<>(props);\n            this.kafkaconsumer.subscribe(collections.singletonlist(topic));\n        }\n\n        @override\n        public void run() {\n            try {\n                consumerrecords<string, string> records = kafkaconsumer.poll(duration.ofmillis(100));\n                for (consumerrecord<string, string> record : records) {\n                    // 业务处理逻辑\n                    system.out.println(record.value());\n                }\n            } catch (exception e) {\n                e.printstacktrace();\n            } finally {\n                kafkaconsumer.close();\n            }\n        }\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n\n\n内部类 kafkaconsumerthread 代表消费线程，其内部包裹着一个独立的 kafkaconsumer 实例。通过外部类的 main()方法来启动多个消费线程，消费线程的数量由 consumerthreadnum 变量指定。一般一个主题的分区数事先可以知晓，可以将 consumerthreadnum 设置成不大于分区数的值，如果不知道主题的分区数，那么也可以通过 kafkaconsumer类的 partitionsfor()方法来间接获取，进而再设置合理的 consumerthreadnum 值。\n\n上面这种多线程的实现方式和开启多个消费进程的方式没有本质上的区别，它的优点是每个线程可以按顺序消费各个分区中的消息。缺点也很明显，每个消费线程都要维护一个独立的tcp连接，如果分区数和consumerthreadnum 的值都很大，那么会造成不小的系统开销。\n\n对于上面代码中的第①行，如果这里对消息的处理非常迅速，那么 poll()拉取的频次也会更高，进而整体消费的性能也会提升;相反，如果在这里对消息的处理缓慢，比如进行一个事务性操作，或者等待一个rpc的同步响应，那么 poll()拉取的频次也会随之下降，进而造成整体消费性能的下降。一般而言， poll()拉取消息的速度是相当快的，而整体消费的瓶颈也正是在处理消息这一块，如果我们通过一定的方式来改进这一部分，那么我们就能带动整体消费性能的提升。参考下图，考虑第三种实现方式，将处理消息模块改成多线程的实现方式。\n\n\n\npublic class firstmulticonsumerthreaddemo {\n\n    public static final string brokerlist = "localhost:9092";\n\n    public static final string topic = "topic-demo";\n\n    public static final string groupid = "group.demo";\n\n    public static properties init() {\n        properties props = new properties();\n        props.put(consumerconfig.bootstrap_servers_config, brokerlist);\n        props.put(consumerconfig.group_id_config, groupid);\n        props.put(consumerconfig.key_deserializer_class_config, stringdeserializer.class.getname());\n        props.put(consumerconfig.value_deserializer_class_config, stringdeserializer.class.getname());\n        props.put(consumerconfig.enable_auto_commit_config, true);\n        return props;\n    }\n\n    public static void main(string[] args) {\n        properties props = init();\n        kafkaconsumerthread thread = new kafkaconsumerthread(props, topic, runtime.getruntime().availableprocessors());\n        thread.start();\n    }\n\n    public static class kafkaconsumerthread extends thread {\n        private final kafkaconsumer<string, string> kafkaconsumer;\n        private final executorservice executorservice;\n\n        private final int consumerthreadnum;\n\n        public kafkaconsumerthread(properties props, string topic, int consumerthreadnum) {\n            this.kafkaconsumer = new kafkaconsumer<>(props);\n            this.kafkaconsumer.subscribe(collections.singletonlist(topic));\n            this.consumerthreadnum = consumerthreadnum;\n            executorservice = new threadpoolexecutor(consumerthreadnum, consumerthreadnum, 0l, timeunit.milliseconds, new arrayblockingqueue<>(1000), new threadpoolexecutor.callerrunspolicy());\n        }\n\n        @override\n        public void run() {\n            try {\n                while (true) {\n                    consumerrecords<string, string> records = kafkaconsumer.poll(duration.ofmillis(100));\n                    if (!records.isempty()) {\n                        executorservice.submit(new recordshandler(records));\n                    }\n                }\n\n            } catch (exception e) {\n                e.printstacktrace();\n            } finally {\n                kafkaconsumer.close();\n            }\n        }\n    }\n\n    public static class recordshandler extends thread {\n        private final consumerrecords<string, string> records;\n\n        public recordshandler(consumerrecords<string, string> records) {\n            this.records = records;\n        }\n\n        @override\n        public void run() {\n            //处理records逻辑\n        }\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n\n\n上面代码中的 recordhandler 类是用来处理消息的，而 kafkaconsumerthread 类的是一个消费线程，里面通过线程池的方式来调用recordhandler 处理一批批的消息。注意kakaconsumerthread类中 threadpoolexccutor 里的最后一个参数设置的是 callerrunspolicy(),这样可以防止线程池的总体消费能力跟不上 poll()拉取的能力，从而导致异常现象的发生。第三种实现方式还可以横向扩展，通过开启多个kafkaconsumerthread 实例来进一步提升整体的消费能力。\n\n第三种实现方式相比第一种实现方式而言，除了横向扩展的能力，还可以减少 tcp 连接对系统资源的消耗，不过缺点就是对于消息的顺序处理就比较困难了。\n\n上面的代码还特别设置了自动提交消费位点。这样旨在说明在具体实现的时候并没有考虑位点提交的情况。对于第一种实现方式而言如果要做具体的位点提交，直接在kafkaconsumerthread中的 run()方法里实现即可。而对于第三种实现方式，这里引入一个共享变量 offsets 来参与提交，如下图：\n\n\n\n每一个处理消息的 recordhandler 类在处理完消息之后都将对应的消费位点保存到共享变量offsets 中,kafkaconsumerthread在每一次 poll()方法之后都读取 offsets 中的内容并对其进行位点提交。\n\n> 在实现的过程中对 offsets 读写需要加锁处理，防止出现并发问题。并且在写入offsets 的时候需要注意位点覆盖的问题，针对这个问题，可以将recordhandler 类中的 run()方法实现改为如下内容。\n\n    public static class recordshandler extends thread {\n    private final consumerrecords<string, string> records;\n\n    private static final map<topicpartition, offsetandmetadata> offsets = new hashmap<>();\n\n    public recordshandler(consumerrecords<string, string> records) {\n        this.records = records;\n    }\n\n    @override\n    public void run() {\n        //处理records逻辑\n        for (topicpartition tp : records.partitions()) {\n            list<consumerrecord<string, string>> tprecords = records.records(tp);\n            long lastconsumedoffset = tprecords.get(tprecords.size() - 1).offset();\n            synchronized (offsets) {\n                if (!offsets.containskey(tp)) {\n                    offsets.put(tp, new offsetandmetadata(lastconsumedoffset + 1));\n                } else {\n                    long position = offsets.get(tp).offset();\n                    if (position < lastconsumedoffset + 1) {\n                        offsets.put(tp, new offsetandmetadata(lastconsumedoffset + 1));\n                    }\n                }\n            }\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n对应的位点提交实现可以添加在第三种多线程实现方式的代码中 kafkaconsumerthread 类的第①行代码下方。\n\nsynchronized(offsets){\n        if(offsets.isempty()){\n        kafkaconsumer.commitsync(offsets);\n        }\n        }\n\n\n1\n2\n3\n4\n5\n\n\n这样实现是否万无一失?其实这种位点提交的方式会有数据丢失的风险。对于同一个分区中的消息，假设一个处理线程 recordhandler1正在处理 offset 为 0~99 的消息，而另一个处理线程 recordhandler2 已经处理完了 offset 为 100~199 的消息并进行了位点提交，此时如果recordhandler1 发生异常，则之后的消费只能从 200 开始而无法再次消费 0~99的消息，从而造成了消息丢失的现象。这里虽然针对位点覆盖做了一定的处理，但还没有解决异常情况下的位点覆盖问题。对此就要引入更加复杂的处理机制，这里再提供一种解决思路，参考下图，总体结构上是基于滑动窗口实现的。对于第三种实现方式而言，它所呈现的结构是通过消费者拉取分批次的消息，然后提交给多线程进行处理，而这里的滑动窗口式的实现方式是将拉取到的消息暂存起来，多个消费线程可以拉取暂存的消息，这个用于暂存消息的缓存大小即为动窗口的大小，总体上而言没有太多的变化，不同的是对于消费位点的把控。\n\n\n\n如图所示，每一个方格代表一个批次的消息，一个滑动窗口包含若干方格，startoffset标注的是当前滑动窗口的起始位置，endoffset标注的是末尾位置。每当 startoffset指向的方格中的消息被消费完成，就可以提交这部分的位点，与此同时，窗口向前滑动一格，删除原来startoffset所指方格中对应的消息，并且拉取新的消息进入窗口。滑动窗口的大小固定，所对应的用来暂存消息的缓存大小也就固定了，这部分内存开销可控。方格大小和滑动窗口的大小同时决定了消费线程的并发数:**一个方格对应一个消费线程，对于窗口大小固定的情况，方格越小并行度越高;对于方格大小固定的情况，窗口越大并行度越高。**不过，若窗口设置得过大不仅会增大内存的开销，而且在发生异常(比如 crash)的情况下也会引起大量的重复消费，同时还考虑线程切换的开销，建议根据实际情况设置一个合理的值，不管是对于方格还是窗口而言，过大或过小都不合适。\n\n如果一个方格内的消息无法被标记为消费完成，那么就会造成 startoffset的悬停。为了使窗口能够继续向前滑动，那么就需要设定一个阈值，当 startoffset悬停一定的时间后就对这部分消息进行本地重试消费，如果重试失败就转入重试队列，如果还不奏效就转入死信队列。真实应用中无法消费的情况极少，一般是由业务代码的处理逻辑引起的，比如消息中的内容格式与业务处理的内容格式不符，无法对这条消息进行决断，这种情况可以通过优化代码逻辑或采取丢弃策略来避免。如果需要消息高度可靠，也可以将无法进行业务逻辑的消息 (这类消息可以称为死信)存入磁盘、数据库或kafka，然后继续消费下一条消息以保证整体消费进度合理推进，之后可以通过一个额外的处理任务来分析死信进而找出异常的原因。\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"主题-主题管理",frontmatter:{title:"主题-主题管理",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"主题-主题管理",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/dbe6fcd9-6490-3b92-804a-ea7117ef815d/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/12.%E4%B8%BB%E9%A2%98-%E4%B8%BB%E9%A2%98%E7%AE%A1%E7%90%86.html",relativePath:"03.消息队列/00.Kafka/12.主题-主题管理.md",key:"v-3e9d649c",path:"/pages/dbe6fcd9-6490-3b92-804a-ea7117ef815d/",headers:[{level:2,title:"1. 创建主题",slug:"_1-创建主题",normalizedTitle:"1. 创建主题",charIndex:640},{level:2,title:"2. 分区副本的分配",slug:"_2-分区副本的分配",normalizedTitle:"2. 分区副本的分配",charIndex:8301},{level:2,title:"3.查看主题",slug:"_3-查看主题",normalizedTitle:"3.查看主题",charIndex:9592},{level:2,title:"4.修改主题",slug:"_4-修改主题",normalizedTitle:"4.修改主题",charIndex:10454},{level:2,title:"5.配置管理",slug:"_5-配置管理",normalizedTitle:"5.配置管理",charIndex:12042},{level:2,title:"6.主题端参数",slug:"_6-主题端参数",normalizedTitle:"6.主题端参数",charIndex:14021},{level:2,title:"7.删除主题",slug:"_7-删除主题",normalizedTitle:"7.删除主题",charIndex:17904}],headersStr:"1. 创建主题 2. 分区副本的分配 3.查看主题 4.修改主题 5.配置管理 6.主题端参数 7.删除主题",content:'生产者和消费者的设计理念所针对的都是主题和分区层面的操作。主题作为消息的归类，可以再细分为一到多个分区，分区可以看做是对消息的二次分类。分区的划分为kafka提供了可伸缩性，水平扩展功能，还可以通过多副本即使来为kafka提供数据冗余以提高数据可靠性。\n\n从kafka的底层实现来看，主题和分区都是逻辑上的概念，分区可以有一到多个副本，每个副本对应一个日志文件，每个日志文件对应一到多个日志分段，每个日志分段还可以细分为索引文件 ，日志存储文件 和 快照文件 等。\n\nTopic管理包括创建，查看Topic信息，修改和删除等操作。可以通过Kafka提供的 kafka-topics.sh 脚本来执行这些操作，这个脚本位于$KAFKA_HOME/bin/目录下，其核心代码仅仅只有一行：\n\nexec $ (dirname $0) /kafka-run-class.sh kafka.admin.TopicCommand "$@"\n\n\n1\n\n\n可以看到其实质上是调用了 kafka.admin.TopicCommand类来执行主题管理的操作。主题的管理并非只有使用kafka-topics.sh 脚本这一种方式，我们还可以通过KafkaAdminClient 的方式实现（这种方式本质上是通过送CreateTopicsRequest,DeleteTopicsRequest等请求来实现的）。\n\n----------------------------------------\n\n\n# 1. 创建主题\n\n如果 broker 端配置参数 auto.create.topics.enable 设置为 tue(默认值就是 true) ，那么当生产者向一个尚未创建的主题发送消息时,会自动创建一个分区数为 num.partitions(默认值为1) 、副本因子为 default.replication.factor (默认值为1) 的主题。除此之外，当一个消费者开始从未知主题中读取消息时，或者当任意一个客户端向未知主题发送元数据请求时，都会按照配置参数 num.partitions 和 default.replication.factor 的值来创建一个相应的主题。很多时候，这种自动创建主题的行为都是非预期的。除非有特殊应用需求，否则不建议将 auto.create.topics.enable 参数设置为 true，这个参数会增加主题的管理与维护的难度。\n\n下面通过 kafka-topics.sh脚本创建一个Topic。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-create --replication-factor 2 --partitions 4\nCreated topic topic-create.\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n\n\n上面的示例中创建了一个分区数为 4、副本因子为 2 的主题。示例中的环境是一个包含 3个 broker 节点的集群，每个节点的名称和 brokerld 的对照关系如下:\n\n节点名称     BROKERID\nKafka0   0\nKafka1   1\nKafka2   2\n\n在执行完脚本之后，Kafka 会在 log.dir 或 log.dirs 参数所配置的目录下创建相应的主题分区，默认情况下这个目录为/tmp/kafka-logs/。我们来看当前broker节点上创建的主题分区：\n\nroot@101ed4754423:/kafka# cd kafka-logs-101ed4754423/\nroot@101ed4754423:/kafka/kafka-logs-101ed4754423# ls -al ./ | grep topic-create\ndrwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-0\ndrwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-1\nroot@101ed4754423:/kafka/kafka-logs-101ed4754423#\n\n\n1\n2\n3\n4\n5\n\n\n可以看到当前节点中创建了 2 个文件夹 topic-create-0 和 topic-create-1，对应主题 topic-create 的2 个分区编号为0和1 的分区，命名方式可以概括为<topic>-<partition>。严谨地说，其实<topic>-<partition> 这类文件夹对应的不是分区，分区同主题一样是一个逻辑的概念而没有物理上的存在。并且这里我们也只是看到了 2 个分区，而我们创建的是 4 个分区，其余 2个分区被分配到了 Kafka1 和 Kafka2 节点中。\n\n# ls -al ./ |grep topic-create\ndrwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-1\ndrwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-2\ndrwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-3\n#\n\n\n1\n2\n3\n4\n5\n\n\n# ls -al ./ |grep topic-create\ndrwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-0\ndrwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-2\ndrwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-3\n#\n\n\n1\n2\n3\n4\n5\n\n\n三个 broker 节点一共创建了 8 个文件夹，这个数字 8 实质上是分区数 4与副本因子2 的乘积。每个副本( 或者更确切地说应该是日志，副本与日志一一对应)才真正对应了一个命名形式如<topic>-<partition>的文件来。\n\n主题和分区都是提供给上层用户的抽象，而在副本层面或更加确切地说是 Log 层面才有实际物理上的存在。同一个分区中的多个副本必须分布在不同的 broker 中，这样才能提供有效的数据冗余。对于示例中的分区数为 4副本因子为 2、broker 数为 3 的情况下，按照 2、3、3 的分区副本个数分配给各个 broker 是最优的选择。再比如在分区数为 3、副本因子为 3，并且 broker 数同样为 3 的情况下，分配 3、3、3的分区副本个数给各个 broker 是最优的选择，也就是每个 broker 中都拥有所有分区的一个副本。\n\n\n\n我们不仅可以通过日志文件的根目录来查看集群中各个 broker 的分区副本的分配情况,可以通过 ZooKeeper 客户端来获取。当创建一个主题时会在 ZooKeeper 的/brokers/topics目录下创建一个同名的实节点，该节点中记录了该主题的分区副本分配方案。示例如下，\n\n[zk: localhost:2181(CONNECTED) 0] get /brokers/topics/topic-create\n{"partitions":{"0":[2,0],"1":[0,1],"2":[1,2],"3":[2,1]},"topic_id":"iBO5jkiXSVuDFrlFowPUVQ","adding_replicas":{},"removing_replicas":{},"version":3}\n[zk: localhost:2181(CONNECTED) 1]\n\n\n1\n2\n3\n\n\n示例数据中的2:[1,2]表示分区 2 分配了 2 个副本，分别在 brokerId 为 1和 2 的 broker节点中。\n\n通过 describe 指令类型来查看分区副本的分配细节。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-create \nTopic: topic-create\tTopicId: iBO5jkiXSVuDFrlFowPUVQ\tPartitionCount: 4\tReplicationFactor: 2\tConfigs: \n\tTopic: topic-create\tPartition: 0\tLeader: 2\tReplicas: 2,0\tIsr: 2,0\n\tTopic: topic-create\tPartition: 1\tLeader: 0\tReplicas: 0,1\tIsr: 0,1\n\tTopic: topic-create\tPartition: 2\tLeader: 1\tReplicas: 1,2\tIsr: 1,2\n\tTopic: topic-create\tPartition: 3\tLeader: 2\tReplicas: 2,1\tIsr: 2,1\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n示例中的 Topic和 Partition 分别表示主题名称和分区号。PartitionCount 表示主题中分区的个数，ReplicationFactor 表示副本因子，而 Configs 表示创建或修改主题指定的参数配置。Leader表示分区的 leader 副本所对应的 brokerId,Isr 表示分区的ISR集合Replicas 表示分区的所有的副本分配情况，即 AR 集合，其中的数字都表示的是 brokerld。\n\nkafka-topics.sh脚本中还提供了一个 replica-assignment 参数来手动指定分区副本的分配方案。这种方式根据分区号的数值大小按照从小到大的顺序进行排列，分区与分区之间用逗号“，”隔开，分区内多个副本用冒号“: ”隔开。并且在使用 replica-assignment 参数创建主题时不需要原本必备的 partitions 和 replication-factor 这两个参数。\n\n通过replica-assignment参数来创建一个与主题topic-create相同的分配方案的主题 topic-create-same 和不同的分配方案的主题 topic-create-diff。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-create-same --replica-assignment 2:0,0:1,1:2,2:1\nCreated topic topic-create-same.\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# \nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe  --topic topic-create-same\nTopic: topic-create-same\tTopicId: Uza2jU5bQymPfChvfbstUg\tPartitionCount: 4\tReplicationFactor: 2\tConfigs: \n\tTopic: topic-create-same\tPartition: 0\tLeader: 2\tReplicas: 2,0\tIsr: 2,0\n\tTopic: topic-create-same\tPartition: 1\tLeader: 0\tReplicas: 0,1\tIsr: 0,1\n\tTopic: topic-create-same\tPartition: 2\tLeader: 1\tReplicas: 1,2\tIsr: 1,2\n\tTopic: topic-create-same\tPartition: 3\tLeader: 2\tReplicas: 2,1\tIsr: 2,1\n\t\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-create-diff --replica-assignment 1:2,2:0,0:1,1:0\nCreated topic topic-create-diff.\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe  --topic topic-create-diff\nTopic: topic-create-diff\tTopicId: caPBCVSDQQGfE3DNJZKfOQ\tPartitionCount: 4\tReplicationFactor: 2\tConfigs: \n\tTopic: topic-create-diff\tPartition: 0\tLeader: 1\tReplicas: 1,2\tIsr: 1,2\n\tTopic: topic-create-diff\tPartition: 1\tLeader: 2\tReplicas: 2,0\tIsr: 2,0\n\tTopic: topic-create-diff\tPartition: 2\tLeader: 0\tReplicas: 0,1\tIsr: 0,1\n\tTopic: topic-create-diff\tPartition: 3\tLeader: 1\tReplicas: 1,0\tIsr: 1,0\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n> 同一个分区内的副本不能有重复,比如指定了0:0,1:1这种,就会报出AdminCommandFailedException异常。\n\n如果分区之间所指定的副本数不同,比如0:1,0,1:0 这种,就会报出AdminOperationException异常。类似 0:1,,0:1,1:0 这种企图跳过一个分区的行为也是不被允许的。\n\n在创建主题时我们还可以通过 config 参数来设置所要创建主题的相关参数，通过这个参数可以覆盖原本的默认配置。在创建主题时可以同时设置多个参数。下面的示例使用了 config 参数来创建一个主题 topic-config。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-config --replication-factor 1 --partitions 1 --config cleanup.policy=compact --config max.message.bytes=10000\n\nCreated topic topic-config.\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe  --topic topic-config\n\nTopic: topic-config\tTopicId: XOsn8iRBTYaRGR6ZRlr3Wg\tPartitionCount: 1\tReplicationFactor: 1\tConfigs: cleanup.policy=compact,max.message.bytes=10000\n\tTopic: topic-config\tPartition: 0\tLeader: 1\tReplicas: 1\tIsr: 1\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n可以看到 Configs 一栏中包含了创建时所设置的参数。我们还可以通过 ZooKeeper 客户端查看所设置的参数，对应的ZooKeeper 节点为/config/topics/[topic]。\n\n[zk: localhost:2181(CONNECTED) 2] get /config/topics/topic-config\n{"version":1,"config":{"cleanup.policy":"compact","max.message.bytes":"10000"}}\n[zk: localhost:2181(CONNECTED) 3]\n\n\n1\n2\n3\n\n\n创建主题时对于主题名称的命名方式也很有讲究。首先是不能与已经存在的主题同名，如果创建了同名的主题就会报错。\n\n> 加了 --if-not-exists 如果存在会忽略，不会报错。\n\nkafka-topics.sh 脚本在创建主题时还会检测是否包含.或_字符。为什么要检测这两个字符呢?因为在 Kafka的内部做埋点时会根据主题的名称来命名metrics的名称，并且会将点号.改成下画线_。假设遇到一个名称为topic.1_2 的主题，还有一个名称为topic_1_2的主题，那么最后的metrics的名称都会为topic_1_2，这样就发生了名称冲突。\n\n> 主题的命名同样不推荐(虽然可以这样做)使用双下画线__开头，因为以双下画线开头的主题一般看作 Kafka 的内部主题,比如__consumer_offsets 和__transaction_state主题的名称必须由大小写字母、数字、点号.、连接线-、下画线_ 组成，不能为空不能只有点号.，也不能只有双点号..，且长度不能超过 249。\n\nKafka 从 0.10.x 版本开始支持指定 broker 的机架信息 (机架的名称)。如果指定了机架信息，则在分区副本分配时会尽可能地让分区副本分配到不同的植架上。指定机架信息是通过broker 端参数 broker.rack 来配置的，比如配置当前 broker 所在的机架为RACK1:\n\nbroker.rack=RACK1\n\n\n1\n\n\n如果一个集群中有部分 broker 指定了机架信息，并且其余的 broker 没有指定机架信息，那么在执行 kafka-topics.sh 脚本创建主题时会报出的 AdminOperationException 的异常。此时若要成功创建主题，要么将集群中的所有 broker 都加上机架信息或都去掉机架信息，要么使用 --disable-rack-aware 参数来忽略机架信息。如果集群中的所有 broker 都有机架信息，那么也可以使用 --disable-rack-aware 参数来忽略机架信息对分区副本的分配影响。\n\n----------------------------------------\n\n\n# 2. 分区副本的分配\n\n生产者的分区分配是指为每条消息指定其所要发往的分区，消费者的分区分配指定是为消费者指定其可以消费消息的分区，而这里说的分区分配是指为集群指定创建主题时的分区副本分配方案，即在哪个broker中创建哪些分区的副本。\n\n使用kafka-topics.sh 脚本创建主题时的内部分配逻辑按照机架信息划分为两种策略；未指定机架信息和指定机架信息。如果集群中所有的broker节点都没有配置 broker.rack 参数，或者使用disable-rack-aware参数来创建主题，那么采用的就是未指定机架信息的分配策略，否则采用的就是指定机架信息的分配策略。\n\n默认情况下，kafka使用的是基本的 _Round Robin_ 分配策略，它只考虑可用的 Broker，而不会明确考虑机架信息。然而，Kafka 提供了一种叫做 Rack Awareness（机架感知）的机制（也就是指定机架信息的分配策略），允许开发人员配置 Broker 所在的机架信息，并在分配分区时考虑机架信息，以提高数据的可用性和容错性。这通常用于确保分区的副本尽量分布在不同的机架上，以应对机架级别的故障。在配置 Rack Awareness时，开发人员可以将不同的 Broker 分配到不同的机架，并指定每个 Broker 的机架信息。然后，Kafka 在分配分区副本时，会考虑确保每个分区的副本尽量分布在不同的机架上，以增加系统的可用性。另外对于_Round Robin_策略：\n\n 1. Kafka 会首先根据集群中可用的 Broker 数量来确定要创建的分区数。通常，如果没有指定 partitions 参数，它将使用默认值。\n 2. 分区将被逐一分配给可用的 Broker，按照它们的编号顺序，从第一个 Broker 开始，然后依次分配给后续的 Broker。\n 3. 一旦所有分区分配完毕，如果还有剩余的 Broker，分区分配将重新从第一个 Broker 开始，以循环方式继续分配。\n\n这意味着在默认情况下，Kafka 会将分区均匀地分配给可用的 Broker，以实现负载均衡。这种默认的分配策略有助于确保分区在集群中的分布是相对均匀的，以确保各个 Broker 上的负载大致相等。\n\n> 默认的分配逻辑可能不考虑各个 Broker 的硬件配置、网络带宽、负载等因素，因此在某些情况下，开发人员可能需要自定义分配策略来更好地满足特定的需求。\n\n另外默认情况下创建主题时总是从编号为0的分区依次轮询进行分配。\n\n创建主题时，无论通过 kafka-topics.sh 脚本还是通过其他方式实质上是在 ZooKeeper 中的/brokers/topics 节点下建与该主题对应的子节点并写入分区副本分配方案，并且在/config/topics/ 节点下创建该主题对应的子节点并写入主题相关的配置信息(这个步骤可以省略不执行)。而 Kafka 创建主题的实质性动作是交由控制器异步去完成的。\n\n----------------------------------------\n\n\n# 3.查看主题\n\n通过list指令可以查看当前所有可用的主题。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka-list\n\n\n1\n\n\n前面我们是通过describe指令来查看单个主题信息的，如果不使用--topic指定主题，则会展示出所有主题的详细信息。--topic 还支持指定多个主题。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--describe--topic topic-aaa,topic-bbb\n\n\n1\n\n\nunder-replicated-partitions 和unavailable-partitions 参数都可以找出有问题的分区通过 under-replicated-partitions 参数可以找出所有包含失效副本的分区。包含失效副本的分区可能正在进行同步操作，也有可能同步发生异常，此时分区的ISR集合小于AR 集合。对于通过该参数查询到的分区要重点监控，因为这很可能意味着集群中的某个 broker 已经失效或同步效率降低等。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--describe--topic topic-aaa--under-replicated-partitions\n\n\n1\n\n\n通过 unavailable-partitions 参数可以查看主题中没有 leader 副本的分区，这些分区已经处于离线状态，对于外界的生产者和消费者来说处于不可用的状态。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--describe--topic topic-aaa unavailable-partitions\n\n\n1\n\n\n----------------------------------------\n\n\n# 4.修改主题\n\n当一个主题被创建之后，依然允许我们对其做一定的修改，比如修改分区个数，修改配置等，这个修改的功能就是由kafka-topics.sh 脚本中的alter指令提供的。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--alter--topic topic-config--partitions 3\n\n\n1\n\n\n当主题中的消息包含 key 时 (即 key 不为 null)，根据 key 计算分区的行为就会受到影响。当 topic-config 的分区数为 1 时，不管消息的 key 为何值，消息都会发往这一个分区;当分区数增加到 3 时，就会根据消息的 key 来计算分区号，原本发往分区 0 的消息现在有可能会发往分区 1 或分区 2。如此还会影响既定消息的顺序，所以在增加分区数时一定要三思而后行。对于基于 key 计算的主题而言，建议在一开始就设置好分区数量避免以后对其进行调整。\n\n目前 Kafka 只支持增加分区数而不支持减少分区数。比如我们再将主题 topic-config 的分区数修改为 1，就会报出 * InvalidPartitionException* 的异常。为什么不支持减少分区？\n\n按照 Kafka 现有的代码逻辑，此功能完全可以实现，不过也会使代码的复杂度急剧增大。实现此功能需要考虑的因素很多，比如删除的分区中的消息该如何处理? 如果随着分区一起消失则消息的可靠性得不到保障;如果需要保留则又需要考虑如何保留。直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于 Spark、Flink 这类需要消息时间戳(事件时间)的组件将会受到影响; 如果分散插入现有的分区，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障?与此同时，顺序性问题.事务性问题，以及分区和副本的状态机切换问题都是不得不面对的。反观这个功能的收益点却是很低的，如果真的需要实现此类功能，则完全可以重新创建一个分区教较小的主题，然后将现有主题中的消息按照既定的逻辑复制过去即可。\n\n除了修改分区数，我们还可以使用 kafka-topics.sh 脚本的 alter 指令来变更主题的配置。在创建主题的时候我们可以通过 config 参数来设置所要创建主题的相关参数，通过这个参数可以覆盖原本的默认配置。在创建完主题之后，我们还可以通过 alter 指令配合 config 参数增加或修改一些配置以覆盖它们配置原有的值。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--alter--topic topic-config--config max.message.bytes=20000\n\n\n1\n\n\n我们可以通过 delete-config 参数来删除之前覆盖的配置，使其恢复原有的默认值。下面的示例将主题 topic-config 中所有修改过的配置都删除:\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--alter--topic topic-config--delete-config segment.bytes\n\n\n1\n\n\n注意到在变更 (增、删、改)配置的操作执行之后都会提示一段告警信息，指明了使用kafka-topics.sh脚本的 alter 指令来变更主题配置的功能已经过时 (deprecated)，将在未来的版本中删除，并且推荐使用 kafka-configs.sh 脚本来实现相关功能。\n\n----------------------------------------\n\n\n# 5.配置管理\n\nkafka-configs.sh 脚本是专门用来对配置进行操作的，这里的操作是指在运行状态下修改原有的配置，如此可以达到动态变更的目的。kafka-configs.sh 脚本包含变更配置 alter 和查看配置 describe 这两种指令类型。同使用 kafka-topics.sh 脚本变更配置的原则一样，增、删、改的行为都可以看作变更操作，不过 kafka-configs.sh 脚本不仅可以支持操作主题相关的配置，还可以支持操作 broker、用户和客户端这3个类型的配置。\n\nkafka-configs.sh 脚本使用entity-type参数来指定操作配置的类型，并且使用entity-name 参数来指定操作配置的名称。比如查看主题 topic-config 的配置可以按如下方式执行:\n\n./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--describe--entity-typetopics--entity-name topic-config\n\n\n1\n\n\n--describe指定了查看配置的指令动作,--entity-type指定了查看配置的实体类--entity-name 指定了查看配置的实体名称。entity-type 只可以配置 4个值: topics 、brokers 、clients 和users,entity-type 与entity-name 的对应关系如下。\n\nENTITY-TYPE 的释义            ENTITY-NAME 的释义\n主题类型的配置，取值为 topics         指定主题的名称\nbroker 类型的配置，取值为 brokers   指定brokerId的值\n客户端类型的配置，取值为 clients       指定clientId的值\n用户类型的配置，取值为 users          指定用户名\n\n使用 alter 指令变更配置时，需要配合 add-config和 delete-config 这两个参数起使用。add-config 参数用来实现配置的增、改，即覆盖原有的配置;delete-config 参数用来实现配置的删，即删除被覆盖的配置以恢复默认值。下面的示例演示了 add-config 参数的用法，覆盖了主题 topic-config 的两个配置cleanup.policy和max.message.bytes(示例执行之前主题 topic-config 无任何被覆盖的配置):\n\n./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--alter--entity-type topics--entity-name topic-config--add-configcleanup.policy=compact,max.message.bytes=10000\n\n        ./kafka-configs.sh--zookeeper kafka-zookeeper:2181kafka--describe--entity-type topics--entity-name topic-config\n\n        ./kafka-topics.sh--zookeeper kafka-zookeeper:2181kafka--describe--topic topic-config--topics-with-overrides\n\n\n1\n2\n3\n4\n5\n\n\n上面示例中还使用了两种方式来查看主题 topic-config 中配置信息，注意比较这两者之间的差别。\n\n使用delete-config参数删除配置时，同add-config参数一样支持多个配置的操作，多个配置之间用逗号, 分隔，下面的示例中演示了如何删除上面刚刚增加的主题配置:\n\n./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--alter--entity-type topics--entity-name topic-config--delete-configcleanup.policy,max.message.bytes\n\n        ./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--describe--entity-type topics--entity-name topic-config\n\n\n1\n2\n3\n\n\n----------------------------------------\n\n\n# 6.主题端参数\n\n与主题相关的所有配置参数在 broker 层面都有对应参数，比如主题端参数 cleanup.policy 对应 broker 层面的 log.cleanup.policy。如果没有修改过主题的任何配置参数那么就会使用 broker 端的对应参数作为其默认值。可以在创建主题时覆盖相应参数的默认值.也可以在创建完主题之后变更相应参数的默认值。比如在创建主题的时候没有指定cleanup.policy 参数的值，那么就使用 log.cleanup.policy 参数所配置的值作为cleanup.policy的值。\n\n下表列出了主题端参数与 broker 端参数的对照关系。\n\n主题端参数                                     作用                                                          BROKER端参数\ncleanup.policy                            日志压缩策略。默认值为 delete，还可以配置为 compact。                          log.cleanup.policy\ncompression.type                          消息的压缩类型。默认值为 producer，表示保留生产者中所使用的原始压缩类型。还可以配置为             compression.type\n                                          uncompressed、snappy、Iz4、gzip\ndelete.retention.ms                       被标识为删除的数据能够保留多久。默认值为 86400000，即1天                           log.cleaner.delete.retention.ms\nfile.delete.delay.ms                      清理文件之前可以等待多长时间，默认值为60000，即1分钟                               log.segment.delete.delay.ms\nflush. messages                           需要收集多少消息才会将它们强制刷新到磁盘，默认值为 Long.MAX                          log.flush.interval.messages\n                                          VALUE，即让操作系统来决定。建议不要修改此参数的默认值\nflush.ms                                  需要等待多久才会将消息强制刷新到磁盘，默认值为 Long.MAX                            log.flush.interval.ms\n                                          VALUE，即让操作系统来决定。建议不要修改此参数的默认值\nfollower.replication.throttled.replicas   用来配置被限制速率的主题所对应的follower 副本列表                               follower.replication.throttled.replicas\nindex.interval.bytes                      用来控制添加索引项的频率。每超过这个参数所设置的消息字节数时就可以添加一个新的索引项，默认值为 4096        log.index.interval.bytes\nleader.replication.throttled.replicas     用来配置被限制速率的主题所对应的 leader副本列表                                 leader.replication.throttled.replicas\nmax.message.bytes                         消息的最大字节数，默认值为 1000012                                       message.max.bytes\nmessage.format. version                   消息格式的版本，默认值为 2.0-IV1                                        log. message. format.version\nmessage.timestamp.difference.max.ms       消息中自带的时间戳与 broker 收到消息时的时间戳之间最大的差值，默认值为Long.MAX             log.message.timestamp.difference.max.ms\n                                          VALUE。此参数只有在meesage.timestamp.type 参数设置为 CreateTime 时才有效\nmessage.timestamp.type                    消息的时间戳类型。默认值为 CreateTime,还可以设置为 LogAppendTime               log.message.timestamp.type\nmin.cleanable.dirty.ratio                 日志清理时的最小污浊率，默认值为 0.5                                        log.cleaner.min.cleanable.ratio\nmin.compaction.lag.ms                     日志再被清理前的最小保留时间，默认值为0                                        log.cleaner.min.compaction.lag.ms\nmin.insync.replicas                       分区 ISR 集合中至少要有多少个副本，默认值为 1                                  min.insync.replicas\npreallocate                               在创建日志分段的时候是否要预分配空间,默认值为 false                               log.preallocate\nretention.bytes                           分区中所能保留的消息总量，默认值为-1,即没有限制                                   log.retention.bytes\nretention.ms                              使用 delete 的日志清理策略时消息能够保留多长时间，默认值为 604800000，即 7             log.retention.ms\n                                          天。如果设置为-1，则表示没有限制\nsegment.bytes                             日志分段的最大值，默认值为 1073741824,即 1GB                              log.segment.bytes\nsegment.index.bytes                       日志分段索引的最大值，默认值为 10485760,即 10MB                             log.index.size.max.bytes\nsegment.jitter.ms                         滚动日志分段时，在 segment.ms 的基础之上增加的随机数，默认为 0                      log.roll.jitter.ms\nsegment.ms                                最长多久滚动一次日志分段，默认值为604800000，即 7 天                            log.roll.ms\nunclean.leader.election.enable            是否可以从非 ISR 集合中选举 leader 副本默认值为 false，如果设置为 true，则可能造成数据丢失   unclean.leader.election.enable\n\n----------------------------------------\n\n\n# 7.删除主题\n\n如果确定不再使用一个主题，那么最好的方式是将其删除，这样可以释放一些资源，比如磁盘、文件句柄等。kafka-topics.sh 脚本中的 delete 指令就可以用来删除主题，比如删除一个主题 topic-delete:\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--delete--topic topic-delete\n\n\n1\n\n\n可以看到在执行完删除命令之后会有相关的提示信息，这个提示信息和 broker 端配置参数delete.topic,enable 有关。必须将 delete.topic.enable 参数配置为 true 才能够除主题，这个参数的默认值就是 true，如果配置为 false，那么删除主题的操作将会被忽略。在实际生产环境中，建议将这个参数的值设置为 true。\n\n如果要删除的主题是 Kafka 的内部主题，那么删除时就会报错。截至 Kaka 2.0.0，Kafka的内部一共包含 2 个主题，分别为__consumer__offsets 和__transaction__state。下面的示例中尝试删除内部主题__consumer__offsets:\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--delete--topic __consumer_offsets\n\n\n1\n\n\n尝试删除一个不存在的主题也会报错。这里同 alter 指令一样，也可以通过 if-exists 参数来忽略异常。\n\n使用 kafka-topics.sh 脚本删除主题的行为本质上只是在 ZooKeeper 中的/admin/delete/topics 路径下创建一个与待删除主题同名的节点，以此标记该主题为待删除的状态。与创建主题相同的是，真正删除主题的动作也是由Kafka 的控制器负责完成的。\n\n删除主题是一个不可逆的操作，一旦主题被删除，与其相关的所有消息数据会被全部删除。\n\n下面列出了kafka-topics.sh脚本中的参数。\n\n参数名称                          作用\nalter                         用于修改主题，包括分区数及主题的配置\nconfig<键值对>                   创建或修改主题时，用于设置主题级别的参数\ncreate                        创建主题\ndelete                        删除主题\ndelete-config<配置名称>           删除主题级别被覆盖的配置\ndescribe                      查看主题的详细信息\ndisable-rack-aware            创建主题时不考虑机架信息\nhelp                          打印帮助信息\nif-exists                     修改或删除主题时使用，只有当主题存在时才会执行动作\nif-not-exists                 创建主题时使用，只有主题不存在时才会执行动作\nlist                          列出所有可用的主题\npartitions <分区数>              创建主题或增加分区时指定分区数\nreplica-assignment<分配方案>      手工指定分区副本分配方案\nreplication-factor<副本数>       创建主题时指定副本因子\ntopic <主题名称>                  指定主题名称\ntopics-with-overrides         使用 describe 查看主题信息时，只展示包含覆盖配置的主题\nunavailable-partitions        使用 describe 查看主题信息时，只展示包含没有 leader 副本的\n分区                            \nunder-replicated-partitions   使用 describe 查看主题信息时，只展示包含失效副本的分区\nzookeeper                     指定连接的 ZooKeeper 地址信息 (必填项)\n\n----------------------------------------',normalizedContent:'生产者和消费者的设计理念所针对的都是主题和分区层面的操作。主题作为消息的归类，可以再细分为一到多个分区，分区可以看做是对消息的二次分类。分区的划分为kafka提供了可伸缩性，水平扩展功能，还可以通过多副本即使来为kafka提供数据冗余以提高数据可靠性。\n\n从kafka的底层实现来看，主题和分区都是逻辑上的概念，分区可以有一到多个副本，每个副本对应一个日志文件，每个日志文件对应一到多个日志分段，每个日志分段还可以细分为索引文件 ，日志存储文件 和 快照文件 等。\n\ntopic管理包括创建，查看topic信息，修改和删除等操作。可以通过kafka提供的 kafka-topics.sh 脚本来执行这些操作，这个脚本位于$kafka_home/bin/目录下，其核心代码仅仅只有一行：\n\nexec $ (dirname $0) /kafka-run-class.sh kafka.admin.topiccommand "$@"\n\n\n1\n\n\n可以看到其实质上是调用了 kafka.admin.topiccommand类来执行主题管理的操作。主题的管理并非只有使用kafka-topics.sh 脚本这一种方式，我们还可以通过kafkaadminclient 的方式实现（这种方式本质上是通过送createtopicsrequest,deletetopicsrequest等请求来实现的）。\n\n----------------------------------------\n\n\n# 1. 创建主题\n\n如果 broker 端配置参数 auto.create.topics.enable 设置为 tue(默认值就是 true) ，那么当生产者向一个尚未创建的主题发送消息时,会自动创建一个分区数为 num.partitions(默认值为1) 、副本因子为 default.replication.factor (默认值为1) 的主题。除此之外，当一个消费者开始从未知主题中读取消息时，或者当任意一个客户端向未知主题发送元数据请求时，都会按照配置参数 num.partitions 和 default.replication.factor 的值来创建一个相应的主题。很多时候，这种自动创建主题的行为都是非预期的。除非有特殊应用需求，否则不建议将 auto.create.topics.enable 参数设置为 true，这个参数会增加主题的管理与维护的难度。\n\n下面通过 kafka-topics.sh脚本创建一个topic。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-create --replication-factor 2 --partitions 4\ncreated topic topic-create.\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n\n\n上面的示例中创建了一个分区数为 4、副本因子为 2 的主题。示例中的环境是一个包含 3个 broker 节点的集群，每个节点的名称和 brokerld 的对照关系如下:\n\n节点名称     brokerid\nkafka0   0\nkafka1   1\nkafka2   2\n\n在执行完脚本之后，kafka 会在 log.dir 或 log.dirs 参数所配置的目录下创建相应的主题分区，默认情况下这个目录为/tmp/kafka-logs/。我们来看当前broker节点上创建的主题分区：\n\nroot@101ed4754423:/kafka# cd kafka-logs-101ed4754423/\nroot@101ed4754423:/kafka/kafka-logs-101ed4754423# ls -al ./ | grep topic-create\ndrwxr-xr-x  2 root root 4096 oct 31 13:49 topic-create-0\ndrwxr-xr-x  2 root root 4096 oct 31 13:49 topic-create-1\nroot@101ed4754423:/kafka/kafka-logs-101ed4754423#\n\n\n1\n2\n3\n4\n5\n\n\n可以看到当前节点中创建了 2 个文件夹 topic-create-0 和 topic-create-1，对应主题 topic-create 的2 个分区编号为0和1 的分区，命名方式可以概括为<topic>-<partition>。严谨地说，其实<topic>-<partition> 这类文件夹对应的不是分区，分区同主题一样是一个逻辑的概念而没有物理上的存在。并且这里我们也只是看到了 2 个分区，而我们创建的是 4 个分区，其余 2个分区被分配到了 kafka1 和 kafka2 节点中。\n\n# ls -al ./ |grep topic-create\ndrwxr-xr-x  2 root root 4096 oct 31 13:49 topic-create-1\ndrwxr-xr-x  2 root root 4096 oct 31 13:49 topic-create-2\ndrwxr-xr-x  2 root root 4096 oct 31 13:49 topic-create-3\n#\n\n\n1\n2\n3\n4\n5\n\n\n# ls -al ./ |grep topic-create\ndrwxr-xr-x  2 root root 4096 oct 31 13:49 topic-create-0\ndrwxr-xr-x  2 root root 4096 oct 31 13:49 topic-create-2\ndrwxr-xr-x  2 root root 4096 oct 31 13:49 topic-create-3\n#\n\n\n1\n2\n3\n4\n5\n\n\n三个 broker 节点一共创建了 8 个文件夹，这个数字 8 实质上是分区数 4与副本因子2 的乘积。每个副本( 或者更确切地说应该是日志，副本与日志一一对应)才真正对应了一个命名形式如<topic>-<partition>的文件来。\n\n主题和分区都是提供给上层用户的抽象，而在副本层面或更加确切地说是 log 层面才有实际物理上的存在。同一个分区中的多个副本必须分布在不同的 broker 中，这样才能提供有效的数据冗余。对于示例中的分区数为 4副本因子为 2、broker 数为 3 的情况下，按照 2、3、3 的分区副本个数分配给各个 broker 是最优的选择。再比如在分区数为 3、副本因子为 3，并且 broker 数同样为 3 的情况下，分配 3、3、3的分区副本个数给各个 broker 是最优的选择，也就是每个 broker 中都拥有所有分区的一个副本。\n\n\n\n我们不仅可以通过日志文件的根目录来查看集群中各个 broker 的分区副本的分配情况,可以通过 zookeeper 客户端来获取。当创建一个主题时会在 zookeeper 的/brokers/topics目录下创建一个同名的实节点，该节点中记录了该主题的分区副本分配方案。示例如下，\n\n[zk: localhost:2181(connected) 0] get /brokers/topics/topic-create\n{"partitions":{"0":[2,0],"1":[0,1],"2":[1,2],"3":[2,1]},"topic_id":"ibo5jkixsvudfrlfowpuvq","adding_replicas":{},"removing_replicas":{},"version":3}\n[zk: localhost:2181(connected) 1]\n\n\n1\n2\n3\n\n\n示例数据中的2:[1,2]表示分区 2 分配了 2 个副本，分别在 brokerid 为 1和 2 的 broker节点中。\n\n通过 describe 指令类型来查看分区副本的分配细节。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-create \ntopic: topic-create\ttopicid: ibo5jkixsvudfrlfowpuvq\tpartitioncount: 4\treplicationfactor: 2\tconfigs: \n\ttopic: topic-create\tpartition: 0\tleader: 2\treplicas: 2,0\tisr: 2,0\n\ttopic: topic-create\tpartition: 1\tleader: 0\treplicas: 0,1\tisr: 0,1\n\ttopic: topic-create\tpartition: 2\tleader: 1\treplicas: 1,2\tisr: 1,2\n\ttopic: topic-create\tpartition: 3\tleader: 2\treplicas: 2,1\tisr: 2,1\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n示例中的 topic和 partition 分别表示主题名称和分区号。partitioncount 表示主题中分区的个数，replicationfactor 表示副本因子，而 configs 表示创建或修改主题指定的参数配置。leader表示分区的 leader 副本所对应的 brokerid,isr 表示分区的isr集合replicas 表示分区的所有的副本分配情况，即 ar 集合，其中的数字都表示的是 brokerld。\n\nkafka-topics.sh脚本中还提供了一个 replica-assignment 参数来手动指定分区副本的分配方案。这种方式根据分区号的数值大小按照从小到大的顺序进行排列，分区与分区之间用逗号“，”隔开，分区内多个副本用冒号“: ”隔开。并且在使用 replica-assignment 参数创建主题时不需要原本必备的 partitions 和 replication-factor 这两个参数。\n\n通过replica-assignment参数来创建一个与主题topic-create相同的分配方案的主题 topic-create-same 和不同的分配方案的主题 topic-create-diff。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-create-same --replica-assignment 2:0,0:1,1:2,2:1\ncreated topic topic-create-same.\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# \nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe  --topic topic-create-same\ntopic: topic-create-same\ttopicid: uza2ju5bqympfchvfbstug\tpartitioncount: 4\treplicationfactor: 2\tconfigs: \n\ttopic: topic-create-same\tpartition: 0\tleader: 2\treplicas: 2,0\tisr: 2,0\n\ttopic: topic-create-same\tpartition: 1\tleader: 0\treplicas: 0,1\tisr: 0,1\n\ttopic: topic-create-same\tpartition: 2\tleader: 1\treplicas: 1,2\tisr: 1,2\n\ttopic: topic-create-same\tpartition: 3\tleader: 2\treplicas: 2,1\tisr: 2,1\n\t\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-create-diff --replica-assignment 1:2,2:0,0:1,1:0\ncreated topic topic-create-diff.\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe  --topic topic-create-diff\ntopic: topic-create-diff\ttopicid: capbcvsdqqgfe3dnjzkfoq\tpartitioncount: 4\treplicationfactor: 2\tconfigs: \n\ttopic: topic-create-diff\tpartition: 0\tleader: 1\treplicas: 1,2\tisr: 1,2\n\ttopic: topic-create-diff\tpartition: 1\tleader: 2\treplicas: 2,0\tisr: 2,0\n\ttopic: topic-create-diff\tpartition: 2\tleader: 0\treplicas: 0,1\tisr: 0,1\n\ttopic: topic-create-diff\tpartition: 3\tleader: 1\treplicas: 1,0\tisr: 1,0\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n> 同一个分区内的副本不能有重复,比如指定了0:0,1:1这种,就会报出admincommandfailedexception异常。\n\n如果分区之间所指定的副本数不同,比如0:1,0,1:0 这种,就会报出adminoperationexception异常。类似 0:1,,0:1,1:0 这种企图跳过一个分区的行为也是不被允许的。\n\n在创建主题时我们还可以通过 config 参数来设置所要创建主题的相关参数，通过这个参数可以覆盖原本的默认配置。在创建主题时可以同时设置多个参数。下面的示例使用了 config 参数来创建一个主题 topic-config。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-config --replication-factor 1 --partitions 1 --config cleanup.policy=compact --config max.message.bytes=10000\n\ncreated topic topic-config.\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe  --topic topic-config\n\ntopic: topic-config\ttopicid: xosn8irbtyargr6zrlr3wg\tpartitioncount: 1\treplicationfactor: 1\tconfigs: cleanup.policy=compact,max.message.bytes=10000\n\ttopic: topic-config\tpartition: 0\tleader: 1\treplicas: 1\tisr: 1\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n可以看到 configs 一栏中包含了创建时所设置的参数。我们还可以通过 zookeeper 客户端查看所设置的参数，对应的zookeeper 节点为/config/topics/[topic]。\n\n[zk: localhost:2181(connected) 2] get /config/topics/topic-config\n{"version":1,"config":{"cleanup.policy":"compact","max.message.bytes":"10000"}}\n[zk: localhost:2181(connected) 3]\n\n\n1\n2\n3\n\n\n创建主题时对于主题名称的命名方式也很有讲究。首先是不能与已经存在的主题同名，如果创建了同名的主题就会报错。\n\n> 加了 --if-not-exists 如果存在会忽略，不会报错。\n\nkafka-topics.sh 脚本在创建主题时还会检测是否包含.或_字符。为什么要检测这两个字符呢?因为在 kafka的内部做埋点时会根据主题的名称来命名metrics的名称，并且会将点号.改成下画线_。假设遇到一个名称为topic.1_2 的主题，还有一个名称为topic_1_2的主题，那么最后的metrics的名称都会为topic_1_2，这样就发生了名称冲突。\n\n> 主题的命名同样不推荐(虽然可以这样做)使用双下画线__开头，因为以双下画线开头的主题一般看作 kafka 的内部主题,比如__consumer_offsets 和__transaction_state主题的名称必须由大小写字母、数字、点号.、连接线-、下画线_ 组成，不能为空不能只有点号.，也不能只有双点号..，且长度不能超过 249。\n\nkafka 从 0.10.x 版本开始支持指定 broker 的机架信息 (机架的名称)。如果指定了机架信息，则在分区副本分配时会尽可能地让分区副本分配到不同的植架上。指定机架信息是通过broker 端参数 broker.rack 来配置的，比如配置当前 broker 所在的机架为rack1:\n\nbroker.rack=rack1\n\n\n1\n\n\n如果一个集群中有部分 broker 指定了机架信息，并且其余的 broker 没有指定机架信息，那么在执行 kafka-topics.sh 脚本创建主题时会报出的 adminoperationexception 的异常。此时若要成功创建主题，要么将集群中的所有 broker 都加上机架信息或都去掉机架信息，要么使用 --disable-rack-aware 参数来忽略机架信息。如果集群中的所有 broker 都有机架信息，那么也可以使用 --disable-rack-aware 参数来忽略机架信息对分区副本的分配影响。\n\n----------------------------------------\n\n\n# 2. 分区副本的分配\n\n生产者的分区分配是指为每条消息指定其所要发往的分区，消费者的分区分配指定是为消费者指定其可以消费消息的分区，而这里说的分区分配是指为集群指定创建主题时的分区副本分配方案，即在哪个broker中创建哪些分区的副本。\n\n使用kafka-topics.sh 脚本创建主题时的内部分配逻辑按照机架信息划分为两种策略；未指定机架信息和指定机架信息。如果集群中所有的broker节点都没有配置 broker.rack 参数，或者使用disable-rack-aware参数来创建主题，那么采用的就是未指定机架信息的分配策略，否则采用的就是指定机架信息的分配策略。\n\n默认情况下，kafka使用的是基本的 _round robin_ 分配策略，它只考虑可用的 broker，而不会明确考虑机架信息。然而，kafka 提供了一种叫做 rack awareness（机架感知）的机制（也就是指定机架信息的分配策略），允许开发人员配置 broker 所在的机架信息，并在分配分区时考虑机架信息，以提高数据的可用性和容错性。这通常用于确保分区的副本尽量分布在不同的机架上，以应对机架级别的故障。在配置 rack awareness时，开发人员可以将不同的 broker 分配到不同的机架，并指定每个 broker 的机架信息。然后，kafka 在分配分区副本时，会考虑确保每个分区的副本尽量分布在不同的机架上，以增加系统的可用性。另外对于_round robin_策略：\n\n 1. kafka 会首先根据集群中可用的 broker 数量来确定要创建的分区数。通常，如果没有指定 partitions 参数，它将使用默认值。\n 2. 分区将被逐一分配给可用的 broker，按照它们的编号顺序，从第一个 broker 开始，然后依次分配给后续的 broker。\n 3. 一旦所有分区分配完毕，如果还有剩余的 broker，分区分配将重新从第一个 broker 开始，以循环方式继续分配。\n\n这意味着在默认情况下，kafka 会将分区均匀地分配给可用的 broker，以实现负载均衡。这种默认的分配策略有助于确保分区在集群中的分布是相对均匀的，以确保各个 broker 上的负载大致相等。\n\n> 默认的分配逻辑可能不考虑各个 broker 的硬件配置、网络带宽、负载等因素，因此在某些情况下，开发人员可能需要自定义分配策略来更好地满足特定的需求。\n\n另外默认情况下创建主题时总是从编号为0的分区依次轮询进行分配。\n\n创建主题时，无论通过 kafka-topics.sh 脚本还是通过其他方式实质上是在 zookeeper 中的/brokers/topics 节点下建与该主题对应的子节点并写入分区副本分配方案，并且在/config/topics/ 节点下创建该主题对应的子节点并写入主题相关的配置信息(这个步骤可以省略不执行)。而 kafka 创建主题的实质性动作是交由控制器异步去完成的。\n\n----------------------------------------\n\n\n# 3.查看主题\n\n通过list指令可以查看当前所有可用的主题。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka-list\n\n\n1\n\n\n前面我们是通过describe指令来查看单个主题信息的，如果不使用--topic指定主题，则会展示出所有主题的详细信息。--topic 还支持指定多个主题。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--describe--topic topic-aaa,topic-bbb\n\n\n1\n\n\nunder-replicated-partitions 和unavailable-partitions 参数都可以找出有问题的分区通过 under-replicated-partitions 参数可以找出所有包含失效副本的分区。包含失效副本的分区可能正在进行同步操作，也有可能同步发生异常，此时分区的isr集合小于ar 集合。对于通过该参数查询到的分区要重点监控，因为这很可能意味着集群中的某个 broker 已经失效或同步效率降低等。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--describe--topic topic-aaa--under-replicated-partitions\n\n\n1\n\n\n通过 unavailable-partitions 参数可以查看主题中没有 leader 副本的分区，这些分区已经处于离线状态，对于外界的生产者和消费者来说处于不可用的状态。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--describe--topic topic-aaa unavailable-partitions\n\n\n1\n\n\n----------------------------------------\n\n\n# 4.修改主题\n\n当一个主题被创建之后，依然允许我们对其做一定的修改，比如修改分区个数，修改配置等，这个修改的功能就是由kafka-topics.sh 脚本中的alter指令提供的。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--alter--topic topic-config--partitions 3\n\n\n1\n\n\n当主题中的消息包含 key 时 (即 key 不为 null)，根据 key 计算分区的行为就会受到影响。当 topic-config 的分区数为 1 时，不管消息的 key 为何值，消息都会发往这一个分区;当分区数增加到 3 时，就会根据消息的 key 来计算分区号，原本发往分区 0 的消息现在有可能会发往分区 1 或分区 2。如此还会影响既定消息的顺序，所以在增加分区数时一定要三思而后行。对于基于 key 计算的主题而言，建议在一开始就设置好分区数量避免以后对其进行调整。\n\n目前 kafka 只支持增加分区数而不支持减少分区数。比如我们再将主题 topic-config 的分区数修改为 1，就会报出 * invalidpartitionexception* 的异常。为什么不支持减少分区？\n\n按照 kafka 现有的代码逻辑，此功能完全可以实现，不过也会使代码的复杂度急剧增大。实现此功能需要考虑的因素很多，比如删除的分区中的消息该如何处理? 如果随着分区一起消失则消息的可靠性得不到保障;如果需要保留则又需要考虑如何保留。直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于 spark、flink 这类需要消息时间戳(事件时间)的组件将会受到影响; 如果分散插入现有的分区，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障?与此同时，顺序性问题.事务性问题，以及分区和副本的状态机切换问题都是不得不面对的。反观这个功能的收益点却是很低的，如果真的需要实现此类功能，则完全可以重新创建一个分区教较小的主题，然后将现有主题中的消息按照既定的逻辑复制过去即可。\n\n除了修改分区数，我们还可以使用 kafka-topics.sh 脚本的 alter 指令来变更主题的配置。在创建主题的时候我们可以通过 config 参数来设置所要创建主题的相关参数，通过这个参数可以覆盖原本的默认配置。在创建完主题之后，我们还可以通过 alter 指令配合 config 参数增加或修改一些配置以覆盖它们配置原有的值。\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--alter--topic topic-config--config max.message.bytes=20000\n\n\n1\n\n\n我们可以通过 delete-config 参数来删除之前覆盖的配置，使其恢复原有的默认值。下面的示例将主题 topic-config 中所有修改过的配置都删除:\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--alter--topic topic-config--delete-config segment.bytes\n\n\n1\n\n\n注意到在变更 (增、删、改)配置的操作执行之后都会提示一段告警信息，指明了使用kafka-topics.sh脚本的 alter 指令来变更主题配置的功能已经过时 (deprecated)，将在未来的版本中删除，并且推荐使用 kafka-configs.sh 脚本来实现相关功能。\n\n----------------------------------------\n\n\n# 5.配置管理\n\nkafka-configs.sh 脚本是专门用来对配置进行操作的，这里的操作是指在运行状态下修改原有的配置，如此可以达到动态变更的目的。kafka-configs.sh 脚本包含变更配置 alter 和查看配置 describe 这两种指令类型。同使用 kafka-topics.sh 脚本变更配置的原则一样，增、删、改的行为都可以看作变更操作，不过 kafka-configs.sh 脚本不仅可以支持操作主题相关的配置，还可以支持操作 broker、用户和客户端这3个类型的配置。\n\nkafka-configs.sh 脚本使用entity-type参数来指定操作配置的类型，并且使用entity-name 参数来指定操作配置的名称。比如查看主题 topic-config 的配置可以按如下方式执行:\n\n./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--describe--entity-typetopics--entity-name topic-config\n\n\n1\n\n\n--describe指定了查看配置的指令动作,--entity-type指定了查看配置的实体类--entity-name 指定了查看配置的实体名称。entity-type 只可以配置 4个值: topics 、brokers 、clients 和users,entity-type 与entity-name 的对应关系如下。\n\nentity-type 的释义            entity-name 的释义\n主题类型的配置，取值为 topics         指定主题的名称\nbroker 类型的配置，取值为 brokers   指定brokerid的值\n客户端类型的配置，取值为 clients       指定clientid的值\n用户类型的配置，取值为 users          指定用户名\n\n使用 alter 指令变更配置时，需要配合 add-config和 delete-config 这两个参数起使用。add-config 参数用来实现配置的增、改，即覆盖原有的配置;delete-config 参数用来实现配置的删，即删除被覆盖的配置以恢复默认值。下面的示例演示了 add-config 参数的用法，覆盖了主题 topic-config 的两个配置cleanup.policy和max.message.bytes(示例执行之前主题 topic-config 无任何被覆盖的配置):\n\n./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--alter--entity-type topics--entity-name topic-config--add-configcleanup.policy=compact,max.message.bytes=10000\n\n        ./kafka-configs.sh--zookeeper kafka-zookeeper:2181kafka--describe--entity-type topics--entity-name topic-config\n\n        ./kafka-topics.sh--zookeeper kafka-zookeeper:2181kafka--describe--topic topic-config--topics-with-overrides\n\n\n1\n2\n3\n4\n5\n\n\n上面示例中还使用了两种方式来查看主题 topic-config 中配置信息，注意比较这两者之间的差别。\n\n使用delete-config参数删除配置时，同add-config参数一样支持多个配置的操作，多个配置之间用逗号, 分隔，下面的示例中演示了如何删除上面刚刚增加的主题配置:\n\n./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--alter--entity-type topics--entity-name topic-config--delete-configcleanup.policy,max.message.bytes\n\n        ./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--describe--entity-type topics--entity-name topic-config\n\n\n1\n2\n3\n\n\n----------------------------------------\n\n\n# 6.主题端参数\n\n与主题相关的所有配置参数在 broker 层面都有对应参数，比如主题端参数 cleanup.policy 对应 broker 层面的 log.cleanup.policy。如果没有修改过主题的任何配置参数那么就会使用 broker 端的对应参数作为其默认值。可以在创建主题时覆盖相应参数的默认值.也可以在创建完主题之后变更相应参数的默认值。比如在创建主题的时候没有指定cleanup.policy 参数的值，那么就使用 log.cleanup.policy 参数所配置的值作为cleanup.policy的值。\n\n下表列出了主题端参数与 broker 端参数的对照关系。\n\n主题端参数                                     作用                                                          broker端参数\ncleanup.policy                            日志压缩策略。默认值为 delete，还可以配置为 compact。                          log.cleanup.policy\ncompression.type                          消息的压缩类型。默认值为 producer，表示保留生产者中所使用的原始压缩类型。还可以配置为             compression.type\n                                          uncompressed、snappy、iz4、gzip\ndelete.retention.ms                       被标识为删除的数据能够保留多久。默认值为 86400000，即1天                           log.cleaner.delete.retention.ms\nfile.delete.delay.ms                      清理文件之前可以等待多长时间，默认值为60000，即1分钟                               log.segment.delete.delay.ms\nflush. messages                           需要收集多少消息才会将它们强制刷新到磁盘，默认值为 long.max                          log.flush.interval.messages\n                                          value，即让操作系统来决定。建议不要修改此参数的默认值\nflush.ms                                  需要等待多久才会将消息强制刷新到磁盘，默认值为 long.max                            log.flush.interval.ms\n                                          value，即让操作系统来决定。建议不要修改此参数的默认值\nfollower.replication.throttled.replicas   用来配置被限制速率的主题所对应的follower 副本列表                               follower.replication.throttled.replicas\nindex.interval.bytes                      用来控制添加索引项的频率。每超过这个参数所设置的消息字节数时就可以添加一个新的索引项，默认值为 4096        log.index.interval.bytes\nleader.replication.throttled.replicas     用来配置被限制速率的主题所对应的 leader副本列表                                 leader.replication.throttled.replicas\nmax.message.bytes                         消息的最大字节数，默认值为 1000012                                       message.max.bytes\nmessage.format. version                   消息格式的版本，默认值为 2.0-iv1                                        log. message. format.version\nmessage.timestamp.difference.max.ms       消息中自带的时间戳与 broker 收到消息时的时间戳之间最大的差值，默认值为long.max             log.message.timestamp.difference.max.ms\n                                          value。此参数只有在meesage.timestamp.type 参数设置为 createtime 时才有效\nmessage.timestamp.type                    消息的时间戳类型。默认值为 createtime,还可以设置为 logappendtime               log.message.timestamp.type\nmin.cleanable.dirty.ratio                 日志清理时的最小污浊率，默认值为 0.5                                        log.cleaner.min.cleanable.ratio\nmin.compaction.lag.ms                     日志再被清理前的最小保留时间，默认值为0                                        log.cleaner.min.compaction.lag.ms\nmin.insync.replicas                       分区 isr 集合中至少要有多少个副本，默认值为 1                                  min.insync.replicas\npreallocate                               在创建日志分段的时候是否要预分配空间,默认值为 false                               log.preallocate\nretention.bytes                           分区中所能保留的消息总量，默认值为-1,即没有限制                                   log.retention.bytes\nretention.ms                              使用 delete 的日志清理策略时消息能够保留多长时间，默认值为 604800000，即 7             log.retention.ms\n                                          天。如果设置为-1，则表示没有限制\nsegment.bytes                             日志分段的最大值，默认值为 1073741824,即 1gb                              log.segment.bytes\nsegment.index.bytes                       日志分段索引的最大值，默认值为 10485760,即 10mb                             log.index.size.max.bytes\nsegment.jitter.ms                         滚动日志分段时，在 segment.ms 的基础之上增加的随机数，默认为 0                      log.roll.jitter.ms\nsegment.ms                                最长多久滚动一次日志分段，默认值为604800000，即 7 天                            log.roll.ms\nunclean.leader.election.enable            是否可以从非 isr 集合中选举 leader 副本默认值为 false，如果设置为 true，则可能造成数据丢失   unclean.leader.election.enable\n\n----------------------------------------\n\n\n# 7.删除主题\n\n如果确定不再使用一个主题，那么最好的方式是将其删除，这样可以释放一些资源，比如磁盘、文件句柄等。kafka-topics.sh 脚本中的 delete 指令就可以用来删除主题，比如删除一个主题 topic-delete:\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--delete--topic topic-delete\n\n\n1\n\n\n可以看到在执行完删除命令之后会有相关的提示信息，这个提示信息和 broker 端配置参数delete.topic,enable 有关。必须将 delete.topic.enable 参数配置为 true 才能够除主题，这个参数的默认值就是 true，如果配置为 false，那么删除主题的操作将会被忽略。在实际生产环境中，建议将这个参数的值设置为 true。\n\n如果要删除的主题是 kafka 的内部主题，那么删除时就会报错。截至 kaka 2.0.0，kafka的内部一共包含 2 个主题，分别为__consumer__offsets 和__transaction__state。下面的示例中尝试删除内部主题__consumer__offsets:\n\n./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--delete--topic __consumer_offsets\n\n\n1\n\n\n尝试删除一个不存在的主题也会报错。这里同 alter 指令一样，也可以通过 if-exists 参数来忽略异常。\n\n使用 kafka-topics.sh 脚本删除主题的行为本质上只是在 zookeeper 中的/admin/delete/topics 路径下创建一个与待删除主题同名的节点，以此标记该主题为待删除的状态。与创建主题相同的是，真正删除主题的动作也是由kafka 的控制器负责完成的。\n\n删除主题是一个不可逆的操作，一旦主题被删除，与其相关的所有消息数据会被全部删除。\n\n下面列出了kafka-topics.sh脚本中的参数。\n\n参数名称                          作用\nalter                         用于修改主题，包括分区数及主题的配置\nconfig<键值对>                   创建或修改主题时，用于设置主题级别的参数\ncreate                        创建主题\ndelete                        删除主题\ndelete-config<配置名称>           删除主题级别被覆盖的配置\ndescribe                      查看主题的详细信息\ndisable-rack-aware            创建主题时不考虑机架信息\nhelp                          打印帮助信息\nif-exists                     修改或删除主题时使用，只有当主题存在时才会执行动作\nif-not-exists                 创建主题时使用，只有主题不存在时才会执行动作\nlist                          列出所有可用的主题\npartitions <分区数>              创建主题或增加分区时指定分区数\nreplica-assignment<分配方案>      手工指定分区副本分配方案\nreplication-factor<副本数>       创建主题时指定副本因子\ntopic <主题名称>                  指定主题名称\ntopics-with-overrides         使用 describe 查看主题信息时，只展示包含覆盖配置的主题\nunavailable-partitions        使用 describe 查看主题信息时，只展示包含没有 leader 副本的\n分区                            \nunder-replicated-partitions   使用 describe 查看主题信息时，只展示包含失效副本的分区\nzookeeper                     指定连接的 zookeeper 地址信息 (必填项)\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"主题-kafkaAdminClient",frontmatter:{title:"主题-kafkaAdminClient",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"主题-kafkaAdminClient",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/b94bdb82-9532-3582-8bb7-19f2bc7e5c4f/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/13.%E4%B8%BB%E9%A2%98-KafkaAdminClient.html",relativePath:"03.消息队列/00.Kafka/13.主题-KafkaAdminClient.md",key:"v-688d279e",path:"/pages/b94bdb82-9532-3582-8bb7-19f2bc7e5c4f/",headers:[{level:2,title:"1.基本使用",slug:"_1-基本使用",normalizedTitle:"1.基本使用",charIndex:113},{level:2,title:"2.主题合法性验证",slug:"_2-主题合法性验证",normalizedTitle:"2.主题合法性验证",charIndex:10801}],headersStr:"1.基本使用 2.主题合法性验证",content:'如果希望将主题管理类的功能集成到公司内部系统中，打造集管理，监控，运维。告警一体的生态平台，那么就需要以程序调用API的方式去实现。\n\n----------------------------------------\n\n\n# 1.基本使用\n\n为什么不使用TopicCommand的方式？交互性差，本身返回值类型为void。KafkaAdminClient不仅可以用来管理broker，配置和ACL，还可以用来管理主题。KafkaAdminClient继承了AdminClient抽象类，并提供了多种方法。下面列举部分方法：\n\n//用于创建一个或多个主题。\nCreateTopicsResult createTopics(final Collection<NewTopic> newTopics,\n                                           final CreateTopicsOptions options)\n\n//用于删除一个或多个主题。\nDeleteTopicsResult deleteTopics(Collection<String> topicNames,\n                                           DeleteTopicsOptions options)\n\n//用于列出 Kafka 集群中的所有主题。\nListTopicsResult listTopics(final ListTopicsOptions options)\n\n//用于获取一个或多个主题的详细信息。\nDescribeTopicsResult describeTopics(final Collection<String> topicNames, DescribeTopicsOptions options)\n\n//用于获取 Kafka 集群的信息。\nDescribeClusterResult describeCluster(DescribeClusterOptions options)\n\n//用于获取 ACL（访问控制列表）的信息。\nDescribeAclsResult describeAcls(final AclBindingFilter filter, DescribeAclsOptions options)\n\n//用于创建 ACL（访问控制列表）。\nCreateAclsResult createAcls(Collection<AclBinding> acls, CreateAclsOptions options)\n\n//用于删除 ACL（访问控制列表）。\nDeleteAclsResult deleteAcls(Collection<AclBindingFilter> filters, DeleteAclsOptions options)\n\n//用于获取配置信息。\nDescribeConfigsResult describeConfigs(Collection<ConfigResource> configResources, final DescribeConfigsOptions options)\n\n//用于修改配置信息。\nalterConfigs(Map<ConfigResource, Config> configs, final AlterConfigsOptions options)\n\n//用于修改副本的日志目录。\nAlterReplicaLogDirsResult alterReplicaLogDirs(Map<TopicPartitionReplica, String> replicaAssignment, final AlterReplicaLogDirsOptions options)\n\n//用于获取 Broker 的日志目录信息。\nDescribeLogDirsResult describeLogDirs(Collection<Integer> brokers, DescribeLogDirsOptions options)\n\n//用于获取副本的日志目录信息。\nDescribeReplicaLogDirsResult describeReplicaLogDirs(Collection<TopicPartitionReplica> replicas, DescribeReplicaLogDirsOptions options)\n\n//用于创建主题的分区。\nCreatePartitionsResult createPartitions(Map<String, NewPartitions> newPartitions,\n                                                   final CreatePartitionsOptions options)\n\n//用于删除指定分区的记录。\nDeleteRecordsResult deleteRecords(final Map<TopicPartition, RecordsToDelete> recordsToDelete,\n                                             final DeleteRecordsOptions options)\n\n//用于创建令牌（token）。\nCreateDelegationTokenResult createDelegationToken(final CreateDelegationTokenOptions options)\n\n//用于续约令牌。\nRenewDelegationTokenResult renewDelegationToken(final byte[] hmac, final RenewDelegationTokenOptions options)\n\n//用于过期令牌。\nExpireDelegationTokenResult expireDelegationToken(final byte[] hmac, final ExpireDelegationTokenOptions options)\n\n\n//用于获取令牌的信息。\nDescribeDelegationTokenResult describeDelegationToken(final DescribeDelegationTokenOptions options)\n\n//用于获取消费者组的信息。\nDescribeConsumerGroupsResult describeConsumerGroups(final Collection<String> groupIds,\n                                                               final DescribeConsumerGroupsOptions options)\n//用于列出 Kafka 集群中的消费者组。\nListConsumerGroupsResult listConsumerGroups(ListConsumerGroupsOptions options)\n\n//用于获取消费者组的位移信息。\nListConsumerGroupOffsetsResult listConsumerGroupOffsets(final String groupId, final ListConsumerGroupOffsetsOptions options)\n\n//用于删除一个或多个消费者组。\nDeleteConsumerGroupsResult deleteConsumerGroups(Collection<String> groupIds, DeleteConsumerGroupsOptions options)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n\n\n使用KafkaAdminClient创建一个主题：\n\nimport org.apache.kafka.clients.admin.AdminClient;\nimport org.apache.kafka.clients.admin.NewTopic;\nimport org.apache.kafka.common.KafkaFuture;\n\nimport java.util.Collections;\nimport java.util.Properties;\n\npublic class CreateKafkaTopic {\n    public static void main(String[] args) {\n        // 配置 KafkaAdminClient 的属性\n        Properties properties = new Properties(); //①\n        properties.put("bootstrap.servers", "localhost:9092"); // 指定 Kafka 集群的地址\n\n        // 创建 KafkaAdminClient\n        AdminClient adminClient = AdminClient.create(properties); //②\n\n        // 创建一个 NewTopic 对象来描述要创建的主题\n        NewTopic newTopic = new NewTopic("my-topic", 1, (short) 1); // ③主题名称、分区数、副本因子数量\n\n        // 使用 KafkaAdminClient 创建主题\n        CreateTopicsResult createTopicResult = adminClient.createTopics(Collections.singleton(newTopic)); //④\n\n        try {\n            createTopicResult.all().get(); // ⑤阻塞等待创建操作完成\n            System.out.println("主题创建成功！");\n        } catch (Exception e) {\n            e.printStackTrace();\n            System.err.println("主题创建失败: " + e.getMessage());\n        } finally {\n            adminClient.close(); // ⑥关闭 KafkaAdminClient\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n\n\n上面的代码中第②行创建了一个KafkaAdminClient实例，实例中通过引入第①行创建的配置来连接kafka集群。AdminClient的create()方法实际上调用的就是KafkaAdminClient中的createInternal()方法构建的KafkaAdminClient实例。\n\npublic static AdminClient create(Properties props){\n        return KafkaAdminClient.createInternal(new AdminClientConfig(props),null);\n        }\n\n\n1\n2\n3\n\n\n第③行中的NewTopic用来设定所要创建主题的具体信息，包含创建主题时需要的主体名称，分区数和副本因子等。\n\n    private final String name; //名称\nprivate final int numPartitions; //分区数\nprivate final short replicationFactor; //副本因子\nprivate final Map<Integer, List<Integer>>replicasAssignments; //分配方案\nprivate Map<String, String> configs=null; //属性配置\n\n\n1\n2\n3\n4\n5\n\n\n同kafka-topics.sh脚本一样，可以通过指定分区数和副本因子来创建一个主题，也可以通过指定分区副本的具体方案来创建一个主题，比如将第③行替换为下面的内容。\n\nMap<Integer, List<Integer>>replicaAssignment=new HashMap<>();\n        replicaAssignment.put(0,Collections.singletonList(0)); // 分区 0 的副本分配到 Broker 0\n        replicaAssignment.put(1,Collections.singletonList(1)); // 分区 1 的副本分配到 Broker 1\n        NewTopic newTopic=new NewTopic("my-topic",replicaAssignment);\n\n\n1\n2\n3\n4\n\n\n也可以在创建主题时指定需要覆盖的配置，比如覆盖cleanup.policy配置，需要在第③行和第④行之间加入如下代码。\n\n        // 创建一个自定义的配置\n        Map<String, String> topicConfig=new HashMap<>();\n        topicConfig.put("cleanup.policy","compact,delete");\n        // 添加更多的自定义配置...\n\n        // 创建一个 NewTopic 对象来描述要创建的主题\n        NewTopic newTopic=new NewTopic("my-topic",replicaAssignment);\n        newTopic.configs(topicConfig);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n第④行是真正创建主题的核心。KafkaAdminClient内部使用kafka的一套自定义二进制协议来实现诸如创建主题的管理动作。他主要的实现步骤如下：\n\n 1. 客户端根据方法调用创建对应的协议请求，比如创建主题的createTopics()方法，其内部就是发送CreateTopicsRequest请求。\n 2. 客户端将请求发送到服务端。\n 3. 服务端处理相应的请求并返回响应，比如与这个CreateTopicsRequest请求对应的就是CreateTopicsResponse。\n 4. 客户端接收相应的响应并进行解析处理。和协议相关的请求和相应的类基本都在requests包下，AbstractRequest和AbstractResponse是这些请求和响应类的基本父类。\n\n第④行的返回值是CreateTopicsResult类型，具体定义如下。\n\npublic class CreateTopicsResult {\n    private final Map<String, KafkaFuture<Void>> futures;\n\n    CreateTopicsResult(Map<String, KafkaFuture<Void>> futures) {\n        this.futures = futures;\n    }\n\n    /**\n     * Return a map from topic names to futures, which can be used to check the status of individual\n     * topic creations.\n     */\n    public Map<String, KafkaFuture<Void>> values() {\n        return futures;\n    }\n\n    /**\n     * Return a future which succeeds if all the topic creations succeed.\n     */\n    public KafkaFuture<Void> all() {\n        return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\nCreateTopicsResult中的方法还是针对成员变量futures的操作，在未来的版本中，会有计划的将KafkaFuture替换成CompletableFuture。\n\n在使用KafkaAdminClient之后记得要调用close()方法释放资源。\n\n接下来查看刚刚创建的主题的基本配置。\n\npublic class DescribeKafkaTopicConfig {\n    public static void main(String[] args) {\n        // 配置 KafkaAdminClient 的属性\n        Properties properties = new Properties();\n        properties.put("bootstrap.servers", "localhost:9092"); // 指定 Kafka 集群的地址\n\n        // 创建 KafkaAdminClient\n        AdminClient adminClient = AdminClient.create(properties);\n\n        // 创建一个 ConfigResource 以描述要获取配置的主题\n        ConfigResource configResource = new ConfigResource(Type.TOPIC, "my-topic");\n\n        // 使用 KafkaAdminClient 获取主题的配置\n        DescribeConfigsResult describeConfigsResult = adminClient.describeConfigs(Collections.singleton(configResource));\n\n        try {\n            // 获取配置信息\n            Map<ConfigResource, Config> configs = describeConfigsResult.all().get();\n            Config topicConfig = configs.get(configResource);\n\n            // 打印配置信息\n            for (ConfigEntry configEntry : topicConfig.entries()) {\n                System.out.println(configEntry.name() + " = " + configEntry.value());\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n            System.err.println("获取主题配置失败: " + e.getMessage());\n        } finally {\n            adminClient.close(); // 关闭 KafkaAdminClient\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n最终的输出结果不会只列出被覆盖的配置信息，而是会列出主体中的所有的配置信息。\n\nalterConfig()方法的使用也比较简单。\n\npublic class RestoreKafkaTopicConfigToDefault {\n    public static void main(String[] args) {\n        // 配置 KafkaAdminClient 的属性\n        Properties properties = new Properties();\n        properties.put("bootstrap.servers", "localhost:9092"); // 指定 Kafka 集群的地址\n\n        // 创建 KafkaAdminClient\n        AdminClient adminClient = AdminClient.create(properties);\n\n        // 创建一个 ConfigResource 以描述要还原配置的主题\n        ConfigResource configResource = new ConfigResource(Type.TOPIC, "my-topic");\n\n        // 获取默认配置值\n        DescribeConfigsResult describeConfigsResult = adminClient.describeConfigs(Collections.singleton(configResource));\n        Config defaultConfig = null;\n        try {\n            Map<ConfigResource, Config> configs = describeConfigsResult.all().get();\n            defaultConfig = configs.get(configResource);\n        } catch (Exception e) {\n            e.printStackTrace();\n            System.err.println("获取默认配置失败: " + e.getMessage());\n            return;\n        }\n\n        // 创建一个 AlterConfigOp 来还原配置到默认值\n        AlterConfigOp alterConfigOp = new AlterConfigOp(defaultConfig.entries(), ConfigSource.DEFAULT_CONFIGS);\n\n        // 使用 KafkaAdminClient 更新主题的配置\n        Map<ConfigResource, Collection<AlterConfigOp>> configUpdates = new HashMap<>();\n        configUpdates.put(configResource, Collections.singleton(alterConfigOp));\n\n        AlterConfigsResult alterConfigsResult = adminClient.incrementalAlterConfigs(configUpdates);\n\n        try {\n            alterConfigsResult.all().get(); // 阻塞等待配置更新完成\n            System.out.println("主题配置已还原到默认值！");\n        } catch (Exception e) {\n            e.printStackTrace();\n            System.err.println("还原主题配置失败: " + e.getMessage());\n        } finally {\n            adminClient.close(); // 关闭 KafkaAdminClient\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n\n\n----------------------------------------\n\n\n# 2.主题合法性验证\n\nkafka的broker端有这样一个参数create.topic.policy.class.name，默认值为null，他提供了一个入口来验证主题创建的合法性。只需要自定义实现CreateTopicPolicy接口，然后将这个类的全限定类名配置到create.topic.policy.class.name参数。\n\n对于CreateTopicPolicy接口的几个方法：\n\n 1. configure()方法会在kafka服务启动的时候执行。\n 2. validate()方法用来鉴定主题参数的合法性，在创建主题的时候执行。\n 3. close()方法在关闭kafka服务时执行。\n\npublic interface CreateTopicPolicy extends Configurable, AutoCloseable {\n    void validate(RequestMetadata requestMetadata) throws PolicyViolationException;\n}\n\n\n1\n2\n3\n\n\n----------------------------------------',normalizedContent:'如果希望将主题管理类的功能集成到公司内部系统中，打造集管理，监控，运维。告警一体的生态平台，那么就需要以程序调用api的方式去实现。\n\n----------------------------------------\n\n\n# 1.基本使用\n\n为什么不使用topiccommand的方式？交互性差，本身返回值类型为void。kafkaadminclient不仅可以用来管理broker，配置和acl，还可以用来管理主题。kafkaadminclient继承了adminclient抽象类，并提供了多种方法。下面列举部分方法：\n\n//用于创建一个或多个主题。\ncreatetopicsresult createtopics(final collection<newtopic> newtopics,\n                                           final createtopicsoptions options)\n\n//用于删除一个或多个主题。\ndeletetopicsresult deletetopics(collection<string> topicnames,\n                                           deletetopicsoptions options)\n\n//用于列出 kafka 集群中的所有主题。\nlisttopicsresult listtopics(final listtopicsoptions options)\n\n//用于获取一个或多个主题的详细信息。\ndescribetopicsresult describetopics(final collection<string> topicnames, describetopicsoptions options)\n\n//用于获取 kafka 集群的信息。\ndescribeclusterresult describecluster(describeclusteroptions options)\n\n//用于获取 acl（访问控制列表）的信息。\ndescribeaclsresult describeacls(final aclbindingfilter filter, describeaclsoptions options)\n\n//用于创建 acl（访问控制列表）。\ncreateaclsresult createacls(collection<aclbinding> acls, createaclsoptions options)\n\n//用于删除 acl（访问控制列表）。\ndeleteaclsresult deleteacls(collection<aclbindingfilter> filters, deleteaclsoptions options)\n\n//用于获取配置信息。\ndescribeconfigsresult describeconfigs(collection<configresource> configresources, final describeconfigsoptions options)\n\n//用于修改配置信息。\nalterconfigs(map<configresource, config> configs, final alterconfigsoptions options)\n\n//用于修改副本的日志目录。\nalterreplicalogdirsresult alterreplicalogdirs(map<topicpartitionreplica, string> replicaassignment, final alterreplicalogdirsoptions options)\n\n//用于获取 broker 的日志目录信息。\ndescribelogdirsresult describelogdirs(collection<integer> brokers, describelogdirsoptions options)\n\n//用于获取副本的日志目录信息。\ndescribereplicalogdirsresult describereplicalogdirs(collection<topicpartitionreplica> replicas, describereplicalogdirsoptions options)\n\n//用于创建主题的分区。\ncreatepartitionsresult createpartitions(map<string, newpartitions> newpartitions,\n                                                   final createpartitionsoptions options)\n\n//用于删除指定分区的记录。\ndeleterecordsresult deleterecords(final map<topicpartition, recordstodelete> recordstodelete,\n                                             final deleterecordsoptions options)\n\n//用于创建令牌（token）。\ncreatedelegationtokenresult createdelegationtoken(final createdelegationtokenoptions options)\n\n//用于续约令牌。\nrenewdelegationtokenresult renewdelegationtoken(final byte[] hmac, final renewdelegationtokenoptions options)\n\n//用于过期令牌。\nexpiredelegationtokenresult expiredelegationtoken(final byte[] hmac, final expiredelegationtokenoptions options)\n\n\n//用于获取令牌的信息。\ndescribedelegationtokenresult describedelegationtoken(final describedelegationtokenoptions options)\n\n//用于获取消费者组的信息。\ndescribeconsumergroupsresult describeconsumergroups(final collection<string> groupids,\n                                                               final describeconsumergroupsoptions options)\n//用于列出 kafka 集群中的消费者组。\nlistconsumergroupsresult listconsumergroups(listconsumergroupsoptions options)\n\n//用于获取消费者组的位移信息。\nlistconsumergroupoffsetsresult listconsumergroupoffsets(final string groupid, final listconsumergroupoffsetsoptions options)\n\n//用于删除一个或多个消费者组。\ndeleteconsumergroupsresult deleteconsumergroups(collection<string> groupids, deleteconsumergroupsoptions options)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n\n\n使用kafkaadminclient创建一个主题：\n\nimport org.apache.kafka.clients.admin.adminclient;\nimport org.apache.kafka.clients.admin.newtopic;\nimport org.apache.kafka.common.kafkafuture;\n\nimport java.util.collections;\nimport java.util.properties;\n\npublic class createkafkatopic {\n    public static void main(string[] args) {\n        // 配置 kafkaadminclient 的属性\n        properties properties = new properties(); //①\n        properties.put("bootstrap.servers", "localhost:9092"); // 指定 kafka 集群的地址\n\n        // 创建 kafkaadminclient\n        adminclient adminclient = adminclient.create(properties); //②\n\n        // 创建一个 newtopic 对象来描述要创建的主题\n        newtopic newtopic = new newtopic("my-topic", 1, (short) 1); // ③主题名称、分区数、副本因子数量\n\n        // 使用 kafkaadminclient 创建主题\n        createtopicsresult createtopicresult = adminclient.createtopics(collections.singleton(newtopic)); //④\n\n        try {\n            createtopicresult.all().get(); // ⑤阻塞等待创建操作完成\n            system.out.println("主题创建成功！");\n        } catch (exception e) {\n            e.printstacktrace();\n            system.err.println("主题创建失败: " + e.getmessage());\n        } finally {\n            adminclient.close(); // ⑥关闭 kafkaadminclient\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n\n\n上面的代码中第②行创建了一个kafkaadminclient实例，实例中通过引入第①行创建的配置来连接kafka集群。adminclient的create()方法实际上调用的就是kafkaadminclient中的createinternal()方法构建的kafkaadminclient实例。\n\npublic static adminclient create(properties props){\n        return kafkaadminclient.createinternal(new adminclientconfig(props),null);\n        }\n\n\n1\n2\n3\n\n\n第③行中的newtopic用来设定所要创建主题的具体信息，包含创建主题时需要的主体名称，分区数和副本因子等。\n\n    private final string name; //名称\nprivate final int numpartitions; //分区数\nprivate final short replicationfactor; //副本因子\nprivate final map<integer, list<integer>>replicasassignments; //分配方案\nprivate map<string, string> configs=null; //属性配置\n\n\n1\n2\n3\n4\n5\n\n\n同kafka-topics.sh脚本一样，可以通过指定分区数和副本因子来创建一个主题，也可以通过指定分区副本的具体方案来创建一个主题，比如将第③行替换为下面的内容。\n\nmap<integer, list<integer>>replicaassignment=new hashmap<>();\n        replicaassignment.put(0,collections.singletonlist(0)); // 分区 0 的副本分配到 broker 0\n        replicaassignment.put(1,collections.singletonlist(1)); // 分区 1 的副本分配到 broker 1\n        newtopic newtopic=new newtopic("my-topic",replicaassignment);\n\n\n1\n2\n3\n4\n\n\n也可以在创建主题时指定需要覆盖的配置，比如覆盖cleanup.policy配置，需要在第③行和第④行之间加入如下代码。\n\n        // 创建一个自定义的配置\n        map<string, string> topicconfig=new hashmap<>();\n        topicconfig.put("cleanup.policy","compact,delete");\n        // 添加更多的自定义配置...\n\n        // 创建一个 newtopic 对象来描述要创建的主题\n        newtopic newtopic=new newtopic("my-topic",replicaassignment);\n        newtopic.configs(topicconfig);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n第④行是真正创建主题的核心。kafkaadminclient内部使用kafka的一套自定义二进制协议来实现诸如创建主题的管理动作。他主要的实现步骤如下：\n\n 1. 客户端根据方法调用创建对应的协议请求，比如创建主题的createtopics()方法，其内部就是发送createtopicsrequest请求。\n 2. 客户端将请求发送到服务端。\n 3. 服务端处理相应的请求并返回响应，比如与这个createtopicsrequest请求对应的就是createtopicsresponse。\n 4. 客户端接收相应的响应并进行解析处理。和协议相关的请求和相应的类基本都在requests包下，abstractrequest和abstractresponse是这些请求和响应类的基本父类。\n\n第④行的返回值是createtopicsresult类型，具体定义如下。\n\npublic class createtopicsresult {\n    private final map<string, kafkafuture<void>> futures;\n\n    createtopicsresult(map<string, kafkafuture<void>> futures) {\n        this.futures = futures;\n    }\n\n    /**\n     * return a map from topic names to futures, which can be used to check the status of individual\n     * topic creations.\n     */\n    public map<string, kafkafuture<void>> values() {\n        return futures;\n    }\n\n    /**\n     * return a future which succeeds if all the topic creations succeed.\n     */\n    public kafkafuture<void> all() {\n        return kafkafuture.allof(futures.values().toarray(new kafkafuture[0]));\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\ncreatetopicsresult中的方法还是针对成员变量futures的操作，在未来的版本中，会有计划的将kafkafuture替换成completablefuture。\n\n在使用kafkaadminclient之后记得要调用close()方法释放资源。\n\n接下来查看刚刚创建的主题的基本配置。\n\npublic class describekafkatopicconfig {\n    public static void main(string[] args) {\n        // 配置 kafkaadminclient 的属性\n        properties properties = new properties();\n        properties.put("bootstrap.servers", "localhost:9092"); // 指定 kafka 集群的地址\n\n        // 创建 kafkaadminclient\n        adminclient adminclient = adminclient.create(properties);\n\n        // 创建一个 configresource 以描述要获取配置的主题\n        configresource configresource = new configresource(type.topic, "my-topic");\n\n        // 使用 kafkaadminclient 获取主题的配置\n        describeconfigsresult describeconfigsresult = adminclient.describeconfigs(collections.singleton(configresource));\n\n        try {\n            // 获取配置信息\n            map<configresource, config> configs = describeconfigsresult.all().get();\n            config topicconfig = configs.get(configresource);\n\n            // 打印配置信息\n            for (configentry configentry : topicconfig.entries()) {\n                system.out.println(configentry.name() + " = " + configentry.value());\n            }\n        } catch (exception e) {\n            e.printstacktrace();\n            system.err.println("获取主题配置失败: " + e.getmessage());\n        } finally {\n            adminclient.close(); // 关闭 kafkaadminclient\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n最终的输出结果不会只列出被覆盖的配置信息，而是会列出主体中的所有的配置信息。\n\nalterconfig()方法的使用也比较简单。\n\npublic class restorekafkatopicconfigtodefault {\n    public static void main(string[] args) {\n        // 配置 kafkaadminclient 的属性\n        properties properties = new properties();\n        properties.put("bootstrap.servers", "localhost:9092"); // 指定 kafka 集群的地址\n\n        // 创建 kafkaadminclient\n        adminclient adminclient = adminclient.create(properties);\n\n        // 创建一个 configresource 以描述要还原配置的主题\n        configresource configresource = new configresource(type.topic, "my-topic");\n\n        // 获取默认配置值\n        describeconfigsresult describeconfigsresult = adminclient.describeconfigs(collections.singleton(configresource));\n        config defaultconfig = null;\n        try {\n            map<configresource, config> configs = describeconfigsresult.all().get();\n            defaultconfig = configs.get(configresource);\n        } catch (exception e) {\n            e.printstacktrace();\n            system.err.println("获取默认配置失败: " + e.getmessage());\n            return;\n        }\n\n        // 创建一个 alterconfigop 来还原配置到默认值\n        alterconfigop alterconfigop = new alterconfigop(defaultconfig.entries(), configsource.default_configs);\n\n        // 使用 kafkaadminclient 更新主题的配置\n        map<configresource, collection<alterconfigop>> configupdates = new hashmap<>();\n        configupdates.put(configresource, collections.singleton(alterconfigop));\n\n        alterconfigsresult alterconfigsresult = adminclient.incrementalalterconfigs(configupdates);\n\n        try {\n            alterconfigsresult.all().get(); // 阻塞等待配置更新完成\n            system.out.println("主题配置已还原到默认值！");\n        } catch (exception e) {\n            e.printstacktrace();\n            system.err.println("还原主题配置失败: " + e.getmessage());\n        } finally {\n            adminclient.close(); // 关闭 kafkaadminclient\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n\n\n----------------------------------------\n\n\n# 2.主题合法性验证\n\nkafka的broker端有这样一个参数create.topic.policy.class.name，默认值为null，他提供了一个入口来验证主题创建的合法性。只需要自定义实现createtopicpolicy接口，然后将这个类的全限定类名配置到create.topic.policy.class.name参数。\n\n对于createtopicpolicy接口的几个方法：\n\n 1. configure()方法会在kafka服务启动的时候执行。\n 2. validate()方法用来鉴定主题参数的合法性，在创建主题的时候执行。\n 3. close()方法在关闭kafka服务时执行。\n\npublic interface createtopicpolicy extends configurable, autocloseable {\n    void validate(requestmetadata requestmetadata) throws policyviolationexception;\n}\n\n\n1\n2\n3\n\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"消费者-客户端开发-参数说明",frontmatter:{title:"消费者-客户端开发-参数说明",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"消费者-客户端开发-参数说明",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/7ece0102-a50f-3e0c-be18-9f58eb0723e1/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/11.%E6%B6%88%E8%B4%B9%E8%80%85-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BC%80%E5%8F%91-%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E.html",relativePath:"03.消息队列/00.Kafka/11.消费者-客户端开发-参数说明.md",key:"v-3dcceb24",path:"/pages/7ece0102-a50f-3e0c-be18-9f58eb0723e1/",headers:[{level:4,title:"1) fetch.min.bytes",slug:"_1-fetch-min-bytes",normalizedTitle:"1) fetch.min.bytes",charIndex:160},{level:4,title:"2) fetch.max.bytes",slug:"_2-fetch-max-bytes",normalizedTitle:"2) fetch.max.bytes",charIndex:435},{level:4,title:"3) fetch.max.wait.ms",slug:"_3-fetch-max-wait-ms",normalizedTitle:"3) fetch.max.wait.ms",charIndex:805},{level:4,title:"4) max.partition.fetch.bytes",slug:"_4-max-partition-fetch-bytes",normalizedTitle:"4) max.partition.fetch.bytes",charIndex:1141},{level:4,title:"5) max.poll.records",slug:"_5-max-poll-records",normalizedTitle:"5) max.poll.records",charIndex:1404},{level:4,title:"6) connections.max.idle.ms",slug:"_6-connections-max-idle-ms",normalizedTitle:"6) connections.max.idle.ms",charIndex:1553},{level:4,title:"7) exclude.internal.topics",slug:"_7-exclude-internal-topics",normalizedTitle:"7) exclude.internal.topics",charIndex:1671},{level:4,title:"8) receive.buffer.bytes",slug:"_8-receive-buffer-bytes",normalizedTitle:"8) receive.buffer.bytes",charIndex:1953},{level:4,title:"9) send.buffer.bytes",slug:"_9-send-buffer-bytes",normalizedTitle:"9) send.buffer.bytes",charIndex:2140},{level:4,title:"10) request.timeout.ms",slug:"_10-request-timeout-ms",normalizedTitle:"10) request.timeout.ms",charIndex:2314},{level:4,title:"11) metadata.max.age.ms",slug:"_11-metadata-max-age-ms",normalizedTitle:"11) metadata.max.age.ms",charIndex:2429},{level:4,title:"12) reconnect.backoff.ms",slug:"_12-reconnect-backoff-ms",normalizedTitle:"12) reconnect.backoff.ms",charIndex:2595},{level:4,title:"13) retry.backoff.ms",slug:"_13-retry-backoff-ms",normalizedTitle:"13) retry.backoff.ms",charIndex:2749},{level:4,title:"14) isolation.level",slug:"_14-isolation-level",normalizedTitle:"14) isolation.level",charIndex:2888},{level:4,title:"15) 汇总",slug:"_15-汇总",normalizedTitle:"15) 汇总",charIndex:3154}],headersStr:"1) fetch.min.bytes 2) fetch.max.bytes 3) fetch.max.wait.ms 4) max.partition.fetch.bytes 5) max.poll.records 6) connections.max.idle.ms 7) exclude.internal.topics 8) receive.buffer.bytes 9) send.buffer.bytes 10) request.timeout.ms 11) metadata.max.age.ms 12) reconnect.backoff.ms 13) retry.backoff.ms 14) isolation.level 15) 汇总",content:'在 KafkaConsumer 中，除了前面提及的4个默认的客户端参数，大部分的参数都有合理的默认值，一般我们也不需要去修改它们。不过了解这些参数可以让我们更好地使用消费者客户端，其中还有一些重要的参数涉及程序的可用性和性能，如果能够熟练掌握它们，也可以让我们在编写相关的程序时能够更好地进行性能调优与故障排查。\n\n# 1) fetch.min.bytes\n\n该参数用来配置 Consumer 在一次拉取请求(调用 poll()方法)中能从 Kafka 中拉取的最小数据量，默认值为 1(B)。Kafka 在收到Consumer的拉取请求时，如果返回给Consumer的数据量小于这个参数所配置的值，那么它就需要进行等待，直到数据量满足这个参数的配置大小。可以适当调大这个参数的值以提高一定的吞吐量，不过也会造成额外的延迟 (latency)，对于延迟敏感的应用可能就不可取了。\n\n----------------------------------------\n\n# 2) fetch.max.bytes\n\n该参数与 fetch.min.bytes 参数对应,它用来配置 Consumer在一次拉取请求中从 Kafka中拉取的最大数据量，默认值为 52428800(B)，也就是 50MB。如果这个参数设置的值比任何一条写入 Kafka 中的消息要小，那么会不会造成无法消费呢? **该参数设定的不是绝对的最大值，如果在第一个非空分区中拉取的第一条消息大于该值,那么该消息将仍然返回，以确保消费者继续工作。**也就是说，上面问题的答案是可以正常消费。与此相关的，Kafka 中所能接收的最大消息的大小通过服务端参数 message.max.bytes (对应于主题端参数 max.message.bytes)来设置。\n\n----------------------------------------\n\n# 3) fetch.max.wait.ms\n\n这个参数也和 fetch.min.bytes 参数有关，如果 Kafka 仅仅参考 fetch.min.bytes参数的要求，那么有可能会一直阻塞等待而无法发送响应给Consumer，显然这是不合理的。fetch.max.wait.ms 参数用于指定 Kafka的等待时间，默认值为500 (ms)。如果 Kafka中没有足够多的消息而满足不了 fetch.min.bytes 参数的要求，那么最终会等待500ms。这个参数的设定和 Consumer 与 Kafka之间的延迟也有关系，如果业务应用对延迟敏感，那么可以适当调小这个参数。\n\n----------------------------------------\n\n# 4) max.partition.fetch.bytes\n\n这个参数用来配置从每个分区里返回给 Consumer 的最大数据量，默认值为 1048576(B)，即 IMB。这个参数与 fetch.max.bytes参数相似，只不过前者用来限制一次拉取中每个分区的消息大小，而后者用来限制一次拉取中整体消息的大小。同样，如果这个参数设定的值比消息的大小要小，那么也不会造成无法消费，Kafka为了保持消费逻辑的正常运转不会对强硬的限制。\n\n----------------------------------------\n\n# 5) max.poll.records\n\n这个参数用来配置 Consumer 在一次拉取请求中拉取的最大消息数，默认值为 500(条)。如果消息的大小都比较小，则可以适当调大这个参数值来提升一定的消费速度。\n\n----------------------------------------\n\n# 6) connections.max.idle.ms\n\n这个参数用来指定在多久之后关闭闲置的连接，默认值是 540000 (ms)，即 9分钟。\n\n----------------------------------------\n\n# 7) exclude.internal.topics\n\nKafka 中有两个内部的主题: _consumer_offsets 和 _transaction_state。exclude.internal.topics用来指定Kafka中的内部主题是否可以向消费者公开，默认值为 true。如果设置为 true，那么能使用 subscribe(Collection)的方式而不能使用 subscribe(Pattern)的方式来订阅内部主题,设置 false 则没有这个限制。\n\n----------------------------------------\n\n# 8) receive.buffer.bytes\n\n这个参数用来设置 Socket 接收消息缓冲区(SO_RECBUF)的大小，默认值为 65536(B)即 64KB。如果设置为-1，则使用操作系统的默认值。如果Consumer与 Kafka 处于不同的机房则可以适当调大这个参数值。\n\n----------------------------------------\n\n# 9) send.buffer.bytes\n\n这个参数用来设置 Socket 发送消息缓冲区(SO_SNDBUF)的大小，默认值为 131072(B)即 128KB。与receive.buffer.bytes参数一样，如果设置为-1，则使用操作系统的默认值。\n\n----------------------------------------\n\n# 10) request.timeout.ms\n\n这个参数用来配置 Consumer 等待请求响应的最长时间，默认值为 30000(ms)。\n\n----------------------------------------\n\n# 11) metadata.max.age.ms\n\n这个参数用来配置元数据的过期时间，默认值为 300000(ms)，即 5 分钟。如果元数据在此参数所限定的时间范围内没有进行更新，则会被强制更新，即使没有任何分区变化或有新broker加入。\n\n----------------------------------------\n\n# 12) reconnect.backoff.ms\n\n这个参数用来配置尝试重新连接指定主机之前的等待时间(也称为退避时间)，避免频繁地连接主机，默认值为 50(ms)。这种机制适用于消费者向broker发送的所有请求。\n\n----------------------------------------\n\n# 13) retry.backoff.ms\n\n这个参数用来配置尝试重新发送失败的请求到指定的主题分区之前的等待 (退避)时间，避免在某些故障情况下频繁地重复发送，默认值为100 (ms)。\n\n----------------------------------------\n\n# 14) isolation.level\n\n这个参数用来配置消费者的事务隔离级别。字符串类型，有效值为read_uncommitted和read_committed，表示消费者所消费到的位置，如果设置为read_committed，那么消费者就会忽略事务未提交的消息，即只能消费到 LSO (LastStableOffset)的位置，默认情况下为read_uncommitted，即可以消费到 HW (High Watermark)处的位置。\n\n----------------------------------------\n\n# 15) 汇总\n\n参数名称                            默认值                                               参数释义\nbootstrap.servers               ""                                                指定连接 Kafka 集群所需的broker 地址清单\nkey.deserializer                                                                  消息中 key\n                                                                                  所对应的反序列化类，需要实现org.apache.kafka.common.serialization.Deserializer接口\nvalue.deserializer                                                                消息中 key\n                                                                                  所对应的反序列化类，需要实现org.apache.kafka.common.serialization.Deserializer接口\ngroup.id                        ""                                                此消费者所隶属的消费组的唯一标识，即消费组的名称\nclient.id                       ""                                                消费者客户端的 id\nheartbeat.interval.ms           3000                                              当使用 Kafka\n                                                                                  的分组管理功能时，心跳到消费者协调器之间的预计时间。心跳用于确保消费者的会话保持活动状态，当有新消费者加入或离开组时方便重新平衡。该值必须比session.timeout.ms小，通常不高于\n                                                                                  1/3。它可以调整得更低，以控制正常重新平衡的预期时间\nsession.timeout.ms              10000                                             组管理协议中用来检测消费者是否失效的超时时间\nmax.poll.interval.ms            300000                                            当通过消费组管理消费者时，该配置指定拉取消息线程最长空闲时间，若超过这个时间间隔还没有发起 poll\n                                                                                  操作，则消费组认为该消费者已离开了消费组，将进行再均衡操作\nauto.offset.reset               latest                                            参数值为字符串类型，有效值为earliest latest none，配置为其余值会报出异常\nenable.auto.commit              true                                              boolean 类型，配置是否开启自动提交消费位点的功能，默认开启\nauto.commit.interval.ms         5000                                              当enbale.auto.commit 参数设置为 true\n                                                                                  时才生效,表示开启自动提交消费位点功能时自动提交消费位点的时间间隔\npartition.assignment.strategy   org.apache.kafka.clients.consumer.RangeAssignor   消费者的分区分配策略\ninterceptor.class               ""                                                用来配置消费者客户端的拦截器\n\n----------------------------------------',normalizedContent:'在 kafkaconsumer 中，除了前面提及的4个默认的客户端参数，大部分的参数都有合理的默认值，一般我们也不需要去修改它们。不过了解这些参数可以让我们更好地使用消费者客户端，其中还有一些重要的参数涉及程序的可用性和性能，如果能够熟练掌握它们，也可以让我们在编写相关的程序时能够更好地进行性能调优与故障排查。\n\n# 1) fetch.min.bytes\n\n该参数用来配置 consumer 在一次拉取请求(调用 poll()方法)中能从 kafka 中拉取的最小数据量，默认值为 1(b)。kafka 在收到consumer的拉取请求时，如果返回给consumer的数据量小于这个参数所配置的值，那么它就需要进行等待，直到数据量满足这个参数的配置大小。可以适当调大这个参数的值以提高一定的吞吐量，不过也会造成额外的延迟 (latency)，对于延迟敏感的应用可能就不可取了。\n\n----------------------------------------\n\n# 2) fetch.max.bytes\n\n该参数与 fetch.min.bytes 参数对应,它用来配置 consumer在一次拉取请求中从 kafka中拉取的最大数据量，默认值为 52428800(b)，也就是 50mb。如果这个参数设置的值比任何一条写入 kafka 中的消息要小，那么会不会造成无法消费呢? **该参数设定的不是绝对的最大值，如果在第一个非空分区中拉取的第一条消息大于该值,那么该消息将仍然返回，以确保消费者继续工作。**也就是说，上面问题的答案是可以正常消费。与此相关的，kafka 中所能接收的最大消息的大小通过服务端参数 message.max.bytes (对应于主题端参数 max.message.bytes)来设置。\n\n----------------------------------------\n\n# 3) fetch.max.wait.ms\n\n这个参数也和 fetch.min.bytes 参数有关，如果 kafka 仅仅参考 fetch.min.bytes参数的要求，那么有可能会一直阻塞等待而无法发送响应给consumer，显然这是不合理的。fetch.max.wait.ms 参数用于指定 kafka的等待时间，默认值为500 (ms)。如果 kafka中没有足够多的消息而满足不了 fetch.min.bytes 参数的要求，那么最终会等待500ms。这个参数的设定和 consumer 与 kafka之间的延迟也有关系，如果业务应用对延迟敏感，那么可以适当调小这个参数。\n\n----------------------------------------\n\n# 4) max.partition.fetch.bytes\n\n这个参数用来配置从每个分区里返回给 consumer 的最大数据量，默认值为 1048576(b)，即 imb。这个参数与 fetch.max.bytes参数相似，只不过前者用来限制一次拉取中每个分区的消息大小，而后者用来限制一次拉取中整体消息的大小。同样，如果这个参数设定的值比消息的大小要小，那么也不会造成无法消费，kafka为了保持消费逻辑的正常运转不会对强硬的限制。\n\n----------------------------------------\n\n# 5) max.poll.records\n\n这个参数用来配置 consumer 在一次拉取请求中拉取的最大消息数，默认值为 500(条)。如果消息的大小都比较小，则可以适当调大这个参数值来提升一定的消费速度。\n\n----------------------------------------\n\n# 6) connections.max.idle.ms\n\n这个参数用来指定在多久之后关闭闲置的连接，默认值是 540000 (ms)，即 9分钟。\n\n----------------------------------------\n\n# 7) exclude.internal.topics\n\nkafka 中有两个内部的主题: _consumer_offsets 和 _transaction_state。exclude.internal.topics用来指定kafka中的内部主题是否可以向消费者公开，默认值为 true。如果设置为 true，那么能使用 subscribe(collection)的方式而不能使用 subscribe(pattern)的方式来订阅内部主题,设置 false 则没有这个限制。\n\n----------------------------------------\n\n# 8) receive.buffer.bytes\n\n这个参数用来设置 socket 接收消息缓冲区(so_recbuf)的大小，默认值为 65536(b)即 64kb。如果设置为-1，则使用操作系统的默认值。如果consumer与 kafka 处于不同的机房则可以适当调大这个参数值。\n\n----------------------------------------\n\n# 9) send.buffer.bytes\n\n这个参数用来设置 socket 发送消息缓冲区(so_sndbuf)的大小，默认值为 131072(b)即 128kb。与receive.buffer.bytes参数一样，如果设置为-1，则使用操作系统的默认值。\n\n----------------------------------------\n\n# 10) request.timeout.ms\n\n这个参数用来配置 consumer 等待请求响应的最长时间，默认值为 30000(ms)。\n\n----------------------------------------\n\n# 11) metadata.max.age.ms\n\n这个参数用来配置元数据的过期时间，默认值为 300000(ms)，即 5 分钟。如果元数据在此参数所限定的时间范围内没有进行更新，则会被强制更新，即使没有任何分区变化或有新broker加入。\n\n----------------------------------------\n\n# 12) reconnect.backoff.ms\n\n这个参数用来配置尝试重新连接指定主机之前的等待时间(也称为退避时间)，避免频繁地连接主机，默认值为 50(ms)。这种机制适用于消费者向broker发送的所有请求。\n\n----------------------------------------\n\n# 13) retry.backoff.ms\n\n这个参数用来配置尝试重新发送失败的请求到指定的主题分区之前的等待 (退避)时间，避免在某些故障情况下频繁地重复发送，默认值为100 (ms)。\n\n----------------------------------------\n\n# 14) isolation.level\n\n这个参数用来配置消费者的事务隔离级别。字符串类型，有效值为read_uncommitted和read_committed，表示消费者所消费到的位置，如果设置为read_committed，那么消费者就会忽略事务未提交的消息，即只能消费到 lso (laststableoffset)的位置，默认情况下为read_uncommitted，即可以消费到 hw (high watermark)处的位置。\n\n----------------------------------------\n\n# 15) 汇总\n\n参数名称                            默认值                                               参数释义\nbootstrap.servers               ""                                                指定连接 kafka 集群所需的broker 地址清单\nkey.deserializer                                                                  消息中 key\n                                                                                  所对应的反序列化类，需要实现org.apache.kafka.common.serialization.deserializer接口\nvalue.deserializer                                                                消息中 key\n                                                                                  所对应的反序列化类，需要实现org.apache.kafka.common.serialization.deserializer接口\ngroup.id                        ""                                                此消费者所隶属的消费组的唯一标识，即消费组的名称\nclient.id                       ""                                                消费者客户端的 id\nheartbeat.interval.ms           3000                                              当使用 kafka\n                                                                                  的分组管理功能时，心跳到消费者协调器之间的预计时间。心跳用于确保消费者的会话保持活动状态，当有新消费者加入或离开组时方便重新平衡。该值必须比session.timeout.ms小，通常不高于\n                                                                                  1/3。它可以调整得更低，以控制正常重新平衡的预期时间\nsession.timeout.ms              10000                                             组管理协议中用来检测消费者是否失效的超时时间\nmax.poll.interval.ms            300000                                            当通过消费组管理消费者时，该配置指定拉取消息线程最长空闲时间，若超过这个时间间隔还没有发起 poll\n                                                                                  操作，则消费组认为该消费者已离开了消费组，将进行再均衡操作\nauto.offset.reset               latest                                            参数值为字符串类型，有效值为earliest latest none，配置为其余值会报出异常\nenable.auto.commit              true                                              boolean 类型，配置是否开启自动提交消费位点的功能，默认开启\nauto.commit.interval.ms         5000                                              当enbale.auto.commit 参数设置为 true\n                                                                                  时才生效,表示开启自动提交消费位点功能时自动提交消费位点的时间间隔\npartition.assignment.strategy   org.apache.kafka.clients.consumer.rangeassignor   消费者的分区分配策略\ninterceptor.class               ""                                                用来配置消费者客户端的拦截器\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"分区-分区管理",frontmatter:{title:"分区-分区管理",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"分区-分区管理",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/14a08dc7-2466-3341-b742-a0ba9b8b26c3/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/14.%E5%88%86%E5%8C%BA-%E5%88%86%E5%8C%BA%E7%AE%A1%E7%90%86.html",relativePath:"03.消息队列/00.Kafka/14.分区-分区管理.md",key:"v-c52462c8",path:"/pages/14a08dc7-2466-3341-b742-a0ba9b8b26c3/",headers:[{level:2,title:"1.优先副本的选举",slug:"_1-优先副本的选举",normalizedTitle:"1.优先副本的选举",charIndex:2},{level:2,title:"2.分区重分配",slug:"_2-分区重分配",normalizedTitle:"2.分区重分配",charIndex:1736},{level:2,title:"3.复制限流",slug:"_3-复制限流",normalizedTitle:"3.复制限流",charIndex:7257},{level:3,title:"3.1kafka-configs.sh脚本实现复制限流",slug:"_3-1kafka-configs-sh脚本实现复制限流",normalizedTitle:"3.1kafka-configs.sh脚本实现复制限流",charIndex:7600},{level:3,title:"3.2kafka-reassign-partitions.sh脚本实现限流",slug:"_3-2kafka-reassign-partitions-sh脚本实现限流",normalizedTitle:"3.2kafka-reassign-partitions.sh脚本实现限流",charIndex:14022},{level:2,title:"4.修改副本因子",slug:"_4-修改副本因子",normalizedTitle:"4.修改副本因子",charIndex:16313}],headersStr:"1.优先副本的选举 2.分区重分配 3.复制限流 3.1kafka-configs.sh脚本实现复制限流 3.2kafka-reassign-partitions.sh脚本实现限流 4.修改副本因子",content:'# 1.优先副本的选举\n\n分区使用多副本机制来提升可靠性，但是只有leader副本对外提供读写服务，而follower副本只负责在内部进行消息同步。如果一个分区的leader副本不可用，那么就意味着整个分区不可用，此时就需要kafka从剩余的follower副本中挑选一个新的leader副本来继续对外提供服务。从某种角度讲，broker节点中的leader副本个数的多少决定了这个节点负载的高低。\n\n在创建Topic的时候，该Topic的分区以及副本会尽可能均匀的分布到kafka集群的各个broker节点上，对应的leader副本的分配也比较均匀。\n\n**针对同一个分区而言，同一个broker节点中不可能出现他的多个副本。**即kafka集群的一个broker中最多只能有它的一个副本，我们可以将leader副本所在的节点叫做分区的leader节点，而follower节点所在的broker节点可以叫做分区的follower节点。\n\n如果kafka集群中的某一个broker挂掉了，也就是分区的leader节点下线，其中一个follower节点就会成为新的leader节点，这样会导致集群的负载不均衡，从而影响整体的健壮性和稳定性。当原来的leader节点恢复之后重新加入集群时，他只能成为一个新的follower节点而不再对外提供服务。\n\n为了有效治理负载失衡的情况，kafka引入了优先副本（preferred replica）的概念。所谓的优先副本是指在AR集合中的第一个副本。理想情况下优先副本就是该分区的leader副本，所以也可以称为preferred leader。kafka要确保所有主题的优先副本在集群中均匀分布，这样就保证了所有分区的leader均匀分布。如果leader分布过于集中，就会造成集群负载不均衡。\n\n所谓优先副本的选举是指通过一定的方式促使优先副本选举为leader副本，以此来促进集群的负载均衡，这一行为也叫做分区平衡。\n\n> 分区平衡并不意味kafka集群的负载均衡，因为还要考虑集群中的分区分配是否均衡。另外每个分区leader副本的负载也是不同的；也就是说，就算集群中分区分配均衡，leader分配均衡，也不能保证整个集群的负载就是均衡的。\n\n在kafka中可以提供分区自动平衡的功能（rebalance），与此对应的broker端参数是auto.leader.rebalance.enable，默认为true。如果开启分区自动平衡，kafka控制器会开启一个定时任务，轮询所有的broker节点，计算每个broker节点的分区不平衡率（broker的不平衡率=非优先副本的leader个数/分区总数）是否超过leader.imbalance.per.broker.percentage参数配置的比值，默认百分之十，如果超过这个值，会自动执行优先副本的选举动作以求分区平衡。执行周期由参数leader.imbalance.check.interval.seconds控制，默认300s。\n\n生产环境不建议开启rebalance功能，可能引起负面的性能问题，也有可能引起客户端一定时间的阻塞。因为执行的时间无法自主掌控，如果在大促期间执行rebalance可能会造成业务阻塞，频繁超时的风险。分区和副本的均衡也不能确保集群整体的均衡，并且集群中一定程度上的不均衡是可以接受的，为防止关键时刻出问题，建议手动执行分区平衡。\n\nkafka中的kafka-perferred-replica-election.sh脚本提供了对分区leader副本进行重新平衡的功能。优先副本的选举过程是一个安全的过程，kafka客户端可以自动感知分区leader副本的变更。\n\n./kafka-preferred-replica-election.sh --zookeeper kafka-zookeeper:2181/kafka\n\n\n1\n\n\n> 在新版本的kafka中，这个脚本已经过期了，推荐使用kafka-leader-election.sh脚本。\n\n----------------------------------------\n\n\n# 2.分区重分配\n\n当集群上的某个broker节点突然下线，如果节点上的分区是单副本的，那么这些分区就变的不可用了，相应的数据也就处于丢失状态；如果节点上的分区是多副本的，那么位于这个broker上的leader副本的角色会转交给集群的其他follower副本中。总之，这个节点上的分区副本都处于失效状态，kafka并不会将这些失效的分区副本自动的迁移到集群中剩余的可用broker上，如果放任不管，不仅会影响整个集群的负载均衡，还会影响整体服务的可用性和可靠性。\n\n当要对集群中的一个节点进行有计划的下线操作的时候，为了保证分区副本的合理分配，我们希望通过某种方式能够将该节点上的分区副本迁移到其他的可用节点上。\n\n当集群中新增broker时，只有新创建的主题分区才可能被分配到这个节点上，之前的主题分区并不会自动分配到新加入的节点，因为在他们被创建时还没有这个新节点，这样新节点的负载和原先节点之间的负载之间严重不平衡。\n\n为了解决上述问题，需要让分区副本再次进行合理分配，也就是所谓的分区重分配。kafka提供了 kafka-reassign-partition.sh脚本来执行分区重分配的工作，他可以在集群扩容，broker节点失效的场景下对分区进行迁移。kafka-reassign-partition.sh脚本使用分为3个步骤：\n\n 1. 创建需要一个包含主题清单的JSON文件。\n 2. 根据主题清单和broker节点清单生成一份重分配方案。\n 3. 根据这份方案执行具体的分配动作。\n\n下面通过一个具体的案例来演示 kafka-reassign-partition.sh 脚本的用法。\n\n 1. 首先在一个由三个broker节点组成的集群中创建一个Topic topic-reassign，主题中包含4个分区和两个副本。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-reassign --replication-factor 2 --partitions 4\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --describe --topic topic-reassign\nTopic: topic-reassign\tTopicId: K1UON9X_QbaqfVbOV4skdw\tPartitionCount: 4\tReplicationFactor: 2\tConfigs: \n\tTopic: topic-reassign\tPartition: 0\tLeader: 0\tReplicas: 0,1\tIsr: 0,1\n\tTopic: topic-reassign\tPartition: 1\tLeader: 1\tReplicas: 1,2\tIsr: 1,2\n\tTopic: topic-reassign\tPartition: 2\tLeader: 2\tReplicas: 2,0\tIsr: 2,0\n\tTopic: topic-reassign\tPartition: 3\tLeader: 0\tReplicas: 0,2\tIsr: 0,2\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以观察到Topictopic-reassign在3个节点上都有对应的分区副本分布。由于某种原因，我们想要下线其中一台broker，在此之前，我们需要将上面的分区副本迁移出去。使用kafka-reassign-partition.sh脚本的第一步就是要创建一个JSON文件，文件内容为要进行分区重新分配的主题清单。\n\n{\n  "topics": [\n    {\n      "topic": "topic-reassign"\n    }\n  ],\n  "version": 1\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n第二步就是根据这个JSON文件和指定所要分配的broker节点列表来生成一份候选的重分配方案。\n\n./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --generate --topics-to-move-json-file reassign.json --broker-list 0,2\n\nCurrent partition replica assignment\n{"version":1,"partitions":[{"topic":"topic-reassign","partition":0,"replicas":[0,1],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":1,"replicas":[1,2],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":2,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":3,"replicas":[0,2],"log_dirs":["any","any"]}]}\n\nProposed partition reassignment configuration\n{"version":1,"partitions":[{"topic":"topic-reassign","partition":0,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":1,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":2,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":3,"replicas":[0,2],"log_dirs":["any","any"]}]}\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n> broker-list 参数指定所要分配的broker节点列表。\n\n上面示例打印出两个json的内容，第一个表示当前分区副本分配情况，第二个表示重分配的新方案。我们将新方案保存到一个名为project.json的文件。\n\n第三步执行具体的重分配动作：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --execute --reassignment-json-file project.json\n\nCurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-reassign","partition":0,"replicas":[0,1],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":1,"replicas":[1,2],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":2,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":3,"replicas":[0,2],"log_dirs":["any","any"]}]}\n\nSave this to use as the --reassignment-json-file option during rollback\nSuccessfully started partition reassignments for topic-reassign-0,topic-reassign-1,topic-reassign-2,topic-reassign-3\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n再次查看Topictopic-reassign的具体信息：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --describe --topic topic-reassign\nTopic: topic-reassign\tTopicId: K1UON9X_QbaqfVbOV4skdw\tPartitionCount: 4\tReplicationFactor: 2\tConfigs: \n\tTopic: topic-reassign\tPartition: 0\tLeader: 2\tReplicas: 2,0\tIsr: 0,2\n\tTopic: topic-reassign\tPartition: 1\tLeader: 0\tReplicas: 0,2\tIsr: 2,0\n\tTopic: topic-reassign\tPartition: 2\tLeader: 2\tReplicas: 2,0\tIsr: 2,0\n\tTopic: topic-reassign\tPartition: 3\tLeader: 0\tReplicas: 0,2\tIsr: 0,2\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n可以看到主题中的所有分区副本都只在0和2的broker节点上分布了。\n\n除了让脚本自动生成候选方案，用户还可以自定义重分配方案，这样就不需要指定第一步和第二步了。\n\n分区重分配的基本原理是先通过控制器为每个分区添加新副本（增加副本因子），新的副本将从分区的leader副本那里复制所有的数据。根据分区的大小不同，复制过程可能要花一些时间，因为数据是通过网络复制到新的副本上的。在复制完成之后，控制器将旧的副本从副本清单中移除（恢复为原来的副本因子）。注意重分配过程中要确保有足够的空间。\n\n对于分区重分配而言，还有可选的第四步：验证查看分区重分配的进度，只需要将上面的execute替换成verify即可。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --verify --reassignment-json-file project.json\n\nStatus of partition reassignment:\nReassignment of partition topic-reassign-0 is complete.\nReassignment of partition topic-reassign-1 is complete.\nReassignment of partition topic-reassign-2 is complete.\nReassignment of partition topic-reassign-3 is complete.\nClearing broker-level throttles on brokers 0,1,2\nClearing topic-level throttles on topic topic-reassign\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n分区重分配对集群性能有很大影响，需要占用额外的资源，比如网络和磁盘。在实际操作中，我们将降低重分配的粒度，分成多个小批次来执行，以此来将负面影响降到最低。\n\n如果要将某个broker下线，那么在执行分区重分配动作之前最好先关闭或者重启broker，这样这个broker就不在是任何分区的leader节点了，他的分区就可以被分配给集群中的其他broker。这样可以减少broker之间的流量复制，以此提升重分配的性能，以及减少对集群的影响。\n\n----------------------------------------\n\n\n# 3.复制限流\n\n分区重分配的本质在于数据复制，先增加新的副本，然后进行数据同步，最后删除旧的副本来达到最终目的。数据复制会占用额外的资源，如果重分配的量太大必然会严重影响整体性能，尤其是处于业务高峰期的时候。减小重分配的粒度，以小批次的方式来操作是一种可行的解决思路。如果集群中某个主题或者某个分区的流量在一段时间特别大，那么只靠减小粒度是不足以应对的，这时就需要有一个限流的机制，可以对副本间的复制流量加以限制来保证重分配期间整体服务不会受到太大的影响。\n\n副本间的复制限流有两种实现方式，kafka-configs.sh脚本和kafka-reassign-partitions.sh脚本。\n\n----------------------------------------\n\n\n# 3.1kafka-configs.sh脚本实现复制限流\n\nkafka-configs.sh脚本主要以动态配置的方式来达到限流的目的，在broker级别有两个与复制限流相关的配置参数：follower.replication.throttled.rate和leader.replication.throttled.rate，前者用于设置follower副本复制的速度，后者用于设置leader副本传输的速度，单位是B/s。通常两者的配置值相同。下面的示例中将某个broker中的leader副本和follower副本的复制速度限制在1024B/s之内，即1KB/s。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type brokers --entity-name 1 --alter --add-config follower.replication.throttled.rate=1024,leader.replication.throttled.rate=1024\nCompleted updating config for entity: brokers \'1\'.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n\n\n我们再来查看一下broker中刚刚添加的配置：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type brokers --entity-name 1 --describe\nConfigs for brokers \'1\' are leader.replication.throttled.rate=1024,follower.replication.throttled.rate=1024\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n\n\n删除刚刚添加的配置也很简单：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type brokers --entity-name 1 --alter --delete-config follower.replication.throttled.rate,leader.replication.throttled.rate\n\nCompleted updating config for entity: brokers \'1\'.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n\n\n在主题级别也有两个相关参数来限制复制的速度：leader.replication.throttled.replicas和 follower.replication.throttled.replicas，他们分别用来配置被限制速度的主题所对应的leader副本列表和follower副本列表。为了演示用法，先来创建一个分区数为3副本数为2的主题topic-throttle，并查看他的详细信息。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-throttle --replication-factor 2 --partitions 3\nCreated topic topic-throttle.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --describe --topic topic-throttle\nTopic: topic-throttle\tTopicId: 2LpemHVoTVe6BbgSFNDjFA\tPartitionCount: 3\tReplicationFactor: 2\tConfigs: \n\tTopic: topic-throttle\tPartition: 0\tLeader: 2\tReplicas: 2,1\tIsr: 2,1\n\tTopic: topic-throttle\tPartition: 1\tLeader: 0\tReplicas: 0,2\tIsr: 0,2\n\tTopic: topic-throttle\tPartition: 2\tLeader: 1\tReplicas: 1,0\tIsr: 1,0\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n主题topic-throttle的三个分区所对应的leader节点分别为0，1，,2，即分区与代理的映射关系为0:2,1:0,2:1，而对应的follower节点分别为1,2,0，相关的分区与代理的映射关系为0:1,1:2,2:0，那么此主题的限流副本列表及具体的操作细节如下：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type topics --entity-name topic-throttle --alter --add-config leader.replication.throttled.replicas=[0:0,1:1,2:2],follower.replication.throttled.replicas=[0:1,1:2,2:0]\n\nCompleted updating config for entity: topic \'topic-throttle\'.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n\n\n在了解了与限流相关的4个配置参数后，我们演示一下带有限流的分区重分配的用法。首先按照上一节的玩法创建一个包含可行性方案的project.json文件，内容如下：\n\n{\n  "version": 1,\n  "partitions": [\n    {\n      "topic": "topic-throttle",\n      "partition": 1,\n      "replicas": [\n        2,\n        0\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 0,\n      "replicas": [\n        0,\n        2\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 2,\n      "replicas": [\n        0,\n        2\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    }\n  ]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n接下来设置被限流的副本列表，这里要注意，首先看一下重分配前和分配后的分区副本对比，详细如下：\n\npartition   重分配前的AR   分配后的预期AR\n0             0，1         0，2 \n1             1，2         2，0\n2             2，0         0，2\n\n\n1\n2\n3\n4\n\n\n如果分区重新分配会引起某个分区AR集合变更，那么这个分区中的leader有关的限制会应用于重分配前的所有副本，因为任何一个副本都肯呢个是leader，而与follower有关的限制会应用于所有移动的目的地。举个例子：对于上面的布局对比而言，分区0重分配的AR为[0,1]，重分配后的AR为[0,2]，那么这里的目的地就是新增的2.也就是说，对分区0而言，leader.replication.throttled.replicas配置为[0:0,0:1]，follower.replication.throttled.replicas配置为[0:2]。同理对于分区1而言，leader.replication.throttled.replicas配置为[1:1，1:2]，follower.replication.throttled.replicas配置为[1:0]。分区3的AR集合没有任何变化，这里可以忽略。\n\n获取限流副本列表之后，我们就可以执行具体的操作了：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type topics --entity-name topic-throttle --alter --add-config leader.replication.throttled.replicas=[1:1,1:2,0:0,0:1],follower.replication.throttled.replicas=[1:0,0:2]\n\nCompleted updating config for entity: topic \'topic-throttle\'.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n\n\n接下来在设置broker2的复制速度为10B/s，这样在下面的操作中可以很方便的观察限流与不限流的不同：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type brokers --entity-name 2 --alter --add-config leader.replication.throttled.rate=10,follower.replication.throttled.rate=10\n\nCompleted updating config for entity: brokers \'2\'.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n\n\n在执行具体的重分配操作之前，我们需要开启一个生产者向主题topic-throttle中发送一批消息，这样可以方便观察正在进行数据复制的过程。\n\n之后我们在执行正常的分区重新分配的操作：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --execute --reassignment-json-file project.json\n\nCurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-throttle","partition":0,"replicas":[2,1],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":1,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":2,"replicas":[1,0],"log_dirs":["any","any"]}]}\n\nSave this to use as the --reassignment-json-file option during rollback\nSuccessfully started partition reassignments for topic-throttle-0,topic-throttle-1,topic-throttle-2\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n执行之后可以查看执行的进度：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --verify --reassignment-json-file project.json\n\nStatus of partition reassignment:\nReassignment of partition topic-throttle-0 is complete.\nReassignment of partition topic-throttle-1 is complete.\nReassignment of partition topic-throttle-2 is complete.\nClearing broker-level throttles on brokers 0,1,2\nClearing topic-level throttles on topic topic-throttle\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n注意到最后两行，提示之前针对broker和topic级别做的两个限流操作已经移除了。\n\n----------------------------------------\n\n\n# 3.2kafka-reassign-partitions.sh脚本实现限流\n\nkafka-reassign-partitions.sh脚本也提供了限流功能，只需要一个参数throttle参数即可。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --execute --reassignment-json-file project.json --throttle 10\n\nCurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-throttle","partition":0,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":1,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":2,"replicas":[0,2],"log_dirs":["any","any"]}]}\n\nSave this to use as the --reassignment-json-file option during rollback\nWarning: You must run --verify periodically, until the reassignment completes, to ensure the throttle is removed.\nThe inter-broker throttle limit was set to 10 B/s\nSuccessfully started partition reassignments for topic-throttle-0,topic-throttle-1,topic-throttle-2\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n上面的信息包含了明确的警告信息：需要周期行的执行查看进度的命令直到重分配完成，这样可以确保限流设置被移除。也就是说使用这种方式的限流同样需要显式的执行某些操作以便在重分配完成之后可以删除限流的设置。上面的信息还告知了目前限流的速度上限为10B/s。\n\n如果想在重分配期间修改限制来增加吞吐量，以便完成的更快，则可以重新运行kafka-reassign-partitions.sh脚本的execute命令，使用相同的reassignment-json-file。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --execute --reassignment-json-file project.json --throttle 1024\n\nCurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-throttle","partition":0,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":1,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":2,"replicas":[0,2],"log_dirs":["any","any"]}]}\n\nSave this to use as the --reassignment-json-file option during rollback\nWarning: You must run --verify periodically, until the reassignment completes, to ensure the throttle is removed.\nThe inter-broker throttle limit was set to 1024 B/s\nSuccessfully started partition reassignments for topic-throttle-0,topic-throttle-1,topic-throttle-2\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n这样限流速度上限为1024。其实kafka-reassign-partitions.sh脚本的实现原理就是配置与限流相关的4个参数，相比于kafka-configs.sh脚本的方式更加简单不容易出错。\n\n----------------------------------------\n\n\n# 4.修改副本因子\n\n在创建主题之后我们还可以修改分区的个数，同样可以修改副本因子(副本数)。修改副本因子的使用场景也很多，比如在创建主题时填写了错误的副本因子数而需要修改，再比如运行段时间之后想要通过增加副本因子数来提高容错性和可靠性。\n\n本节中修改副本因子的功能也是通过重分配所使用的 kafka-reassign-partition.sh脚本实现的。回过头来看上一节用到的project.json文件。\n\n{\n  "version": 1,\n  "partitions": [\n    {\n      "topic": "topic-throttle",\n      "partition": 1,\n      "replicas": [\n        2,\n        0\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 0,\n      "replicas": [\n        0,\n        2\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 2,\n      "replicas": [\n        0,\n        2\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    }\n  ]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n可以观察到JSON 内容里的 replicas 都是 2 个副本，我们可以自行添加一个副本，比如对分区 1 而言，可以改成下面的内容:\n\n    {\n  "topic": "topic-throttle",\n  "partition": 1,\n  "replicas": [\n    2,\n    1,\n    0\n  ],\n  "log_dirs": [\n    "any",\n    "any",\n    "any"\n  ]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n我们可以将其他分区的 replicas 内容也改成[0,1,2]，这样每个分区的副本因子就都从 2增加到了3。注意增加副本因子时也要在 log_dirs 中添加一个any，这个 log_dirs 代表kafka中的日志日录，对应于 broker 端的 log.dir或 log.dirs 参数的配置值，如果不需要关注此方面的细节，那么可以简单地设置为 any。我们将修改后的JSON内容保存为新add.json 文件。在执行 kafka-reassign-partition.sh 脚本前，主题 topic-throttle的详细信息(副本因子为2) 如下:\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-throttle\nTopic: topic-throttle\tTopicId: 7HSKjZkrRhiiGTGl7mZeVA\tPartitionCount: 3\tReplicationFactor: 2\tConfigs: \n\tTopic: topic-throttle\tPartition: 0\tLeader: 1\tReplicas: 1,2\tIsr: 1,2\n\tTopic: topic-throttle\tPartition: 1\tLeader: 2\tReplicas: 2,0\tIsr: 2,0\n\tTopic: topic-throttle\tPartition: 2\tLeader: 0\tReplicas: 0,1\tIsr: 0,1\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# \n\n\n1\n2\n3\n4\n5\n6\n\n\n执行kafka-reassign-partition.sh 脚本的execute。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181 --execute --reassignment-json-file add.json\n\nCurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-throttle","partition":0,"replicas":[1,2],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":1,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":2,"replicas":[0,1],"log_dirs":["any","any"]}]}\n\nSave this to use as the --reassignment-json-file option during rollback\nSuccessfully started partition reassignments for topic-throttle-0,topic-throttle-1,topic-throttle-2\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n执行之后再次查看主题 topic-throttle 的详细信息。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-throttle\nTopic: topic-throttle\tTopicId: 7HSKjZkrRhiiGTGl7mZeVA\tPartitionCount: 3\tReplicationFactor: 3\tConfigs: \n\tTopic: topic-throttle\tPartition: 0\tLeader: 1\tReplicas: 0,1,2\tIsr: 1,2,0\n\tTopic: topic-throttle\tPartition: 1\tLeader: 2\tReplicas: 2,1,0\tIsr: 2,0,1\n\tTopic: topic-throttle\tPartition: 2\tLeader: 0\tReplicas: 0,1,2\tIsr: 0,1,2\n\n\n1\n2\n3\n4\n5\n\n\n可以看到相应的副本因子数已经增加到3了。\n\n与修改分区数不同的是，副本数还可以减小，这里我们通过kafka-reassign-partition.sh脚本来减少分区的副本因子。再次修改project.json文件中的内容，内容参考如下：\n\n{\n  "version": 1,\n  "partitions": [\n    {\n      "topic": "topic-throttle",\n      "partition": 1,\n      "replicas": [\n        2\n      ],\n      "log_dirs": [\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 0,\n      "replicas": [\n        1\n      ],\n      "log_dirs": [\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 2,\n      "replicas": [\n        0\n      ],\n      "log_dirs": [\n        "any"\n      ]\n    }\n  ]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n再次执行kafka-reassign-partition.sh 脚本的execute。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181 --execute --reassignment-json-file add.json\n\nCurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-throttle","partition":0,"replicas":[0,1,2],"log_dirs":["any","any","any"]},{"topic":"topic-throttle","partition":1,"replicas":[2,1,0],"log_dirs":["any","any","any"]},{"topic":"topic-throttle","partition":2,"replicas":[0,1,2],"log_dirs":["any","any","any"]}]}\n\nSave this to use as the --reassignment-json-file option during rollback\nSuccessfully started partition reassignments for topic-throttle-0,topic-throttle-1,topic-throttle-2\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n主题topic-throttle的详细信息如下：\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-throttle\nTopic: topic-throttle\tTopicId: 7HSKjZkrRhiiGTGl7mZeVA\tPartitionCount: 3\tReplicationFactor: 1\tConfigs: \n\tTopic: topic-throttle\tPartition: 0\tLeader: 1\tReplicas: 1\tIsr: 1\n\tTopic: topic-throttle\tPartition: 1\tLeader: 2\tReplicas: 2\tIsr: 2\n\tTopic: topic-throttle\tPartition: 2\tLeader: 0\tReplicas: 0\tIsr: 0\n\n\n1\n2\n3\n4\n5\n\n\n可以看到主题 topic-throttle 的副本因子又被修改为 1 了。我们执行kafka-reassign-partition.sh 脚本(execute)所使用的候选方案都是手动修改的，在增加副本因子的时候由于整个示例集群中只有 3个 broker 节点，从 2 增加到 3只需填满副本即可。再者,示例中减少副本因子的时候改成了 1，这样可以简单地把各个 broker节点轮询一遍，如此也就不太会有负载不均衡的影响。不过在真实应用中，可能面对的是一个包含了几十个 broker 节点的集群，将副本数从2 修改为 5，或者从 4 修改为 3 的时候，如何进行合理的分配是一个关键的问题。我们可以通过程序来计算出分配方案，假设已经确定了主题的分区数、副本因子数量和可用的Broker 数。\n\npublic class KafkaReplicaAssignment {\n\n    public static void main(String[] args) {\n        int partitions = 10; // 主题的分区数\n        int replicationFactor = 2; // 副本因子数量\n        int brokers = 4; // 可用的 Broker 数\n\n        List<List<Integer>> replicaAssignment = replicaAssignment(brokers, replicationFactor, partitions);\n\n        // 打印分区的副本分配\n        for (int partition = 0; partition < partitions; partition++) {\n            List<Integer> replicas = replicaAssignment.get(partition);\n            System.out.println("Partition " + partition + " replicas: " + replicas);\n        }\n    }\n\n    public static List<List<Integer>> replicaAssignment(int brokers, int factor, int partitions) {\n        List<List<Integer>> replicaAssignment = new ArrayList<>();\n        for (int partition = 0; partition < partitions; partition++) {\n            List<Integer> replicas = new ArrayList<>();\n            for (int i = 0; i < factor; i++) {\n                replicas.add((partition + i) % brokers);\n            }\n            replicaAssignment.add(replicas);\n        }\n        return replicaAssignment;\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n----------------------------------------',normalizedContent:'# 1.优先副本的选举\n\n分区使用多副本机制来提升可靠性，但是只有leader副本对外提供读写服务，而follower副本只负责在内部进行消息同步。如果一个分区的leader副本不可用，那么就意味着整个分区不可用，此时就需要kafka从剩余的follower副本中挑选一个新的leader副本来继续对外提供服务。从某种角度讲，broker节点中的leader副本个数的多少决定了这个节点负载的高低。\n\n在创建topic的时候，该topic的分区以及副本会尽可能均匀的分布到kafka集群的各个broker节点上，对应的leader副本的分配也比较均匀。\n\n**针对同一个分区而言，同一个broker节点中不可能出现他的多个副本。**即kafka集群的一个broker中最多只能有它的一个副本，我们可以将leader副本所在的节点叫做分区的leader节点，而follower节点所在的broker节点可以叫做分区的follower节点。\n\n如果kafka集群中的某一个broker挂掉了，也就是分区的leader节点下线，其中一个follower节点就会成为新的leader节点，这样会导致集群的负载不均衡，从而影响整体的健壮性和稳定性。当原来的leader节点恢复之后重新加入集群时，他只能成为一个新的follower节点而不再对外提供服务。\n\n为了有效治理负载失衡的情况，kafka引入了优先副本（preferred replica）的概念。所谓的优先副本是指在ar集合中的第一个副本。理想情况下优先副本就是该分区的leader副本，所以也可以称为preferred leader。kafka要确保所有主题的优先副本在集群中均匀分布，这样就保证了所有分区的leader均匀分布。如果leader分布过于集中，就会造成集群负载不均衡。\n\n所谓优先副本的选举是指通过一定的方式促使优先副本选举为leader副本，以此来促进集群的负载均衡，这一行为也叫做分区平衡。\n\n> 分区平衡并不意味kafka集群的负载均衡，因为还要考虑集群中的分区分配是否均衡。另外每个分区leader副本的负载也是不同的；也就是说，就算集群中分区分配均衡，leader分配均衡，也不能保证整个集群的负载就是均衡的。\n\n在kafka中可以提供分区自动平衡的功能（rebalance），与此对应的broker端参数是auto.leader.rebalance.enable，默认为true。如果开启分区自动平衡，kafka控制器会开启一个定时任务，轮询所有的broker节点，计算每个broker节点的分区不平衡率（broker的不平衡率=非优先副本的leader个数/分区总数）是否超过leader.imbalance.per.broker.percentage参数配置的比值，默认百分之十，如果超过这个值，会自动执行优先副本的选举动作以求分区平衡。执行周期由参数leader.imbalance.check.interval.seconds控制，默认300s。\n\n生产环境不建议开启rebalance功能，可能引起负面的性能问题，也有可能引起客户端一定时间的阻塞。因为执行的时间无法自主掌控，如果在大促期间执行rebalance可能会造成业务阻塞，频繁超时的风险。分区和副本的均衡也不能确保集群整体的均衡，并且集群中一定程度上的不均衡是可以接受的，为防止关键时刻出问题，建议手动执行分区平衡。\n\nkafka中的kafka-perferred-replica-election.sh脚本提供了对分区leader副本进行重新平衡的功能。优先副本的选举过程是一个安全的过程，kafka客户端可以自动感知分区leader副本的变更。\n\n./kafka-preferred-replica-election.sh --zookeeper kafka-zookeeper:2181/kafka\n\n\n1\n\n\n> 在新版本的kafka中，这个脚本已经过期了，推荐使用kafka-leader-election.sh脚本。\n\n----------------------------------------\n\n\n# 2.分区重分配\n\n当集群上的某个broker节点突然下线，如果节点上的分区是单副本的，那么这些分区就变的不可用了，相应的数据也就处于丢失状态；如果节点上的分区是多副本的，那么位于这个broker上的leader副本的角色会转交给集群的其他follower副本中。总之，这个节点上的分区副本都处于失效状态，kafka并不会将这些失效的分区副本自动的迁移到集群中剩余的可用broker上，如果放任不管，不仅会影响整个集群的负载均衡，还会影响整体服务的可用性和可靠性。\n\n当要对集群中的一个节点进行有计划的下线操作的时候，为了保证分区副本的合理分配，我们希望通过某种方式能够将该节点上的分区副本迁移到其他的可用节点上。\n\n当集群中新增broker时，只有新创建的主题分区才可能被分配到这个节点上，之前的主题分区并不会自动分配到新加入的节点，因为在他们被创建时还没有这个新节点，这样新节点的负载和原先节点之间的负载之间严重不平衡。\n\n为了解决上述问题，需要让分区副本再次进行合理分配，也就是所谓的分区重分配。kafka提供了 kafka-reassign-partition.sh脚本来执行分区重分配的工作，他可以在集群扩容，broker节点失效的场景下对分区进行迁移。kafka-reassign-partition.sh脚本使用分为3个步骤：\n\n 1. 创建需要一个包含主题清单的json文件。\n 2. 根据主题清单和broker节点清单生成一份重分配方案。\n 3. 根据这份方案执行具体的分配动作。\n\n下面通过一个具体的案例来演示 kafka-reassign-partition.sh 脚本的用法。\n\n 1. 首先在一个由三个broker节点组成的集群中创建一个topic topic-reassign，主题中包含4个分区和两个副本。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-reassign --replication-factor 2 --partitions 4\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --describe --topic topic-reassign\ntopic: topic-reassign\ttopicid: k1uon9x_qbaqfvbov4skdw\tpartitioncount: 4\treplicationfactor: 2\tconfigs: \n\ttopic: topic-reassign\tpartition: 0\tleader: 0\treplicas: 0,1\tisr: 0,1\n\ttopic: topic-reassign\tpartition: 1\tleader: 1\treplicas: 1,2\tisr: 1,2\n\ttopic: topic-reassign\tpartition: 2\tleader: 2\treplicas: 2,0\tisr: 2,0\n\ttopic: topic-reassign\tpartition: 3\tleader: 0\treplicas: 0,2\tisr: 0,2\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以观察到topictopic-reassign在3个节点上都有对应的分区副本分布。由于某种原因，我们想要下线其中一台broker，在此之前，我们需要将上面的分区副本迁移出去。使用kafka-reassign-partition.sh脚本的第一步就是要创建一个json文件，文件内容为要进行分区重新分配的主题清单。\n\n{\n  "topics": [\n    {\n      "topic": "topic-reassign"\n    }\n  ],\n  "version": 1\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n第二步就是根据这个json文件和指定所要分配的broker节点列表来生成一份候选的重分配方案。\n\n./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --generate --topics-to-move-json-file reassign.json --broker-list 0,2\n\ncurrent partition replica assignment\n{"version":1,"partitions":[{"topic":"topic-reassign","partition":0,"replicas":[0,1],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":1,"replicas":[1,2],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":2,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":3,"replicas":[0,2],"log_dirs":["any","any"]}]}\n\nproposed partition reassignment configuration\n{"version":1,"partitions":[{"topic":"topic-reassign","partition":0,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":1,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":2,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":3,"replicas":[0,2],"log_dirs":["any","any"]}]}\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n> broker-list 参数指定所要分配的broker节点列表。\n\n上面示例打印出两个json的内容，第一个表示当前分区副本分配情况，第二个表示重分配的新方案。我们将新方案保存到一个名为project.json的文件。\n\n第三步执行具体的重分配动作：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --execute --reassignment-json-file project.json\n\ncurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-reassign","partition":0,"replicas":[0,1],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":1,"replicas":[1,2],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":2,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-reassign","partition":3,"replicas":[0,2],"log_dirs":["any","any"]}]}\n\nsave this to use as the --reassignment-json-file option during rollback\nsuccessfully started partition reassignments for topic-reassign-0,topic-reassign-1,topic-reassign-2,topic-reassign-3\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n再次查看topictopic-reassign的具体信息：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --describe --topic topic-reassign\ntopic: topic-reassign\ttopicid: k1uon9x_qbaqfvbov4skdw\tpartitioncount: 4\treplicationfactor: 2\tconfigs: \n\ttopic: topic-reassign\tpartition: 0\tleader: 2\treplicas: 2,0\tisr: 0,2\n\ttopic: topic-reassign\tpartition: 1\tleader: 0\treplicas: 0,2\tisr: 2,0\n\ttopic: topic-reassign\tpartition: 2\tleader: 2\treplicas: 2,0\tisr: 2,0\n\ttopic: topic-reassign\tpartition: 3\tleader: 0\treplicas: 0,2\tisr: 0,2\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n可以看到主题中的所有分区副本都只在0和2的broker节点上分布了。\n\n除了让脚本自动生成候选方案，用户还可以自定义重分配方案，这样就不需要指定第一步和第二步了。\n\n分区重分配的基本原理是先通过控制器为每个分区添加新副本（增加副本因子），新的副本将从分区的leader副本那里复制所有的数据。根据分区的大小不同，复制过程可能要花一些时间，因为数据是通过网络复制到新的副本上的。在复制完成之后，控制器将旧的副本从副本清单中移除（恢复为原来的副本因子）。注意重分配过程中要确保有足够的空间。\n\n对于分区重分配而言，还有可选的第四步：验证查看分区重分配的进度，只需要将上面的execute替换成verify即可。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --verify --reassignment-json-file project.json\n\nstatus of partition reassignment:\nreassignment of partition topic-reassign-0 is complete.\nreassignment of partition topic-reassign-1 is complete.\nreassignment of partition topic-reassign-2 is complete.\nreassignment of partition topic-reassign-3 is complete.\nclearing broker-level throttles on brokers 0,1,2\nclearing topic-level throttles on topic topic-reassign\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n分区重分配对集群性能有很大影响，需要占用额外的资源，比如网络和磁盘。在实际操作中，我们将降低重分配的粒度，分成多个小批次来执行，以此来将负面影响降到最低。\n\n如果要将某个broker下线，那么在执行分区重分配动作之前最好先关闭或者重启broker，这样这个broker就不在是任何分区的leader节点了，他的分区就可以被分配给集群中的其他broker。这样可以减少broker之间的流量复制，以此提升重分配的性能，以及减少对集群的影响。\n\n----------------------------------------\n\n\n# 3.复制限流\n\n分区重分配的本质在于数据复制，先增加新的副本，然后进行数据同步，最后删除旧的副本来达到最终目的。数据复制会占用额外的资源，如果重分配的量太大必然会严重影响整体性能，尤其是处于业务高峰期的时候。减小重分配的粒度，以小批次的方式来操作是一种可行的解决思路。如果集群中某个主题或者某个分区的流量在一段时间特别大，那么只靠减小粒度是不足以应对的，这时就需要有一个限流的机制，可以对副本间的复制流量加以限制来保证重分配期间整体服务不会受到太大的影响。\n\n副本间的复制限流有两种实现方式，kafka-configs.sh脚本和kafka-reassign-partitions.sh脚本。\n\n----------------------------------------\n\n\n# 3.1kafka-configs.sh脚本实现复制限流\n\nkafka-configs.sh脚本主要以动态配置的方式来达到限流的目的，在broker级别有两个与复制限流相关的配置参数：follower.replication.throttled.rate和leader.replication.throttled.rate，前者用于设置follower副本复制的速度，后者用于设置leader副本传输的速度，单位是b/s。通常两者的配置值相同。下面的示例中将某个broker中的leader副本和follower副本的复制速度限制在1024b/s之内，即1kb/s。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type brokers --entity-name 1 --alter --add-config follower.replication.throttled.rate=1024,leader.replication.throttled.rate=1024\ncompleted updating config for entity: brokers \'1\'.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n\n\n我们再来查看一下broker中刚刚添加的配置：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type brokers --entity-name 1 --describe\nconfigs for brokers \'1\' are leader.replication.throttled.rate=1024,follower.replication.throttled.rate=1024\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n\n\n删除刚刚添加的配置也很简单：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type brokers --entity-name 1 --alter --delete-config follower.replication.throttled.rate,leader.replication.throttled.rate\n\ncompleted updating config for entity: brokers \'1\'.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n\n\n在主题级别也有两个相关参数来限制复制的速度：leader.replication.throttled.replicas和 follower.replication.throttled.replicas，他们分别用来配置被限制速度的主题所对应的leader副本列表和follower副本列表。为了演示用法，先来创建一个分区数为3副本数为2的主题topic-throttle，并查看他的详细信息。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-throttle --replication-factor 2 --partitions 3\ncreated topic topic-throttle.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --describe --topic topic-throttle\ntopic: topic-throttle\ttopicid: 2lpemhvotve6bbgsfndjfa\tpartitioncount: 3\treplicationfactor: 2\tconfigs: \n\ttopic: topic-throttle\tpartition: 0\tleader: 2\treplicas: 2,1\tisr: 2,1\n\ttopic: topic-throttle\tpartition: 1\tleader: 0\treplicas: 0,2\tisr: 0,2\n\ttopic: topic-throttle\tpartition: 2\tleader: 1\treplicas: 1,0\tisr: 1,0\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n主题topic-throttle的三个分区所对应的leader节点分别为0，1，,2，即分区与代理的映射关系为0:2,1:0,2:1，而对应的follower节点分别为1,2,0，相关的分区与代理的映射关系为0:1,1:2,2:0，那么此主题的限流副本列表及具体的操作细节如下：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type topics --entity-name topic-throttle --alter --add-config leader.replication.throttled.replicas=[0:0,1:1,2:2],follower.replication.throttled.replicas=[0:1,1:2,2:0]\n\ncompleted updating config for entity: topic \'topic-throttle\'.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n\n\n在了解了与限流相关的4个配置参数后，我们演示一下带有限流的分区重分配的用法。首先按照上一节的玩法创建一个包含可行性方案的project.json文件，内容如下：\n\n{\n  "version": 1,\n  "partitions": [\n    {\n      "topic": "topic-throttle",\n      "partition": 1,\n      "replicas": [\n        2,\n        0\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 0,\n      "replicas": [\n        0,\n        2\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 2,\n      "replicas": [\n        0,\n        2\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    }\n  ]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n接下来设置被限流的副本列表，这里要注意，首先看一下重分配前和分配后的分区副本对比，详细如下：\n\npartition   重分配前的ar   分配后的预期ar\n0             0，1         0，2 \n1             1，2         2，0\n2             2，0         0，2\n\n\n1\n2\n3\n4\n\n\n如果分区重新分配会引起某个分区ar集合变更，那么这个分区中的leader有关的限制会应用于重分配前的所有副本，因为任何一个副本都肯呢个是leader，而与follower有关的限制会应用于所有移动的目的地。举个例子：对于上面的布局对比而言，分区0重分配的ar为[0,1]，重分配后的ar为[0,2]，那么这里的目的地就是新增的2.也就是说，对分区0而言，leader.replication.throttled.replicas配置为[0:0,0:1]，follower.replication.throttled.replicas配置为[0:2]。同理对于分区1而言，leader.replication.throttled.replicas配置为[1:1，1:2]，follower.replication.throttled.replicas配置为[1:0]。分区3的ar集合没有任何变化，这里可以忽略。\n\n获取限流副本列表之后，我们就可以执行具体的操作了：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type topics --entity-name topic-throttle --alter --add-config leader.replication.throttled.replicas=[1:1,1:2,0:0,0:1],follower.replication.throttled.replicas=[1:0,0:2]\n\ncompleted updating config for entity: topic \'topic-throttle\'.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n\n\n接下来在设置broker2的复制速度为10b/s，这样在下面的操作中可以很方便的观察限流与不限流的不同：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-configs.sh --zookeeper kafka-zookeeper:2181/kafka --entity-type brokers --entity-name 2 --alter --add-config leader.replication.throttled.rate=10,follower.replication.throttled.rate=10\n\ncompleted updating config for entity: brokers \'2\'.\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n\n\n在执行具体的重分配操作之前，我们需要开启一个生产者向主题topic-throttle中发送一批消息，这样可以方便观察正在进行数据复制的过程。\n\n之后我们在执行正常的分区重新分配的操作：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --execute --reassignment-json-file project.json\n\ncurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-throttle","partition":0,"replicas":[2,1],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":1,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":2,"replicas":[1,0],"log_dirs":["any","any"]}]}\n\nsave this to use as the --reassignment-json-file option during rollback\nsuccessfully started partition reassignments for topic-throttle-0,topic-throttle-1,topic-throttle-2\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n执行之后可以查看执行的进度：\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --verify --reassignment-json-file project.json\n\nstatus of partition reassignment:\nreassignment of partition topic-throttle-0 is complete.\nreassignment of partition topic-throttle-1 is complete.\nreassignment of partition topic-throttle-2 is complete.\nclearing broker-level throttles on brokers 0,1,2\nclearing topic-level throttles on topic topic-throttle\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n注意到最后两行，提示之前针对broker和topic级别做的两个限流操作已经移除了。\n\n----------------------------------------\n\n\n# 3.2kafka-reassign-partitions.sh脚本实现限流\n\nkafka-reassign-partitions.sh脚本也提供了限流功能，只需要一个参数throttle参数即可。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --execute --reassignment-json-file project.json --throttle 10\n\ncurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-throttle","partition":0,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":1,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":2,"replicas":[0,2],"log_dirs":["any","any"]}]}\n\nsave this to use as the --reassignment-json-file option during rollback\nwarning: you must run --verify periodically, until the reassignment completes, to ensure the throttle is removed.\nthe inter-broker throttle limit was set to 10 b/s\nsuccessfully started partition reassignments for topic-throttle-0,topic-throttle-1,topic-throttle-2\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n上面的信息包含了明确的警告信息：需要周期行的执行查看进度的命令直到重分配完成，这样可以确保限流设置被移除。也就是说使用这种方式的限流同样需要显式的执行某些操作以便在重分配完成之后可以删除限流的设置。上面的信息还告知了目前限流的速度上限为10b/s。\n\n如果想在重分配期间修改限制来增加吞吐量，以便完成的更快，则可以重新运行kafka-reassign-partitions.sh脚本的execute命令，使用相同的reassignment-json-file。\n\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181/kafka --execute --reassignment-json-file project.json --throttle 1024\n\ncurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-throttle","partition":0,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":1,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":2,"replicas":[0,2],"log_dirs":["any","any"]}]}\n\nsave this to use as the --reassignment-json-file option during rollback\nwarning: you must run --verify periodically, until the reassignment completes, to ensure the throttle is removed.\nthe inter-broker throttle limit was set to 1024 b/s\nsuccessfully started partition reassignments for topic-throttle-0,topic-throttle-1,topic-throttle-2\nroot@b531dc9d377f:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n这样限流速度上限为1024。其实kafka-reassign-partitions.sh脚本的实现原理就是配置与限流相关的4个参数，相比于kafka-configs.sh脚本的方式更加简单不容易出错。\n\n----------------------------------------\n\n\n# 4.修改副本因子\n\n在创建主题之后我们还可以修改分区的个数，同样可以修改副本因子(副本数)。修改副本因子的使用场景也很多，比如在创建主题时填写了错误的副本因子数而需要修改，再比如运行段时间之后想要通过增加副本因子数来提高容错性和可靠性。\n\n本节中修改副本因子的功能也是通过重分配所使用的 kafka-reassign-partition.sh脚本实现的。回过头来看上一节用到的project.json文件。\n\n{\n  "version": 1,\n  "partitions": [\n    {\n      "topic": "topic-throttle",\n      "partition": 1,\n      "replicas": [\n        2,\n        0\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 0,\n      "replicas": [\n        0,\n        2\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 2,\n      "replicas": [\n        0,\n        2\n      ],\n      "log_dirs": [\n        "any",\n        "any"\n      ]\n    }\n  ]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n可以观察到json 内容里的 replicas 都是 2 个副本，我们可以自行添加一个副本，比如对分区 1 而言，可以改成下面的内容:\n\n    {\n  "topic": "topic-throttle",\n  "partition": 1,\n  "replicas": [\n    2,\n    1,\n    0\n  ],\n  "log_dirs": [\n    "any",\n    "any",\n    "any"\n  ]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n我们可以将其他分区的 replicas 内容也改成[0,1,2]，这样每个分区的副本因子就都从 2增加到了3。注意增加副本因子时也要在 log_dirs 中添加一个any，这个 log_dirs 代表kafka中的日志日录，对应于 broker 端的 log.dir或 log.dirs 参数的配置值，如果不需要关注此方面的细节，那么可以简单地设置为 any。我们将修改后的json内容保存为新add.json 文件。在执行 kafka-reassign-partition.sh 脚本前，主题 topic-throttle的详细信息(副本因子为2) 如下:\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-throttle\ntopic: topic-throttle\ttopicid: 7hskjzkrrhiigtgl7mzeva\tpartitioncount: 3\treplicationfactor: 2\tconfigs: \n\ttopic: topic-throttle\tpartition: 0\tleader: 1\treplicas: 1,2\tisr: 1,2\n\ttopic: topic-throttle\tpartition: 1\tleader: 2\treplicas: 2,0\tisr: 2,0\n\ttopic: topic-throttle\tpartition: 2\tleader: 0\treplicas: 0,1\tisr: 0,1\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# \n\n\n1\n2\n3\n4\n5\n6\n\n\n执行kafka-reassign-partition.sh 脚本的execute。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181 --execute --reassignment-json-file add.json\n\ncurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-throttle","partition":0,"replicas":[1,2],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":1,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"topic-throttle","partition":2,"replicas":[0,1],"log_dirs":["any","any"]}]}\n\nsave this to use as the --reassignment-json-file option during rollback\nsuccessfully started partition reassignments for topic-throttle-0,topic-throttle-1,topic-throttle-2\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n执行之后再次查看主题 topic-throttle 的详细信息。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-throttle\ntopic: topic-throttle\ttopicid: 7hskjzkrrhiigtgl7mzeva\tpartitioncount: 3\treplicationfactor: 3\tconfigs: \n\ttopic: topic-throttle\tpartition: 0\tleader: 1\treplicas: 0,1,2\tisr: 1,2,0\n\ttopic: topic-throttle\tpartition: 1\tleader: 2\treplicas: 2,1,0\tisr: 2,0,1\n\ttopic: topic-throttle\tpartition: 2\tleader: 0\treplicas: 0,1,2\tisr: 0,1,2\n\n\n1\n2\n3\n4\n5\n\n\n可以看到相应的副本因子数已经增加到3了。\n\n与修改分区数不同的是，副本数还可以减小，这里我们通过kafka-reassign-partition.sh脚本来减少分区的副本因子。再次修改project.json文件中的内容，内容参考如下：\n\n{\n  "version": 1,\n  "partitions": [\n    {\n      "topic": "topic-throttle",\n      "partition": 1,\n      "replicas": [\n        2\n      ],\n      "log_dirs": [\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 0,\n      "replicas": [\n        1\n      ],\n      "log_dirs": [\n        "any"\n      ]\n    },\n    {\n      "topic": "topic-throttle",\n      "partition": 2,\n      "replicas": [\n        0\n      ],\n      "log_dirs": [\n        "any"\n      ]\n    }\n  ]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n再次执行kafka-reassign-partition.sh 脚本的execute。\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-reassign-partitions.sh --zookeeper kafka-zookeeper:2181 --execute --reassignment-json-file add.json\n\ncurrent partition replica assignment\n\n{"version":1,"partitions":[{"topic":"topic-throttle","partition":0,"replicas":[0,1,2],"log_dirs":["any","any","any"]},{"topic":"topic-throttle","partition":1,"replicas":[2,1,0],"log_dirs":["any","any","any"]},{"topic":"topic-throttle","partition":2,"replicas":[0,1,2],"log_dirs":["any","any","any"]}]}\n\nsave this to use as the --reassignment-json-file option during rollback\nsuccessfully started partition reassignments for topic-throttle-0,topic-throttle-1,topic-throttle-2\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n主题topic-throttle的详细信息如下：\n\nroot@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-throttle\ntopic: topic-throttle\ttopicid: 7hskjzkrrhiigtgl7mzeva\tpartitioncount: 3\treplicationfactor: 1\tconfigs: \n\ttopic: topic-throttle\tpartition: 0\tleader: 1\treplicas: 1\tisr: 1\n\ttopic: topic-throttle\tpartition: 1\tleader: 2\treplicas: 2\tisr: 2\n\ttopic: topic-throttle\tpartition: 2\tleader: 0\treplicas: 0\tisr: 0\n\n\n1\n2\n3\n4\n5\n\n\n可以看到主题 topic-throttle 的副本因子又被修改为 1 了。我们执行kafka-reassign-partition.sh 脚本(execute)所使用的候选方案都是手动修改的，在增加副本因子的时候由于整个示例集群中只有 3个 broker 节点，从 2 增加到 3只需填满副本即可。再者,示例中减少副本因子的时候改成了 1，这样可以简单地把各个 broker节点轮询一遍，如此也就不太会有负载不均衡的影响。不过在真实应用中，可能面对的是一个包含了几十个 broker 节点的集群，将副本数从2 修改为 5，或者从 4 修改为 3 的时候，如何进行合理的分配是一个关键的问题。我们可以通过程序来计算出分配方案，假设已经确定了主题的分区数、副本因子数量和可用的broker 数。\n\npublic class kafkareplicaassignment {\n\n    public static void main(string[] args) {\n        int partitions = 10; // 主题的分区数\n        int replicationfactor = 2; // 副本因子数量\n        int brokers = 4; // 可用的 broker 数\n\n        list<list<integer>> replicaassignment = replicaassignment(brokers, replicationfactor, partitions);\n\n        // 打印分区的副本分配\n        for (int partition = 0; partition < partitions; partition++) {\n            list<integer> replicas = replicaassignment.get(partition);\n            system.out.println("partition " + partition + " replicas: " + replicas);\n        }\n    }\n\n    public static list<list<integer>> replicaassignment(int brokers, int factor, int partitions) {\n        list<list<integer>> replicaassignment = new arraylist<>();\n        for (int partition = 0; partition < partitions; partition++) {\n            list<integer> replicas = new arraylist<>();\n            for (int i = 0; i < factor; i++) {\n                replicas.add((partition + i) % brokers);\n            }\n            replicaassignment.add(replicas);\n        }\n        return replicaassignment;\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"分区-如何选择合适的分区数",frontmatter:{title:"分区-如何选择合适的分区数",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"分区-如何选择合适的分区数",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/bd36a2fb-82ce-3f34-bf5a-91f5703e12a6/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/15.%E5%88%86%E5%8C%BA-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%88%86%E5%8C%BA%E6%95%B0.html",relativePath:"03.消息队列/00.Kafka/15.分区-如何选择合适的分区数.md",key:"v-2a48cbdf",path:"/pages/bd36a2fb-82ce-3f34-bf5a-91f5703e12a6/",headers:[{level:2,title:"1.性能测试工具",slug:"_1-性能测试工具",normalizedTitle:"1.性能测试工具",charIndex:2},{level:2,title:"2.分区数越多吞吐量就越高么",slug:"_2-分区数越多吞吐量就越高么",normalizedTitle:"2.分区数越多吞吐量就越高么",charIndex:14894},{level:2,title:"3.分区数的上限",slug:"_3-分区数的上限",normalizedTitle:"3.分区数的上限",charIndex:16065},{level:2,title:"4.考量因素",slug:"_4-考量因素",normalizedTitle:"4.考量因素",charIndex:18502}],headersStr:"1.性能测试工具 2.分区数越多吞吐量就越高么 3.分区数的上限 4.考量因素",content:"# 1.性能测试工具\n\n本节要讨论的性能测试工具是kafka本身提供的生产者性能测试的 kafka-producer-perf-test.sh和用于消费者性能测试的kafka-consumer-perf-test.sh。\n\n首先通过一个示例来了解一下kafka-producer-perf-test.sh脚本的使用。我们向一个只有一个分区和一个副本的主题topic-1中发送1万条消息，并且每条消息大小为1024B，生产者对应的acks参数为1。\n\nbash-5.1# ./kafka-producer-perf-test.sh --topic topic-1 --num-records 10000 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=localhost:9092 acks=1\n4756 records sent, 913.4 records/sec (0.89 MB/sec), 2026.3 ms avg latency, 4547.0 ms max latency.\n4740 records sent, 942.2 records/sec (0.92 MB/sec), 6926.3 ms avg latency, 9514.0 ms max latency.\n10000 records sent, 932.227091 records/sec (0.91 MB/sec), 4734.96 ms avg latency, 9983.00 ms max latency, 4767 ms 50th, 9513 ms 95th, 9777 ms 99th, 9982 ms 99.9th.\nbash-5.1#\n\n\n1\n2\n3\n4\n5\n\n\n上面在使用kafka-producer-perf-test.sh脚本的时候多了一个参数，其中topic用来指定生产者发送消息的目标主题；num-records用来指定发送消息的总条数；record-size用来设置每条消息的字节数；produceer-props参数用来指定生产者的配置，可以同时指定多组配置，各组配置之间用空格分隔，与producer-props参数对应的还有一个producer.config参数，他用来指定生产者的配置文件；throughput参数用来进行限流控制，当设定的值小于0时不限流，当设定的值大于0时，当发送的吞吐量大于该值时会被限流阻塞一段时间。下面的示例中设置了throughout的值为100字节：\n\nbash-5.1# ./kafka-producer-perf-test.sh --topic topic-1 --num-records 10000 --record-size 1024 --throughput 100 --producer-props bootstrap.servers=localhost:9092 acks=1\n502 records sent, 100.3 records/sec (0.10 MB/sec), 4.9 ms avg latency, 513.0 ms max latency.\n501 records sent, 100.0 records/sec (0.10 MB/sec), 1.3 ms avg latency, 2.0 ms max latency.\n500 records sent, 99.9 records/sec (0.10 MB/sec), 1.2 ms avg latency, 3.0 ms max latency.\n501 records sent, 100.2 records/sec (0.10 MB/sec), 1.2 ms avg latency, 3.0 ms max latency.\n500 records sent, 100.0 records/sec (0.10 MB/sec), 1.2 ms avg latency, 5.0 ms max latency.\n500 records sent, 100.0 records/sec (0.10 MB/sec), 1.2 ms avg latency, 4.0 ms max latency.\n500 records sent, 100.0 records/sec (0.10 MB/sec), 1.2 ms avg latency, 4.0 ms max latency.\n501 records sent, 100.1 records/sec (0.10 MB/sec), 1.1 ms avg latency, 4.0 ms max latency.\n500 records sent, 100.0 records/sec (0.10 MB/sec), 1.1 ms avg latency, 4.0 ms max latency.\n501 records sent, 100.0 records/sec (0.10 MB/sec), 1.2 ms avg latency, 5.0 ms max latency.\n500 records sent, 99.9 records/sec (0.10 MB/sec), 1.2 ms avg latency, 5.0 ms max latency.\n501 records sent, 100.1 records/sec (0.10 MB/sec), 1.1 ms avg latency, 2.0 ms max latency.\n501 records sent, 100.0 records/sec (0.10 MB/sec), 1.1 ms avg latency, 5.0 ms max latency.\n501 records sent, 100.1 records/sec (0.10 MB/sec), 1.1 ms avg latency, 3.0 ms max latency.\n500 records sent, 100.0 records/sec (0.10 MB/sec), 1.1 ms avg latency, 4.0 ms max latency.\n500 records sent, 99.9 records/sec (0.10 MB/sec), 1.1 ms avg latency, 2.0 ms max latency.\n501 records sent, 100.1 records/sec (0.10 MB/sec), 1.1 ms avg latency, 2.0 ms max latency.\n501 records sent, 100.1 records/sec (0.10 MB/sec), 1.1 ms avg latency, 4.0 ms max latency.\n500 records sent, 99.9 records/sec (0.10 MB/sec), 1.1 ms avg latency, 3.0 ms max latency.\n10000 records sent, 99.993000 records/sec (0.10 MB/sec), 1.34 ms avg latency, 513.00 ms max latency, 1 ms 50th, 2 ms 95th, 2 ms 99th, 26 ms 99.9th.\nbash-5.1#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\nkafka-producer-perf-test.sh脚本中还有一个有意思的参数print-metrics，指定了这个参数时会在测试完成之后打印很多指标信息，对很多测试任务而言具有一定参考价值。\n\nbash-5.1# ./kafka-producer-perf-test.sh --topic topic-1 --num-records 10000 --record-size 1024 --throughput -1 --print-metrics --producer-props bootstrap.servers=localhost:9092 acks=1\n4906 records sent, 969.0 records/sec (0.95 MB/sec), 1854.0 ms avg latency, 4444.0 ms max latency.\n4875 records sent, 940.0 records/sec (0.92 MB/sec), 6912.0 ms avg latency, 9593.0 ms max latency.\n10000 records sent, 955.474871 records/sec (0.93 MB/sec), 4489.89 ms avg latency, 9807.00 ms max latency, 4449 ms 50th, 9150 ms 95th, 9600 ms 99th, 9807 ms 99.9th.\n\nMetric Name                                                                         Value\napp-info:commit-id:{client-id=producer-1}                                         : 839b886f9b732b15\napp-info:start-time-ms:{client-id=producer-1}                                     : 1698903621840\napp-info:version:{client-id=producer-1}                                           : 2.8.1\nkafka-metrics-count:count:{client-id=producer-1}                                  : 102.000\nproducer-metrics:batch-size-avg:{client-id=producer-1}                            : 15548.256\nproducer-metrics:batch-size-max:{client-id=producer-1}                            : 15556.000\nproducer-metrics:batch-split-rate:{client-id=producer-1}                          : 0.000\nproducer-metrics:batch-split-total:{client-id=producer-1}                         : 0.000\nproducer-metrics:buffer-available-bytes:{client-id=producer-1}                    : 33554432.000\nproducer-metrics:buffer-exhausted-rate:{client-id=producer-1}                     : 0.000\nproducer-metrics:buffer-exhausted-total:{client-id=producer-1}                    : 0.000\nproducer-metrics:buffer-total-bytes:{client-id=producer-1}                        : 33554432.000\nproducer-metrics:bufferpool-wait-ratio:{client-id=producer-1}                     : 0.000\nproducer-metrics:bufferpool-wait-time-total:{client-id=producer-1}                : 0.000\nproducer-metrics:compression-rate-avg:{client-id=producer-1}                      : 1.000\nproducer-metrics:connection-close-rate:{client-id=producer-1}                     : 0.000\nproducer-metrics:connection-close-total:{client-id=producer-1}                    : 0.000\nproducer-metrics:connection-count:{client-id=producer-1}                          : 2.000\nproducer-metrics:connection-creation-rate:{client-id=producer-1}                  : 0.049\nproducer-metrics:connection-creation-total:{client-id=producer-1}                 : 2.000\nproducer-metrics:failed-authentication-rate:{client-id=producer-1}                : 0.000\nproducer-metrics:failed-authentication-total:{client-id=producer-1}               : 0.000\nproducer-metrics:failed-reauthentication-rate:{client-id=producer-1}              : 0.000\nproducer-metrics:failed-reauthentication-total:{client-id=producer-1}             : 0.000\nproducer-metrics:incoming-byte-rate:{client-id=producer-1}                        : 989.038\nproducer-metrics:incoming-byte-total:{client-id=producer-1}                       : 39699.000\nproducer-metrics:io-ratio:{client-id=producer-1}                                  : 0.002\nproducer-metrics:io-time-ns-avg:{client-id=producer-1}                            : 74919.058\nproducer-metrics:io-wait-ratio:{client-id=producer-1}                             : 0.236\nproducer-metrics:io-wait-time-ns-avg:{client-id=producer-1}                       : 7621808.752\nproducer-metrics:io-waittime-total:{client-id=producer-1}                         : 9557748175.000\nproducer-metrics:iotime-total:{client-id=producer-1}                              : 93948499.000\nproducer-metrics:metadata-age:{client-id=producer-1}                              : 10.037\nproducer-metrics:network-io-rate:{client-id=producer-1}                           : 33.382\nproducer-metrics:network-io-total:{client-id=producer-1}                          : 1340.000\nproducer-metrics:outgoing-byte-rate:{client-id=producer-1}                        : 259220.658\nproducer-metrics:outgoing-byte-total:{client-id=producer-1}                       : 10404858.000\nproducer-metrics:produce-throttle-time-avg:{client-id=producer-1}                 : 0.000\nproducer-metrics:produce-throttle-time-max:{client-id=producer-1}                 : 0.000\nproducer-metrics:reauthentication-latency-avg:{client-id=producer-1}              : NaN\nproducer-metrics:reauthentication-latency-max:{client-id=producer-1}              : NaN\nproducer-metrics:record-error-rate:{client-id=producer-1}                         : 0.000\nproducer-metrics:record-error-total:{client-id=producer-1}                        : 0.000\nproducer-metrics:record-queue-time-avg:{client-id=producer-1}                     : 4419.091\nproducer-metrics:record-queue-time-max:{client-id=producer-1}                     : 9601.000\nproducer-metrics:record-retry-rate:{client-id=producer-1}                         : 0.000\nproducer-metrics:record-retry-total:{client-id=producer-1}                        : 0.000\nproducer-metrics:record-send-rate:{client-id=producer-1}                          : 250.275\nproducer-metrics:record-send-total:{client-id=producer-1}                         : 10000.000\nproducer-metrics:record-size-avg:{client-id=producer-1}                           : 1110.000\nproducer-metrics:record-size-max:{client-id=producer-1}                           : 1110.000\nproducer-metrics:records-per-request-avg:{client-id=producer-1}                   : 14.993\nproducer-metrics:request-latency-avg:{client-id=producer-1}                       : 73.406\nproducer-metrics:request-latency-max:{client-id=producer-1}                       : 270.000\nproducer-metrics:request-rate:{client-id=producer-1}                              : 16.691\nproducer-metrics:request-size-avg:{client-id=producer-1}                          : 15529.639\nproducer-metrics:request-size-max:{client-id=producer-1}                          : 15607.000\nproducer-metrics:request-total:{client-id=producer-1}                             : 670.000\nproducer-metrics:requests-in-flight:{client-id=producer-1}                        : 0.000\nproducer-metrics:response-rate:{client-id=producer-1}                             : 16.692\nproducer-metrics:response-total:{client-id=producer-1}                            : 670.000\nproducer-metrics:select-rate:{client-id=producer-1}                               : 30.991\nproducer-metrics:select-total:{client-id=producer-1}                              : 1254.000\nproducer-metrics:successful-authentication-no-reauth-total:{client-id=producer-1} : 0.000\nproducer-metrics:successful-authentication-rate:{client-id=producer-1}            : 0.000\nproducer-metrics:successful-authentication-total:{client-id=producer-1}           : 0.000\nproducer-metrics:successful-reauthentication-rate:{client-id=producer-1}          : 0.000\nproducer-metrics:successful-reauthentication-total:{client-id=producer-1}         : 0.000\nproducer-metrics:waiting-threads:{client-id=producer-1}                           : 0.000\nproducer-node-metrics:incoming-byte-rate:{client-id=producer-1, node-id=node--1}  : 14.823\nproducer-node-metrics:incoming-byte-rate:{client-id=producer-1, node-id=node-0}   : 978.407\nproducer-node-metrics:incoming-byte-total:{client-id=producer-1, node-id=node--1} : 595.000\nproducer-node-metrics:incoming-byte-total:{client-id=producer-1, node-id=node-0}  : 39104.000\nproducer-node-metrics:outgoing-byte-rate:{client-id=producer-1, node-id=node--1}  : 2.591\nproducer-node-metrics:outgoing-byte-rate:{client-id=producer-1, node-id=node-0}   : 260307.573\nproducer-node-metrics:outgoing-byte-total:{client-id=producer-1, node-id=node--1} : 104.000\nproducer-node-metrics:outgoing-byte-total:{client-id=producer-1, node-id=node-0}  : 10404754.000\nproducer-node-metrics:request-latency-avg:{client-id=producer-1, node-id=node--1} : NaN\nproducer-node-metrics:request-latency-avg:{client-id=producer-1, node-id=node-0}  : 73.406\nproducer-node-metrics:request-latency-max:{client-id=producer-1, node-id=node--1} : NaN\nproducer-node-metrics:request-latency-max:{client-id=producer-1, node-id=node-0}  : 270.000\nproducer-node-metrics:request-rate:{client-id=producer-1, node-id=node--1}        : 0.050\nproducer-node-metrics:request-rate:{client-id=producer-1, node-id=node-0}         : 16.712\nproducer-node-metrics:request-size-avg:{client-id=producer-1, node-id=node--1}    : 52.000\nproducer-node-metrics:request-size-avg:{client-id=producer-1, node-id=node-0}     : 15575.979\nproducer-node-metrics:request-size-max:{client-id=producer-1, node-id=node--1}    : 54.000\nproducer-node-metrics:request-size-max:{client-id=producer-1, node-id=node-0}     : 15607.000\nproducer-node-metrics:request-total:{client-id=producer-1, node-id=node--1}       : 2.000\nproducer-node-metrics:request-total:{client-id=producer-1, node-id=node-0}        : 668.000\nproducer-node-metrics:response-rate:{client-id=producer-1, node-id=node--1}       : 0.050\nproducer-node-metrics:response-rate:{client-id=producer-1, node-id=node-0}        : 16.714\nproducer-node-metrics:response-total:{client-id=producer-1, node-id=node--1}      : 2.000\nproducer-node-metrics:response-total:{client-id=producer-1, node-id=node-0}       : 668.000\nproducer-topic-metrics:byte-rate:{client-id=producer-1, topic=topic-1}            : 259559.179\nproducer-topic-metrics:byte-total:{client-id=producer-1, topic=topic-1}           : 10370687.000\nproducer-topic-metrics:compression-rate:{client-id=producer-1, topic=topic-1}     : 1.000\nproducer-topic-metrics:record-error-rate:{client-id=producer-1, topic=topic-1}    : 0.000\nproducer-topic-metrics:record-error-total:{client-id=producer-1, topic=topic-1}   : 0.000\nproducer-topic-metrics:record-retry-rate:{client-id=producer-1, topic=topic-1}    : 0.000\nproducer-topic-metrics:record-retry-total:{client-id=producer-1, topic=topic-1}   : 0.000\nproducer-topic-metrics:record-send-rate:{client-id=producer-1, topic=topic-1}     : 250.282\nproducer-topic-metrics:record-send-total:{client-id=producer-1, topic=topic-1}    : 10000.000\nbash-5.1#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n\n\n我们来看一下kafka-producer-perf-test.sh脚本的输出信息：\n\n10000 records sent, 955.474871 records/sec (0.93 MB/sec), 4489.89 ms avg latency, 9807.00 ms max latency, 4449 ms 50th, 9150 ms 95th, 9600 ms 99th, 9807 ms 99.9th.\n\n\n1\n\n\nrecords sent表示测试时发送的消息总数；records/sec表示以每秒发送的消息数来统计吞吐量，括号中的MB/sec表示以每秒发送的消息大小来统计吞吐量，注意这两者的纬度；avg latency表示消息处理的平均耗时；max latency表示消息处理的最大耗时；50th, 95th ,99th分别表示P50，P95，P99指标。\n\nkafka-consumer-perf-test.sh脚本的使用也比较简单，下面的示例演示了其使用方式：\n\nbash-5.1# ./kafka-consumer-perf-test.sh --topic topic-1 --messages 10000 --broker-list localhost:9092\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec\n2023-11-02 05:48:03:299, 2023-11-02 05:48:15:277, 9.8096, 0.8190, 10045, 838.6208, 1578, 10400, 0.9432, 965.8654\nbash-5.1#\n\n\n1\n2\n3\n4\n\n\n示例中只是简单的消费主题topic-1中的1万条消息。脚本中还包含了很多其他的参数。输出结果中包含了多项信息，对应关系如下：\n\nSTART.TIME   END.TIME   DATA.CONSUMED.IN.MB   NMSG.SEC        REBALANCE.TIME.MS   FETCH.TIME.MS   FETCH.MB.SEC   FETCH.NMSG.SEC\n开始运行时间       结束时间       消费的消息总量               按消息个数计算消费的吞吐量   再平衡的时间              拉取消息的持续时间       每秒拉取消息的字节数     每秒拉取消息的个数\n\n其中fetch.time.ms=end.time-start.time-rebalance.time.ms。\n\n----------------------------------------\n\n\n# 2.分区数越多吞吐量就越高么\n\n分区是kafka中最小的并行操作单元，对生产者而言，每一个分区的数据写入完全是可以并行化的；对消费者而言，kafka只允许单个分区中的消息被一个消费者线程消费，一个消费者的消费并行度完全依赖于所消费的分区数。如此看来，如果一个主题中的分区数越多，理论上能达到的吞吐量就越大，但是实际上并不是这样。\n\n首先分别创建分区数为1，20,50，100，200，500,1000的主题，对应的主题名称分别为topic-1,topic-20,topic-50,topic-100,topic-200,topic-500,topic-1000，所有主题的副本因子都设置为1。\n\n消息中间件的性能一般是指吞吐量。抛开硬件资源的影响，消息写入的吞吐量还会收到消息大小，消息压缩方式，消息发送方式（同步/异步），消息确认类型（acks），副本因子等参数影响，所有的测试除了主题的分区数不同，其余的因素都保持相同。\n\n使用kafka-producer-perf-test.sh脚本分别向这些主题中发送100万条消息体大小为1kb的消息，测试命令如下：\n\n./kafka-producer-perf-test.sh --topic topic-xxx --num-records 1000000 --records-size 1024 --throughput -1 --producer-props bootstrap.servers=localhost:9092 acks=1\n\n\n1\n\n\n对于生产者测试的结果，不同的硬件环境，甚至不同批次的测试得到的测试结果也不会完全相同，但是总体趋势是先升后降。\n\n分区数为1时吞吐量最低，随着分区数的增长，相应的吞吐量也跟着上涨。一旦分区数超过了某个阈值之后，整体的吞吐量是不增反降的。也就是说并不是分区数越多吞吐量越大。这里的分区数临界阈值针对不同的测试环境也会表现出不同的结果，实际应用中可以通过类似的案例找到一个合理的临界值区间。\n\n对消息消费者而言同样有吞吐量方面的考量。使用kafka-consumer-perf-test.sh脚本分别消费这些主题中的100w条消息，对应的测试命令如下：\n\n./kafka-consumer-perf-test.sh --topic topic-xxx --messages 1000000 --broker-list localhost:9092\n\n\n1\n\n\n消费者的测试结果也和生产者类似，总体趋势保持先升后降。随着分区数的增加，相应的吞吐量也会增长，一旦分区数超过了某个阈值，整体的吞吐量是不升反降的，同样说明了分区数越多并不会让吞吐量一直增长。\n\n----------------------------------------\n\n\n# 3.分区数的上限\n\n一味的增加分区数并不能使吞吐量一直得到提升，并且分区数也并不能一直增加，如果超过默认的配置值，会引起kafka进程的崩溃。尝试在kafka上执行如下命令：\n\n./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb --replication-factor 1 --partitions 10000\n\n\n1\n\n\n执行完成后使用jps命令或者ps -aux|grep kafka命令检查kafka进程是否还存在。一般情况下，会发现原本运行完好的kafka进程已经崩溃。创建这么多分区是不是因为内存不足而引起的进程崩溃？其实不是，创建这些分区而引起的内存增长kafka完全cover的住。\n\n为了分析真实原因，我们可以打开kafka的服务日志文件（$KAFKA_HOME/logs/server.log）来排查问题，会发现服务日志中出现大量异常：\n\njava.io.Exception:Too many open files\n\n\n1\n\n\n异常中最关键的信息是Too many open files，这是一种常见的Linux系统错误，通常意味着文件描述符不足，他一般发生在创建进程，创建Socket，打开文件这些场景下。在Linux系统默认设置下，这个文件描述符的个数不是很多，通过下面的命令可以查看：\n\n[root@VM-24-3-centos ~]# ulimit -n\n1024\n[root@VM-24-3-centos ~]# ulimit -Sn \n1024\n[root@VM-24-3-centos ~]# ulimit -Hn\n4096\n\n\n1\n2\n3\n4\n5\n6\n\n\nS表示当前软件限制 H表示硬限制。硬限制设定之后不能再添加，而软限制则可以增加到硬限制规定的值。\n\n接下来我们来验证kafka进程的崩溃是否是由于文件描述符。\n\n首先通过ps命令查看kafka进程的当前pid：\n\nroot@7b4579bd9e87:/# ps -aux | grep kafka\nroot         1 10.6  2.2 7871756 371664 ?   ....\n\n\n1\n2\n\n\n查看当前kafka进程所占用的文件描述符个数：\n\nls /proc/1/fd | wc -l\n\n\n1\n\n\n在新建一个只有一个分区的主题，并查看kafka进程所占用的文件描述符的个数：\n\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-1 --replication-factor 1 --partitions 1\nCreated topic topic-bomb-1.\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ls /proc/1/fd | wc -l\n148\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n\n\n可以看到增加了一个分区，对应的也只增加了一个文件描述符。之前我们通过ulimit命令可以看到软限制是1024，我们创建一个具有829个分区的主题：\n\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-2 --replication-factor 1 --partitions 829\n\n\n1\n\n\n此时kafka进程占用了1024个文件描述符，并且运行完好。这时我们还可以联想到硬限制4096这个关键数字，我们在创建一个包含3071个分区的主题，此时占用4095个文件描述符。\n\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-3 --replication-factor 1 --partitions 3071\n\n\n1\n\n\nkafka进程依旧完好，文件描述符占用为4095，最后我们在创建一个只有一个分区的主题：\n\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-4 --replication-factor 1 --partitions 1\n\n\n1\n\n\n此时kafka进程已经崩溃，查看进程号时已经没有相关信息，查看kafka日志还会发现前面的异常Too many open files ，表明已经达到上限。\n\n如何避免这种异常情况？对于一个高并发，高性能的应用来说，1024或者4096太小了，可以设置成65535，这样足以应对大多数的情况。\n\nulimit -n 65535\n\n\n1\n\n\nlimits.conf文件修改之后需要重启才能生效。limits.conf文件与ulimit命令的区别在于前者针对所有用户，而且在任何shell都生效，后者只针对特定用户的当前shell。\n\n----------------------------------------\n\n\n# 4.考量因素\n\n如何选择合适的分区数？看具体情况而定。\n\n 1. 从吞吐量方面考虑，增加合适的分区数可以在一定程度上提升整体的吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求，则建议在发布之前做压测。\n 2. 有些应用场景会要求主题中的消息都能保证顺序性，这种情况下在创建主题时可以设定分区数为1，通过分区有序性的这一特性来达到主题有序性的目的。\n\n> 当然分区也不能一味的增加，分区数会占用文件描述符，而一个进程所能支配的文件描述符是有限的，这也是通常所说的文件句柄开销。在选择合适的分区数之前，最好在考量一下当前kafka进程中已经使用的文件描述符个数。\n\n3.分区数的多少还会影响系统可用性。kafka通过多副本机制实现集群高可用，每个分区都会有一到多个副本，每个副本分别存在于不同的broker节点上，并且只有leader副本对外提供服务。在kafka集群的内部，所有的副本都采用自动化的方式进行管理，并确保所有副本中的数据都能保持一定程度上的不同。当broker发生故障时，leader节点上的所有分区将暂时处于不可用状态，此时kafka会自动在其他follower副本之间选举新的leader用于接收外部客户端请求，整个过程由kafka控制器负责完成，分区在进行leader角色切换过程中会变得不可用，不过对于单个分区而言这个过程非常短暂，对用户可以忽略不计。如果集群中的某个broker节点宕机，那么会有大量分区同时进行leader角色切换，这个切换过程会相对较长，并且在这个时间窗口内这些分区会变得不可用。\n\n> 分区数越多也会让kafka的正常启动和关闭的耗时变得越长，与此同时，主题的分区数越多不仅会增加日志清理耗时，而且在被删除时也会耗费更多的时间。对于旧版本的客户端而言，分区数多也会增加他们的开销，不过这一点在新版本的客户端得到了有效的抑制。\n\n如何选择合适的分区数？\n\n一般情况下，根据预估的吞吐量以及是否与key相关的规则来设定分区数即可，后期可以通过增加分区数，增加broker或者分区重分配等手段来进行改进。如果一定要一个准则，建议将分数设置为集群中broker的倍数，至于倍数的选定可以参考预估的吞吐量。不过如果集群中的broker节点很多，这种准则也不适用，在选定分区数时进一步可以引入机架等参考因素。\n\n----------------------------------------",normalizedContent:"# 1.性能测试工具\n\n本节要讨论的性能测试工具是kafka本身提供的生产者性能测试的 kafka-producer-perf-test.sh和用于消费者性能测试的kafka-consumer-perf-test.sh。\n\n首先通过一个示例来了解一下kafka-producer-perf-test.sh脚本的使用。我们向一个只有一个分区和一个副本的主题topic-1中发送1万条消息，并且每条消息大小为1024b，生产者对应的acks参数为1。\n\nbash-5.1# ./kafka-producer-perf-test.sh --topic topic-1 --num-records 10000 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=localhost:9092 acks=1\n4756 records sent, 913.4 records/sec (0.89 mb/sec), 2026.3 ms avg latency, 4547.0 ms max latency.\n4740 records sent, 942.2 records/sec (0.92 mb/sec), 6926.3 ms avg latency, 9514.0 ms max latency.\n10000 records sent, 932.227091 records/sec (0.91 mb/sec), 4734.96 ms avg latency, 9983.00 ms max latency, 4767 ms 50th, 9513 ms 95th, 9777 ms 99th, 9982 ms 99.9th.\nbash-5.1#\n\n\n1\n2\n3\n4\n5\n\n\n上面在使用kafka-producer-perf-test.sh脚本的时候多了一个参数，其中topic用来指定生产者发送消息的目标主题；num-records用来指定发送消息的总条数；record-size用来设置每条消息的字节数；produceer-props参数用来指定生产者的配置，可以同时指定多组配置，各组配置之间用空格分隔，与producer-props参数对应的还有一个producer.config参数，他用来指定生产者的配置文件；throughput参数用来进行限流控制，当设定的值小于0时不限流，当设定的值大于0时，当发送的吞吐量大于该值时会被限流阻塞一段时间。下面的示例中设置了throughout的值为100字节：\n\nbash-5.1# ./kafka-producer-perf-test.sh --topic topic-1 --num-records 10000 --record-size 1024 --throughput 100 --producer-props bootstrap.servers=localhost:9092 acks=1\n502 records sent, 100.3 records/sec (0.10 mb/sec), 4.9 ms avg latency, 513.0 ms max latency.\n501 records sent, 100.0 records/sec (0.10 mb/sec), 1.3 ms avg latency, 2.0 ms max latency.\n500 records sent, 99.9 records/sec (0.10 mb/sec), 1.2 ms avg latency, 3.0 ms max latency.\n501 records sent, 100.2 records/sec (0.10 mb/sec), 1.2 ms avg latency, 3.0 ms max latency.\n500 records sent, 100.0 records/sec (0.10 mb/sec), 1.2 ms avg latency, 5.0 ms max latency.\n500 records sent, 100.0 records/sec (0.10 mb/sec), 1.2 ms avg latency, 4.0 ms max latency.\n500 records sent, 100.0 records/sec (0.10 mb/sec), 1.2 ms avg latency, 4.0 ms max latency.\n501 records sent, 100.1 records/sec (0.10 mb/sec), 1.1 ms avg latency, 4.0 ms max latency.\n500 records sent, 100.0 records/sec (0.10 mb/sec), 1.1 ms avg latency, 4.0 ms max latency.\n501 records sent, 100.0 records/sec (0.10 mb/sec), 1.2 ms avg latency, 5.0 ms max latency.\n500 records sent, 99.9 records/sec (0.10 mb/sec), 1.2 ms avg latency, 5.0 ms max latency.\n501 records sent, 100.1 records/sec (0.10 mb/sec), 1.1 ms avg latency, 2.0 ms max latency.\n501 records sent, 100.0 records/sec (0.10 mb/sec), 1.1 ms avg latency, 5.0 ms max latency.\n501 records sent, 100.1 records/sec (0.10 mb/sec), 1.1 ms avg latency, 3.0 ms max latency.\n500 records sent, 100.0 records/sec (0.10 mb/sec), 1.1 ms avg latency, 4.0 ms max latency.\n500 records sent, 99.9 records/sec (0.10 mb/sec), 1.1 ms avg latency, 2.0 ms max latency.\n501 records sent, 100.1 records/sec (0.10 mb/sec), 1.1 ms avg latency, 2.0 ms max latency.\n501 records sent, 100.1 records/sec (0.10 mb/sec), 1.1 ms avg latency, 4.0 ms max latency.\n500 records sent, 99.9 records/sec (0.10 mb/sec), 1.1 ms avg latency, 3.0 ms max latency.\n10000 records sent, 99.993000 records/sec (0.10 mb/sec), 1.34 ms avg latency, 513.00 ms max latency, 1 ms 50th, 2 ms 95th, 2 ms 99th, 26 ms 99.9th.\nbash-5.1#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\nkafka-producer-perf-test.sh脚本中还有一个有意思的参数print-metrics，指定了这个参数时会在测试完成之后打印很多指标信息，对很多测试任务而言具有一定参考价值。\n\nbash-5.1# ./kafka-producer-perf-test.sh --topic topic-1 --num-records 10000 --record-size 1024 --throughput -1 --print-metrics --producer-props bootstrap.servers=localhost:9092 acks=1\n4906 records sent, 969.0 records/sec (0.95 mb/sec), 1854.0 ms avg latency, 4444.0 ms max latency.\n4875 records sent, 940.0 records/sec (0.92 mb/sec), 6912.0 ms avg latency, 9593.0 ms max latency.\n10000 records sent, 955.474871 records/sec (0.93 mb/sec), 4489.89 ms avg latency, 9807.00 ms max latency, 4449 ms 50th, 9150 ms 95th, 9600 ms 99th, 9807 ms 99.9th.\n\nmetric name                                                                         value\napp-info:commit-id:{client-id=producer-1}                                         : 839b886f9b732b15\napp-info:start-time-ms:{client-id=producer-1}                                     : 1698903621840\napp-info:version:{client-id=producer-1}                                           : 2.8.1\nkafka-metrics-count:count:{client-id=producer-1}                                  : 102.000\nproducer-metrics:batch-size-avg:{client-id=producer-1}                            : 15548.256\nproducer-metrics:batch-size-max:{client-id=producer-1}                            : 15556.000\nproducer-metrics:batch-split-rate:{client-id=producer-1}                          : 0.000\nproducer-metrics:batch-split-total:{client-id=producer-1}                         : 0.000\nproducer-metrics:buffer-available-bytes:{client-id=producer-1}                    : 33554432.000\nproducer-metrics:buffer-exhausted-rate:{client-id=producer-1}                     : 0.000\nproducer-metrics:buffer-exhausted-total:{client-id=producer-1}                    : 0.000\nproducer-metrics:buffer-total-bytes:{client-id=producer-1}                        : 33554432.000\nproducer-metrics:bufferpool-wait-ratio:{client-id=producer-1}                     : 0.000\nproducer-metrics:bufferpool-wait-time-total:{client-id=producer-1}                : 0.000\nproducer-metrics:compression-rate-avg:{client-id=producer-1}                      : 1.000\nproducer-metrics:connection-close-rate:{client-id=producer-1}                     : 0.000\nproducer-metrics:connection-close-total:{client-id=producer-1}                    : 0.000\nproducer-metrics:connection-count:{client-id=producer-1}                          : 2.000\nproducer-metrics:connection-creation-rate:{client-id=producer-1}                  : 0.049\nproducer-metrics:connection-creation-total:{client-id=producer-1}                 : 2.000\nproducer-metrics:failed-authentication-rate:{client-id=producer-1}                : 0.000\nproducer-metrics:failed-authentication-total:{client-id=producer-1}               : 0.000\nproducer-metrics:failed-reauthentication-rate:{client-id=producer-1}              : 0.000\nproducer-metrics:failed-reauthentication-total:{client-id=producer-1}             : 0.000\nproducer-metrics:incoming-byte-rate:{client-id=producer-1}                        : 989.038\nproducer-metrics:incoming-byte-total:{client-id=producer-1}                       : 39699.000\nproducer-metrics:io-ratio:{client-id=producer-1}                                  : 0.002\nproducer-metrics:io-time-ns-avg:{client-id=producer-1}                            : 74919.058\nproducer-metrics:io-wait-ratio:{client-id=producer-1}                             : 0.236\nproducer-metrics:io-wait-time-ns-avg:{client-id=producer-1}                       : 7621808.752\nproducer-metrics:io-waittime-total:{client-id=producer-1}                         : 9557748175.000\nproducer-metrics:iotime-total:{client-id=producer-1}                              : 93948499.000\nproducer-metrics:metadata-age:{client-id=producer-1}                              : 10.037\nproducer-metrics:network-io-rate:{client-id=producer-1}                           : 33.382\nproducer-metrics:network-io-total:{client-id=producer-1}                          : 1340.000\nproducer-metrics:outgoing-byte-rate:{client-id=producer-1}                        : 259220.658\nproducer-metrics:outgoing-byte-total:{client-id=producer-1}                       : 10404858.000\nproducer-metrics:produce-throttle-time-avg:{client-id=producer-1}                 : 0.000\nproducer-metrics:produce-throttle-time-max:{client-id=producer-1}                 : 0.000\nproducer-metrics:reauthentication-latency-avg:{client-id=producer-1}              : nan\nproducer-metrics:reauthentication-latency-max:{client-id=producer-1}              : nan\nproducer-metrics:record-error-rate:{client-id=producer-1}                         : 0.000\nproducer-metrics:record-error-total:{client-id=producer-1}                        : 0.000\nproducer-metrics:record-queue-time-avg:{client-id=producer-1}                     : 4419.091\nproducer-metrics:record-queue-time-max:{client-id=producer-1}                     : 9601.000\nproducer-metrics:record-retry-rate:{client-id=producer-1}                         : 0.000\nproducer-metrics:record-retry-total:{client-id=producer-1}                        : 0.000\nproducer-metrics:record-send-rate:{client-id=producer-1}                          : 250.275\nproducer-metrics:record-send-total:{client-id=producer-1}                         : 10000.000\nproducer-metrics:record-size-avg:{client-id=producer-1}                           : 1110.000\nproducer-metrics:record-size-max:{client-id=producer-1}                           : 1110.000\nproducer-metrics:records-per-request-avg:{client-id=producer-1}                   : 14.993\nproducer-metrics:request-latency-avg:{client-id=producer-1}                       : 73.406\nproducer-metrics:request-latency-max:{client-id=producer-1}                       : 270.000\nproducer-metrics:request-rate:{client-id=producer-1}                              : 16.691\nproducer-metrics:request-size-avg:{client-id=producer-1}                          : 15529.639\nproducer-metrics:request-size-max:{client-id=producer-1}                          : 15607.000\nproducer-metrics:request-total:{client-id=producer-1}                             : 670.000\nproducer-metrics:requests-in-flight:{client-id=producer-1}                        : 0.000\nproducer-metrics:response-rate:{client-id=producer-1}                             : 16.692\nproducer-metrics:response-total:{client-id=producer-1}                            : 670.000\nproducer-metrics:select-rate:{client-id=producer-1}                               : 30.991\nproducer-metrics:select-total:{client-id=producer-1}                              : 1254.000\nproducer-metrics:successful-authentication-no-reauth-total:{client-id=producer-1} : 0.000\nproducer-metrics:successful-authentication-rate:{client-id=producer-1}            : 0.000\nproducer-metrics:successful-authentication-total:{client-id=producer-1}           : 0.000\nproducer-metrics:successful-reauthentication-rate:{client-id=producer-1}          : 0.000\nproducer-metrics:successful-reauthentication-total:{client-id=producer-1}         : 0.000\nproducer-metrics:waiting-threads:{client-id=producer-1}                           : 0.000\nproducer-node-metrics:incoming-byte-rate:{client-id=producer-1, node-id=node--1}  : 14.823\nproducer-node-metrics:incoming-byte-rate:{client-id=producer-1, node-id=node-0}   : 978.407\nproducer-node-metrics:incoming-byte-total:{client-id=producer-1, node-id=node--1} : 595.000\nproducer-node-metrics:incoming-byte-total:{client-id=producer-1, node-id=node-0}  : 39104.000\nproducer-node-metrics:outgoing-byte-rate:{client-id=producer-1, node-id=node--1}  : 2.591\nproducer-node-metrics:outgoing-byte-rate:{client-id=producer-1, node-id=node-0}   : 260307.573\nproducer-node-metrics:outgoing-byte-total:{client-id=producer-1, node-id=node--1} : 104.000\nproducer-node-metrics:outgoing-byte-total:{client-id=producer-1, node-id=node-0}  : 10404754.000\nproducer-node-metrics:request-latency-avg:{client-id=producer-1, node-id=node--1} : nan\nproducer-node-metrics:request-latency-avg:{client-id=producer-1, node-id=node-0}  : 73.406\nproducer-node-metrics:request-latency-max:{client-id=producer-1, node-id=node--1} : nan\nproducer-node-metrics:request-latency-max:{client-id=producer-1, node-id=node-0}  : 270.000\nproducer-node-metrics:request-rate:{client-id=producer-1, node-id=node--1}        : 0.050\nproducer-node-metrics:request-rate:{client-id=producer-1, node-id=node-0}         : 16.712\nproducer-node-metrics:request-size-avg:{client-id=producer-1, node-id=node--1}    : 52.000\nproducer-node-metrics:request-size-avg:{client-id=producer-1, node-id=node-0}     : 15575.979\nproducer-node-metrics:request-size-max:{client-id=producer-1, node-id=node--1}    : 54.000\nproducer-node-metrics:request-size-max:{client-id=producer-1, node-id=node-0}     : 15607.000\nproducer-node-metrics:request-total:{client-id=producer-1, node-id=node--1}       : 2.000\nproducer-node-metrics:request-total:{client-id=producer-1, node-id=node-0}        : 668.000\nproducer-node-metrics:response-rate:{client-id=producer-1, node-id=node--1}       : 0.050\nproducer-node-metrics:response-rate:{client-id=producer-1, node-id=node-0}        : 16.714\nproducer-node-metrics:response-total:{client-id=producer-1, node-id=node--1}      : 2.000\nproducer-node-metrics:response-total:{client-id=producer-1, node-id=node-0}       : 668.000\nproducer-topic-metrics:byte-rate:{client-id=producer-1, topic=topic-1}            : 259559.179\nproducer-topic-metrics:byte-total:{client-id=producer-1, topic=topic-1}           : 10370687.000\nproducer-topic-metrics:compression-rate:{client-id=producer-1, topic=topic-1}     : 1.000\nproducer-topic-metrics:record-error-rate:{client-id=producer-1, topic=topic-1}    : 0.000\nproducer-topic-metrics:record-error-total:{client-id=producer-1, topic=topic-1}   : 0.000\nproducer-topic-metrics:record-retry-rate:{client-id=producer-1, topic=topic-1}    : 0.000\nproducer-topic-metrics:record-retry-total:{client-id=producer-1, topic=topic-1}   : 0.000\nproducer-topic-metrics:record-send-rate:{client-id=producer-1, topic=topic-1}     : 250.282\nproducer-topic-metrics:record-send-total:{client-id=producer-1, topic=topic-1}    : 10000.000\nbash-5.1#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n\n\n我们来看一下kafka-producer-perf-test.sh脚本的输出信息：\n\n10000 records sent, 955.474871 records/sec (0.93 mb/sec), 4489.89 ms avg latency, 9807.00 ms max latency, 4449 ms 50th, 9150 ms 95th, 9600 ms 99th, 9807 ms 99.9th.\n\n\n1\n\n\nrecords sent表示测试时发送的消息总数；records/sec表示以每秒发送的消息数来统计吞吐量，括号中的mb/sec表示以每秒发送的消息大小来统计吞吐量，注意这两者的纬度；avg latency表示消息处理的平均耗时；max latency表示消息处理的最大耗时；50th, 95th ,99th分别表示p50，p95，p99指标。\n\nkafka-consumer-perf-test.sh脚本的使用也比较简单，下面的示例演示了其使用方式：\n\nbash-5.1# ./kafka-consumer-perf-test.sh --topic topic-1 --messages 10000 --broker-list localhost:9092\nstart.time, end.time, data.consumed.in.mb, mb.sec, data.consumed.in.nmsg, nmsg.sec, rebalance.time.ms, fetch.time.ms, fetch.mb.sec, fetch.nmsg.sec\n2023-11-02 05:48:03:299, 2023-11-02 05:48:15:277, 9.8096, 0.8190, 10045, 838.6208, 1578, 10400, 0.9432, 965.8654\nbash-5.1#\n\n\n1\n2\n3\n4\n\n\n示例中只是简单的消费主题topic-1中的1万条消息。脚本中还包含了很多其他的参数。输出结果中包含了多项信息，对应关系如下：\n\nstart.time   end.time   data.consumed.in.mb   nmsg.sec        rebalance.time.ms   fetch.time.ms   fetch.mb.sec   fetch.nmsg.sec\n开始运行时间       结束时间       消费的消息总量               按消息个数计算消费的吞吐量   再平衡的时间              拉取消息的持续时间       每秒拉取消息的字节数     每秒拉取消息的个数\n\n其中fetch.time.ms=end.time-start.time-rebalance.time.ms。\n\n----------------------------------------\n\n\n# 2.分区数越多吞吐量就越高么\n\n分区是kafka中最小的并行操作单元，对生产者而言，每一个分区的数据写入完全是可以并行化的；对消费者而言，kafka只允许单个分区中的消息被一个消费者线程消费，一个消费者的消费并行度完全依赖于所消费的分区数。如此看来，如果一个主题中的分区数越多，理论上能达到的吞吐量就越大，但是实际上并不是这样。\n\n首先分别创建分区数为1，20,50，100，200，500,1000的主题，对应的主题名称分别为topic-1,topic-20,topic-50,topic-100,topic-200,topic-500,topic-1000，所有主题的副本因子都设置为1。\n\n消息中间件的性能一般是指吞吐量。抛开硬件资源的影响，消息写入的吞吐量还会收到消息大小，消息压缩方式，消息发送方式（同步/异步），消息确认类型（acks），副本因子等参数影响，所有的测试除了主题的分区数不同，其余的因素都保持相同。\n\n使用kafka-producer-perf-test.sh脚本分别向这些主题中发送100万条消息体大小为1kb的消息，测试命令如下：\n\n./kafka-producer-perf-test.sh --topic topic-xxx --num-records 1000000 --records-size 1024 --throughput -1 --producer-props bootstrap.servers=localhost:9092 acks=1\n\n\n1\n\n\n对于生产者测试的结果，不同的硬件环境，甚至不同批次的测试得到的测试结果也不会完全相同，但是总体趋势是先升后降。\n\n分区数为1时吞吐量最低，随着分区数的增长，相应的吞吐量也跟着上涨。一旦分区数超过了某个阈值之后，整体的吞吐量是不增反降的。也就是说并不是分区数越多吞吐量越大。这里的分区数临界阈值针对不同的测试环境也会表现出不同的结果，实际应用中可以通过类似的案例找到一个合理的临界值区间。\n\n对消息消费者而言同样有吞吐量方面的考量。使用kafka-consumer-perf-test.sh脚本分别消费这些主题中的100w条消息，对应的测试命令如下：\n\n./kafka-consumer-perf-test.sh --topic topic-xxx --messages 1000000 --broker-list localhost:9092\n\n\n1\n\n\n消费者的测试结果也和生产者类似，总体趋势保持先升后降。随着分区数的增加，相应的吞吐量也会增长，一旦分区数超过了某个阈值，整体的吞吐量是不升反降的，同样说明了分区数越多并不会让吞吐量一直增长。\n\n----------------------------------------\n\n\n# 3.分区数的上限\n\n一味的增加分区数并不能使吞吐量一直得到提升，并且分区数也并不能一直增加，如果超过默认的配置值，会引起kafka进程的崩溃。尝试在kafka上执行如下命令：\n\n./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb --replication-factor 1 --partitions 10000\n\n\n1\n\n\n执行完成后使用jps命令或者ps -aux|grep kafka命令检查kafka进程是否还存在。一般情况下，会发现原本运行完好的kafka进程已经崩溃。创建这么多分区是不是因为内存不足而引起的进程崩溃？其实不是，创建这些分区而引起的内存增长kafka完全cover的住。\n\n为了分析真实原因，我们可以打开kafka的服务日志文件（$kafka_home/logs/server.log）来排查问题，会发现服务日志中出现大量异常：\n\njava.io.exception:too many open files\n\n\n1\n\n\n异常中最关键的信息是too many open files，这是一种常见的linux系统错误，通常意味着文件描述符不足，他一般发生在创建进程，创建socket，打开文件这些场景下。在linux系统默认设置下，这个文件描述符的个数不是很多，通过下面的命令可以查看：\n\n[root@vm-24-3-centos ~]# ulimit -n\n1024\n[root@vm-24-3-centos ~]# ulimit -sn \n1024\n[root@vm-24-3-centos ~]# ulimit -hn\n4096\n\n\n1\n2\n3\n4\n5\n6\n\n\ns表示当前软件限制 h表示硬限制。硬限制设定之后不能再添加，而软限制则可以增加到硬限制规定的值。\n\n接下来我们来验证kafka进程的崩溃是否是由于文件描述符。\n\n首先通过ps命令查看kafka进程的当前pid：\n\nroot@7b4579bd9e87:/# ps -aux | grep kafka\nroot         1 10.6  2.2 7871756 371664 ?   ....\n\n\n1\n2\n\n\n查看当前kafka进程所占用的文件描述符个数：\n\nls /proc/1/fd | wc -l\n\n\n1\n\n\n在新建一个只有一个分区的主题，并查看kafka进程所占用的文件描述符的个数：\n\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-1 --replication-factor 1 --partitions 1\ncreated topic topic-bomb-1.\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ls /proc/1/fd | wc -l\n148\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin#\n\n\n1\n2\n3\n4\n5\n\n\n可以看到增加了一个分区，对应的也只增加了一个文件描述符。之前我们通过ulimit命令可以看到软限制是1024，我们创建一个具有829个分区的主题：\n\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-2 --replication-factor 1 --partitions 829\n\n\n1\n\n\n此时kafka进程占用了1024个文件描述符，并且运行完好。这时我们还可以联想到硬限制4096这个关键数字，我们在创建一个包含3071个分区的主题，此时占用4095个文件描述符。\n\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-3 --replication-factor 1 --partitions 3071\n\n\n1\n\n\nkafka进程依旧完好，文件描述符占用为4095，最后我们在创建一个只有一个分区的主题：\n\nroot@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-4 --replication-factor 1 --partitions 1\n\n\n1\n\n\n此时kafka进程已经崩溃，查看进程号时已经没有相关信息，查看kafka日志还会发现前面的异常too many open files ，表明已经达到上限。\n\n如何避免这种异常情况？对于一个高并发，高性能的应用来说，1024或者4096太小了，可以设置成65535，这样足以应对大多数的情况。\n\nulimit -n 65535\n\n\n1\n\n\nlimits.conf文件修改之后需要重启才能生效。limits.conf文件与ulimit命令的区别在于前者针对所有用户，而且在任何shell都生效，后者只针对特定用户的当前shell。\n\n----------------------------------------\n\n\n# 4.考量因素\n\n如何选择合适的分区数？看具体情况而定。\n\n 1. 从吞吐量方面考虑，增加合适的分区数可以在一定程度上提升整体的吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求，则建议在发布之前做压测。\n 2. 有些应用场景会要求主题中的消息都能保证顺序性，这种情况下在创建主题时可以设定分区数为1，通过分区有序性的这一特性来达到主题有序性的目的。\n\n> 当然分区也不能一味的增加，分区数会占用文件描述符，而一个进程所能支配的文件描述符是有限的，这也是通常所说的文件句柄开销。在选择合适的分区数之前，最好在考量一下当前kafka进程中已经使用的文件描述符个数。\n\n3.分区数的多少还会影响系统可用性。kafka通过多副本机制实现集群高可用，每个分区都会有一到多个副本，每个副本分别存在于不同的broker节点上，并且只有leader副本对外提供服务。在kafka集群的内部，所有的副本都采用自动化的方式进行管理，并确保所有副本中的数据都能保持一定程度上的不同。当broker发生故障时，leader节点上的所有分区将暂时处于不可用状态，此时kafka会自动在其他follower副本之间选举新的leader用于接收外部客户端请求，整个过程由kafka控制器负责完成，分区在进行leader角色切换过程中会变得不可用，不过对于单个分区而言这个过程非常短暂，对用户可以忽略不计。如果集群中的某个broker节点宕机，那么会有大量分区同时进行leader角色切换，这个切换过程会相对较长，并且在这个时间窗口内这些分区会变得不可用。\n\n> 分区数越多也会让kafka的正常启动和关闭的耗时变得越长，与此同时，主题的分区数越多不仅会增加日志清理耗时，而且在被删除时也会耗费更多的时间。对于旧版本的客户端而言，分区数多也会增加他们的开销，不过这一点在新版本的客户端得到了有效的抑制。\n\n如何选择合适的分区数？\n\n一般情况下，根据预估的吞吐量以及是否与key相关的规则来设定分区数即可，后期可以通过增加分区数，增加broker或者分区重分配等手段来进行改进。如果一定要一个准则，建议将分数设置为集群中broker的倍数，至于倍数的选定可以参考预估的吞吐量。不过如果集群中的broker节点很多，这种准则也不适用，在选定分区数时进一步可以引入机架等参考因素。\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"生产者-客户端开发",frontmatter:{title:"生产者-客户端开发",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"生产者-客户端开发",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/00e44d72-3af4-33ec-95aa-573c4e2603b1/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/2.%E7%94%9F%E4%BA%A7%E8%80%85-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BC%80%E5%8F%91.html",relativePath:"03.消息队列/00.Kafka/2.生产者-客户端开发.md",key:"v-e6a3f9b4",path:"/pages/00e44d72-3af4-33ec-95aa-573c4e2603b1/",headers:[{level:2,title:"1.必填参数",slug:"_1-必填参数",normalizedTitle:"1.必填参数",charIndex:1718},{level:2,title:"2.消息发送",slug:"_2-消息发送",normalizedTitle:"2.消息发送",charIndex:2033},{level:2,title:"3.序列化",slug:"_3-序列化",normalizedTitle:"3.序列化",charIndex:3716},{level:2,title:"4.分区器",slug:"_4-分区器",normalizedTitle:"4.分区器",charIndex:7191},{level:2,title:"5.拦截器",slug:"_5-拦截器",normalizedTitle:"5.拦截器",charIndex:8250}],headersStr:"1.必填参数 2.消息发送 3.序列化 4.分区器 5.拦截器",content:'从下面的代码可以看到，将消息发往kafka主要经历四个步骤。\n\n 1. 配置生产者客户端参数以及创建对应的生产者实例。\n 2. 构建要发送的消息。\n 3. 发送消息\n 4. 关闭生产者实例。\n\npublic static void produce() {\n    Properties props = new Properties();\n    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    ProducerRecord<String, String> record = new ProducerRecord<>(topicName, "key", "value");\n\n    for (int i = 0; i < 100; i++) {\n        producer.send(record, (metadata, exception) -> {\n            if (exception == null) {\n                System.out.println("Message sent to partition " + metadata.partition() + " with offset " + metadata.offset());\n            } else {\n                exception.printStackTrace();\n            }\n        });\n    }\n\n    producer.close();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n> ProducerConfig 是Kafka中提供的常量类。\n\n对于要发送的消息，我们需要构建成ProducerRecord对象。但是它并不是单纯意义上的消息，它的本身包含多个属性，原本需要发送的消息仅仅是消息体的其中一个属性（value）。\n\npublic class ProducerRecord<K, V> {\n\n    private final String topic; //消息将要发送到的主题\n    private final Integer partition; //消息将要发送到的分区\n    private final Headers headers; //消息的header，可以为空\n    private final K key; //消息的key\n    private final V value; //真正要发送的消息\n    private final Long timestamp; //时间戳\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n * topic 和 partition 表示消息的目标主题和分区。\n * header字段是消息头部。\n * key 用来指定消息的键，可以用来计算分区号让消息发送特定的分区。同一个key的消息会被发送到同一个分区中，另外有key的消息还支持消息压缩。\n * value 表示消息体，一般不为空。\n * timestamp 是指消息的时间戳，它有创建时间和追加到日志的时间这两种类型。\n\n----------------------------------------\n\n\n# 1.必填参数\n\n * bootstrap.servers\n * key.serializer\n * value.serializer\n\n对于这三个参数前面已经介绍过，再此不再赘述，对于开发人员来讲，开发的时候直接拼配置字符串不好拼，可以直接使用kafka客户端提供的 ProducerConfig类。另外补充介绍一个参数client.id，生产者对应的客户端ID，默认为空，如果客户端没有设置，KafkaProducer会自动生成一个。\n\nKafkaProducer是线程安全的，可以在一个线程中共享单个KafkaProducer实例。\n\n----------------------------------------\n\n\n# 2.消息发送\n\n创建完生产者实例，构建完消息以后，就是真正的发送消息。发送消息有三种模式：单向发送，同步发送和异步发送。\n\n单向发送：大多数情况下，单向发送没什么问题，不过在发生不可重试异常的时候，会造成消息丢失，这种方式性能最高，但是可靠性最差。\n\n同步发送：同步发送的性能最差，可靠性相对最高，需要阻塞等待一条消息发送完以后才能发送下一条。\n\nFuture<RecordMetadata> future = producer.send(record);\nRecordMetadata recordMetadata = future.get();\n\n\n1\n2\n\n\n实际上send方法本身就是异步的，send方法返回的Future对象可以使调用方稍后获得调用的结果RecordMetadata对象。\n\nRecordMetadata对象包含消息的一些元数据，类似 topic partition offset 等等。Future表示一个任务的生命周期，并提供了相应的方法来判断任务是否已经完成或取消，以及获取任务的结果和取消任务等等。\n\nKafkaProducer中一般会发生两种类型的异常：可重试异常和不可重试异常。常见的可重试异常：NetworkException LeaderNotAvailableException UnknownTopicOrPartitionExceptionNotEnoughReplicasException等；对于不可重试异常，例如：RecordTooLargeException异常，表示发送的消息过大，KafkaProducer对此不会进行任何重试，直接抛出异常。\n\n对于可以重试的异常，可以通过 retries 参数控制重试次数，并且只要在规定的重试次数内自行恢复了，就不会抛出异常。 retries参数默认值等于0。配置方式如下：\n\nprops.put(ProducerConfig.RETRIES_CONFIG, 3);\n\n\n1\n\n\n如果发生异常以后重试了3次都没有恢复，那么仍然会抛出异常。\n\n异步发送：一般是在send方法里面指定一个Callback回调函数，Kafka再返回响应时调用该函数来实现异步的发送确认。\n\n> send方法本身就是异步的，为什么还要额外使用Callback做异步？Future 里面的get方法在何时调用，以及怎么调用都是需要面对的问题，消息不停的发送，那么消息对应的 Future对象的处理难免会引起代码处理逻辑的混乱。使用 Callback 的方式非常简单明了，Kafka有响应就会回调，要么成功，要么异常。\n\nproducer.send(record, (metadata, exception) -> {\n    if (exception !=null){\n        System.out.println("发生异常了！");\n        return;\n    }\n    System.out.println("发送成功！");\n  \n});\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nlambda表达式的两个参数是互斥的，消息发送成功，metadata 一定不为空，但是exception一定是空，反之发送失败，metadata一定是空，但是exception不为空。另外对于同一个分区而言，如果消息A在消息B之前发送，那么KafkaProducer就可以保证对应的A的回调在B的回调之前调用，也就是说，回调函数的调用也可以保证分区有序。\n\n一般在项目关闭时，会释放掉项目中的所有资源，在释放生产者实例对象时，通过调用KafkaProducer的close方法来回收资源。close方法会阻塞等待之前所有的发送请求完成后在关闭KafkaProducer，如果调用的是带超时时间的close方法，那么只会在等待timeout时间内来完成所有尚未完成的请求处理，然后强行退出。\n\n----------------------------------------\n\n\n# 3.序列化\n\n生产者需要使用序列器将对象转换成字节数组才能通过网络发送到Kafka。而在另一端，消费者需要使用反序列化器把从Kafka中收到的字节数组转换成对应的对象。\n\nKafka默认提供了几种序列化器，如下，他们都实现了Serializer接口，此接口有四个方法。\n\npublic interface Serializer<T> extends Closeable {\n\n    default void configure(Map<String, ?> configs, boolean isKey) {\n        // intentionally left blank\n    }\n\n    byte[] serialize(String topic, T data);\n\n    default byte[] serialize(String topic, Headers headers, T data) {\n        return serialize(topic, data);\n    }\n\n    @Override\n    default void close() {\n        // intentionally left blank\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nconfigure方法用来配置当前类，serialize方法用来执行序列化操作，close方法用来关闭当前序列化容器。\n\n生产者使用的序列化器和消费者使用的反序列化器是需要一一对应的。\n\n下面以StringSerializer类来分析序列化器。\n\n首先是configure方法，这个方法是在创建KafkaProducer实例的时候调用的，主要用来确定编码类型，不过一般客户端对于key.serializer.encoding ，value.serializer.encoding和 serializer.encoding 这几个参数不会配置而已。一般情况下，默认的encoding的值就是 UTF-8。\n\nprivate String encoding = "UTF8";\n\n@Override\npublic void configure(Map<String, ?> configs, boolean isKey) {\n    String propertyName = isKey ? "key.serializer.encoding" : "value.serializer.encoding";\n    Object encodingValue = configs.get(propertyName);\n    if (encodingValue == null)\n        encodingValue = configs.get("serializer.encoding");\n    if (encodingValue instanceof String)\n        encoding = (String) encodingValue;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\nserialize方法比较直观，就是把String类型转换为字节数组类型。\n\n@Override\npublic byte[] serialize(String topic, String data) {\n    try {\n        if (data == null)\n            return null;\n        else\n            return data.getBytes(encoding);\n    } catch (UnsupportedEncodingException e) {\n        throw new SerializationException("Error when serializing string to byte[] due to unsupported encoding " + encoding);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n如果Kafka客户端提供的几种序列化器都无法满足要求，则可以使用如Avro，JSON，Thrift，ProtoBuf等通用的序列化工具来实现，或者自定义序列化器。\n\n使用自定义的序列化器主要分为两步。\n\n 1. 实现自定义的序列化器。\n 2. 将自定义的序列化器指定给Kafka。\n\n例如我们实现一个仅有两个属性的User类的序列化器。\n\npublic class UserSerializer implements Serializer<UserSerializer.User> {\n\n    private static final String encoding = "UTF-8";\n  \n    @Override\n    public byte[] serialize(String topic, User data) {\n        if (data == null) {\n            return null;\n        }\n        try {\n            byte[] id, name;\n            if (data.getId() != null) {\n                id = data.getId().getBytes(encoding);\n            }else{\n                id = new byte[0];\n            }\n            if (data.getName()!=null){\n                name =data.getName().getBytes(encoding);\n            }else{\n                name = new byte[0];\n            }\n            ByteBuffer buffer = ByteBuffer.allocate(4 + 4 + id.length + name.length);\n            buffer.putInt(id.length);\n            buffer.put(id);\n            buffer.putInt(name.length);\n            buffer.put(name);\n            return buffer.array();\n        } catch (UnsupportedEncodingException e) {\n            e.printStackTrace();\n        }\n        return new byte[0];\n    }\n  \n  \n    @Data\n    public static class User implements Serializable {\n        private String id;\n  \n        private String name;\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n如何在Kafka指定自定义的序列化器？只需要将value.serializer参数设置为自定义序列化器的全限定类名即可。\n\nprops.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, UserSerializer.class.getName());\n\n\n1\n\n\n> 如果仅仅指定消息的默认序列化器，key对应的序列化器还是默认的StringSerializer。\n\n----------------------------------------\n\n\n# 4.分区器\n\n消息在通过send方法发送到broker的过程中，可能需要经过拦截器，序列化器和分区器的一系列作用。消息经过序列化之后就需要确定它发往的分区，如果消息ProduceRecord中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。总的来说，分区器的作用就是为消息分配分区。\n\nkafka提供的默认分区器是DefaultPartitioner，它实现了Partitioner接口，这个接口中定义了三个方法。\n\npublic int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);\n\n\npublic void close();\n\n\ndefault public void onNewBatch(String topic, Cluster cluster, int prevPartition) {\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\npartition方法用来计算分区号，返回值为int类型，partition方法中的参数分别表示主题，键，序列化后的键，值，序列化后的值，以及集群的元数据信息。\n\nclose方法用于在关闭分区器的时候实现一些资源的回收。\n\n在默认的分区分配方法中，如果key不为null，那么默认的分区器会对key进行Hash，最终根据得到的hash值来计算分区号，拥有相同key的消息会被写入同一个分区。如果key为null，那么消息会以特定轮询的方法发往主题内的每个可用分区。\n\n在不改变主题分区数量的情况下，key与分区之间的映射可以保持不变，不过一旦主题中增加了分区，那么就难以保证key与分区之间的映射关系了。\n\n除了使用kafka默认提供的分区器进行分区分配，还可以使用自定义的分区器，只需要同DefaultPartitioner一样实现Partitioner接口即可。\n\n实现自定义的分区器以后，需要通过配置参数 partitioner.class 来显式指定这个分区器。\n\nprops.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, DefaultPartitioner.class.getName());\n\n\n1\n\n\n----------------------------------------\n\n\n# 5.拦截器\n\nkafka一共有两种拦截器：生产者拦截器和消费者拦截器。生产者拦截器可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息，修改消息的内容等等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。\n\n生产者拦截器的使用需要实现ProducerInterceptor接口，该接口包含三个方法。\n\npublic interface ProducerInterceptor<K, V> extends Configurable {\n\n    public ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);\n\n    public void onAcknowledgement(RecordMetadata metadata, Exception exception);\n\n    public void close();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nKafkaProducer在将消息序列化和计算分区之前会调用生产者拦截器的onSend方法来对消息进行相应的定制化操作。\n\nKafkaProducer会在消息被应答之前或者消息发送失败时调用生产者拦截器的onAcknowledgement方法，优先于用于设置的Callback之前执行。这个方法运行在生产者的IO线程中，所以逻辑越简单越好或者使用异步的处理方式。close方法用于在关闭拦截器时执行一些资源的清理操作，这三个方法抛出的异常会被捕获并记录到日志中，但并不会向上传递。\n\n实现自定义的拦截器之后，需要在KafkaProducer的配置参数 interceptor.classes 中指定这个拦截器，此参数默认值时空字符串。\n\nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, "");\n\n\n1\n\n\nKafkaProducer可以指定多个拦截器形成拦截器链。拦截器链会按照interceptor.classes参数配置的拦截器顺序一一执行，配置的时候，多个拦截器之间使用逗号分隔。\n\n如果拦截器链中的某个拦截器的执行需要依赖于前一个拦截器的输出，那么就有可能产生副作用。如果某个拦截器链执行失败，那么下一个拦截器会接着上一个执行成功的拦截器继续执行。\n\n----------------------------------------',normalizedContent:'从下面的代码可以看到，将消息发往kafka主要经历四个步骤。\n\n 1. 配置生产者客户端参数以及创建对应的生产者实例。\n 2. 构建要发送的消息。\n 3. 发送消息\n 4. 关闭生产者实例。\n\npublic static void produce() {\n    properties props = new properties();\n    props.put(producerconfig.bootstrap_servers_config, brokerlist);\n    props.put(producerconfig.key_serializer_class_config, stringserializer.class.getname());\n    props.put(producerconfig.value_serializer_class_config, stringserializer.class.getname());\n\n    kafkaproducer<string, string> producer = new kafkaproducer<>(props);\n\n    producerrecord<string, string> record = new producerrecord<>(topicname, "key", "value");\n\n    for (int i = 0; i < 100; i++) {\n        producer.send(record, (metadata, exception) -> {\n            if (exception == null) {\n                system.out.println("message sent to partition " + metadata.partition() + " with offset " + metadata.offset());\n            } else {\n                exception.printstacktrace();\n            }\n        });\n    }\n\n    producer.close();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n> producerconfig 是kafka中提供的常量类。\n\n对于要发送的消息，我们需要构建成producerrecord对象。但是它并不是单纯意义上的消息，它的本身包含多个属性，原本需要发送的消息仅仅是消息体的其中一个属性（value）。\n\npublic class producerrecord<k, v> {\n\n    private final string topic; //消息将要发送到的主题\n    private final integer partition; //消息将要发送到的分区\n    private final headers headers; //消息的header，可以为空\n    private final k key; //消息的key\n    private final v value; //真正要发送的消息\n    private final long timestamp; //时间戳\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n * topic 和 partition 表示消息的目标主题和分区。\n * header字段是消息头部。\n * key 用来指定消息的键，可以用来计算分区号让消息发送特定的分区。同一个key的消息会被发送到同一个分区中，另外有key的消息还支持消息压缩。\n * value 表示消息体，一般不为空。\n * timestamp 是指消息的时间戳，它有创建时间和追加到日志的时间这两种类型。\n\n----------------------------------------\n\n\n# 1.必填参数\n\n * bootstrap.servers\n * key.serializer\n * value.serializer\n\n对于这三个参数前面已经介绍过，再此不再赘述，对于开发人员来讲，开发的时候直接拼配置字符串不好拼，可以直接使用kafka客户端提供的 producerconfig类。另外补充介绍一个参数client.id，生产者对应的客户端id，默认为空，如果客户端没有设置，kafkaproducer会自动生成一个。\n\nkafkaproducer是线程安全的，可以在一个线程中共享单个kafkaproducer实例。\n\n----------------------------------------\n\n\n# 2.消息发送\n\n创建完生产者实例，构建完消息以后，就是真正的发送消息。发送消息有三种模式：单向发送，同步发送和异步发送。\n\n单向发送：大多数情况下，单向发送没什么问题，不过在发生不可重试异常的时候，会造成消息丢失，这种方式性能最高，但是可靠性最差。\n\n同步发送：同步发送的性能最差，可靠性相对最高，需要阻塞等待一条消息发送完以后才能发送下一条。\n\nfuture<recordmetadata> future = producer.send(record);\nrecordmetadata recordmetadata = future.get();\n\n\n1\n2\n\n\n实际上send方法本身就是异步的，send方法返回的future对象可以使调用方稍后获得调用的结果recordmetadata对象。\n\nrecordmetadata对象包含消息的一些元数据，类似 topic partition offset 等等。future表示一个任务的生命周期，并提供了相应的方法来判断任务是否已经完成或取消，以及获取任务的结果和取消任务等等。\n\nkafkaproducer中一般会发生两种类型的异常：可重试异常和不可重试异常。常见的可重试异常：networkexception leadernotavailableexception unknowntopicorpartitionexceptionnotenoughreplicasexception等；对于不可重试异常，例如：recordtoolargeexception异常，表示发送的消息过大，kafkaproducer对此不会进行任何重试，直接抛出异常。\n\n对于可以重试的异常，可以通过 retries 参数控制重试次数，并且只要在规定的重试次数内自行恢复了，就不会抛出异常。 retries参数默认值等于0。配置方式如下：\n\nprops.put(producerconfig.retries_config, 3);\n\n\n1\n\n\n如果发生异常以后重试了3次都没有恢复，那么仍然会抛出异常。\n\n异步发送：一般是在send方法里面指定一个callback回调函数，kafka再返回响应时调用该函数来实现异步的发送确认。\n\n> send方法本身就是异步的，为什么还要额外使用callback做异步？future 里面的get方法在何时调用，以及怎么调用都是需要面对的问题，消息不停的发送，那么消息对应的 future对象的处理难免会引起代码处理逻辑的混乱。使用 callback 的方式非常简单明了，kafka有响应就会回调，要么成功，要么异常。\n\nproducer.send(record, (metadata, exception) -> {\n    if (exception !=null){\n        system.out.println("发生异常了！");\n        return;\n    }\n    system.out.println("发送成功！");\n  \n});\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nlambda表达式的两个参数是互斥的，消息发送成功，metadata 一定不为空，但是exception一定是空，反之发送失败，metadata一定是空，但是exception不为空。另外对于同一个分区而言，如果消息a在消息b之前发送，那么kafkaproducer就可以保证对应的a的回调在b的回调之前调用，也就是说，回调函数的调用也可以保证分区有序。\n\n一般在项目关闭时，会释放掉项目中的所有资源，在释放生产者实例对象时，通过调用kafkaproducer的close方法来回收资源。close方法会阻塞等待之前所有的发送请求完成后在关闭kafkaproducer，如果调用的是带超时时间的close方法，那么只会在等待timeout时间内来完成所有尚未完成的请求处理，然后强行退出。\n\n----------------------------------------\n\n\n# 3.序列化\n\n生产者需要使用序列器将对象转换成字节数组才能通过网络发送到kafka。而在另一端，消费者需要使用反序列化器把从kafka中收到的字节数组转换成对应的对象。\n\nkafka默认提供了几种序列化器，如下，他们都实现了serializer接口，此接口有四个方法。\n\npublic interface serializer<t> extends closeable {\n\n    default void configure(map<string, ?> configs, boolean iskey) {\n        // intentionally left blank\n    }\n\n    byte[] serialize(string topic, t data);\n\n    default byte[] serialize(string topic, headers headers, t data) {\n        return serialize(topic, data);\n    }\n\n    @override\n    default void close() {\n        // intentionally left blank\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nconfigure方法用来配置当前类，serialize方法用来执行序列化操作，close方法用来关闭当前序列化容器。\n\n生产者使用的序列化器和消费者使用的反序列化器是需要一一对应的。\n\n下面以stringserializer类来分析序列化器。\n\n首先是configure方法，这个方法是在创建kafkaproducer实例的时候调用的，主要用来确定编码类型，不过一般客户端对于key.serializer.encoding ，value.serializer.encoding和 serializer.encoding 这几个参数不会配置而已。一般情况下，默认的encoding的值就是 utf-8。\n\nprivate string encoding = "utf8";\n\n@override\npublic void configure(map<string, ?> configs, boolean iskey) {\n    string propertyname = iskey ? "key.serializer.encoding" : "value.serializer.encoding";\n    object encodingvalue = configs.get(propertyname);\n    if (encodingvalue == null)\n        encodingvalue = configs.get("serializer.encoding");\n    if (encodingvalue instanceof string)\n        encoding = (string) encodingvalue;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\nserialize方法比较直观，就是把string类型转换为字节数组类型。\n\n@override\npublic byte[] serialize(string topic, string data) {\n    try {\n        if (data == null)\n            return null;\n        else\n            return data.getbytes(encoding);\n    } catch (unsupportedencodingexception e) {\n        throw new serializationexception("error when serializing string to byte[] due to unsupported encoding " + encoding);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n如果kafka客户端提供的几种序列化器都无法满足要求，则可以使用如avro，json，thrift，protobuf等通用的序列化工具来实现，或者自定义序列化器。\n\n使用自定义的序列化器主要分为两步。\n\n 1. 实现自定义的序列化器。\n 2. 将自定义的序列化器指定给kafka。\n\n例如我们实现一个仅有两个属性的user类的序列化器。\n\npublic class userserializer implements serializer<userserializer.user> {\n\n    private static final string encoding = "utf-8";\n  \n    @override\n    public byte[] serialize(string topic, user data) {\n        if (data == null) {\n            return null;\n        }\n        try {\n            byte[] id, name;\n            if (data.getid() != null) {\n                id = data.getid().getbytes(encoding);\n            }else{\n                id = new byte[0];\n            }\n            if (data.getname()!=null){\n                name =data.getname().getbytes(encoding);\n            }else{\n                name = new byte[0];\n            }\n            bytebuffer buffer = bytebuffer.allocate(4 + 4 + id.length + name.length);\n            buffer.putint(id.length);\n            buffer.put(id);\n            buffer.putint(name.length);\n            buffer.put(name);\n            return buffer.array();\n        } catch (unsupportedencodingexception e) {\n            e.printstacktrace();\n        }\n        return new byte[0];\n    }\n  \n  \n    @data\n    public static class user implements serializable {\n        private string id;\n  \n        private string name;\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n如何在kafka指定自定义的序列化器？只需要将value.serializer参数设置为自定义序列化器的全限定类名即可。\n\nprops.put(producerconfig.value_serializer_class_config, userserializer.class.getname());\n\n\n1\n\n\n> 如果仅仅指定消息的默认序列化器，key对应的序列化器还是默认的stringserializer。\n\n----------------------------------------\n\n\n# 4.分区器\n\n消息在通过send方法发送到broker的过程中，可能需要经过拦截器，序列化器和分区器的一系列作用。消息经过序列化之后就需要确定它发往的分区，如果消息producerecord中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。总的来说，分区器的作用就是为消息分配分区。\n\nkafka提供的默认分区器是defaultpartitioner，它实现了partitioner接口，这个接口中定义了三个方法。\n\npublic int partition(string topic, object key, byte[] keybytes, object value, byte[] valuebytes, cluster cluster);\n\n\npublic void close();\n\n\ndefault public void onnewbatch(string topic, cluster cluster, int prevpartition) {\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\npartition方法用来计算分区号，返回值为int类型，partition方法中的参数分别表示主题，键，序列化后的键，值，序列化后的值，以及集群的元数据信息。\n\nclose方法用于在关闭分区器的时候实现一些资源的回收。\n\n在默认的分区分配方法中，如果key不为null，那么默认的分区器会对key进行hash，最终根据得到的hash值来计算分区号，拥有相同key的消息会被写入同一个分区。如果key为null，那么消息会以特定轮询的方法发往主题内的每个可用分区。\n\n在不改变主题分区数量的情况下，key与分区之间的映射可以保持不变，不过一旦主题中增加了分区，那么就难以保证key与分区之间的映射关系了。\n\n除了使用kafka默认提供的分区器进行分区分配，还可以使用自定义的分区器，只需要同defaultpartitioner一样实现partitioner接口即可。\n\n实现自定义的分区器以后，需要通过配置参数 partitioner.class 来显式指定这个分区器。\n\nprops.put(producerconfig.partitioner_class_config, defaultpartitioner.class.getname());\n\n\n1\n\n\n----------------------------------------\n\n\n# 5.拦截器\n\nkafka一共有两种拦截器：生产者拦截器和消费者拦截器。生产者拦截器可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息，修改消息的内容等等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。\n\n生产者拦截器的使用需要实现producerinterceptor接口，该接口包含三个方法。\n\npublic interface producerinterceptor<k, v> extends configurable {\n\n    public producerrecord<k, v> onsend(producerrecord<k, v> record);\n\n    public void onacknowledgement(recordmetadata metadata, exception exception);\n\n    public void close();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nkafkaproducer在将消息序列化和计算分区之前会调用生产者拦截器的onsend方法来对消息进行相应的定制化操作。\n\nkafkaproducer会在消息被应答之前或者消息发送失败时调用生产者拦截器的onacknowledgement方法，优先于用于设置的callback之前执行。这个方法运行在生产者的io线程中，所以逻辑越简单越好或者使用异步的处理方式。close方法用于在关闭拦截器时执行一些资源的清理操作，这三个方法抛出的异常会被捕获并记录到日志中，但并不会向上传递。\n\n实现自定义的拦截器之后，需要在kafkaproducer的配置参数 interceptor.classes 中指定这个拦截器，此参数默认值时空字符串。\n\nprops.put(producerconfig.interceptor_classes_config, "");\n\n\n1\n\n\nkafkaproducer可以指定多个拦截器形成拦截器链。拦截器链会按照interceptor.classes参数配置的拦截器顺序一一执行，配置的时候，多个拦截器之间使用逗号分隔。\n\n如果拦截器链中的某个拦截器的执行需要依赖于前一个拦截器的输出，那么就有可能产生副作用。如果某个拦截器链执行失败，那么下一个拦截器会接着上一个执行成功的拦截器继续执行。\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"生产者-原理分析",frontmatter:{title:"生产者-原理分析",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"生产者-原理分析",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/517a0a21-c440-3dd1-9e5e-a00d7a7fc18a/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/3.%E7%94%9F%E4%BA%A7%E8%80%85-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90.html",relativePath:"03.消息队列/00.Kafka/3.生产者-原理分析.md",key:"v-b4a5b7ac",path:"/pages/517a0a21-c440-3dd1-9e5e-a00d7a7fc18a/",headers:[{level:2,title:"1.整体架构",slug:"_1-整体架构",normalizedTitle:"1.整体架构",charIndex:73},{level:2,title:"2.元数据的更新",slug:"_2-元数据的更新",normalizedTitle:"2.元数据的更新",charIndex:2130},{level:2,title:"3.重要的生产者参数",slug:"_3-重要的生产者参数",normalizedTitle:"3.重要的生产者参数",charIndex:3284}],headersStr:"1.整体架构 2.元数据的更新 3.重要的生产者参数",content:'本节主要对kafka生产者客户端的内部原理进行分析。\n\n----------------------------------------\n\n\n# 1.整体架构\n\n生产者客户端的整体架构如下所示。 生产者客户端由两个线程协调运行，这两个线程分别是主线程和Sender线程。在主线程中由KafkaProducer创建消息，然后通过可能的拦截器，序列化器和分区器的作用之后缓存到消息累加器中。Sender线程负责从消息累加器中获取消息并将其发送到kafka。\n\n消息累加器主要用来缓存消息以便Sender线程可以批量发送，进而减少网络传输的资源消耗以提升性能。通过客户端参数buffer.memory可以控制消息累加器缓存的大小，默认为32MB。如果生产者发送消息的速度超过消息发送到服务器的速度，则会导致生产者空间不足，这个时候KafkaProducer的send方法要么被阻塞，要么抛出异常，这个取决于参数 max.block.ms的配置，此参数默认值是60s。\n\n主线程中发送过来的消息都会被追加到消息累加器的某个双端队列中，在消息累加器内部为每一个分区都维护了一个双端队列，队列中的内容就是ProducerBatch （Deque<ProducerBatch>）。消息写入缓存的时候，追加到双端队列的尾部；Sender线程读取消息的时候从双端队列的头部读取。\n\n> ProducerBatch不是ProducerReocrd。ProducerBatch是指一个消息批次，ProducerRecord会被包含在ProducerBatch中，将多个ProducerRecord拼装成一个ProducerBatch一方面能节省空间，另一方面可以减少网络请求的次数以提升整体的吞吐量。\n\n如果生产者需要向很多分区发送消息，则可以将 buffer.memory 参数调大以增加整体的吞吐量。\n\n消息在网络上都是以字节的形式传输的，在发送之前需要创建一块内存区域来保存对应的消息。在kafka生产者客户端中，通过ByteBuffer实现消息内存的创建和释放，因为频繁的创建和释放比较消耗资源，所以累加器内部引入了池化技术BufferPool，实现对ByteBuffer的复用。但是BufferPool仅仅针对特定大小的ByteBuffer进行管理，其他大小的并不会缓存。这个特定大小由参数 batch.size参数指定，默认是16 KB。\n\nProducerBatch的大小和 batch.size参数也有很大关系。当一条消息进入消息累加器，会先寻找与消息分区对应的双端队列（没有则新建），再从这个队列的尾部获取一个ProducerBatch（没有则新建），查看这个ProducerBatch是否还可以写入这条消息，如果可以则写入，如果不可以则需要创建一个新的ProducerBatch，在新建ProducerBatch的时候会评估这条消息大小是否超过了 batch.size参数的大小，如果不超过，那么就以 batch.size参数的大小创建ProducerBatch，这样在使用完这段内存区域之后，可以通过BufferPool的管理来进行复用；如果超过，那么就以评估的大小来创建ProducerBatch，但是这段内存不会被复用。\n\nSender从消息累加器中获取缓存的消息之后，会进一步将原本的 <分区，Deque<ProducerBatch>>结构转换为 <Node,List<ProducerRecord>>的结构。其中Node表示与kafka连接的Broker节点。对于网络连接来说，生产者客户端是与具体的Broker建立的连接，也就是向具体的Broker发送消息，而不关心消息属于哪一个分区；而对于KafkaProducer的应用层来说，应用层只关注往哪一个分区发送消息，所以这里需要做一个结构转换。\n\n在进行结构转换之后，Sender还会进一步封装成 <Node,Request>结构，这样就可以将Request发送到各个Broker节点了，这里的Request指的是kafka的各种协议请求，对于消息发送来说，就是指ProducerRequest。\n\n请求在从Sender线程发送到kafka之前还会保存到InFlightRequests中，InFlightRequests保存对象的具体结构是：Map<NodeId,Deque<Request>>，它缓存的是已经发出去但是还没有收到响应的请求。通过参数 max.in.flight.requests.per.connection可以限制每个连接最多缓存的请求数（客户端与Node之间的连接），默认是5，即每个连接最多只能缓存5个未响应的请求，超过该数值之后就不会继续往这个连接发送更多的请求了。\n\n> 通过比较Request队列的大小和这个参数的大小可以判断对应的节点中是否已经堆积了很多未响应的消息，如果确实堆积了，说明这个节点的负载较大或者网络连接有问题，在继续向这个节点发送请求会增大请求超时的可能。\n\n----------------------------------------\n\n\n# 2.元数据的更新\n\nInFlightRequests还可以获取到leastLoadedNode，即所有Node中负载最小的那一个。这里的负载最小是通过每一个Node在InFlightRequests中还未确认的请求数确定的，未确认的请求越多则认为负载越大。选择leastLoadedNode发送请求可以使它能够尽快发出，避免因为网络拥塞等异常因素而影响整体的进度。\n\n通常我们使用如下的方式创建一条kafka的消息。\n\nProducerRecord<String, String> record=new ProducerRecord<>(topicName,"key","value");\n\n\n1\n\n\nKafkaProducer要将这条消息追加到指定主题的某个分区所对应的leader副本之前，首先需要知道主题的分区数量，然后经过计算得出目标分区，之后KafkaProducer需要知道目标分区的leader副本所在的broker节点的地址，端口等等信息才能建立连接，最终才能将消息发送到kafka，在这一过程中所需要的信息都属于元数据信息。\n\n前面说过在配置 bootstrap.servers 参数只需要配置部分 broker节点的地址即可，不需要配置所有的broker节点的地址，因为客户端可以自己发现其他broker节点的地址，这一过程其实也属于元数据相关的更新操作。另外，分区数量以及leader副本的分布都会动态地变化，客户端也需要动态的捕捉这些变化。\n\n元数据是指kafka集群的元数据，这些元数据具体记录了集群中有哪些主题，这些主题有哪些分区，每个分区的leader副本分配在哪一个节点上，follower副本分配在哪些节点上，哪些副本在AR，ISR等集合中，集群中有哪些节点，控制器节点是哪一个等信息。\n\n当客户端中没有需要使用的元数据信息时，比如没有指定的主题信息，或者超过 metadata.max.age.ms参数设置的时间没有更新元数据都会引起元数据的更新操作。metadata.max.age.ms参数默认是5分钟。元数据的更新操作是在客户端内部进行的，对客户端的外部使用者不可见。当需要更新元数据时，会先挑选出leastLoadedNode，然后向这个Node发送MetadataRequest请求来获取具体的元数据信息。这个更新操作是由Sender线程发起的，在创建完MetadataRequest之后同样会存入InFlightRequests。\n\n元数据虽然由Sender线程更新，但是主线程也需要读取这些信息，这里的数据同步通过synchronized和final关键字来保障。\n\n----------------------------------------\n\n\n# 3.重要的生产者参数\n\n在KafkaProducer中，除了3个默认的客户端参数，大部分的参数都有合理的默认值，一般不需要修改它们。不过了解这些参数可以让我们更合理地使用生产者客户端，\n\n 1. acks\n\n这个参数**用来指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。**acks是生产者客户端中一个非常重要的参数，它涉及消息的可靠性和吞吐量之间的权衡。acks参数有3种类型的值(都是字符串类型)。\n\n * acks=1。默认值即为1。生产者发送消息之后，只要分区的leader副本成功写入消息，那么它就会收到来自服务端的成功响应。如果消息无法写入 leader副本，比如在 leader副本崩溃、重新选举新的leader副本的过程中，那么生产者就会收到一个错误的响应，为了避免消息丢失，生产者可以选择重发消息。如果消息写入leader副本并返回成功响应给生产者，且在被其他follower副本拉取之前leader副本崩溃，那么此时消息还是会丢失，因为新选举的leader副本中并没有这条对应的消息。acks设置为1，是消息可靠性和吞吐量之间的折中方案。\n * acks =0。**生产者发送消息之后不需要等待任何服务端的响应。**如果在消息从发送到写入Kafka的过程中出现某些异常，导致Kafka并没有收到这条消息，那么生产者也无从得知，消息也就丢失了。在其他配置环境相同的情况下，acks设置为0可以达到最大的吞吐量。\n * acks =-1或acks =all。生产者在消息发送之后，**需要等待ISR中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应。**在其他配置环境相同的情况下， acks 设置为-1(all)可以达到最强的可靠性。但这并不意味着消息就一定可靠，因为ISR中可能只有leader副本，这样就退化成了acks=1的情况。要获得更高的消息可靠性需要配合min.insync.replicas等参数的联动。\n\n**acks 参数配置的值是一个字符串类型，而不是整数类型。**举个例子，将acks参数设置为0，需要采用下面这种形式:\n\nprops.put(ProducerConfig.ACKS_CONFIG,"0");\n\n\n1\n\n 2. max.request.size\n\n这个参数用来限制生产者客户端能发送的消息的最大值，默认值为1MB。\n\n一般情况下,这个默认值就可以满足大多数的应用场景了。不建议盲目地增大这个参数的配置值，因为这个参数还涉及一些其他参数的联动，比如broker端的message.max.bytes参数，如果配置错误可能会引起一些不必要的异常。\n\n 3. retries 和 retry.backoff.ms\n\nretries 参数用来配置生产者重试的次数，默认值为0，即在发生异常的时候不进行任何重试动作。消息在从生产者发出到成功写入服务器之前可能发生一些临时性的异常，比如网络抖动、leader副本的选举等，这种异常往往是可以自行恢复的，生产者可以通过配置retries大于0的值，以此通过内部重试来恢复而不是一味地将异常抛给生产者的应用程序。如果重试达到设定的次数，那么生产者就会放弃重试并返回异常。不过并不是所有的异常都是可以通过重试来解决的，比如消息太大，超过max.request.size参数配置的值时，这种方式就不可行了。\n\n重试还和另一个参数retry.backoff.ms有关，这个参数的默认值为100,它用来设定两次重试之间的时间间隔，避免无效的频繁重试。在配置retries 和 retry.backoff.ms之前，最好先估算一下可能的异常恢复时间，这样可以设定总的重试时间大于这个异常恢复时间，以此来避免生产者过早地放弃重试。\n\nKafka可以保证同一个分区中的消息是有序的。如果生产者按照一定的顺序发送消息，那么这些消息也会顺序地写入分区，进而消费者也可以按照同样的顺序消费它们。\n\n如果将 retries参数配置为非零值，并且max.in.flight.requests.per.connection参数配置为大于1的值，那么就会出现错序的现象:如果第一批次消息写入失败，而第二批次消息写入成功，那么生产者会重试发送第一批次的消息，此时如果第一批次的消息写入成功，那么这两个批次的消息就出现了错序。一般而言，在需要保证消息顺序的场合建议把参数 max.in.flight.requests .per.connection配置为1，而不是把retries 配置为0，不过这样也会影响整体的吞吐。\n\n 4. compression.type\n\n这个参数**用来指定消息的压缩方式，默认值为“none”，即默认情况下，消息不会被压缩。**该参数还可以配置为“gzip”“snappy”和“lz4”。对消息进行压缩可以极大地减少网络传输量、降低网络I/O，从而提高整体的性能。消息压缩是一种使用时间换空间的优化方式，如果对时延有一定的要求，则不推荐对消息进行压缩。\n\n 5. connections.max.idle.ms\n\n这个参数用来指定在多久之后关闭闲置的连接，默认值是540000(ms)，即9分钟。\n\n 6. linger.ms\n\n这个参数用来指定生产者发送ProducerBatch之前等待更多消息(ProducerRecord)加入 ProducerBatch的时间，默认值为0。生产者客户端会在ProducerBatch被填满或等待时间超过 linger.ms 值时发送出去。(增大这个参数的值会增加消息的延迟，但是同时能提升一定的吞吐量。)\n\n 7. receive.buffer.bytes\n\n这个参数用来设置Socket接收消息缓冲区(SO_RECBUF)的大小，默认值为32KB。如果设置为-1，则使用操作系统的默认值。如果Producer与Kafka处于不同的机房，则可以适地调大这个参数值。\n\n 8. send.buffer.bytes\n\n这个参数用来设置Socket发送消息缓冲区(SO_SNDBUF)的大小，默认值为128KB。 与receive.buffer.bytes参数一样，如果设置为-1，则使用操作系统的默认值。\n\n 9. request.timeout.ms\n\n这个参数**用来配置 Producer等待请求响应的最长时间，默认值为30000(ms)。**请求超时之后可以选择进行重试。注意这个参数需要比broker端参数replica.lag.time.max.ms的值要大，这样可以减少因客户端重试而引起的消息重复的概率。\n\n----------------------------------------',normalizedContent:'本节主要对kafka生产者客户端的内部原理进行分析。\n\n----------------------------------------\n\n\n# 1.整体架构\n\n生产者客户端的整体架构如下所示。 生产者客户端由两个线程协调运行，这两个线程分别是主线程和sender线程。在主线程中由kafkaproducer创建消息，然后通过可能的拦截器，序列化器和分区器的作用之后缓存到消息累加器中。sender线程负责从消息累加器中获取消息并将其发送到kafka。\n\n消息累加器主要用来缓存消息以便sender线程可以批量发送，进而减少网络传输的资源消耗以提升性能。通过客户端参数buffer.memory可以控制消息累加器缓存的大小，默认为32mb。如果生产者发送消息的速度超过消息发送到服务器的速度，则会导致生产者空间不足，这个时候kafkaproducer的send方法要么被阻塞，要么抛出异常，这个取决于参数 max.block.ms的配置，此参数默认值是60s。\n\n主线程中发送过来的消息都会被追加到消息累加器的某个双端队列中，在消息累加器内部为每一个分区都维护了一个双端队列，队列中的内容就是producerbatch （deque<producerbatch>）。消息写入缓存的时候，追加到双端队列的尾部；sender线程读取消息的时候从双端队列的头部读取。\n\n> producerbatch不是producerreocrd。producerbatch是指一个消息批次，producerrecord会被包含在producerbatch中，将多个producerrecord拼装成一个producerbatch一方面能节省空间，另一方面可以减少网络请求的次数以提升整体的吞吐量。\n\n如果生产者需要向很多分区发送消息，则可以将 buffer.memory 参数调大以增加整体的吞吐量。\n\n消息在网络上都是以字节的形式传输的，在发送之前需要创建一块内存区域来保存对应的消息。在kafka生产者客户端中，通过bytebuffer实现消息内存的创建和释放，因为频繁的创建和释放比较消耗资源，所以累加器内部引入了池化技术bufferpool，实现对bytebuffer的复用。但是bufferpool仅仅针对特定大小的bytebuffer进行管理，其他大小的并不会缓存。这个特定大小由参数 batch.size参数指定，默认是16 kb。\n\nproducerbatch的大小和 batch.size参数也有很大关系。当一条消息进入消息累加器，会先寻找与消息分区对应的双端队列（没有则新建），再从这个队列的尾部获取一个producerbatch（没有则新建），查看这个producerbatch是否还可以写入这条消息，如果可以则写入，如果不可以则需要创建一个新的producerbatch，在新建producerbatch的时候会评估这条消息大小是否超过了 batch.size参数的大小，如果不超过，那么就以 batch.size参数的大小创建producerbatch，这样在使用完这段内存区域之后，可以通过bufferpool的管理来进行复用；如果超过，那么就以评估的大小来创建producerbatch，但是这段内存不会被复用。\n\nsender从消息累加器中获取缓存的消息之后，会进一步将原本的 <分区，deque<producerbatch>>结构转换为 <node,list<producerrecord>>的结构。其中node表示与kafka连接的broker节点。对于网络连接来说，生产者客户端是与具体的broker建立的连接，也就是向具体的broker发送消息，而不关心消息属于哪一个分区；而对于kafkaproducer的应用层来说，应用层只关注往哪一个分区发送消息，所以这里需要做一个结构转换。\n\n在进行结构转换之后，sender还会进一步封装成 <node,request>结构，这样就可以将request发送到各个broker节点了，这里的request指的是kafka的各种协议请求，对于消息发送来说，就是指producerrequest。\n\n请求在从sender线程发送到kafka之前还会保存到inflightrequests中，inflightrequests保存对象的具体结构是：map<nodeid,deque<request>>，它缓存的是已经发出去但是还没有收到响应的请求。通过参数 max.in.flight.requests.per.connection可以限制每个连接最多缓存的请求数（客户端与node之间的连接），默认是5，即每个连接最多只能缓存5个未响应的请求，超过该数值之后就不会继续往这个连接发送更多的请求了。\n\n> 通过比较request队列的大小和这个参数的大小可以判断对应的节点中是否已经堆积了很多未响应的消息，如果确实堆积了，说明这个节点的负载较大或者网络连接有问题，在继续向这个节点发送请求会增大请求超时的可能。\n\n----------------------------------------\n\n\n# 2.元数据的更新\n\ninflightrequests还可以获取到leastloadednode，即所有node中负载最小的那一个。这里的负载最小是通过每一个node在inflightrequests中还未确认的请求数确定的，未确认的请求越多则认为负载越大。选择leastloadednode发送请求可以使它能够尽快发出，避免因为网络拥塞等异常因素而影响整体的进度。\n\n通常我们使用如下的方式创建一条kafka的消息。\n\nproducerrecord<string, string> record=new producerrecord<>(topicname,"key","value");\n\n\n1\n\n\nkafkaproducer要将这条消息追加到指定主题的某个分区所对应的leader副本之前，首先需要知道主题的分区数量，然后经过计算得出目标分区，之后kafkaproducer需要知道目标分区的leader副本所在的broker节点的地址，端口等等信息才能建立连接，最终才能将消息发送到kafka，在这一过程中所需要的信息都属于元数据信息。\n\n前面说过在配置 bootstrap.servers 参数只需要配置部分 broker节点的地址即可，不需要配置所有的broker节点的地址，因为客户端可以自己发现其他broker节点的地址，这一过程其实也属于元数据相关的更新操作。另外，分区数量以及leader副本的分布都会动态地变化，客户端也需要动态的捕捉这些变化。\n\n元数据是指kafka集群的元数据，这些元数据具体记录了集群中有哪些主题，这些主题有哪些分区，每个分区的leader副本分配在哪一个节点上，follower副本分配在哪些节点上，哪些副本在ar，isr等集合中，集群中有哪些节点，控制器节点是哪一个等信息。\n\n当客户端中没有需要使用的元数据信息时，比如没有指定的主题信息，或者超过 metadata.max.age.ms参数设置的时间没有更新元数据都会引起元数据的更新操作。metadata.max.age.ms参数默认是5分钟。元数据的更新操作是在客户端内部进行的，对客户端的外部使用者不可见。当需要更新元数据时，会先挑选出leastloadednode，然后向这个node发送metadatarequest请求来获取具体的元数据信息。这个更新操作是由sender线程发起的，在创建完metadatarequest之后同样会存入inflightrequests。\n\n元数据虽然由sender线程更新，但是主线程也需要读取这些信息，这里的数据同步通过synchronized和final关键字来保障。\n\n----------------------------------------\n\n\n# 3.重要的生产者参数\n\n在kafkaproducer中，除了3个默认的客户端参数，大部分的参数都有合理的默认值，一般不需要修改它们。不过了解这些参数可以让我们更合理地使用生产者客户端，\n\n 1. acks\n\n这个参数**用来指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。**acks是生产者客户端中一个非常重要的参数，它涉及消息的可靠性和吞吐量之间的权衡。acks参数有3种类型的值(都是字符串类型)。\n\n * acks=1。默认值即为1。生产者发送消息之后，只要分区的leader副本成功写入消息，那么它就会收到来自服务端的成功响应。如果消息无法写入 leader副本，比如在 leader副本崩溃、重新选举新的leader副本的过程中，那么生产者就会收到一个错误的响应，为了避免消息丢失，生产者可以选择重发消息。如果消息写入leader副本并返回成功响应给生产者，且在被其他follower副本拉取之前leader副本崩溃，那么此时消息还是会丢失，因为新选举的leader副本中并没有这条对应的消息。acks设置为1，是消息可靠性和吞吐量之间的折中方案。\n * acks =0。**生产者发送消息之后不需要等待任何服务端的响应。**如果在消息从发送到写入kafka的过程中出现某些异常，导致kafka并没有收到这条消息，那么生产者也无从得知，消息也就丢失了。在其他配置环境相同的情况下，acks设置为0可以达到最大的吞吐量。\n * acks =-1或acks =all。生产者在消息发送之后，**需要等待isr中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应。**在其他配置环境相同的情况下， acks 设置为-1(all)可以达到最强的可靠性。但这并不意味着消息就一定可靠，因为isr中可能只有leader副本，这样就退化成了acks=1的情况。要获得更高的消息可靠性需要配合min.insync.replicas等参数的联动。\n\n**acks 参数配置的值是一个字符串类型，而不是整数类型。**举个例子，将acks参数设置为0，需要采用下面这种形式:\n\nprops.put(producerconfig.acks_config,"0");\n\n\n1\n\n 2. max.request.size\n\n这个参数用来限制生产者客户端能发送的消息的最大值，默认值为1mb。\n\n一般情况下,这个默认值就可以满足大多数的应用场景了。不建议盲目地增大这个参数的配置值，因为这个参数还涉及一些其他参数的联动，比如broker端的message.max.bytes参数，如果配置错误可能会引起一些不必要的异常。\n\n 3. retries 和 retry.backoff.ms\n\nretries 参数用来配置生产者重试的次数，默认值为0，即在发生异常的时候不进行任何重试动作。消息在从生产者发出到成功写入服务器之前可能发生一些临时性的异常，比如网络抖动、leader副本的选举等，这种异常往往是可以自行恢复的，生产者可以通过配置retries大于0的值，以此通过内部重试来恢复而不是一味地将异常抛给生产者的应用程序。如果重试达到设定的次数，那么生产者就会放弃重试并返回异常。不过并不是所有的异常都是可以通过重试来解决的，比如消息太大，超过max.request.size参数配置的值时，这种方式就不可行了。\n\n重试还和另一个参数retry.backoff.ms有关，这个参数的默认值为100,它用来设定两次重试之间的时间间隔，避免无效的频繁重试。在配置retries 和 retry.backoff.ms之前，最好先估算一下可能的异常恢复时间，这样可以设定总的重试时间大于这个异常恢复时间，以此来避免生产者过早地放弃重试。\n\nkafka可以保证同一个分区中的消息是有序的。如果生产者按照一定的顺序发送消息，那么这些消息也会顺序地写入分区，进而消费者也可以按照同样的顺序消费它们。\n\n如果将 retries参数配置为非零值，并且max.in.flight.requests.per.connection参数配置为大于1的值，那么就会出现错序的现象:如果第一批次消息写入失败，而第二批次消息写入成功，那么生产者会重试发送第一批次的消息，此时如果第一批次的消息写入成功，那么这两个批次的消息就出现了错序。一般而言，在需要保证消息顺序的场合建议把参数 max.in.flight.requests .per.connection配置为1，而不是把retries 配置为0，不过这样也会影响整体的吞吐。\n\n 4. compression.type\n\n这个参数**用来指定消息的压缩方式，默认值为“none”，即默认情况下，消息不会被压缩。**该参数还可以配置为“gzip”“snappy”和“lz4”。对消息进行压缩可以极大地减少网络传输量、降低网络i/o，从而提高整体的性能。消息压缩是一种使用时间换空间的优化方式，如果对时延有一定的要求，则不推荐对消息进行压缩。\n\n 5. connections.max.idle.ms\n\n这个参数用来指定在多久之后关闭闲置的连接，默认值是540000(ms)，即9分钟。\n\n 6. linger.ms\n\n这个参数用来指定生产者发送producerbatch之前等待更多消息(producerrecord)加入 producerbatch的时间，默认值为0。生产者客户端会在producerbatch被填满或等待时间超过 linger.ms 值时发送出去。(增大这个参数的值会增加消息的延迟，但是同时能提升一定的吞吐量。)\n\n 7. receive.buffer.bytes\n\n这个参数用来设置socket接收消息缓冲区(so_recbuf)的大小，默认值为32kb。如果设置为-1，则使用操作系统的默认值。如果producer与kafka处于不同的机房，则可以适地调大这个参数值。\n\n 8. send.buffer.bytes\n\n这个参数用来设置socket发送消息缓冲区(so_sndbuf)的大小，默认值为128kb。 与receive.buffer.bytes参数一样，如果设置为-1，则使用操作系统的默认值。\n\n 9. request.timeout.ms\n\n这个参数**用来配置 producer等待请求响应的最长时间，默认值为30000(ms)。**请求超时之后可以选择进行重试。注意这个参数需要比broker端参数replica.lag.time.max.ms的值要大，这样可以减少因客户端重试而引起的消息重复的概率。\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"消费者-消费者&消费者组",frontmatter:{title:"消费者-消费者&消费者组",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"消费者-消费者&消费者组",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/c4ec1b4a-45f6-3fd7-8faf-7af762dfb0ed/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/4.%E6%B6%88%E8%B4%B9%E8%80%85-%E6%B6%88%E8%B4%B9%E8%80%85&%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84.html",relativePath:"03.消息队列/00.Kafka/4.消费者-消费者&消费者组.md",key:"v-060d414d",path:"/pages/c4ec1b4a-45f6-3fd7-8faf-7af762dfb0ed/",headersStr:null,content:"应用程序可以通过KafkaConsumer来订阅主题，并从订阅的主题中拉取消息。\n\n----------------------------------------\n\n消费者负责订阅kafka中的Topic，并且从订阅的Topic上拉取消息。与其他一些消息中间件不同的是：在kafka的消费理念中还有一层消费组的概念，每个消费者都有一个对应的消费组。当消息发布到Topic后，只会被投递给订阅它的每个消费组中的一个消费者。\n\n\n\n如上图所示，某个Topic有4个分区，有两个消费组A和B都订阅了这个Topic，消费组A有4个消费者，消费组B有两个消费者。按照Kafka默认的规则，最后的分配结果是消费组A中每一个消费者分配到一个分区，消费组B中每一个消费者分配到两个分区，两个消费组之间互不影响。每个消费者只能消费到所分配的分区中的消息。或者说：每一个分区只能被一个消费组中的一个消费者所消费。\n\n当消费组内的消费者个数发生变化时，所对应的分区分配的演变：\n\n假设目前某消费组内只有一个消费者C0，订阅了一个Topic，这个Topic包含7个分区：P0~P6。也就是说，这个消费者C0订阅了7个分区。\n\n此时消费组内又加入一个新的消费者C1，按照既定的逻辑，需要将C0的部分分区分配给消费者C1消费，分配之后C0消费P0到P3,C1消费P4到P6。C0和C1各自负责消费所分配到的分区，彼此之间并无逻辑上的干扰。\n\n紧接着消费组内又加入了一个新的消费者C2，消费者C0和C1将各自消费的部分分区分配给消费者C2，三者各自消费所分配到的分区。\n\n消费者与消费者组这种模型可以让整体的消费能力具备横向伸缩性，可以通过增加或者减少消费者个数来提高或者降低整体的消费能力。对于分区数固定的情况，一味的增加消费者并不会让消费能力一直得到提升，如果消费者过多，出现了消费者的个数大于分区个数的情况，就会有消费者分配不到任何分区。比如一个组内有8个消费者，但是Topic只有7个分区，那么将有一台消费者分配不到任何分区而无法消费任何消息。\n\n以上分配逻辑都是基于默认的分区分配策略进行分析的，可以通过消费者客户端参数partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。\n\n对于消息中间件而言，一般有两种消息投递模式:点对点 (P2P，Point-to-Point)模式和发布/订阅 (Pub/Sub)模式。点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。发布订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题 (Topic)，主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布/订阅模式在消息的一对多广播时采用。Kafka同时支持两种消息投递模式，而这正是得益于消费者与消费组模型的契合:\n\n * 如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。\n * 如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。\n\n消费组是一个逻辑上的概念，它将旗下的消费者归为一类，每一个消费者只隶属于一个消费组。每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，这个可以通过消费者客户端参数group.id来配置，默认值为空字符串。\n\n消费者并非逻辑上的概念，它是实际的应用实例，它可以是一个线程，也可以是一个进程。同一个消费组内的消费者既可以部署在同一台机器上，也可以部署在不同的机器上。\n\n----------------------------------------",normalizedContent:"应用程序可以通过kafkaconsumer来订阅主题，并从订阅的主题中拉取消息。\n\n----------------------------------------\n\n消费者负责订阅kafka中的topic，并且从订阅的topic上拉取消息。与其他一些消息中间件不同的是：在kafka的消费理念中还有一层消费组的概念，每个消费者都有一个对应的消费组。当消息发布到topic后，只会被投递给订阅它的每个消费组中的一个消费者。\n\n\n\n如上图所示，某个topic有4个分区，有两个消费组a和b都订阅了这个topic，消费组a有4个消费者，消费组b有两个消费者。按照kafka默认的规则，最后的分配结果是消费组a中每一个消费者分配到一个分区，消费组b中每一个消费者分配到两个分区，两个消费组之间互不影响。每个消费者只能消费到所分配的分区中的消息。或者说：每一个分区只能被一个消费组中的一个消费者所消费。\n\n当消费组内的消费者个数发生变化时，所对应的分区分配的演变：\n\n假设目前某消费组内只有一个消费者c0，订阅了一个topic，这个topic包含7个分区：p0~p6。也就是说，这个消费者c0订阅了7个分区。\n\n此时消费组内又加入一个新的消费者c1，按照既定的逻辑，需要将c0的部分分区分配给消费者c1消费，分配之后c0消费p0到p3,c1消费p4到p6。c0和c1各自负责消费所分配到的分区，彼此之间并无逻辑上的干扰。\n\n紧接着消费组内又加入了一个新的消费者c2，消费者c0和c1将各自消费的部分分区分配给消费者c2，三者各自消费所分配到的分区。\n\n消费者与消费者组这种模型可以让整体的消费能力具备横向伸缩性，可以通过增加或者减少消费者个数来提高或者降低整体的消费能力。对于分区数固定的情况，一味的增加消费者并不会让消费能力一直得到提升，如果消费者过多，出现了消费者的个数大于分区个数的情况，就会有消费者分配不到任何分区。比如一个组内有8个消费者，但是topic只有7个分区，那么将有一台消费者分配不到任何分区而无法消费任何消息。\n\n以上分配逻辑都是基于默认的分区分配策略进行分析的，可以通过消费者客户端参数partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。\n\n对于消息中间件而言，一般有两种消息投递模式:点对点 (p2p，point-to-point)模式和发布/订阅 (pub/sub)模式。点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。发布订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题 (topic)，主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布/订阅模式在消息的一对多广播时采用。kafka同时支持两种消息投递模式，而这正是得益于消费者与消费组模型的契合:\n\n * 如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。\n * 如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。\n\n消费组是一个逻辑上的概念，它将旗下的消费者归为一类，每一个消费者只隶属于一个消费组。每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，这个可以通过消费者客户端参数group.id来配置，默认值为空字符串。\n\n消费者并非逻辑上的概念，它是实际的应用实例，它可以是一个线程，也可以是一个进程。同一个消费组内的消费者既可以部署在同一台机器上，也可以部署在不同的机器上。\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"消费者-客户端开发-消费逻辑",frontmatter:{title:"消费者-客户端开发-消费逻辑",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"消费者-客户端开发-消费逻辑",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/6a99e6af-7333-3944-94f1-6a8a3a84a946/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/5.%E6%B6%88%E8%B4%B9%E8%80%85-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BC%80%E5%8F%91-%E6%B6%88%E8%B4%B9%E9%80%BB%E8%BE%91.html",relativePath:"03.消息队列/00.Kafka/5.消费者-客户端开发-消费逻辑.md",key:"v-25d46bba",path:"/pages/6a99e6af-7333-3944-94f1-6a8a3a84a946/",headers:[{level:2,title:"1.必要的参数配置",slug:"_1-必要的参数配置",normalizedTitle:"1.必要的参数配置",charIndex:985},{level:2,title:"2.订阅主题&分区",slug:"_2-订阅主题-分区",normalizedTitle:"2.订阅主题&amp;分区",charIndex:null},{level:2,title:"3.反序列化",slug:"_3-反序列化",normalizedTitle:"3.反序列化",charIndex:5593},{level:2,title:"4.消息消费",slug:"_4-消息消费",normalizedTitle:"4.消息消费",charIndex:7706},{level:2,title:"5.控制或关闭消费",slug:"_5-控制或关闭消费",normalizedTitle:"5.控制或关闭消费",charIndex:11219}],headersStr:"1.必要的参数配置 2.订阅主题&分区 3.反序列化 4.消息消费 5.控制或关闭消费",content:'一个正常的消费逻辑需要具备以下几个步骤:\n\n 1. 配置消费者客户端参数及创建相应的消费者实例。\n 2. 订阅主题。\n 3. 拉取消息并消费。\n 4. 提交消费位点。\n 5. 关闭消费者实例。\n\n  public static void consume(){\n        Properties props=new Properties();\n        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,brokerList);\n        props.put(ConsumerConfig.GROUP_ID_CONFIG,groupName);\n        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());\n        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());\n\n        KafkaConsumer<String, String> consumer=new KafkaConsumer<>(props);\n        consumer.subscribe(Collections.singletonList(topicName));\n\n        while(true){\n        ConsumerRecords<String, String> records=consumer.poll(Duration.ofMillis(100));\n        records.forEach(record->System.out.println("Received message: key = "+record.key()+", value = "+record.value()));\n        }\n        }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n----------------------------------------\n\n\n# 1.必要的参数配置\n\n在kafka消费者客户端中有4个参数是必填的。\n\n * bootstrap.servers:该参数的释义和生产者客户端中的相同，用来指定连接Kafka集群所需的broker地址清单，具体内容形式为host1: port1，host2:port2 ，可以设置一个或多个地址，中间用逗号隔开，此参数的默认值为""。注意这里并非需要设置集群中全部的broker地址，消费者会从现有的配置中查找到全部的Kafka集群成员。这里设置两个以上的broker地址信息，当其中任意一个宕机时，消费者仍然可以连接到Kafka集群上。\n * group.id：消费者隶属的消费组的名称，默认值为""。如果设置为空，则会报出异常。一般而言，这个参数需要设置成具有一定的业务意义的名称。\n * key.deserializer和value.deserializer：与生产者客户端中的key.serializer和value.serializer参数对应.消费者从broker端获取的消息格式都是字节数组(byte[)类型，所以需要执行相应的反序列化操作才能还原成原有的对象格式。这两个参数分别用来指定消息中key和value所需反序列化操作的反序列化器，这两个参数无默认值。 这里必须填写反序列化器类的全限定名，比如示例中的org.apache.kafka.common.serialization.StringDeserializer，单单指定字符串解串器是错误的。\n * client.id：这个参数用来设定Kafka消费者对应的客户端id，默认值也为""。如果客户端不设置，则Kafka消费者会自动生成一个非空字符串，内容形式如"consumer-1""consumer-2"，即字符串"consumer-"与数字的拼接。\n\n> 开发中设置配置推荐使用类ConsumerConfig。\n\n在配置完必要的参数之后，我们就可以利用它来创建一个消费者实例了。\n\n----------------------------------------\n\n\n# 2.订阅主题&分区\n\n在创建好消费者之后，就需要为该消费者订阅相关的主题了。一个消费者可以订阅一个或多个主题，前面的代码中我们使用subscribe方法订阅了一个主题，对于这个方法而言,既可以以集合的形式订阅多个主题，也可以以正则表达式的形式订阅特定模式的主题。subscribe的几个重载方法如下:\n\n        void subscribe(Collection<String> topics);\n\n\n        void subscribe(Collection<String> topics,ConsumerRebalanceListener callback);\n\n\n        void subscribe(Pattern pattern,ConsumerRebalanceListener callback);\n\n\n        void subscribe(Pattern pattern);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n如果前后两次订阅了不同的主题，那么消费者以最后一次的为准。\n\nconsumer.subscribe(Arrays.asList(topicl));\nconsumer.subscribe(Arrays.asList(topic2));\n\n\n1\n2\n\n\n上面的示例中，最终消费者订阅的是 topic2，而不是 topicl,也不是 topicl 和 topic2 的并集。\n\n如果消费者采用的是正则表达式的方式(subscribe(Pattern))订阅，在之后的过程中，如果有人又创建了新的主题，并且主题的名字与正则表达式相匹配，那么这个消费者就可以消费到新添加的主题中的消息。\n\n> 在 subscribe的重载方法中有一个参数类型是 ConsumerRebalanceListener，这个是用来设置相应的再均衡监听器的。\n\n消费者不仅可以通过KafkaConsumer.subscribe()方法订阅主题，还可以直接订阅某些主题特定分区，在 KafkaConsumer中还提供了一个 assign方法来实现这些功能。\n\npublic void assign(Collection<TopicPartition> partitions)\n\n\n1\n\n\n这个方法只接受一个参数 partitions，用来指定需要订阅的分区集合。这里补充说明一下 TopicPartition 类，在 Kafka 的客户端中，它用来表示分区。\n\npublic final class TopicPartition implements Serializable {\n    private static final long serialVersionUID = -613627415771699627L;\n\n    private int hash = 0;\n    private final int partition;\n    private final String topic;\n\n    public TopicPartition(String topic, int partition) {\n        this.partition = partition;\n        this.topic = topic;\n    }\n\n    public int partition() {\n        return partition;\n    }\n\n    public String topic() {\n        return topic;\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\nTopicPartition 类只有 2 个属性:topic 和partition，分别代表分区所属的主题和自身的分区编号，这个类可以和我们通常所说的主题一分区的概念映射起来。\n\n我们将前面代码中的 subscribe方法修改为 assign 方法，这里只订阅 topic-demo 主题中分区编号为 0 的分区，相关代码如下:\n\nconsumer.assign(Arrays.asList(new TopicPartition("topic-demo",0)));\n\n\n1\n\n\n如果我们事先并不知道主题中有多少个分区怎么办?KafkaConsumer中的partitionsFor方法可以用来查询指定主题的元数据信息，partitionsFor方法的具体定义如下:\n\npublic List<PartitionInfo> partitionsFor(String topic)\n\n\n1\n\n\n其中 PartitionInfo 类型即为主题的分区元数据信息，此类的主要结构如下:\n\npublic class PartitionInfo {\n    private final String topic; //主题\n    private final int partition; //分区\n    private final Node leader; //leader 所在的broker节点\n    private final Node[] replicas; // AR\n    private final Node[] inSyncReplicas; //ISR\n    private final Node[] offlineReplicas; // OSR\n    //省略部分内容...\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n通过 partitionsFor方法的协助，我们可以通过 assign方法来实现订阅主题 (全部分区)的功能。\n\n    List<TopicPartition> partitions=new ArrayList<> 0);\n        List<PartitionInfo> partitionInfos=consumer.partitionsFor(topic);\n        if(partitionInfos!=null){\n        partitionInfos.stream().map(tpInfo->new TopicPartition(tpInfo.topic(),tpInfo.partition())).forEach(partitions::add);\n        }\n        consumer.assign(partitions);\n\n\n1\n2\n3\n4\n5\n6\n\n\n可以使用 KafkaConsumer 中的 unsubscribe方法来取消主题的订阅。这个方法既可以取消通过 subscribe(Collection)方式实现的订阅，也可以取消通过subscribe(Pattern)方式实现的订阅，还可以取消通过 assign(Collection)方式实现的订阅。\n\nconsumer.unsubscribe();\n\n\n1\n\n\n如果将subscribe(Collection)或 assign(Collection)中的集合参数设置为空集合，那么作用等同于 unsubscribe()方法。\n\nconsumer.unsubscribe();\n        consumer.subscribe(new ArrayList<String>());\n        consumer.assign(new ArrayList<TopicPartition>());\n\n\n1\n2\n3\n\n\n如果没有订阅任何主题或分区，那么再继续执行消费程序的时候会报出IllegalStateException异常。\n\n集合订阅的方式subscribe(Collection)、正则表达式订阅的方式 subscribe(Pattern)和指定分区的订阅方式 assign(Collection)分表代表了三种不同的订阅状态:AUTO TOPICS、AUTO PATTERN和 USER ASSIGNED(如果没有订阅，那么订阅状态为NONE)。然而这三种状态是互斥的，在一个消费者中只能使用其中的一种，否则会报出IlegalStateException异常。\n\n通过 subscribe方法订阅主题具有消费者自动再平衡的功能，在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当消费组内的消费者增加或减少时,分区分配关系会自动调整，以实现消费负载均衡及故障自动转移。而通过assign方法订阅分区时，是不具备消费者自动均衡的功能的，其实这一点从 assign方法的参数中就可以看出端倪,两种类型的subscribe都有ConsumerRebalanceListener类型参数的方法,而assign方法却没有。\n\n----------------------------------------\n\n\n# 3.反序列化\n\nKafkaProducer有对应的序列化器，那么与此对应的KafkaConsumer就会有反序列化器。Kafka所提供的反序列化器有 ByteArrayDeserializer ByteBufferDeserializer BytesDeserializer DoubleDeserializer FloatDeserializer IntegerDeserializer ListDeserializer LongDeserializer ShortDeserializer StringDeserializer UUIDDeserializer VoidDeserializer，这些序列化器也都实现了Deserializer接口，与KafkaProducer中提及的Serializer接口一样，Deserializer接口也有三个方法。\n\npublic interface Deserializer<T> extends Closeable {\n    //用来配置当前类\n    void configure(Map<String, ?> configs, boolean isKey);\n\n    //如果data为null，那么处理的时候直接返回null而不是抛出一个异常。\n    T deserialize(String topic, byte[] data);\n\n    //用来关闭当前序列化器。\n    void close();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n以StringDeserializer为例分析反序列化器的具体实现。\n\npublic class StringDeserializer implements Deserializer<String> {\n    private String encoding = "UTF8";\n\n    @Override\n    public void configure(Map<String, ?> configs, boolean isKey) {\n        String propertyName = isKey ? "key.deserializer.encoding" : "value.deserializer.encoding";\n        Object encodingValue = configs.get(propertyName);\n        if (encodingValue == null)\n            encodingValue = configs.get("deserializer.encoding");\n        if (encodingValue instanceof String)\n            encoding = (String) encodingValue;\n    }\n\n    @Override\n    public String deserialize(String topic, byte[] data) {\n        try {\n            if (data == null)\n                return null;\n            else\n                return new String(data, encoding);\n        } catch (UnsupportedEncodingException e) {\n            throw new SerializationException("Error when deserializing byte[] to string due to unsupported encoding " + encoding);\n        }\n    }\n\n    @Override\n    public void close() {\n        // nothing to do\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\nconfigure方法主要是做字符编码的配置。deserialize方法就是简单的把字节数组转化成字符串，如果为空的时候并不会抛出异常，而是返回null。\n\n另外我们还可以自定义反序列化器，主要有两个步骤：自定义反序列化器和指定自定义的反序列化器。不建议使用自定义的序列化和反序列化器，这样会增加生产者和消费者之间的耦合。在Kafka提供的序列化器和反序列化器满足不了当前应用程序的需求前提下，推荐使用 Avro JSON Thrift ProtoBuf 或 Protostuff等通用的序列化工具来包装。\n\n----------------------------------------\n\n\n# 4.消息消费\n\nKafka中的消息是基于拉模式的。消息的消费一般有两种模式：推模式和拉模式。推模式是服务端主动将消息推送给消费者，而拉模式是消费者主动向服务端发起请求来拉取消息。\n\nKafka中的消息消费是一个不断轮询的过程，消费者所要做的就是重复的调用poll方法，而poll方法返回的是所订阅的主题/分区上的一组消息。\n\n对于poll方法而言，如果某些分区中没可供消费的消息，那么此分区对应的消息拉取结果就为空；如果订阅的所有分区都没有可供消费的消息，那么poll方法返回为空的消息集合。\n\npublic ConsumerRecords<K, V> poll(final Duration timeout);\n\n\n1\n\n\npoll方法里面还有一个超时时间参数timeout，用来控制poll方法的阻塞时间，在消费者的缓冲区里没有可用数据的时候会发生阻塞。timeout的设置取决于应用程序对响应速度的要求，比如需要在多长时间内将控制权移交给执行轮询的应用线程。可以直接将timeout设置为0，这样poll方法会立刻返回，而不管是否已经拉取到了消息。如果应用线程唯一的工作就是从Kafka中拉取并消费消息，则可以将这个参数设置为Long.MAX_VALUE。\n\n消费者消费到的每条消息的类型为ConsumerRecord，具体的结构如下：\n\npublic class ConsumerRecord<K, V> {\n    public static final long NO_TIMESTAMP = RecordBatch.NO_TIMESTAMP;\n    public static final int NULL_SIZE = -1;\n    public static final int NULL_CHECKSUM = -1;\n\n    private final String topic; //消息所属主题\n    private final int partition; //消息所属分区\n    private final long offset; //当前消息在所属分区的偏移量\n    private final long timestamp; //创建时间或追加到日志文件的时间\n    private final TimestampType timestampType; //\n    private final int serializedKeySize; //\n    private final int serializedValueSize; //\n    private final Headers headers; //消息头\n    private final K key; //键\n    private final V value; //消息体\n\n    private volatile Long checksum; // CRC32的校验值\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n我们在消费消息的时候可以直接对ConsumerRecord中感兴趣的字段进行具体的业务逻辑处理。\n\npoll方法的返回值类型是ConsumerRecords它用来表示一次拉取操作所获得的消息集，内部包含了若干ConsumerRecord，它提供了一个iterator方法来循环遍历消息集内部的消息。\n\n除了上面的方式，我们还可以按照分区维度来进行消费，这一点很重要，在手动提交消费位点的时候特别明显。ConsumerRecords类提供了一个records(TopicPartition)方法来获取消息集中指定分区的消息。\n\npublic List<ConsumerRecord<K, V>>records(TopicPartition partition);\n\n\n1\n\n\n下面的案例是按照分区维度消费消息。\n\nConsumerRecords<String, String> records=consumer.poll(Duration.ofMillis(1000));\n        records.partitions().stream().flatMap(partition->records.records(partition).stream()).map(record->record.partition()+" : "+record.value()).forEach(System.out::println);\n\n\n1\n2\n\n\n上面的ConsumerRecords.partitions()方法用来获取消息集合中的所有分区。在ConsumerRecords类中还提供了按照主题维度进行消费的方法，这个方法是records(TopicPartition)的重载方法。\n\npublic Iterable<ConsumerRecord<K, V>>records(String topic);\n\n\n1\n\n\nConsumerRecords类中并没有提供与partitions方法类似的topics()方法，如果需要按照主题维度来进行消费，那么只能根据消费者订阅主题时的列表来进行逻辑处理。下面的案例演示了如何使用ConsumerRecords的record(String topic)方法。\n\npublic static void consume(){\n        Properties properties=new Properties();\n        properties.put("key.deserializer","org.apache.kafka.common.serialization.StringDeserializer");\n        properties.put("value.deserializer","org.apache.kafka.common.serialization.StringDeserializer");\n        properties.put("bootstrap.servers",brokerList);\n        properties.put("group.id",groupId);\n        KafkaConsumer<String, String> consumer=new KafkaConsumer<>(properties);\n        List<String> topicList=List.of("topic1","topic2");\n        consumer.subscribe(topicList);\n        while(true){\n            ConsumerRecords<String, String> records=consumer.poll(Duration.ofMillis(1000));\n            for(String topic:topicList){\n                for(ConsumerRecord<String, String> record:records.records(topic)){\n                    System.out.println(record.partition()+" : "+record.value());\n                }\n            }\n        }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n在ConsumerRecords类中还提供了几个方法来方便我们对消息集合进行处理：count()方法返回消息集中的消息个数，返回类型为int；isEmpty()方法用来判断消息集合是否为空，返回类型是boolean；empty()方法用来获取一个空的消息集合，返回类型为ConsumerRecords<K,V>。\n\n截止目前，可以简单的认为poll()方法只是拉取一下消息而已，实际上它的内部涉及消费位点，消费者协调器，组协调器，消费者的选举，分区分配的分发，再均衡的逻辑，心跳等内容。\n\n----------------------------------------\n\n\n# 5.控制或关闭消费\n\nKafkaConsumer提供了对消费速度进行控制的方法，在某些场景下我们可能需要临时暂停某些分区的消费而先消费其他分区，当达到一定条件的时候再恢复这些分区的消费。KafkaConsumer中使用 pause()和 resume() 方法来分别实现暂停某些分区在拉取操作时返回数据给客户端和恢复某些分区向客户端返回数据的操作。\n\n    void pause(Collection<TopicPartition> partitions);\n\n    void resume(Collection<TopicPartition> partitions);\n\n\n1\n2\n3\n\n\nKafkaConsumer 还提供了一个无参的 paused0方法来返回被暂停的分区集合。\n\nSet<TopicPartition> paused();\n\n\n1\n\n\n如何优雅的退出消费？\n\n 1. 使用while(isRunning.get())的方式，这样可以通过在其他地方设定isRunning.set(false)来退出 while 循环。\n 2. 调用 KafkaConsumer 的 wakeup()方法，wakeup()方法是 KafkaConsumer 中唯一可以从其他线程里安全调用的方法(KafkaConsumer 是非线程安全的)，调用 wakeup()方法后可以退出 pol1()的逻辑,并抛出 WakeupException的异常，我们也不需要处理WakeupException 的异常，它只是一种跳出循环的方式。\n\n> 跳出循环以后一定要显式地执行关闭动作以释放运行过程中占用的各种系统资源，包括内存资源、Socket 连接等。\n\n对于close()方法，可以指定一个超时参数，如果使用无参的方法，默认的最长等待时间是30s，超过这个时间后会强制退出。\n\n----------------------------------------',normalizedContent:'一个正常的消费逻辑需要具备以下几个步骤:\n\n 1. 配置消费者客户端参数及创建相应的消费者实例。\n 2. 订阅主题。\n 3. 拉取消息并消费。\n 4. 提交消费位点。\n 5. 关闭消费者实例。\n\n  public static void consume(){\n        properties props=new properties();\n        props.put(consumerconfig.bootstrap_servers_config,brokerlist);\n        props.put(consumerconfig.group_id_config,groupname);\n        props.put(consumerconfig.key_deserializer_class_config,stringdeserializer.class.getname());\n        props.put(consumerconfig.value_deserializer_class_config,stringdeserializer.class.getname());\n\n        kafkaconsumer<string, string> consumer=new kafkaconsumer<>(props);\n        consumer.subscribe(collections.singletonlist(topicname));\n\n        while(true){\n        consumerrecords<string, string> records=consumer.poll(duration.ofmillis(100));\n        records.foreach(record->system.out.println("received message: key = "+record.key()+", value = "+record.value()));\n        }\n        }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n----------------------------------------\n\n\n# 1.必要的参数配置\n\n在kafka消费者客户端中有4个参数是必填的。\n\n * bootstrap.servers:该参数的释义和生产者客户端中的相同，用来指定连接kafka集群所需的broker地址清单，具体内容形式为host1: port1，host2:port2 ，可以设置一个或多个地址，中间用逗号隔开，此参数的默认值为""。注意这里并非需要设置集群中全部的broker地址，消费者会从现有的配置中查找到全部的kafka集群成员。这里设置两个以上的broker地址信息，当其中任意一个宕机时，消费者仍然可以连接到kafka集群上。\n * group.id：消费者隶属的消费组的名称，默认值为""。如果设置为空，则会报出异常。一般而言，这个参数需要设置成具有一定的业务意义的名称。\n * key.deserializer和value.deserializer：与生产者客户端中的key.serializer和value.serializer参数对应.消费者从broker端获取的消息格式都是字节数组(byte[)类型，所以需要执行相应的反序列化操作才能还原成原有的对象格式。这两个参数分别用来指定消息中key和value所需反序列化操作的反序列化器，这两个参数无默认值。 这里必须填写反序列化器类的全限定名，比如示例中的org.apache.kafka.common.serialization.stringdeserializer，单单指定字符串解串器是错误的。\n * client.id：这个参数用来设定kafka消费者对应的客户端id，默认值也为""。如果客户端不设置，则kafka消费者会自动生成一个非空字符串，内容形式如"consumer-1""consumer-2"，即字符串"consumer-"与数字的拼接。\n\n> 开发中设置配置推荐使用类consumerconfig。\n\n在配置完必要的参数之后，我们就可以利用它来创建一个消费者实例了。\n\n----------------------------------------\n\n\n# 2.订阅主题&分区\n\n在创建好消费者之后，就需要为该消费者订阅相关的主题了。一个消费者可以订阅一个或多个主题，前面的代码中我们使用subscribe方法订阅了一个主题，对于这个方法而言,既可以以集合的形式订阅多个主题，也可以以正则表达式的形式订阅特定模式的主题。subscribe的几个重载方法如下:\n\n        void subscribe(collection<string> topics);\n\n\n        void subscribe(collection<string> topics,consumerrebalancelistener callback);\n\n\n        void subscribe(pattern pattern,consumerrebalancelistener callback);\n\n\n        void subscribe(pattern pattern);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n如果前后两次订阅了不同的主题，那么消费者以最后一次的为准。\n\nconsumer.subscribe(arrays.aslist(topicl));\nconsumer.subscribe(arrays.aslist(topic2));\n\n\n1\n2\n\n\n上面的示例中，最终消费者订阅的是 topic2，而不是 topicl,也不是 topicl 和 topic2 的并集。\n\n如果消费者采用的是正则表达式的方式(subscribe(pattern))订阅，在之后的过程中，如果有人又创建了新的主题，并且主题的名字与正则表达式相匹配，那么这个消费者就可以消费到新添加的主题中的消息。\n\n> 在 subscribe的重载方法中有一个参数类型是 consumerrebalancelistener，这个是用来设置相应的再均衡监听器的。\n\n消费者不仅可以通过kafkaconsumer.subscribe()方法订阅主题，还可以直接订阅某些主题特定分区，在 kafkaconsumer中还提供了一个 assign方法来实现这些功能。\n\npublic void assign(collection<topicpartition> partitions)\n\n\n1\n\n\n这个方法只接受一个参数 partitions，用来指定需要订阅的分区集合。这里补充说明一下 topicpartition 类，在 kafka 的客户端中，它用来表示分区。\n\npublic final class topicpartition implements serializable {\n    private static final long serialversionuid = -613627415771699627l;\n\n    private int hash = 0;\n    private final int partition;\n    private final string topic;\n\n    public topicpartition(string topic, int partition) {\n        this.partition = partition;\n        this.topic = topic;\n    }\n\n    public int partition() {\n        return partition;\n    }\n\n    public string topic() {\n        return topic;\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\ntopicpartition 类只有 2 个属性:topic 和partition，分别代表分区所属的主题和自身的分区编号，这个类可以和我们通常所说的主题一分区的概念映射起来。\n\n我们将前面代码中的 subscribe方法修改为 assign 方法，这里只订阅 topic-demo 主题中分区编号为 0 的分区，相关代码如下:\n\nconsumer.assign(arrays.aslist(new topicpartition("topic-demo",0)));\n\n\n1\n\n\n如果我们事先并不知道主题中有多少个分区怎么办?kafkaconsumer中的partitionsfor方法可以用来查询指定主题的元数据信息，partitionsfor方法的具体定义如下:\n\npublic list<partitioninfo> partitionsfor(string topic)\n\n\n1\n\n\n其中 partitioninfo 类型即为主题的分区元数据信息，此类的主要结构如下:\n\npublic class partitioninfo {\n    private final string topic; //主题\n    private final int partition; //分区\n    private final node leader; //leader 所在的broker节点\n    private final node[] replicas; // ar\n    private final node[] insyncreplicas; //isr\n    private final node[] offlinereplicas; // osr\n    //省略部分内容...\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n通过 partitionsfor方法的协助，我们可以通过 assign方法来实现订阅主题 (全部分区)的功能。\n\n    list<topicpartition> partitions=new arraylist<> 0);\n        list<partitioninfo> partitioninfos=consumer.partitionsfor(topic);\n        if(partitioninfos!=null){\n        partitioninfos.stream().map(tpinfo->new topicpartition(tpinfo.topic(),tpinfo.partition())).foreach(partitions::add);\n        }\n        consumer.assign(partitions);\n\n\n1\n2\n3\n4\n5\n6\n\n\n可以使用 kafkaconsumer 中的 unsubscribe方法来取消主题的订阅。这个方法既可以取消通过 subscribe(collection)方式实现的订阅，也可以取消通过subscribe(pattern)方式实现的订阅，还可以取消通过 assign(collection)方式实现的订阅。\n\nconsumer.unsubscribe();\n\n\n1\n\n\n如果将subscribe(collection)或 assign(collection)中的集合参数设置为空集合，那么作用等同于 unsubscribe()方法。\n\nconsumer.unsubscribe();\n        consumer.subscribe(new arraylist<string>());\n        consumer.assign(new arraylist<topicpartition>());\n\n\n1\n2\n3\n\n\n如果没有订阅任何主题或分区，那么再继续执行消费程序的时候会报出illegalstateexception异常。\n\n集合订阅的方式subscribe(collection)、正则表达式订阅的方式 subscribe(pattern)和指定分区的订阅方式 assign(collection)分表代表了三种不同的订阅状态:auto topics、auto pattern和 user assigned(如果没有订阅，那么订阅状态为none)。然而这三种状态是互斥的，在一个消费者中只能使用其中的一种，否则会报出ilegalstateexception异常。\n\n通过 subscribe方法订阅主题具有消费者自动再平衡的功能，在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当消费组内的消费者增加或减少时,分区分配关系会自动调整，以实现消费负载均衡及故障自动转移。而通过assign方法订阅分区时，是不具备消费者自动均衡的功能的，其实这一点从 assign方法的参数中就可以看出端倪,两种类型的subscribe都有consumerrebalancelistener类型参数的方法,而assign方法却没有。\n\n----------------------------------------\n\n\n# 3.反序列化\n\nkafkaproducer有对应的序列化器，那么与此对应的kafkaconsumer就会有反序列化器。kafka所提供的反序列化器有 bytearraydeserializer bytebufferdeserializer bytesdeserializer doubledeserializer floatdeserializer integerdeserializer listdeserializer longdeserializer shortdeserializer stringdeserializer uuiddeserializer voiddeserializer，这些序列化器也都实现了deserializer接口，与kafkaproducer中提及的serializer接口一样，deserializer接口也有三个方法。\n\npublic interface deserializer<t> extends closeable {\n    //用来配置当前类\n    void configure(map<string, ?> configs, boolean iskey);\n\n    //如果data为null，那么处理的时候直接返回null而不是抛出一个异常。\n    t deserialize(string topic, byte[] data);\n\n    //用来关闭当前序列化器。\n    void close();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n以stringdeserializer为例分析反序列化器的具体实现。\n\npublic class stringdeserializer implements deserializer<string> {\n    private string encoding = "utf8";\n\n    @override\n    public void configure(map<string, ?> configs, boolean iskey) {\n        string propertyname = iskey ? "key.deserializer.encoding" : "value.deserializer.encoding";\n        object encodingvalue = configs.get(propertyname);\n        if (encodingvalue == null)\n            encodingvalue = configs.get("deserializer.encoding");\n        if (encodingvalue instanceof string)\n            encoding = (string) encodingvalue;\n    }\n\n    @override\n    public string deserialize(string topic, byte[] data) {\n        try {\n            if (data == null)\n                return null;\n            else\n                return new string(data, encoding);\n        } catch (unsupportedencodingexception e) {\n            throw new serializationexception("error when deserializing byte[] to string due to unsupported encoding " + encoding);\n        }\n    }\n\n    @override\n    public void close() {\n        // nothing to do\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\nconfigure方法主要是做字符编码的配置。deserialize方法就是简单的把字节数组转化成字符串，如果为空的时候并不会抛出异常，而是返回null。\n\n另外我们还可以自定义反序列化器，主要有两个步骤：自定义反序列化器和指定自定义的反序列化器。不建议使用自定义的序列化和反序列化器，这样会增加生产者和消费者之间的耦合。在kafka提供的序列化器和反序列化器满足不了当前应用程序的需求前提下，推荐使用 avro json thrift protobuf 或 protostuff等通用的序列化工具来包装。\n\n----------------------------------------\n\n\n# 4.消息消费\n\nkafka中的消息是基于拉模式的。消息的消费一般有两种模式：推模式和拉模式。推模式是服务端主动将消息推送给消费者，而拉模式是消费者主动向服务端发起请求来拉取消息。\n\nkafka中的消息消费是一个不断轮询的过程，消费者所要做的就是重复的调用poll方法，而poll方法返回的是所订阅的主题/分区上的一组消息。\n\n对于poll方法而言，如果某些分区中没可供消费的消息，那么此分区对应的消息拉取结果就为空；如果订阅的所有分区都没有可供消费的消息，那么poll方法返回为空的消息集合。\n\npublic consumerrecords<k, v> poll(final duration timeout);\n\n\n1\n\n\npoll方法里面还有一个超时时间参数timeout，用来控制poll方法的阻塞时间，在消费者的缓冲区里没有可用数据的时候会发生阻塞。timeout的设置取决于应用程序对响应速度的要求，比如需要在多长时间内将控制权移交给执行轮询的应用线程。可以直接将timeout设置为0，这样poll方法会立刻返回，而不管是否已经拉取到了消息。如果应用线程唯一的工作就是从kafka中拉取并消费消息，则可以将这个参数设置为long.max_value。\n\n消费者消费到的每条消息的类型为consumerrecord，具体的结构如下：\n\npublic class consumerrecord<k, v> {\n    public static final long no_timestamp = recordbatch.no_timestamp;\n    public static final int null_size = -1;\n    public static final int null_checksum = -1;\n\n    private final string topic; //消息所属主题\n    private final int partition; //消息所属分区\n    private final long offset; //当前消息在所属分区的偏移量\n    private final long timestamp; //创建时间或追加到日志文件的时间\n    private final timestamptype timestamptype; //\n    private final int serializedkeysize; //\n    private final int serializedvaluesize; //\n    private final headers headers; //消息头\n    private final k key; //键\n    private final v value; //消息体\n\n    private volatile long checksum; // crc32的校验值\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n我们在消费消息的时候可以直接对consumerrecord中感兴趣的字段进行具体的业务逻辑处理。\n\npoll方法的返回值类型是consumerrecords它用来表示一次拉取操作所获得的消息集，内部包含了若干consumerrecord，它提供了一个iterator方法来循环遍历消息集内部的消息。\n\n除了上面的方式，我们还可以按照分区维度来进行消费，这一点很重要，在手动提交消费位点的时候特别明显。consumerrecords类提供了一个records(topicpartition)方法来获取消息集中指定分区的消息。\n\npublic list<consumerrecord<k, v>>records(topicpartition partition);\n\n\n1\n\n\n下面的案例是按照分区维度消费消息。\n\nconsumerrecords<string, string> records=consumer.poll(duration.ofmillis(1000));\n        records.partitions().stream().flatmap(partition->records.records(partition).stream()).map(record->record.partition()+" : "+record.value()).foreach(system.out::println);\n\n\n1\n2\n\n\n上面的consumerrecords.partitions()方法用来获取消息集合中的所有分区。在consumerrecords类中还提供了按照主题维度进行消费的方法，这个方法是records(topicpartition)的重载方法。\n\npublic iterable<consumerrecord<k, v>>records(string topic);\n\n\n1\n\n\nconsumerrecords类中并没有提供与partitions方法类似的topics()方法，如果需要按照主题维度来进行消费，那么只能根据消费者订阅主题时的列表来进行逻辑处理。下面的案例演示了如何使用consumerrecords的record(string topic)方法。\n\npublic static void consume(){\n        properties properties=new properties();\n        properties.put("key.deserializer","org.apache.kafka.common.serialization.stringdeserializer");\n        properties.put("value.deserializer","org.apache.kafka.common.serialization.stringdeserializer");\n        properties.put("bootstrap.servers",brokerlist);\n        properties.put("group.id",groupid);\n        kafkaconsumer<string, string> consumer=new kafkaconsumer<>(properties);\n        list<string> topiclist=list.of("topic1","topic2");\n        consumer.subscribe(topiclist);\n        while(true){\n            consumerrecords<string, string> records=consumer.poll(duration.ofmillis(1000));\n            for(string topic:topiclist){\n                for(consumerrecord<string, string> record:records.records(topic)){\n                    system.out.println(record.partition()+" : "+record.value());\n                }\n            }\n        }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n在consumerrecords类中还提供了几个方法来方便我们对消息集合进行处理：count()方法返回消息集中的消息个数，返回类型为int；isempty()方法用来判断消息集合是否为空，返回类型是boolean；empty()方法用来获取一个空的消息集合，返回类型为consumerrecords<k,v>。\n\n截止目前，可以简单的认为poll()方法只是拉取一下消息而已，实际上它的内部涉及消费位点，消费者协调器，组协调器，消费者的选举，分区分配的分发，再均衡的逻辑，心跳等内容。\n\n----------------------------------------\n\n\n# 5.控制或关闭消费\n\nkafkaconsumer提供了对消费速度进行控制的方法，在某些场景下我们可能需要临时暂停某些分区的消费而先消费其他分区，当达到一定条件的时候再恢复这些分区的消费。kafkaconsumer中使用 pause()和 resume() 方法来分别实现暂停某些分区在拉取操作时返回数据给客户端和恢复某些分区向客户端返回数据的操作。\n\n    void pause(collection<topicpartition> partitions);\n\n    void resume(collection<topicpartition> partitions);\n\n\n1\n2\n3\n\n\nkafkaconsumer 还提供了一个无参的 paused0方法来返回被暂停的分区集合。\n\nset<topicpartition> paused();\n\n\n1\n\n\n如何优雅的退出消费？\n\n 1. 使用while(isrunning.get())的方式，这样可以通过在其他地方设定isrunning.set(false)来退出 while 循环。\n 2. 调用 kafkaconsumer 的 wakeup()方法，wakeup()方法是 kafkaconsumer 中唯一可以从其他线程里安全调用的方法(kafkaconsumer 是非线程安全的)，调用 wakeup()方法后可以退出 pol1()的逻辑,并抛出 wakeupexception的异常，我们也不需要处理wakeupexception 的异常，它只是一种跳出循环的方式。\n\n> 跳出循环以后一定要显式地执行关闭动作以释放运行过程中占用的各种系统资源，包括内存资源、socket 连接等。\n\n对于close()方法，可以指定一个超时参数，如果使用无参的方法，默认的最长等待时间是30s，超过这个时间后会强制退出。\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"消费者-客户端开发-位点提交",frontmatter:{title:"消费者-客户端开发-位点提交",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"消费者-客户端开发-位点提交",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/0768d08c-72ff-34e7-aada-50c4eecb08b5/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/6.%E6%B6%88%E8%B4%B9%E8%80%85-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BC%80%E5%8F%91-%E4%BD%8D%E7%82%B9%E6%8F%90%E4%BA%A4.html",relativePath:"03.消息队列/00.Kafka/6.消费者-客户端开发-位点提交.md",key:"v-2880c44a",path:"/pages/0768d08c-72ff-34e7-aada-50c4eecb08b5/",headersStr:null,content:'对于 Kafka 中的分区而言，它的每条消息都有唯一的 offset，用来表示消息在分区中对应的位置。对于消费者而言，它也有一个 offset 的概念，消费者使用 offset来表示消费到分区中某个消息所在的位置。对于消息在分区中的位置，我们将offset称为"偏移量";对于消费者消费到的位置，将 offset 称为"消费位点"。当然，对于一条消息而言，它的偏移量和消费者消费它时的消费位点是相等的。\n\n在每次调用poll方法时，它返回的是还没有被消费过的消息集(当然这个前提是消息已经存储在Kafka中了，并且暂不考虑异常情况的发生)，要做到这一点，就需要记录上一次消费时的消费位点。并且这个消费位点必须做持久化保存，而不是单单保存在内存中，否则消费者重启之后就无法知晓之前的消费位点。再考虑一种情况，当有新的消费者加入时，那么必然会有再均衡的动作，对于同一分区而言，它可能在再均衡动作之后分配给新的消费者，如果不持久化保存消费位点，那么这个新的消费者也无法知晓之前的消费位点。\n\n在旧消费者客户端中，消费位点是存储在 ZooKeeper 中的。而在新消费者客户端中，消费位点存储在Kafka内部的主题 consumer_offsets 中。这里把将消费位点存储起来(持久化)的动作称为"提交"，消费者在消费完消息之后需要执行消费位点的提交。\n\n参考下图的消费位点，x 表示某一次拉取操作中此分区消息的最大偏移量，假设当前消费者已经消费了 x位置的消息，那么我们就可以说消费者的消费位点为x，图中也用了lastConsumedOffset这个单词来标识它。\n\n\n\n当前消费者需要提交的位点不是x，而是x+1，对应于上图中的position，它表示下一条需要拉取的消息的位置。在消费者中还有一个committed offset的概念，他表示已经提交过的消费位点。\n\nKafkaConsumer类提供了position(TopicPartition)和committed(TopicPartition)两个方法来分别获取上面所说的position和committed offset的值。\n\npublic long position(TopicPartition partition);\n\npublic OffsetAndMetadata committed(TopicPartition partition);\n\n\n1\n2\n3\n\n\ncommited offset == position == (lastConsumedOffset + 1)\n\n> position 和 commited offset 并不会一直相同。\n\n位点提交的时机不同，有可能会造成重复消费和消息丢失的现象。\n\n参考下图，当前一次poll操作所拉取的消息集为[x+2,x+7]，x+2 代表上一次提交的消费位点，说明已经完成了 x+1 之前(包括 x+1 在内)的所有消息的消费，x+5 表示当前正在处理的位置，如果拉取到消息之后就进行了位点提交，即提交了 x+8，那么当前消费 x+5 的时候遇到了异常在故障恢复之后，我们重新拉取的消息是从 x+8 开始的。也就是说，x+5 至 x+7之间的消息未能被消费，如此便发生了消息丢失的现象。 再考虑另外一种情形，位点提交的动作是在消费完所有拉取到的消息之后才执行的，那么当消费x+5的时候遇到了异常，在故障恢复之后，我们重新拉取的消息是从x+2 开始的。也就是说，x+2 至 x+4 之间的消息又重新消费了一遍，故而又发生了重复消费的现象。\n\n在 Kafka 中默认的消费位点的提交方式是自动提交，这个由消费者客户端参数enable.auto.commit 配置，默认值为 true。当然这个默认的自动提交不是每消费一条消息就提交一次，而是定期提交，这个定期的周期时间由客户端参数 auto.commit.interval.ms配置，默认值为 5 秒，此参数生效的前提是 enable.auto.commit 参数为true)。\n\n在默认的方式下，消费者每隔 5 秒会将拉取到的每个分区中最大的消费位点进行提交。自动位点提交的动作是在poll方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位点提交，如果可以，那么就会提交上一次轮询的位点。\n\n在Kafka消费的编程逻辑中位点提交是一大难点，自动提交消费位点的方式非常简便，但随之而来的是重复消费和消息丢失的问题。假设刚刚提交完一次消费位点，然后拉取一批消息进行消费，在下一次自动提交消费位点之前，消费者崩溃了，那么又得从上一次位点提交的地方重新开始消费，这样便发生了重复消费的现象。(对于再均衡的情况同样适用)。我们可以通过减小位点提交的时间间隔来减小重复消息的窗口大小，但这样并不能避免重复消费的发生，而且也会使位点提交更加频繁。\n\n通常来讲，自动提交是延时提交，重复消费可以理解，那么消息丢失又是在什么情形下会发生的呢? 如下图，拉取线程A不断地拉取消息并存入本地缓存，比如在 BlockingQucue 中，另一个处理线程B从缓存中拉取消息并进行相应的逻辑处理。假设目前进行到了第 y+1 次拉取，以及第 m 次位点提交的时候，也就是x+6之前的位点已经确认提交了，处理线程 B 却还正在消费 x+3 的消息。此时如果处理线程 B 发生了异常，待其恢复之后会从第 m此位点提交处，也就是 x+6 的位置开始拉取消息，那么 x+3 至 x+6 之间的消息就没有得到相应的处理，这样便发生消息丢失的现象。\n\n\n\n在kafka中还提供了手动提交位点的方式，这样可以让我们对于消费位点的管理控制更加灵活。开启手动提交功能的前提是消费者客户端参数enable.auto.commit配置为false。\n\nprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,false);\n\n\n1\n\n\n手动提交可以细分为同步提交和异步提交。对应于KafkaConsumer中的 commitSync() 和 commitAsync() 两个方法。\n\n同步提交的简单用法：\n\nKafkaConsumer<String, String> consumer=new KafkaConsumer<>(props);\n        consumer.subscribe(Collections.singletonList(topicName));\n\n        while(true){\n        ConsumerRecords<String, String> records=consumer.poll(Duration.ofMillis(100));\n        for(ConsumerRecord<String, String> record:records){\n        System.out.println(record.value());\n\n        }\n        consumer.commitSync();\n        }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n对于上面的代码，可以看到先对拉取到的每一条消息做相应的逻辑处理，然后对整个消息集做同步提交。参考KafkaConsumer源码中提供的示例，针对上面的示例还可以修改为批量处理+批量提交的方式，关键代码如下:\n\n\nfinal int minBatchSize=200;\n        List<ConsumerRecord> buffer=new ArrayList<>;\nwhile(true){\n        ConsumerRecords<String, String> records=consumer.poll(1000);\n        for(ConsumerRecord<String, String> record:records){\n        buffer.add(record);\n        }\n        if(buffer.size()>=minBatchSize){\n        //do some logical processing with buffer\n        consumer.commitSync();\n        buffer.clear();\n        }\n        }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n上面的代码中将拉取到的消息存入缓存 buffer，等到积累到足够多的时候，也就是示例中大于等于200个的时候，再做相应的批量处理，之后再做批量提交。上面这两个示例都有重复消费的问题，如果在业务逻辑处理完之后，并且在同步位点提交前，程序出现了崩溃，那么待恢复之后又只能从上一次位点提交的地方拉取消息，由此在两次位点提交的窗口中出现了重复消费的现象。\n\ncommitSync()方法会根据poll()方法拉取的最新位点来进行提交，只要没有发生不可恢复的错误，它就会阻塞消费者线程直至位点提交完成。对于不可恢复异常，需要业务捕获处理。\n\n对于采用commitSync()的无参方法而言，它提交消费位点的频率和拉取批次消息、处理批次消息的频率是一样的，如果想寻求更细粒度的、更精准的提交，那么就需要使用 commitSync()的另一个含参方法。\n\nvoid commitSync(Map<TopicPartition, OffsetAndMetadata> offsets);\n\n\n1\n\n\n该方法提供了一个 offsets 参数，用来提交指定分区的位点。无参的commitSync()方注只能提交当前批次对应的position值。如果需要提交一个中间值，比如业务每消费一条消息提交一次位点，那么就可以使用这种方式。\n\n与 commitSync()方法相反，异步提交的方式(commitAsync())在执行的时候消费者线程不会被阻塞，可能在提交消费位点的结果还未返回之前就开始了新一次的拉取操作。异步提交可以使消费者的性能得到一定的增强。\n\n    void commitAsync();\n\n        void commitAsync(OffsetCommitCallback callback);\n\n        void commitAsync(Map<TopicPartition, OffsetAndMetadata> offsets,OffsetCommitCallback callback);\n\n\n1\n2\n3\n4\n5\n\n\n第一个无参的方法和第三个方法中的 offsets 都很好理解，对照 commitSync()方法即可。关键的是这里的第二个方法和第三个方法中的 callback 参数，它提供了一个异步提交的回调方法,当位点提交完成后会回调OffsetCommitCallback中的 onComplete()方法。这里采用第二个方法来演示回调函数的用法，关键代码如下:\n\n    while(true){\n        ConsumerRecords<String, String> records=consumer.poll(1000);\n        for(ConsumerRecord<String, String> record:records){\n        System.out.println(record.value());\n        }\n        consumer.commitAsync((offsets,exception)->{\n        if(exception==null){\n        System.out.println(offsets);\n        }else{\n        log.error("fail to commit offsets {}",offsets,exception);\n        }\n        });\n        }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\ncommitAsync()提交的时候同样会有失败的情况发生，那么我们应该怎么处理呢?重试么，问题的关键也就在这里了。如果某一次异步提交的消费位点为x，但是提交失败了，然后下一次又异步提交了消费位点为x+y，这次成功了。如果这里引入了重试机制.前一次的异步提交的消费位点在重试的时候提交成功了，那么此时的消费位点又变为了x。如果此时发生异常(或者再均衡)，那么恢复之后的消费者(或者新的消费者)就会从 X 处开始消费消息，这样就发生了重复消费的问题。\n\n为此我们可以设置一个递增的序号来维护异步提交的顺序，每次位点提交之后就增加序号相对应的值。在遇到位点提交失败需要重试的时候，可以检查所提交的位点和序号的值的大小。如果前者小于后者，则说明有更大的位点已经提交了，不需要再进行本次重试;如果两者相同则说明可以进行重试提交。除非程序编码错误，否则不会出现前者大于后者的情况。(乐观锁)\n\n----------------------------------------',normalizedContent:'对于 kafka 中的分区而言，它的每条消息都有唯一的 offset，用来表示消息在分区中对应的位置。对于消费者而言，它也有一个 offset 的概念，消费者使用 offset来表示消费到分区中某个消息所在的位置。对于消息在分区中的位置，我们将offset称为"偏移量";对于消费者消费到的位置，将 offset 称为"消费位点"。当然，对于一条消息而言，它的偏移量和消费者消费它时的消费位点是相等的。\n\n在每次调用poll方法时，它返回的是还没有被消费过的消息集(当然这个前提是消息已经存储在kafka中了，并且暂不考虑异常情况的发生)，要做到这一点，就需要记录上一次消费时的消费位点。并且这个消费位点必须做持久化保存，而不是单单保存在内存中，否则消费者重启之后就无法知晓之前的消费位点。再考虑一种情况，当有新的消费者加入时，那么必然会有再均衡的动作，对于同一分区而言，它可能在再均衡动作之后分配给新的消费者，如果不持久化保存消费位点，那么这个新的消费者也无法知晓之前的消费位点。\n\n在旧消费者客户端中，消费位点是存储在 zookeeper 中的。而在新消费者客户端中，消费位点存储在kafka内部的主题 consumer_offsets 中。这里把将消费位点存储起来(持久化)的动作称为"提交"，消费者在消费完消息之后需要执行消费位点的提交。\n\n参考下图的消费位点，x 表示某一次拉取操作中此分区消息的最大偏移量，假设当前消费者已经消费了 x位置的消息，那么我们就可以说消费者的消费位点为x，图中也用了lastconsumedoffset这个单词来标识它。\n\n\n\n当前消费者需要提交的位点不是x，而是x+1，对应于上图中的position，它表示下一条需要拉取的消息的位置。在消费者中还有一个committed offset的概念，他表示已经提交过的消费位点。\n\nkafkaconsumer类提供了position(topicpartition)和committed(topicpartition)两个方法来分别获取上面所说的position和committed offset的值。\n\npublic long position(topicpartition partition);\n\npublic offsetandmetadata committed(topicpartition partition);\n\n\n1\n2\n3\n\n\ncommited offset == position == (lastconsumedoffset + 1)\n\n> position 和 commited offset 并不会一直相同。\n\n位点提交的时机不同，有可能会造成重复消费和消息丢失的现象。\n\n参考下图，当前一次poll操作所拉取的消息集为[x+2,x+7]，x+2 代表上一次提交的消费位点，说明已经完成了 x+1 之前(包括 x+1 在内)的所有消息的消费，x+5 表示当前正在处理的位置，如果拉取到消息之后就进行了位点提交，即提交了 x+8，那么当前消费 x+5 的时候遇到了异常在故障恢复之后，我们重新拉取的消息是从 x+8 开始的。也就是说，x+5 至 x+7之间的消息未能被消费，如此便发生了消息丢失的现象。 再考虑另外一种情形，位点提交的动作是在消费完所有拉取到的消息之后才执行的，那么当消费x+5的时候遇到了异常，在故障恢复之后，我们重新拉取的消息是从x+2 开始的。也就是说，x+2 至 x+4 之间的消息又重新消费了一遍，故而又发生了重复消费的现象。\n\n在 kafka 中默认的消费位点的提交方式是自动提交，这个由消费者客户端参数enable.auto.commit 配置，默认值为 true。当然这个默认的自动提交不是每消费一条消息就提交一次，而是定期提交，这个定期的周期时间由客户端参数 auto.commit.interval.ms配置，默认值为 5 秒，此参数生效的前提是 enable.auto.commit 参数为true)。\n\n在默认的方式下，消费者每隔 5 秒会将拉取到的每个分区中最大的消费位点进行提交。自动位点提交的动作是在poll方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位点提交，如果可以，那么就会提交上一次轮询的位点。\n\n在kafka消费的编程逻辑中位点提交是一大难点，自动提交消费位点的方式非常简便，但随之而来的是重复消费和消息丢失的问题。假设刚刚提交完一次消费位点，然后拉取一批消息进行消费，在下一次自动提交消费位点之前，消费者崩溃了，那么又得从上一次位点提交的地方重新开始消费，这样便发生了重复消费的现象。(对于再均衡的情况同样适用)。我们可以通过减小位点提交的时间间隔来减小重复消息的窗口大小，但这样并不能避免重复消费的发生，而且也会使位点提交更加频繁。\n\n通常来讲，自动提交是延时提交，重复消费可以理解，那么消息丢失又是在什么情形下会发生的呢? 如下图，拉取线程a不断地拉取消息并存入本地缓存，比如在 blockingqucue 中，另一个处理线程b从缓存中拉取消息并进行相应的逻辑处理。假设目前进行到了第 y+1 次拉取，以及第 m 次位点提交的时候，也就是x+6之前的位点已经确认提交了，处理线程 b 却还正在消费 x+3 的消息。此时如果处理线程 b 发生了异常，待其恢复之后会从第 m此位点提交处，也就是 x+6 的位置开始拉取消息，那么 x+3 至 x+6 之间的消息就没有得到相应的处理，这样便发生消息丢失的现象。\n\n\n\n在kafka中还提供了手动提交位点的方式，这样可以让我们对于消费位点的管理控制更加灵活。开启手动提交功能的前提是消费者客户端参数enable.auto.commit配置为false。\n\nprops.put(consumerconfig.enable_auto_commit_config,false);\n\n\n1\n\n\n手动提交可以细分为同步提交和异步提交。对应于kafkaconsumer中的 commitsync() 和 commitasync() 两个方法。\n\n同步提交的简单用法：\n\nkafkaconsumer<string, string> consumer=new kafkaconsumer<>(props);\n        consumer.subscribe(collections.singletonlist(topicname));\n\n        while(true){\n        consumerrecords<string, string> records=consumer.poll(duration.ofmillis(100));\n        for(consumerrecord<string, string> record:records){\n        system.out.println(record.value());\n\n        }\n        consumer.commitsync();\n        }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n对于上面的代码，可以看到先对拉取到的每一条消息做相应的逻辑处理，然后对整个消息集做同步提交。参考kafkaconsumer源码中提供的示例，针对上面的示例还可以修改为批量处理+批量提交的方式，关键代码如下:\n\n\nfinal int minbatchsize=200;\n        list<consumerrecord> buffer=new arraylist<>;\nwhile(true){\n        consumerrecords<string, string> records=consumer.poll(1000);\n        for(consumerrecord<string, string> record:records){\n        buffer.add(record);\n        }\n        if(buffer.size()>=minbatchsize){\n        //do some logical processing with buffer\n        consumer.commitsync();\n        buffer.clear();\n        }\n        }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n上面的代码中将拉取到的消息存入缓存 buffer，等到积累到足够多的时候，也就是示例中大于等于200个的时候，再做相应的批量处理，之后再做批量提交。上面这两个示例都有重复消费的问题，如果在业务逻辑处理完之后，并且在同步位点提交前，程序出现了崩溃，那么待恢复之后又只能从上一次位点提交的地方拉取消息，由此在两次位点提交的窗口中出现了重复消费的现象。\n\ncommitsync()方法会根据poll()方法拉取的最新位点来进行提交，只要没有发生不可恢复的错误，它就会阻塞消费者线程直至位点提交完成。对于不可恢复异常，需要业务捕获处理。\n\n对于采用commitsync()的无参方法而言，它提交消费位点的频率和拉取批次消息、处理批次消息的频率是一样的，如果想寻求更细粒度的、更精准的提交，那么就需要使用 commitsync()的另一个含参方法。\n\nvoid commitsync(map<topicpartition, offsetandmetadata> offsets);\n\n\n1\n\n\n该方法提供了一个 offsets 参数，用来提交指定分区的位点。无参的commitsync()方注只能提交当前批次对应的position值。如果需要提交一个中间值，比如业务每消费一条消息提交一次位点，那么就可以使用这种方式。\n\n与 commitsync()方法相反，异步提交的方式(commitasync())在执行的时候消费者线程不会被阻塞，可能在提交消费位点的结果还未返回之前就开始了新一次的拉取操作。异步提交可以使消费者的性能得到一定的增强。\n\n    void commitasync();\n\n        void commitasync(offsetcommitcallback callback);\n\n        void commitasync(map<topicpartition, offsetandmetadata> offsets,offsetcommitcallback callback);\n\n\n1\n2\n3\n4\n5\n\n\n第一个无参的方法和第三个方法中的 offsets 都很好理解，对照 commitsync()方法即可。关键的是这里的第二个方法和第三个方法中的 callback 参数，它提供了一个异步提交的回调方法,当位点提交完成后会回调offsetcommitcallback中的 oncomplete()方法。这里采用第二个方法来演示回调函数的用法，关键代码如下:\n\n    while(true){\n        consumerrecords<string, string> records=consumer.poll(1000);\n        for(consumerrecord<string, string> record:records){\n        system.out.println(record.value());\n        }\n        consumer.commitasync((offsets,exception)->{\n        if(exception==null){\n        system.out.println(offsets);\n        }else{\n        log.error("fail to commit offsets {}",offsets,exception);\n        }\n        });\n        }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\ncommitasync()提交的时候同样会有失败的情况发生，那么我们应该怎么处理呢?重试么，问题的关键也就在这里了。如果某一次异步提交的消费位点为x，但是提交失败了，然后下一次又异步提交了消费位点为x+y，这次成功了。如果这里引入了重试机制.前一次的异步提交的消费位点在重试的时候提交成功了，那么此时的消费位点又变为了x。如果此时发生异常(或者再均衡)，那么恢复之后的消费者(或者新的消费者)就会从 x 处开始消费消息，这样就发生了重复消费的问题。\n\n为此我们可以设置一个递增的序号来维护异步提交的顺序，每次位点提交之后就增加序号相对应的值。在遇到位点提交失败需要重试的时候，可以检查所提交的位点和序号的值的大小。如果前者小于后者，则说明有更大的位点已经提交了，不需要再进行本次重试;如果两者相同则说明可以进行重试提交。除非程序编码错误，否则不会出现前者大于后者的情况。(乐观锁)\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"消费者-客户端开发-指定消费位点",frontmatter:{title:"消费者-客户端开发-指定消费位点",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"消费者-客户端开发-指定消费位点",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/5ab26239-f80c-3f5e-affc-fc2c33f5178f/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/7.%E6%B6%88%E8%B4%B9%E8%80%85-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BC%80%E5%8F%91-%E6%8C%87%E5%AE%9A%E4%BD%8D%E7%82%B9%E6%B6%88%E8%B4%B9.html",relativePath:"03.消息队列/00.Kafka/7.消费者-客户端开发-指定位点消费.md",key:"v-d5a2bdec",path:"/pages/5ab26239-f80c-3f5e-affc-fc2c33f5178f/",headersStr:null,content:'当一个新的消费组建立的时候，它根本没有可以查找的消费位点。或者消费组内的一个新消费者订阅了一个新的主题，它也没有可以查找的消费位点。当 consumor_offsets主题中有关这个消费组的位点信息过期而被删除后，它也没有可以查找的消费位点。\n\n在 Kafka 中每当消费者查找不到所记录的消费位点时，就会根据消费者客户端参数auto.offset.reset的配置来决定从何处开始进行消费，这个参数的默认值为latest，表示从分区末尾开始消费消息。参考下图，按照默认的配置，消费者会从9开始进行消费 9 是下一条要写入消息的位置,更加确地说是从 9 开始拉取消息。如果将 auto.offset.reset参数配置为earliest，那么消费者会从起始处，也就是 0开始消费。\n\n\n\n> 除了查找不到消费位点，位点越界也会触发 auto.offset.reset 参数的执行。\n\nauto.offset.reset 参数还有一个可配置的值一none，配置为此值就意味着出现查不到消费位点的时候，既不从最新的消息位置处开始消费，也不从最早的消息位置处开始消费，此时会报出NoOffsetForPartitionException 异常。如果能够找到消费位点，那么配置为none不会出现任何异常。如果配置的不是latest,earliest,和none，则会报出 ConfigException 异常。\n\n消息的拉取是根据 poll() 方法中的逻辑来处理的，这个 poll()方法中的逻辑对于普通的开发人员而言是一个黑盒，无法精确地掌控其消费的起始位置。提供的auto.offset.reset参数也只能在找不到消费位点或位点越界的情况下粗粒度地从开头或末尾开始消费。有些时候，我们需要一种更细粒度的掌控，可以让我们从特定的位点处开始拉取消息，而KafkaConsumer中的 seek() 方法正好提供了这个功能，让我们得以追前消费或回溯消费。\n\npublic void seek(TopicPartition partition,long offset);\n\n\n1\n\n\nseek()方法中的参数 partition 表示分区，而 offset 参数用来指定从分区的哪个位置开始消费。seek()方法只能重置消费者分配到的分区的消费位置，而分区的分配是在 poll() 方法的调用过程中实现的。也就是说，在执行 seek()方法之前需要先执行一次 poll() 方法，等到分配到分区之后才可以重置消费位置。\n\n以下是seek方法的使用示例：\n\n        Properties props=new Properties();\n        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,brokerList);\n        props.put(ConsumerConfig.GROUP_ID_CONFIG,groupName);\n        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());\n        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());\n\n        KafkaConsumer<String, String> consumer=new KafkaConsumer<>(props);\n        consumer.subscribe(Collections.singletonList(topicName));\n        consumer.poll(Duration.ofMillis(1000));\n        Set<TopicPartition> assignment=consumer.assignment();\n        for(TopicPartition partition:assignment){\n        consumer.seek(partition,10);\n        }\n        while(true){\n        ConsumerRecords<String, String> records=consumer.poll(Duration.ofMillis(1000));\n        for(ConsumerRecord<String, String> record:records){\n        System.out.println("message : "+record.value());\n        }\n        }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\nassignment()方法是用来获取消费者所分配到的分区信息的。\n\npublic Set<TopicPartition> assignment0);\n\n\n1\n\n\n> 在上面的seek()方法使用的示例代码中，如果第一次调用poll()方法的时间间隔设置为0，在此之后，会发现 seek()方法并未有任何作用。因为当 poll() 方法中的参数为 0 时，此方法立刻返回，那么 poll()方法内部进行分区分配的逻辑就会来不及实施。也就是说，消费者此时并未分配到任何分区。那么我们应该如何优雅的seek呢？\n\n    private void test(){\n        Properties props=new Properties();\n        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,brokerList);\n        props.put(ConsumerConfig.GROUP_ID_CONFIG,groupName);\n        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());\n        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());\n\n        KafkaConsumer<String, String> consumer=new KafkaConsumer<>(props);\n        consumer.subscribe(Collections.singletonList(topicName));\n        Set<TopicPartition> assignment=new HashSet<>();\n        while(assignment==null||assignment.size()==0){\n        consumer.poll(Duration.ofMillis(100));\n        assignment=consumer.assignment();\n        }\n\n        for(TopicPartition partition:assignment){\n        consumer.seek(partition,10);\n        }\n        while(true){\n        ConsumerRecords<String, String> records=consumer.poll(Duration.ofMillis(1000));\n        for(ConsumerRecord<String, String> record:records){\n        System.out.println("message : "+record.value());\n        }\n        }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n如果对未分配到的分区执行 seek() 方法，那么会报出 IllegalStateException 的异常。类似在调用 subscribe()方法之后直接调用 seek() 方法:\n\nconsumer.subscribe(Arrays.asList(topic));\nconsumer.seek(new TopicPartition(topic,0),10);\n\n\n1\n2\n\n\n如果消费组内的消费者在启动的时候能够找到消费位点，除非发生位点越界，否则 auto.offset.reset参数并不会奏效,此时如果想指定从开头或末尾开始消费,就要使用 seck() 方法了。\n\n    private void test(){\n        Properties props=new Properties();\n        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,brokerList);\n        props.put(ConsumerConfig.GROUP_ID_CONFIG,groupName);\n        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());\n        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());\n\n        KafkaConsumer<String, String> consumer=new KafkaConsumer<>(props);\n        consumer.subscribe(Collections.singletonList(topicName));\n        Set<TopicPartition> assignment=new HashSet<>();\n        while(assignment==null||assignment.size()==0){\n        consumer.poll(Duration.ofMillis(100));\n        assignment=consumer.assignment();\n        }\n        Map<TopicPartition, Long> map=consumer.endOffsets(assignment);\n        for(TopicPartition partition:assignment){\n        consumer.seek(partition,map.get(partition));\n        }\n        while(true){\n        ConsumerRecords<String, String> records=consumer.poll(Duration.ofMillis(1000));\n        for(ConsumerRecord<String, String> record:records){\n        System.out.println("message : "+record.value());\n        }\n\n        }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n> endOffsets()方法用来获取指定分区的末尾的消息位置。\n\n    Map<TopicPartition, Long> endOffsets(Collection<TopicPartition> partitions);\n\n    Map<TopicPartition, Long> endOffsets(Collection<TopicPartition> partitions,Duration timeout);\n\n\n1\n2\n3\n\n\n与 endOffsets() 方法 对应的是 beginningOffsets() 方法，一个分区的起始位置起初是0，但并不代表每时每刻都为0，因为日志清理的动作会清旧的数据，所以分区的起始位置会自然而然地增加。\n\n    Map<TopicPartition, Long> beginningOffsets(Collection<TopicPartition> partitions);\n\n    Map<TopicPartition, Long> beginningOffsets(Collection<TopicPartition> partitions,Duration timeout);\n\n\n1\n2\n3\n\n\n其实 KafkaConsumer 中直接提供了 seekToBeginning() 方法, seekToEnd() 方法来实现这两个功能。\n\n    void seekToBeginning(Collection<TopicPartition> partitions);\n\n        void seekToEnd(Collection<TopicPartition> partitions);\n\n\n1\n2\n3\n\n\n有时候我们并不知道特定的消费位置，却知道一个相关的时间点，比如我们想要消费昨天8点之后的消息，这个需求更符合正常的思维逻辑。此时我们无法直接使用 seek()方法来追溯到相应的位置。KafkaConsumer 同样考虑到了这种情况，它提供了一个 offsetsForTimes() 方法，通过timestamp来查询与此对应的分区位置。\n\nMap<TopicPartition, OffsetAndTimestamp> offsetsForTimes(Map<TopicPartition, Long> timestampsToSearch);\n\nMap<TopicPartition, OffsetAndTimestamp> offsetsForTimes(Map<TopicPartition, Long> timestampsToSearch,Duration timeout);\n\n\n1\n2\n3\n\n\noffsetsForTimes() 方法的参数 timestampsToSearch 是一个 Map 类型,key 为待查询的分区，而value为待查询的时间戳，该方法会返回时间戳大于等于待查询时间的第一条消息对应的位置和时间戳，对应于 OffsetAndTimestamp中的offset 和 timestamp 字段。\n\n前面说过位点越界也会触发 auto.offset.reset 参数的执行，位点越界是指知道消费位置却无法在实际的分区中查找到，比如想要从上图中的位置10处拉取消息时就会发生位点越界。注意拉取上图中位置 9 处的消息时并未越界，这个位置代表特定的含义 (LEO)。\n\nKafka中的消费位点是存储在一个内部主题中的，而本节的 seek() 方法可以突破这一限制：消费位点可以保存在任意的存储介质中，比如数据库，文件系统等等。\n\nseek()方法为我们提供了从特定位置读取消息的能力，我们可以通过这个方法来向前跳过若干消息，也可以通过这个方法来向后回溯若干消息，这样为消息的消费提供了很大的灵活性。seek()方法也为我们提供了将消费位点保存在外部存储介质中的能力，还可以配合再均衡监听器来提供更加精准的消费能力。\n\n----------------------------------------',normalizedContent:'当一个新的消费组建立的时候，它根本没有可以查找的消费位点。或者消费组内的一个新消费者订阅了一个新的主题，它也没有可以查找的消费位点。当 consumor_offsets主题中有关这个消费组的位点信息过期而被删除后，它也没有可以查找的消费位点。\n\n在 kafka 中每当消费者查找不到所记录的消费位点时，就会根据消费者客户端参数auto.offset.reset的配置来决定从何处开始进行消费，这个参数的默认值为latest，表示从分区末尾开始消费消息。参考下图，按照默认的配置，消费者会从9开始进行消费 9 是下一条要写入消息的位置,更加确地说是从 9 开始拉取消息。如果将 auto.offset.reset参数配置为earliest，那么消费者会从起始处，也就是 0开始消费。\n\n\n\n> 除了查找不到消费位点，位点越界也会触发 auto.offset.reset 参数的执行。\n\nauto.offset.reset 参数还有一个可配置的值一none，配置为此值就意味着出现查不到消费位点的时候，既不从最新的消息位置处开始消费，也不从最早的消息位置处开始消费，此时会报出nooffsetforpartitionexception 异常。如果能够找到消费位点，那么配置为none不会出现任何异常。如果配置的不是latest,earliest,和none，则会报出 configexception 异常。\n\n消息的拉取是根据 poll() 方法中的逻辑来处理的，这个 poll()方法中的逻辑对于普通的开发人员而言是一个黑盒，无法精确地掌控其消费的起始位置。提供的auto.offset.reset参数也只能在找不到消费位点或位点越界的情况下粗粒度地从开头或末尾开始消费。有些时候，我们需要一种更细粒度的掌控，可以让我们从特定的位点处开始拉取消息，而kafkaconsumer中的 seek() 方法正好提供了这个功能，让我们得以追前消费或回溯消费。\n\npublic void seek(topicpartition partition,long offset);\n\n\n1\n\n\nseek()方法中的参数 partition 表示分区，而 offset 参数用来指定从分区的哪个位置开始消费。seek()方法只能重置消费者分配到的分区的消费位置，而分区的分配是在 poll() 方法的调用过程中实现的。也就是说，在执行 seek()方法之前需要先执行一次 poll() 方法，等到分配到分区之后才可以重置消费位置。\n\n以下是seek方法的使用示例：\n\n        properties props=new properties();\n        props.put(consumerconfig.bootstrap_servers_config,brokerlist);\n        props.put(consumerconfig.group_id_config,groupname);\n        props.put(consumerconfig.key_deserializer_class_config,stringdeserializer.class.getname());\n        props.put(consumerconfig.value_deserializer_class_config,stringdeserializer.class.getname());\n\n        kafkaconsumer<string, string> consumer=new kafkaconsumer<>(props);\n        consumer.subscribe(collections.singletonlist(topicname));\n        consumer.poll(duration.ofmillis(1000));\n        set<topicpartition> assignment=consumer.assignment();\n        for(topicpartition partition:assignment){\n        consumer.seek(partition,10);\n        }\n        while(true){\n        consumerrecords<string, string> records=consumer.poll(duration.ofmillis(1000));\n        for(consumerrecord<string, string> record:records){\n        system.out.println("message : "+record.value());\n        }\n        }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\nassignment()方法是用来获取消费者所分配到的分区信息的。\n\npublic set<topicpartition> assignment0);\n\n\n1\n\n\n> 在上面的seek()方法使用的示例代码中，如果第一次调用poll()方法的时间间隔设置为0，在此之后，会发现 seek()方法并未有任何作用。因为当 poll() 方法中的参数为 0 时，此方法立刻返回，那么 poll()方法内部进行分区分配的逻辑就会来不及实施。也就是说，消费者此时并未分配到任何分区。那么我们应该如何优雅的seek呢？\n\n    private void test(){\n        properties props=new properties();\n        props.put(consumerconfig.bootstrap_servers_config,brokerlist);\n        props.put(consumerconfig.group_id_config,groupname);\n        props.put(consumerconfig.key_deserializer_class_config,stringdeserializer.class.getname());\n        props.put(consumerconfig.value_deserializer_class_config,stringdeserializer.class.getname());\n\n        kafkaconsumer<string, string> consumer=new kafkaconsumer<>(props);\n        consumer.subscribe(collections.singletonlist(topicname));\n        set<topicpartition> assignment=new hashset<>();\n        while(assignment==null||assignment.size()==0){\n        consumer.poll(duration.ofmillis(100));\n        assignment=consumer.assignment();\n        }\n\n        for(topicpartition partition:assignment){\n        consumer.seek(partition,10);\n        }\n        while(true){\n        consumerrecords<string, string> records=consumer.poll(duration.ofmillis(1000));\n        for(consumerrecord<string, string> record:records){\n        system.out.println("message : "+record.value());\n        }\n        }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n如果对未分配到的分区执行 seek() 方法，那么会报出 illegalstateexception 的异常。类似在调用 subscribe()方法之后直接调用 seek() 方法:\n\nconsumer.subscribe(arrays.aslist(topic));\nconsumer.seek(new topicpartition(topic,0),10);\n\n\n1\n2\n\n\n如果消费组内的消费者在启动的时候能够找到消费位点，除非发生位点越界，否则 auto.offset.reset参数并不会奏效,此时如果想指定从开头或末尾开始消费,就要使用 seck() 方法了。\n\n    private void test(){\n        properties props=new properties();\n        props.put(consumerconfig.bootstrap_servers_config,brokerlist);\n        props.put(consumerconfig.group_id_config,groupname);\n        props.put(consumerconfig.key_deserializer_class_config,stringdeserializer.class.getname());\n        props.put(consumerconfig.value_deserializer_class_config,stringdeserializer.class.getname());\n\n        kafkaconsumer<string, string> consumer=new kafkaconsumer<>(props);\n        consumer.subscribe(collections.singletonlist(topicname));\n        set<topicpartition> assignment=new hashset<>();\n        while(assignment==null||assignment.size()==0){\n        consumer.poll(duration.ofmillis(100));\n        assignment=consumer.assignment();\n        }\n        map<topicpartition, long> map=consumer.endoffsets(assignment);\n        for(topicpartition partition:assignment){\n        consumer.seek(partition,map.get(partition));\n        }\n        while(true){\n        consumerrecords<string, string> records=consumer.poll(duration.ofmillis(1000));\n        for(consumerrecord<string, string> record:records){\n        system.out.println("message : "+record.value());\n        }\n\n        }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n> endoffsets()方法用来获取指定分区的末尾的消息位置。\n\n    map<topicpartition, long> endoffsets(collection<topicpartition> partitions);\n\n    map<topicpartition, long> endoffsets(collection<topicpartition> partitions,duration timeout);\n\n\n1\n2\n3\n\n\n与 endoffsets() 方法 对应的是 beginningoffsets() 方法，一个分区的起始位置起初是0，但并不代表每时每刻都为0，因为日志清理的动作会清旧的数据，所以分区的起始位置会自然而然地增加。\n\n    map<topicpartition, long> beginningoffsets(collection<topicpartition> partitions);\n\n    map<topicpartition, long> beginningoffsets(collection<topicpartition> partitions,duration timeout);\n\n\n1\n2\n3\n\n\n其实 kafkaconsumer 中直接提供了 seektobeginning() 方法, seektoend() 方法来实现这两个功能。\n\n    void seektobeginning(collection<topicpartition> partitions);\n\n        void seektoend(collection<topicpartition> partitions);\n\n\n1\n2\n3\n\n\n有时候我们并不知道特定的消费位置，却知道一个相关的时间点，比如我们想要消费昨天8点之后的消息，这个需求更符合正常的思维逻辑。此时我们无法直接使用 seek()方法来追溯到相应的位置。kafkaconsumer 同样考虑到了这种情况，它提供了一个 offsetsfortimes() 方法，通过timestamp来查询与此对应的分区位置。\n\nmap<topicpartition, offsetandtimestamp> offsetsfortimes(map<topicpartition, long> timestampstosearch);\n\nmap<topicpartition, offsetandtimestamp> offsetsfortimes(map<topicpartition, long> timestampstosearch,duration timeout);\n\n\n1\n2\n3\n\n\noffsetsfortimes() 方法的参数 timestampstosearch 是一个 map 类型,key 为待查询的分区，而value为待查询的时间戳，该方法会返回时间戳大于等于待查询时间的第一条消息对应的位置和时间戳，对应于 offsetandtimestamp中的offset 和 timestamp 字段。\n\n前面说过位点越界也会触发 auto.offset.reset 参数的执行，位点越界是指知道消费位置却无法在实际的分区中查找到，比如想要从上图中的位置10处拉取消息时就会发生位点越界。注意拉取上图中位置 9 处的消息时并未越界，这个位置代表特定的含义 (leo)。\n\nkafka中的消费位点是存储在一个内部主题中的，而本节的 seek() 方法可以突破这一限制：消费位点可以保存在任意的存储介质中，比如数据库，文件系统等等。\n\nseek()方法为我们提供了从特定位置读取消息的能力，我们可以通过这个方法来向前跳过若干消息，也可以通过这个方法来向后回溯若干消息，这样为消息的消费提供了很大的灵活性。seek()方法也为我们提供了将消费位点保存在外部存储介质中的能力，还可以配合再均衡监听器来提供更加精准的消费能力。\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"消费者-客户端开发-Rebalance",frontmatter:{title:"消费者-客户端开发-Rebalance",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"消费者-客户端开发-Rebalance",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/2b4b8b25-552c-374f-9419-12d2c51dbeb1/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/8.%E6%B6%88%E8%B4%B9%E8%80%85-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BC%80%E5%8F%91-Rebalance.html",relativePath:"03.消息队列/00.Kafka/8.消费者-客户端开发-Rebalance.md",key:"v-a51427f8",path:"/pages/2b4b8b25-552c-374f-9419-12d2c51dbeb1/",headersStr:null,content:"再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。不过在再均衡发生期间，消费组内的消费者是无法读取消息的，也就是说，在再均衡发生期间的这一小段时间内，消费组会变得不可用。另外，当一个分区被重新分配给另一个消费者时，消费者当前的状态也会丢失。比如消费者消费完某个分区中的一部分消息时还没有来得及提交消费位点就发生了再均衡操作，之后这个分区又被分配给了消费组内的另一个消费者，原来被消费的那部分消息又被重新消费一遍，也就是发生了重复消费。\n\n前面再说 subscribe()方法的时候提到了可以注册一个ConsumerRebalanceListener在平衡监听器。这个监听器用来设定在发生Rebalance前后的一些动作。\n\n    void subscribe(Collection<String> topics,ConsumerRebalanceListener callback);\n\n        void subscribe(Pattern pattern,ConsumerRebalanceListener callback);\n\n\n1\n2\n3\n\n\n    void onPartitionsRevoked(Collection<TopicPartition> partitions);\n\n        void onPartitionsAssigned(Collection<TopicPartition> partitions);\n\n\n1\n2\n3\n\n 1. onPartitionsRevoked() 方法会在Rebalance开始之前和消费者停止读取消息之后被调用。可以通过这个方法来处理消费位点的提交。参数partitions表示Rebalance前所分配到的分区。\n 2. onPartitionsAssigned() 方法会在Rebalance重新分配分区之后和消费者开始消费之前被调用。参数partitions表示Rebalance后所分配到的分区。\n\n本节仅仅介绍ConsumerRebalanceListener的用法，Rebalance期间消费者客户端与Kafka服务端之间的交互逻辑以及相关原理后面在分析。\n\n----------------------------------------",normalizedContent:"再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。不过在再均衡发生期间，消费组内的消费者是无法读取消息的，也就是说，在再均衡发生期间的这一小段时间内，消费组会变得不可用。另外，当一个分区被重新分配给另一个消费者时，消费者当前的状态也会丢失。比如消费者消费完某个分区中的一部分消息时还没有来得及提交消费位点就发生了再均衡操作，之后这个分区又被分配给了消费组内的另一个消费者，原来被消费的那部分消息又被重新消费一遍，也就是发生了重复消费。\n\n前面再说 subscribe()方法的时候提到了可以注册一个consumerrebalancelistener在平衡监听器。这个监听器用来设定在发生rebalance前后的一些动作。\n\n    void subscribe(collection<string> topics,consumerrebalancelistener callback);\n\n        void subscribe(pattern pattern,consumerrebalancelistener callback);\n\n\n1\n2\n3\n\n\n    void onpartitionsrevoked(collection<topicpartition> partitions);\n\n        void onpartitionsassigned(collection<topicpartition> partitions);\n\n\n1\n2\n3\n\n 1. onpartitionsrevoked() 方法会在rebalance开始之前和消费者停止读取消息之后被调用。可以通过这个方法来处理消费位点的提交。参数partitions表示rebalance前所分配到的分区。\n 2. onpartitionsassigned() 方法会在rebalance重新分配分区之后和消费者开始消费之前被调用。参数partitions表示rebalance后所分配到的分区。\n\n本节仅仅介绍consumerrebalancelistener的用法，rebalance期间消费者客户端与kafka服务端之间的交互逻辑以及相关原理后面在分析。\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"消费者-客户端开发-拦截器",frontmatter:{title:"消费者-客户端开发-拦截器",date:"2023-01-01T00:00:00.000Z",tags:["Kafka","消息队列"],categories:["Kafka"],description:"消费者-客户端开发-拦截器",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/40f82a04-0969-342d-8b82-bb27281bb7e0/"},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/00.Kafka/9.%E6%B6%88%E8%B4%B9%E8%80%85-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BC%80%E5%8F%91-%E6%8B%A6%E6%88%AA%E5%99%A8.html",relativePath:"03.消息队列/00.Kafka/9.消费者-客户端开发-拦截器.md",key:"v-336aff4e",path:"/pages/40f82a04-0969-342d-8b82-bb27281bb7e0/",headersStr:null,content:"消费者拦截器主要在消费到消息或在提交消费位点时进行一些定制化的操作。消费者拦截器需要自定义实现 ConsumerInterceptor接口。该接口包含三个方法。\n\npublic ConsumerRecords<K, V> onConsume(ConsumerRecords<K, V> records);\n\npublic void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets);\n\npublic void close();\n\n\n1\n2\n3\n4\n5\n\n\nKafkaConsumer 会在poll()方法返回之前调用拦截器的onConsume()方法来对消息进行相的定制化操作，比如修改返回的消息内容、按照某种规则过滤消息(可能会减少 poll() 方法返回的消息的个数)。如果onConsume()方法中抛出异常，那么会被捕获并记录到日志中，但是通常不会再向上传递。\n\nKafkaConsumer 会在提交完消费位点之后调用拦截器的onCommit()方法，可以使用这个方法来记录跟踪所提交的位点信息，比如当消费者使用 commitSync()的无参方法时，我们不知道提交的消费位点的具体细节，而使用拦截器的 onCommit() 方法却可以做到这一点。\n\nclose()方法和 ConsumerInterceptor 的父接口中的configure()方法与生产者的 ProducerInterceptor 接口中的用途一样。\n\n实现自定义的 ConsumerInterceptor 之后，需要在 KafkaConsumer 中配置指定这个拦截器，同样是通过参数interceptor.classes指定。\n\n在消费者中也有拦截器链的概念，和生产者拦截器链条一样，也是按照 interceptor.classes参数配置的拦截器的顺序来一一执行的，同样也要防止副作用的发生。如果在拦截器链中某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。\n\n----------------------------------------",normalizedContent:"消费者拦截器主要在消费到消息或在提交消费位点时进行一些定制化的操作。消费者拦截器需要自定义实现 consumerinterceptor接口。该接口包含三个方法。\n\npublic consumerrecords<k, v> onconsume(consumerrecords<k, v> records);\n\npublic void oncommit(map<topicpartition, offsetandmetadata> offsets);\n\npublic void close();\n\n\n1\n2\n3\n4\n5\n\n\nkafkaconsumer 会在poll()方法返回之前调用拦截器的onconsume()方法来对消息进行相的定制化操作，比如修改返回的消息内容、按照某种规则过滤消息(可能会减少 poll() 方法返回的消息的个数)。如果onconsume()方法中抛出异常，那么会被捕获并记录到日志中，但是通常不会再向上传递。\n\nkafkaconsumer 会在提交完消费位点之后调用拦截器的oncommit()方法，可以使用这个方法来记录跟踪所提交的位点信息，比如当消费者使用 commitsync()的无参方法时，我们不知道提交的消费位点的具体细节，而使用拦截器的 oncommit() 方法却可以做到这一点。\n\nclose()方法和 consumerinterceptor 的父接口中的configure()方法与生产者的 producerinterceptor 接口中的用途一样。\n\n实现自定义的 consumerinterceptor 之后，需要在 kafkaconsumer 中配置指定这个拦截器，同样是通过参数interceptor.classes指定。\n\n在消费者中也有拦截器链的概念，和生产者拦截器链条一样，也是按照 interceptor.classes参数配置的拦截器的顺序来一一执行的，同样也要防止副作用的发生。如果在拦截器链中某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/20/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/01.RocketMQ/01.xxx.html",relativePath:"03.消息队列/01.RocketMQ/01.xxx.md",key:"v-63d529e4",path:"/pages/20/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/21/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/03.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/02.RabbitMQ/01.xxx.html",relativePath:"03.消息队列/02.RabbitMQ/01.xxx.md",key:"v-44762c24",path:"/pages/21/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/22/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/04.%E6%95%B0%E6%8D%AE%E5%BA%93/00.MySQL/01.xxx.html",relativePath:"04.数据库/00.MySQL/01.xxx.md",key:"v-d1f5af9c",path:"/pages/22/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/23/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/04.%E6%95%B0%E6%8D%AE%E5%BA%93/01.Redis/01.xxx.html",relativePath:"04.数据库/01.Redis/01.xxx.md",key:"v-3e055fb4",path:"/pages/23/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/24/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/05.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/00.%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/01.xxx.html",relativePath:"05.微服务架构/00.架构演进/01.xxx.md",key:"v-82ddb1de",path:"/pages/24/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/25/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/05.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/01.%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/01.xxx.html",relativePath:"05.微服务架构/01.分布式事务/01.xxx.md",key:"v-27fcd69b",path:"/pages/25/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/26/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/05.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/02.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/01.xxx.html",relativePath:"05.微服务架构/02.设计模式/01.xxx.md",key:"v-45c57d20",path:"/pages/26/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/27/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/05.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/03.%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/01.xxx.html",relativePath:"05.微服务架构/03.领域驱动设计/01.xxx.md",key:"v-4d97f68d",path:"/pages/27/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/28/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/06.%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/00.ElasticSearch/01.xxx.html",relativePath:"06.搜索引擎/00.ElasticSearch/01.xxx.md",key:"v-112a6e78",path:"/pages/28/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/29/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/07.JVM/01.xxx.html",relativePath:"07.JVM/01.xxx.md",key:"v-01bbe51f",path:"/pages/29/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"About Me",frontmatter:{title:"About Me",date:"2021年9月11日22:50:43",permalink:"/pages/30/",type:"个人简历",tags:["简历","面试"],author:{name:"huidong.yin",link:"https://huidongyin.github.io"},categories:["AboutMe"]},regularPath:"/08.%E4%BA%91%E8%AE%A1%E7%AE%97/00.Docker/01.xxx.html",relativePath:"08.云计算/00.Docker/01.xxx.md",key:"v-787e3e12",path:"/pages/30/",headers:[{level:3,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:167},{level:3,title:"工作履历",slug:"工作履历",normalizedTitle:"工作履历",charIndex:952},{level:3,title:"项目经验",slug:"项目经验",normalizedTitle:"项目经验",charIndex:1059},{level:3,title:"教育背景",slug:"教育背景",normalizedTitle:"教育背景",charIndex:1146}],headersStr:"专业技能 工作履历 项目经验 教育背景",content:"姓名    工作年限   出生日期         性别   TEL           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握Java基础知识，了解各版本特性，读过并发编程，集合框架，IO流等常用API底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过Spring，SpringMVC，Mybatis，SpringBoot，SpringCloud(Eureka,Nacos,Sentinel,OpenFeign,Ribbon,Gateway)源码。\n 4.  读过Tomcat，Dubbo，Zookeeper，Quartz源码。\n 5.  读过Redis源码。\n 6.  了解Nginx，ApiSix等网关。\n 7.  读过《深入理解Java虚拟机》，有多次JVM线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握MySQL底层原理，SQL调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过RocketMQ源码，掌握Kafka核心原理，熟练使用RabbitMQ，目前负责消息队列相关工作开发。\n 10. 熟练掌握ElasticSearch API，深入理解ElasticSearch底层原理，了解ElasticSearch集群运维，读过部分ElasticSearch源码。\n 11. 读过Netty源码，了解Netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用Linux操作系统，Docker，Jenkins等CICD相关工具。\n 13. 了解HTTP与HTTPS协议原理，序列化与反序列化原理，RPC通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用JIRA，Asana等项目流程管理工具，熟练使用Markdown，Word，Excel，PPT等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- ZOOM AsyncMQ\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. ZOOM消息队列-AsyncMQ\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",normalizedContent:"姓名    工作年限   出生日期         性别   tel           邮箱\n尹会东   3年     1998.11.16   男    13342969497   huidong.yin247203@gmail.com\n\n----------------------------------------\n\n\n# 专业技能\n\n 1.  熟练掌握java基础知识，了解各版本特性，读过并发编程，集合框架，io流等常用api底层源码。\n 2.  能够在开发中利用设计模式抽象代码，深入理解领域驱动设计。\n 3.  读过spring，springmvc，mybatis，springboot，springcloud(eureka,nacos,sentinel,openfeign,ribbon,gateway)源码。\n 4.  读过tomcat，dubbo，zookeeper，quartz源码。\n 5.  读过redis源码。\n 6.  了解nginx，apisix等网关。\n 7.  读过《深入理解java虚拟机》，有多次jvm线上问题排查与调优经验，经历过小米618大促现场调优。\n 8.  掌握mysql底层原理，sql调优经验丰富，有小米新零售数据建模开发经验。\n 9.  读过rocketmq源码，掌握kafka核心原理，熟练使用rabbitmq，目前负责消息队列相关工作开发。\n 10. 熟练掌握elasticsearch api，深入理解elasticsearch底层原理，了解elasticsearch集群运维，读过部分elasticsearch源码。\n 11. 读过netty源码，了解netty池化内存管理，有小米新零售直播开发经验。\n 12. 熟练使用linux操作系统，docker，jenkins等cicd相关工具。\n 13. 了解http与https协议原理，序列化与反序列化原理，rpc通信原理，熟悉分布式微服务架构，掌握分布式事务解决方案。\n 14. 熟练使用jira，asana等项目流程管理工具，熟练使用markdown，word，excel，ppt等工具。\n\n----------------------------------------\n\n\n# 工作履历\n\n 1. 2020.11-2022.06 小米新零售技术部\n 2. 2022.07- zoom asyncmq\n\n----------------------------------------\n\n\n# 项目经验\n\n 1. 小米新零售-零售通\n 2. zoom消息队列-asyncmq\n\n----------------------------------------\n\n\n# 教育背景\n\n学校名称     专业         就读时间        学位\n齐齐哈尔大学   计算机科学与技术   2017~2021   本科\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"SublimeText3",frontmatter:{title:"SublimeText3",date:"2023-01-01T00:00:00.000Z",tags:["Mac","日常开发"],categories:["Mac"],description:"SublimeText3",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/1c1021ad-9e46-3426-be54-98f2d02a1fa5/"},regularPath:"/09.%E6%97%A5%E5%B8%B8%E5%BC%80%E5%8F%91/00.Mac%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8/00.SublimeText3%E9%9A%8F%E6%89%8B%E8%AE%B0.html",relativePath:"09.日常开发/00.Mac日常使用/00.SublimeText3随手记.md",key:"v-c41b9cfa",path:"/pages/1c1021ad-9e46-3426-be54-98f2d02a1fa5/",headers:[{level:2,title:"1.安装配置",slug:"_1-安装配置",normalizedTitle:"1.安装配置",charIndex:112},{level:3,title:"1.1 设置显示侧边栏",slug:"_1-1-设置显示侧边栏",normalizedTitle:"1.1 设置显示侧边栏",charIndex:153},{level:2,title:"![](/images/Mac/SublimeText3随手记/01.png)",slug:"images-mac-sublimetext3随手记-01-png",normalizedTitle:'<img src="/images/mac/sublimetext3%e9%9a%8f%e6%89%8b%e8%ae%b0/01.png" alt="">',charIndex:null},{level:3,title:"1.2 显示上边栏",slug:"_1-2-显示上边栏",normalizedTitle:"1.2 显示上边栏",charIndex:173},{level:3,title:"1.3 字体名称和大小",slug:"_1-3-字体名称和大小",normalizedTitle:"1.3 字体名称和大小",charIndex:231},{level:2,title:"2.插件配置",slug:"_2-插件配置",normalizedTitle:"2.插件配置",charIndex:291},{level:3,title:"2.1 安装Package Control",slug:"_2-1-安装package-control",normalizedTitle:"2.1 安装package control",charIndex:302},{level:3,title:"2.1 右侧边栏插件",slug:"_2-1-右侧边栏插件",normalizedTitle:"2.1 右侧边栏插件",charIndex:372},{level:3,title:"2.3 安装Theme-Soda 插件",slug:"_2-3-安装theme-soda-插件",normalizedTitle:"2.3 安装theme-soda 插件",charIndex:431}],headersStr:"1.安装配置 1.1 设置显示侧边栏 ![](/images/Mac/SublimeText3随手记/01.png) 1.2 显示上边栏 1.3 字体名称和大小 2.插件配置 2.1 安装Package Control 2.1 右侧边栏插件 2.3 安装Theme-Soda 插件",content:"Sublime Text 3 ,类似于Windows记事本，官网地址:https://www.sublimetext.com/3。\n\n----------------------------------------\n\n\n# 1.安装配置\n\n安装过程基本无脑干就行，主要记录下安装完之后的一些配置。\n\n\n# 1.1 设置显示侧边栏\n\n\n#\n\n\n# 1.2 显示上边栏\n\n\n\n----------------------------------------\n\n\n# 1.3 字体名称和大小\n\n\n\n----------------------------------------\n\n\n# 2.插件配置\n\n\n# 2.1 安装Package Control\n\n\n\n----------------------------------------\n\n\n# 2.1 右侧边栏插件\n\n\n\n----------------------------------------\n\n\n# 2.3 安装Theme-Soda 插件\n\n\n\n----------------------------------------",normalizedContent:"sublime text 3 ,类似于windows记事本，官网地址:https://www.sublimetext.com/3。\n\n----------------------------------------\n\n\n# 1.安装配置\n\n安装过程基本无脑干就行，主要记录下安装完之后的一些配置。\n\n\n# 1.1 设置显示侧边栏\n\n\n#\n\n\n# 1.2 显示上边栏\n\n\n\n----------------------------------------\n\n\n# 1.3 字体名称和大小\n\n\n\n----------------------------------------\n\n\n# 2.插件配置\n\n\n# 2.1 安装package control\n\n\n\n----------------------------------------\n\n\n# 2.1 右侧边栏插件\n\n\n\n----------------------------------------\n\n\n# 2.3 安装theme-soda 插件\n\n\n\n----------------------------------------",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"去除桌面的硬盘图标",frontmatter:{title:"去除桌面的硬盘图标",date:"2023-01-01T00:00:00.000Z",tags:["Mac","日常开发"],categories:["Mac"],description:"去除桌面的硬盘图标",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/6b6ad1f6-ccb5-397f-8ca8-29b053ff97e2/"},regularPath:"/09.%E6%97%A5%E5%B8%B8%E5%BC%80%E5%8F%91/00.Mac%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8/01.%E5%8E%BB%E9%99%A4%E6%A1%8C%E9%9D%A2%E7%9A%84%E7%A1%AC%E7%9B%98%E5%9B%BE%E6%A0%87.html",relativePath:"09.日常开发/00.Mac日常使用/01.去除桌面的硬盘图标.md",key:"v-3c49f337",path:"/pages/6b6ad1f6-ccb5-397f-8ca8-29b053ff97e2/",headers:[{level:2,title:"方法一",slug:"方法一",normalizedTitle:"方法一",charIndex:2},{level:2,title:"方法二",slug:"方法二",normalizedTitle:"方法二",charIndex:71}],headersStr:"方法一 方法二",content:"# 方法一\n\n进入访达设置，按照下面的图片设置。\n\n----------------------------------------\n\n\n# 方法二\n\n终端命令\n\ndefaultswritecom.apple.finderCreateDesktop-boolfalse\n\nkillallFinder\n\n\n1\n2\n3\n\n\n想再次显示回来？\n\ndefaultswritecom.apple.finderCreateDesktop-booltrue\n\nkillallFinder\n\n\n1\n2\n3\n",normalizedContent:"# 方法一\n\n进入访达设置，按照下面的图片设置。\n\n----------------------------------------\n\n\n# 方法二\n\n终端命令\n\ndefaultswritecom.apple.findercreatedesktop-boolfalse\n\nkillallfinder\n\n\n1\n2\n3\n\n\n想再次显示回来？\n\ndefaultswritecom.apple.findercreatedesktop-booltrue\n\nkillallfinder\n\n\n1\n2\n3\n",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"安装JProfiler",frontmatter:{title:"安装JProfiler",date:"2023-01-01T00:00:00.000Z",tags:["Mac","日常开发"],categories:["Mac"],description:"安装JProfiler",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/b719f0b3-c7e1-303b-ae66-cbd44c17c1c5/"},regularPath:"/09.%E6%97%A5%E5%B8%B8%E5%BC%80%E5%8F%91/00.Mac%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8/02.%E5%AE%89%E8%A3%85Jprofiler.html",relativePath:"09.日常开发/00.Mac日常使用/02.安装Jprofiler.md",key:"v-0b1d5734",path:"/pages/b719f0b3-c7e1-303b-ae66-cbd44c17c1c5/",headersStr:null,content:"下载地址\n\n激活码Follow备忘录。",normalizedContent:"下载地址\n\n激活码follow备忘录。",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"文件夹显示隐藏文件",frontmatter:{title:"文件夹显示隐藏文件",date:"2023-01-01T00:00:00.000Z",tags:["Mac","日常开发"],categories:["Mac"],description:"文件夹显示隐藏文件",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/77b8e011-088b-3337-bc78-1694d12258e7/"},regularPath:"/09.%E6%97%A5%E5%B8%B8%E5%BC%80%E5%8F%91/00.Mac%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8/03.%E6%96%87%E4%BB%B6%E5%A4%B9%E6%98%BE%E7%A4%BA%E9%9A%90%E8%97%8F%E6%96%87%E4%BB%B6.html",relativePath:"09.日常开发/00.Mac日常使用/03.文件夹显示隐藏文件.md",key:"v-535a8cba",path:"/pages/77b8e011-088b-3337-bc78-1694d12258e7/",headersStr:null,content:"command + shift键 + .",normalizedContent:"command + shift键 + .",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"解决鼠标滚轮上下翻转",frontmatter:{title:"解决鼠标滚轮上下翻转",date:"2023-01-01T00:00:00.000Z",tags:["Mac","日常开发"],categories:["Mac"],description:"解决鼠标滚轮上下翻转",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/64b132ef-4cde-3692-9a03-b3f0e7841561/"},regularPath:"/09.%E6%97%A5%E5%B8%B8%E5%BC%80%E5%8F%91/00.Mac%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8/04.%E8%A7%A3%E5%86%B3%E9%BC%A0%E6%A0%87%E6%BB%9A%E8%BD%AE%E4%B8%8A%E4%B8%8B%E7%BF%BB%E8%BD%AC.html",relativePath:"09.日常开发/00.Mac日常使用/04.解决鼠标滚轮上下翻转.md",key:"v-0e63a70b",path:"/pages/64b132ef-4cde-3692-9a03-b3f0e7841561/",headersStr:null,content:"下载软件 Scroll reverser",normalizedContent:"下载软件 scroll reverser",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"配置ZSH",frontmatter:{title:"配置ZSH",date:"2023-01-01T00:00:00.000Z",tags:["Mac","日常开发"],categories:["Mac"],description:"配置ZSH",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/723e2b0a-de27-32e9-9704-f57ba9e27c73/"},regularPath:"/09.%E6%97%A5%E5%B8%B8%E5%BC%80%E5%8F%91/00.Mac%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8/05.%E9%85%8D%E7%BD%AEZSH.html",relativePath:"09.日常开发/00.Mac日常使用/05.配置ZSH.md",key:"v-2a6c0621",path:"/pages/723e2b0a-de27-32e9-9704-f57ba9e27c73/",headers:[{level:2,title:"1.zsh安装",slug:"_1-zsh安装",normalizedTitle:"1.zsh安装",charIndex:2},{level:2,title:"2.oh-my-zsh",slug:"_2-oh-my-zsh",normalizedTitle:"2.oh-my-zsh",charIndex:556},{level:3,title:"2.1 安装",slug:"_2-1-安装",normalizedTitle:"2.1 安装",charIndex:572},{level:3,title:"2.2 简单使用",slug:"_2-2-简单使用",normalizedTitle:"2.2 简单使用",charIndex:1900},{level:2,title:"3.终端提示插件和高亮插件",slug:"_3-终端提示插件和高亮插件",normalizedTitle:"3.终端提示插件和高亮插件",charIndex:2131},{level:3,title:"3.1 终端提示插件",slug:"_3-1-终端提示插件",normalizedTitle:"3.1 终端提示插件",charIndex:2149},{level:3,title:"3.2 终端高亮插件",slug:"_3-2-终端高亮插件",normalizedTitle:"3.2 终端高亮插件",charIndex:2570},{level:3,title:"3.3 自定义终端快捷命令",slug:"_3-3-自定义终端快捷命令",normalizedTitle:"3.3 自定义终端快捷命令",charIndex:2789},{level:3,title:"3.4 设置命令输入行样式",slug:"_3-4-设置命令输入行样式",normalizedTitle:"3.4 设置命令输入行样式",charIndex:2977}],headersStr:"1.zsh安装 2.oh-my-zsh 2.1 安装 2.2 简单使用 3.终端提示插件和高亮插件 3.1 终端提示插件 3.2 终端高亮插件 3.3 自定义终端快捷命令 3.4 设置命令输入行样式",content:'# 1.zsh安装\n\nMacOS一般自带了ZSH，但是不是最新版本，如果需要最新版本可以通过Homebrew来安装。\n\nbrew install zsh zsh-completions\n\n\n1\n\n\n> rpm包和deb包是两种Linux系统下最常见的安装包格式。rpm包主要应用在RedHat系列包括 Fedora等发行版的Linux系统上，deb包主要应用于Debian系列包括现在比较流行的Ubuntu等发行版上。\n\n> \n\nyum命令是在Fedora和RedHat以及SUSE中基于rpm的软件包管理器，它可以使系统管理人员交互和自动化地更细与管理RPM软件包，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。\n\n> apt-get命令是Debian Linux发行版中的APT软件包管理工具。所有基于Debian的发行都使用这个包管理系统。deb包可以把一个应用的文件包在一起，大体就如同Windows上的安装文件。(更多关于apt和apt-get )\n\n一些乱七八糟的设置： Follow the screenshot below\n\n----------------------------------------\n\n\n# 2.oh-my-zsh\n\n\n# 2.1 安装\n\n安装 oh my zsh 之前必须安装zsh，否则会收到如下提示：Zsh is not installed! Please install zsh first!\n\n#方法一：wget方式自动化安装oh my zsh：\n$ wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh\n\n#方法二：\n$ curl -L https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh | sh \n\n#官网上的另外一种写法 \n$ sh -c "$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)"\n$ sh -c "$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)"\n\n#方法三：当然也可以通过git下载 \n$ git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh                       \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nwget，Linux命令，用来从指定的URL下载文件。mac使用这个命令，需要安装：brew install wget。\n\n * $ wget(选项)(参数)\n * $ wget url 下载一个文件到当前目录\n * $ wget url -O - 在终端展示文件内容\n\n> -O -在终端展示文件内容 Saving to: “STDOUT”。stdout,标准输出，默认将信息输出到终端，在默认情况下，stdout是行缓冲的，他的输出会放在一个buffer里面，只有到换行的时候，才会输出到屏幕。\n\n> curl，linux命令，是一种命令行工具，作用是发出网络请求，然后得到和提取数据，显示在"标准输出" （stdout）上面。它被广泛应用在Unix、多种Linux发行版中，并且有DOS和Win32、Win64下的移植版本,已经是苹果机上内置的命令行工具之一了。window上的安装和使用参考 或这里。\n\n> sh命令是shell命令语言解释器，执行命令从标准输入读取或从一个文件中读取。通过用户输入命令，和内核进行沟通！\n\n$ sh [options] [file]  -c string    //命令从-c后的字符串读取。\n\n\n1\n\n\n在执行脚本的时候是用sh + 脚本名的方式来执行，其实，大部分的时候，简单脚本只要权限设置正确，可以直接执行，不需要sh命令的。\n\n| ,Linux管道符，利用管道符将两个命令隔开，管道符左边命令的输出就会作为管道符右边命令的输入。\n\n----------------------------------------\n\n\n# 2.2 简单使用\n\n 1. 查看什么主题可以使用\n\nls ~/.oh-my-zsh/themes\n\n\n1\n\n 2. Oh-My-Zsh的默认配置文件在：~/.zshrc。编辑~/.zshrc修改主题，默认情况下，使用的是robbyrussell主题。\n\n> 重启终端后有效或者使用source ~/.zshrc更新配置。\n\nZSH_THEME="amuse"\n\n\n1\n\n\n----------------------------------------\n\n\n# 3.终端提示插件和高亮插件\n\n\n# 3.1 终端提示插件\n\nFor Example: 补全提示按键：->。\n\n 1. 打开终端，复制下面指令下载自动提示插件zsh-autosuggestions\n\ngit clone https://gitee.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n\n\n1\n\n 2. 进入.zshrc文件的可编辑模式\n\nvim ~/.zshrc\n\n\n1\n\n 3. 找到plugins 在后面追加 逗号分割，逗号前后需要有间距\n\nplugins=(\n  git ,\n  zsh-autosuggestions\n)\n\n\n1\n2\n3\n4\n\n 4. 重新加载~/.zshrc\n\nsource ~/.zshrc\n\n\n1\n\n\n----------------------------------------\n\n\n# 3.2 终端高亮插件\n\n 1. 安装高亮语法插件\n\ngit clone https://gitee.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n\n1\n\n\n其余步骤同上。\n\n----------------------------------------\n\n\n# 3.3 自定义终端快捷命令\n\n语法格式：\n\nalias aCommandAlias=\'xxxxxx\'\n\n# 例如新建git push快捷命令:\nalias gp=\'git push origin xxx\'\n\n\n1\n2\n3\n4\n\n\n直接在~/.zshrc 文件下面添加alias别名。\n\n----------------------------------------\n\n\n# 3.4 设置命令输入行样式\n\nFor Example：\n\n 1. 查看当前值，然后备份。\n\necho $PROMPT\n\n\n1\n\n 2. 确定好当前使用的主题，然后修改对应主题的配置文件。\n\ncd ~/.oh-my-zsh/themes\nvim amuse.zsh-theme\n\n\n1\n2\n\n 3. 替换PROMPT\n\nPROMPT=\'👨 %{$fg_bold[green]%}%n%{$reset_color%} 📌  %{$fg_bold[green]%}%~%{$reset_color%}$(git_prompt_info)$(virtualenv_prompt_info) ⌚ %{$fg_bold[red]%}%D %*%{$reset_color%}\n$ \'\n\n\n1\n2\n\n\n\n\n----------------------------------------',normalizedContent:'# 1.zsh安装\n\nmacos一般自带了zsh，但是不是最新版本，如果需要最新版本可以通过homebrew来安装。\n\nbrew install zsh zsh-completions\n\n\n1\n\n\n> rpm包和deb包是两种linux系统下最常见的安装包格式。rpm包主要应用在redhat系列包括 fedora等发行版的linux系统上，deb包主要应用于debian系列包括现在比较流行的ubuntu等发行版上。\n\n> \n\nyum命令是在fedora和redhat以及suse中基于rpm的软件包管理器，它可以使系统管理人员交互和自动化地更细与管理rpm软件包，能够从指定的服务器自动下载rpm包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。\n\n> apt-get命令是debian linux发行版中的apt软件包管理工具。所有基于debian的发行都使用这个包管理系统。deb包可以把一个应用的文件包在一起，大体就如同windows上的安装文件。(更多关于apt和apt-get )\n\n一些乱七八糟的设置： follow the screenshot below\n\n----------------------------------------\n\n\n# 2.oh-my-zsh\n\n\n# 2.1 安装\n\n安装 oh my zsh 之前必须安装zsh，否则会收到如下提示：zsh is not installed! please install zsh first!\n\n#方法一：wget方式自动化安装oh my zsh：\n$ wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -o - | sh\n\n#方法二：\n$ curl -l https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh | sh \n\n#官网上的另外一种写法 \n$ sh -c "$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -o -)"\n$ sh -c "$(curl -fssl https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)"\n\n#方法三：当然也可以通过git下载 \n$ git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh                       \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nwget，linux命令，用来从指定的url下载文件。mac使用这个命令，需要安装：brew install wget。\n\n * $ wget(选项)(参数)\n * $ wget url 下载一个文件到当前目录\n * $ wget url -o - 在终端展示文件内容\n\n> -o -在终端展示文件内容 saving to: “stdout”。stdout,标准输出，默认将信息输出到终端，在默认情况下，stdout是行缓冲的，他的输出会放在一个buffer里面，只有到换行的时候，才会输出到屏幕。\n\n> curl，linux命令，是一种命令行工具，作用是发出网络请求，然后得到和提取数据，显示在"标准输出" （stdout）上面。它被广泛应用在unix、多种linux发行版中，并且有dos和win32、win64下的移植版本,已经是苹果机上内置的命令行工具之一了。window上的安装和使用参考 或这里。\n\n> sh命令是shell命令语言解释器，执行命令从标准输入读取或从一个文件中读取。通过用户输入命令，和内核进行沟通！\n\n$ sh [options] [file]  -c string    //命令从-c后的字符串读取。\n\n\n1\n\n\n在执行脚本的时候是用sh + 脚本名的方式来执行，其实，大部分的时候，简单脚本只要权限设置正确，可以直接执行，不需要sh命令的。\n\n| ,linux管道符，利用管道符将两个命令隔开，管道符左边命令的输出就会作为管道符右边命令的输入。\n\n----------------------------------------\n\n\n# 2.2 简单使用\n\n 1. 查看什么主题可以使用\n\nls ~/.oh-my-zsh/themes\n\n\n1\n\n 2. oh-my-zsh的默认配置文件在：~/.zshrc。编辑~/.zshrc修改主题，默认情况下，使用的是robbyrussell主题。\n\n> 重启终端后有效或者使用source ~/.zshrc更新配置。\n\nzsh_theme="amuse"\n\n\n1\n\n\n----------------------------------------\n\n\n# 3.终端提示插件和高亮插件\n\n\n# 3.1 终端提示插件\n\nfor example: 补全提示按键：->。\n\n 1. 打开终端，复制下面指令下载自动提示插件zsh-autosuggestions\n\ngit clone https://gitee.com/zsh-users/zsh-autosuggestions ${zsh_custom:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n\n\n1\n\n 2. 进入.zshrc文件的可编辑模式\n\nvim ~/.zshrc\n\n\n1\n\n 3. 找到plugins 在后面追加 逗号分割，逗号前后需要有间距\n\nplugins=(\n  git ,\n  zsh-autosuggestions\n)\n\n\n1\n2\n3\n4\n\n 4. 重新加载~/.zshrc\n\nsource ~/.zshrc\n\n\n1\n\n\n----------------------------------------\n\n\n# 3.2 终端高亮插件\n\n 1. 安装高亮语法插件\n\ngit clone https://gitee.com/zsh-users/zsh-syntax-highlighting.git ${zsh_custom:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n\n1\n\n\n其余步骤同上。\n\n----------------------------------------\n\n\n# 3.3 自定义终端快捷命令\n\n语法格式：\n\nalias acommandalias=\'xxxxxx\'\n\n# 例如新建git push快捷命令:\nalias gp=\'git push origin xxx\'\n\n\n1\n2\n3\n4\n\n\n直接在~/.zshrc 文件下面添加alias别名。\n\n----------------------------------------\n\n\n# 3.4 设置命令输入行样式\n\nfor example：\n\n 1. 查看当前值，然后备份。\n\necho $prompt\n\n\n1\n\n 2. 确定好当前使用的主题，然后修改对应主题的配置文件。\n\ncd ~/.oh-my-zsh/themes\nvim amuse.zsh-theme\n\n\n1\n2\n\n 3. 替换prompt\n\nprompt=\'👨 %{$fg_bold[green]%}%n%{$reset_color%} 📌  %{$fg_bold[green]%}%~%{$reset_color%}$(git_prompt_info)$(virtualenv_prompt_info) ⌚ %{$fg_bold[red]%}%d %*%{$reset_color%}\n$ \'\n\n\n1\n2\n\n\n\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"访达隐藏文件显示",frontmatter:{title:"访达隐藏文件显示",date:"2023-01-01T00:00:00.000Z",tags:["Mac","日常开发"],categories:["Mac"],description:"访达隐藏文件显示",toc_number:!1,author:{name:"huidong.yin",link:"https://huidongyin.github.io"},permalink:"/pages/xxxxxxxxxx/"},regularPath:"/09.%E6%97%A5%E5%B8%B8%E5%BC%80%E5%8F%91/00.Mac%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8/06.%E8%AE%BF%E8%BE%BE%E9%9A%90%E8%97%8F%E6%96%87%E4%BB%B6%E6%98%BE%E7%A4%BA.html",relativePath:"09.日常开发/00.Mac日常使用/06.访达隐藏文件显示.md",key:"v-5fa503ff",path:"/pages/xxxxxxxxxx/",headersStr:null,content:"参考下图：\n\n",normalizedContent:"参考下图：\n\n",charsets:{cjk:!0},lastUpdated:"2023/11/04, 13:58:20",lastUpdatedTimestamp:16990775e5},{title:"标签",frontmatter:{tagsPage:!0,title:"标签",permalink:"/tags/",article:!1},regularPath:"/@pages/tagsPage.html",relativePath:"@pages/tagsPage.md",key:"v-240b277f",path:"/tags/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/15, 14:28:18",lastUpdatedTimestamp:1657866498e3},{title:"专栏",frontmatter:{categoriesPage:!0,title:"专栏",permalink:"/categories/",article:!1},regularPath:"/@pages/categoriesPage.html",relativePath:"@pages/categoriesPage.md",key:"v-46ec5342",path:"/categories/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/11/04, 10:52:44",lastUpdatedTimestamp:1699066364e3},{title:"Home",frontmatter:{home:!0,actionText:"开始 →",actionLink:"/archives/",heroText:"Java essay",tagline:"最大的资本不是经验丰富、胸有成竹，而是敢于做梦、勇于试错。",features:[{title:"Java主流技术生态圈",details:"Java基础、Spring全家桶，SpringBoot，Mybatis，面试八股文等"},{title:"分布式微服务架构",details:"SpringCloud，CloudAlibaba，Dubbo等主流微服务框架，设计高并发高可用架构。"},{title:"技术人成长进阶路线",details:"以技术为基石，思维升级，提高技术修养，进阶架构，项目管理。",footer:"Copyright © Mr.Fire"}]},regularPath:"/",relativePath:"README.md",key:"v-1bb1d17c",path:"/",headersStr:null,content:"✨✨✨\n\n学习三部曲\n\n每当我们接触一个新的技术时，我们都应该去思考的三个问题，是什么，怎么用，为什么这样设计，即what，how，why。从这三方面入手，当完成最后一步时，你已经对他非常熟悉了。\n\n来自 Mr.Fire",normalizedContent:"✨✨✨\n\n学习三部曲\n\n每当我们接触一个新的技术时，我们都应该去思考的三个问题，是什么，怎么用，为什么这样设计，即what，how，why。从这三方面入手，当完成最后一步时，你已经对他非常熟悉了。\n\n来自 mr.fire",charsets:{cjk:!0},lastUpdated:"2023/03/01, 22:17:09",lastUpdatedTimestamp:1677680229e3},{title:"归档",frontmatter:{archivesPage:!0,title:"归档",permalink:"/archives/",article:!1},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-66aca7ff",path:"/archives/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/15, 14:28:18",lastUpdatedTimestamp:1657866498e3}],themeConfig:{logo:"/img/code.gif",lastUpdated:"lastUpdateTime",smoothScroll:!0,sidebarDepth:2,nav:[{text:"Java基础",items:[{text:"JavaSE",link:"/pages/aboutme/"},{text:"并发编程",link:"/pages/aboutme/"},{text:"JavaWeb",link:"/pages/aboutme/"},{text:"版本新特性",link:"/pages/aboutme/"}]},{text:"Spring全家桶",items:[{text:"Spring",link:"/pages/aboutme/"},{text:"SpringMvc",link:"/pages/aboutme/"},{text:"Mybatis",link:"/pages/aboutme/"},{text:"SpringBoot",link:"/pages/aboutme/"},{text:"SpringCloud",link:"/pages/aboutme/"},{text:"Dubbo",link:"/pages/aboutme/"},{text:"Zookeeper",link:"/pages/aboutme/"},{text:"Netty",link:"/pages/aboutme/"},{text:"Tomcat",link:"/pages/aboutme/"}]},{text:"消息队列",items:[{text:"Kafka",link:"/pages/c8412896-0c96-3cef-8d32-94dcb1852140/"},{text:"RocketMQ",link:"/pages/aboutme"},{text:"RabbitMQ",link:"/pages/aboutme"}]},{text:"数据库",items:[{text:"MySQL",link:"/pages/aboutme"},{text:"Redis",link:"/pages/aboutme"}]},{text:"微服务架构",items:[{text:"架构演进",link:"/pages/aboutme"},{text:"分布式事务",link:"/pages/aboutme"},{text:"设计模式",link:"/pages/aboutme"},{text:"领域驱动设计",link:"/pages/aboutme"}]},{text:"搜索引擎",items:[{text:"ElasticSearch",link:"/pages/aboutme"}]},{text:"JVM",link:"/"},{text:"云计算",items:[{text:"Docker",link:"/pages/aboutme"}]},{text:"AboutMe",items:[{text:"个人简历",link:"/pages/aboutme/"},{text:"项目经验",link:"/pages/a2a9d5e6-b580-3ee0-b2c2-5b1557852fd5/"}]}],searchMaxSuggestions:10,editLinks:!1,editLinkText:"edit",sidebar:{"/00.AboutMe/":[["01.个人简历.md","About Me","/pages/aboutme/"],{title:"项目经验",collapsable:!0,children:[["02.项目经验/00.小米新零售BI数据领域建设思考与沉淀.md","小米新零售BI数据领域建设思考与沉淀","/pages/a2a9d5e6-b580-3ee0-b2c2-5b1557852fd5/"]]}],catalogue:{},"/01.Java基础/":[{title:"JavaSE",collapsable:!0,children:[["00.JavaSE/01.xxx.md","About Me","/pages/1/"]]},{title:"并发编程",collapsable:!0,children:[["01.并发编程/01.xxx.md","About Me","/pages/2/"]]},{title:"JavaWeb",collapsable:!0,children:[["02.JavaWeb/01.xxx.md","About Me","/pages/3/"]]},{title:"版本新特性",collapsable:!0,children:[["03.版本新特性/01.xxx.md","About Me","/pages/4/"]]}],"/02.Spring全家桶/":[{title:"Spring",collapsable:!0,children:[["00.Spring/01.xxx.md","About Me","/pages/11/"]]},{title:"SpringMvc",collapsable:!0,children:[["01.SpringMvc/01.xxx.md","About Me","/pages/12/"]]},{title:"Mybatis",collapsable:!0,children:[["02.Mybatis/01.xxx.md","About Me","/pages/13/"]]},{title:"SpringBoot",collapsable:!0,children:[["03.SpringBoot/01.xxx.md","About Me","/pages/14/"]]},{title:"SpringCloud",collapsable:!0,children:[["04.SpringCloud/01.xxx.md","About Me","/pages/15/"]]},{title:"Dubbo",collapsable:!0,children:[["05.Dubbo/01.xxx.md","About Me","/pages/16/"]]},{title:"Zookeeper",collapsable:!0,children:[["06.Zookeeper/01.xxx.md","About Me","/pages/17/"]]},{title:"Netty",collapsable:!0,children:[["07.Netty/01.xxx.md","About Me","/pages/18/"]]},{title:"Tomcat",collapsable:!0,children:[["08.Tomcat/01.xxx.md","About Me","/pages/19/"]]}],"/03.消息队列/":[{title:"Kafka",collapsable:!0,children:[["00.Kafka/1.Kafka入门.md","Kafka入门","/pages/c8412896-0c96-3cef-8d32-94dcb1852140/"],["00.Kafka/2.生产者-客户端开发.md","生产者-客户端开发","/pages/00e44d72-3af4-33ec-95aa-573c4e2603b1/"],["00.Kafka/3.生产者-原理分析.md","生产者-原理分析","/pages/517a0a21-c440-3dd1-9e5e-a00d7a7fc18a/"],["00.Kafka/4.消费者-消费者&消费者组.md","消费者-消费者&消费者组","/pages/c4ec1b4a-45f6-3fd7-8faf-7af762dfb0ed/"],["00.Kafka/5.消费者-客户端开发-消费逻辑.md","消费者-客户端开发-消费逻辑","/pages/6a99e6af-7333-3944-94f1-6a8a3a84a946/"],["00.Kafka/6.消费者-客户端开发-位点提交.md","消费者-客户端开发-位点提交","/pages/0768d08c-72ff-34e7-aada-50c4eecb08b5/"],["00.Kafka/7.消费者-客户端开发-指定位点消费.md","消费者-客户端开发-指定消费位点","/pages/5ab26239-f80c-3f5e-affc-fc2c33f5178f/"],["00.Kafka/8.消费者-客户端开发-Rebalance.md","消费者-客户端开发-Rebalance","/pages/2b4b8b25-552c-374f-9419-12d2c51dbeb1/"],["00.Kafka/9.消费者-客户端开发-拦截器.md","消费者-客户端开发-拦截器","/pages/40f82a04-0969-342d-8b82-bb27281bb7e0/"],["00.Kafka/10.消费者-客户端开发-多线程实现.md","消费者-客户端开发-多线程实现","/pages/278cdef6-836b-3904-aa7f-a51df28ee2da/"],["00.Kafka/11.消费者-客户端开发-参数说明.md","消费者-客户端开发-参数说明","/pages/7ece0102-a50f-3e0c-be18-9f58eb0723e1/"],["00.Kafka/12.主题-主题管理.md","主题-主题管理","/pages/dbe6fcd9-6490-3b92-804a-ea7117ef815d/"],["00.Kafka/13.主题-KafkaAdminClient.md","主题-kafkaAdminClient","/pages/b94bdb82-9532-3582-8bb7-19f2bc7e5c4f/"],["00.Kafka/14.分区-分区管理.md","分区-分区管理","/pages/14a08dc7-2466-3341-b742-a0ba9b8b26c3/"],["00.Kafka/15.分区-如何选择合适的分区数.md","分区-如何选择合适的分区数","/pages/bd36a2fb-82ce-3f34-bf5a-91f5703e12a6/"]]},{title:"RocketMQ",collapsable:!0,children:[["01.RocketMQ/01.xxx.md","About Me","/pages/20/"]]},{title:"RabbitMQ",collapsable:!0,children:[["02.RabbitMQ/01.xxx.md","About Me","/pages/21/"]]}],"/04.数据库/":[{title:"MySQL",collapsable:!0,children:[["00.MySQL/01.xxx.md","About Me","/pages/22/"]]},{title:"Redis",collapsable:!0,children:[["01.Redis/01.xxx.md","About Me","/pages/23/"]]}],"/05.微服务架构/":[{title:"架构演进",collapsable:!0,children:[["00.架构演进/01.xxx.md","About Me","/pages/24/"]]},{title:"分布式事务",collapsable:!0,children:[["01.分布式事务/01.xxx.md","About Me","/pages/25/"]]},{title:"设计模式",collapsable:!0,children:[["02.设计模式/01.xxx.md","About Me","/pages/26/"]]},{title:"领域驱动设计",collapsable:!0,children:[["03.领域驱动设计/01.xxx.md","About Me","/pages/27/"]]}],"/06.搜索引擎/":[{title:"ElasticSearch",collapsable:!0,children:[["00.ElasticSearch/01.xxx.md","About Me","/pages/28/"]]}],"/07.JVM/":[["01.xxx.md","About Me","/pages/29/"]],"/08.云计算/":[{title:"Docker",collapsable:!0,children:[["00.Docker/01.xxx.md","About Me","/pages/30/"]]}],"/09.日常开发/":[{title:"Mac日常使用",collapsable:!0,children:[["00.Mac日常使用/00.SublimeText3随手记.md","SublimeText3","/pages/1c1021ad-9e46-3426-be54-98f2d02a1fa5/"],["00.Mac日常使用/01.去除桌面的硬盘图标.md","去除桌面的硬盘图标","/pages/6b6ad1f6-ccb5-397f-8ca8-29b053ff97e2/"],["00.Mac日常使用/02.安装Jprofiler.md","安装JProfiler","/pages/b719f0b3-c7e1-303b-ae66-cbd44c17c1c5/"],["00.Mac日常使用/03.文件夹显示隐藏文件.md","文件夹显示隐藏文件","/pages/77b8e011-088b-3337-bc78-1694d12258e7/"],["00.Mac日常使用/04.解决鼠标滚轮上下翻转.md","解决鼠标滚轮上下翻转","/pages/64b132ef-4cde-3692-9a03-b3f0e7841561/"],["00.Mac日常使用/05.配置ZSH.md","配置ZSH","/pages/723e2b0a-de27-32e9-9704-f57ba9e27c73/"],["00.Mac日常使用/06.访达隐藏文件显示.md","访达隐藏文件显示","/pages/xxxxxxxxxx/"]]}]},author:{name:"huidong.yin",link:"https://huidongyin.github.io"},blogger:{avatar:"/img/code.gif",name:"huidong.yin",slogan:"我不是大佬"},categoryText:"随笔",social:{icons:[{iconClass:"icon-youjian",title:"发邮件",link:"mailto:huidong.yin247203@gamil.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/huidongyin/"},{iconClass:"icon-gitee",title:"Gitee",link:"https://gitee.com/yin_huidong/"},{iconClass:"icon-erji",title:"听音乐",link:"https://music.163.com/#/playlist?id=755597173"}]},footer:{createYear:2023,copyrightInfo:'huidong.yin | <a href="https://huidongyin.github.io" target="_blank">MIT License</a>'},extendFrontmatter:{author:{name:"huidong.yin",link:"https://huidongyin.github.io"}},htmlModules:{}},locales:{"/":{lang:"zh-CN",title:"Huidong Blogs",description:"花花世界迷人眼，没有实力别赛脸。",path:"/"}}};var dc=t(97),fc=t(98),mc=t(11);var hc={computed:{$filterPosts(){return this.$site.pages.filter(n=>{const{frontmatter:{pageComponent:e,article:t,home:r}}=n;return!(e||!1===t||!0===r)})},$sortPosts(){return(n=this.$filterPosts).sort((n,e)=>{const t=n.frontmatter.sticky,r=e.frontmatter.sticky;return t&&r?t==r?Object(mc.a)(n,e):t-r:t&&!r?-1:!t&&r?1:Object(mc.a)(n,e)}),n;var n},$sortPostsByDate(){return(n=this.$filterPosts).sort((n,e)=>Object(mc.a)(n,e)),n;var n},$groupPosts(){return function(n){const e={},t={};for(let r=0,o=n.length;r<o;r++){const{frontmatter:{categories:o,tags:i}}=n[r];"array"===Object(mc.n)(o)&&o.forEach(t=>{t&&(e[t]||(e[t]=[]),e[t].push(n[r]))}),"array"===Object(mc.n)(i)&&i.forEach(e=>{e&&(t[e]||(t[e]=[]),t[e].push(n[r]))})}return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(n){const e=[],t=[];for(let t in n.categories)e.push({key:t,length:n.categories[t].length});for(let e in n.tags)t.push({key:e,length:n.tags[e].length});return{categories:e,tags:t}}(this.$groupPosts)}}};Jt.component(dc.default),Jt.component(fc.default);function gc(n){return n.toString().padStart(2,"0")}t(246);Jt.component("Badge",()=>Promise.all([t.e(0),t.e(6)]).then(t.bind(null,382))),Jt.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,97))),Jt.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,98)));t(247),t(248);function kc(n){const e=document.documentElement.getBoundingClientRect(),t=n.getBoundingClientRect();return{x:t.left-e.left,y:t.top-e.top}}t(249);var bc=t(96),vc=t.n(bc),yc=t(27);let xc,_c;var Sc;"valine"===(Sc="valine")?t.e(92).then(t.t.bind(null,374,7)).then(n=>_c=n.default):"gitalk"===Sc&&Promise.all([t.e(0),t.e(91)]).then(t.t.bind(null,375,7)).then(()=>t.e(90).then(t.t.bind(null,376,7))).then(n=>xc=n.default);function Ec(n,e){const t={};return Reflect.ownKeys(n).forEach(r=>{if("string"==typeof n[r])try{t[r]=vc.a.render(n[r],e)}catch(e){console.warn(`Comment config option error at key named "${r}"`),console.warn("More info: "+e.message),t[r]=n[r]}else t[r]=n[r]}),t}console.log(`How to use "valine" in ${yc.name}@v${yc.version}:`,yc.homepage);const wc={gitalk:{render(n,e){const t=document.createElement("div");t.id=e;document.querySelector("main.page").appendChild(t);new xc(Ec({el:"#valine-vuepress-comment",appId:"DTvjv5hjkPB9OWpEQtm275gw-gzGzoHsz",appKey:"yzMYgj5LDur92jlDvOSzcOql"},{frontmatter:n})).render(e)},clear(n){const e=document.querySelector("#"+n);return e&&e.remove(),!0}},valine:{render(n,e){const t=document.createElement("div");t.id=e;document.querySelector("main.page").appendChild(t),new _c({...Ec({el:"#valine-vuepress-comment",appId:"DTvjv5hjkPB9OWpEQtm275gw-gzGzoHsz",appKey:"yzMYgj5LDur92jlDvOSzcOql"},{frontmatter:n}),el:"#"+e})},clear(n){const e=document.querySelector("#"+n);return e&&e.remove(),!0}}};let Cc=null;function Tc(n){{let n="#valine-vuepress-comment";return n.startsWith("#")&&(n=n.slice(1)),console.log(n),wc.valine.clear(n)}}function zc(n){return!1!==n.comment&&!1!==n.comments}function Ac(n){clearTimeout(Cc);if(document.querySelector("main.page")){let e="#valine-vuepress-comment";return e.startsWith("#")&&(e=e.slice(1)),wc.valine.render(n,e)}Cc=setTimeout(()=>Ac(n),200)}var Pc={mounted(){Cc=setTimeout(()=>{const n={to:{},from:{},...this.$frontmatter};Tc()&&zc(n)&&Ac(n)},1e3),this.$router.afterEach((n,e)=>{if(n&&e&&n.path===e.path)return;const t={to:n,from:e,...this.$frontmatter};Tc()&&zc(t)&&Ac(t)})}},Oc=Object(cc.a)(Pc,(function(){return(0,this._self._c)("div")}),[],!1,null,null,null).exports,Ic=[({router:n})=>{n.beforeEach((n,e,t)=>{console.log("切换路由",n.fullPath,e.fullPath),"undefined"!=typeof _hmt&&n.path&&(_hmt.push(["_trackPageview",n.fullPath]),console.log("上报百度统计",n.fullPath)),t()})},({Vue:n,options:e,router:t,siteData:r})=>{r.pages.map(n=>{const{frontmatter:{date:e,author:t}}=n;"string"==typeof e&&"Z"===e.charAt(e.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return`${n.getUTCFullYear()}-${gc(n.getUTCMonth()+1)}-${gc(n.getUTCDate())} ${gc(n.getUTCHours())}:${gc(n.getUTCMinutes())}:${gc(n.getUTCSeconds())}`}(e)),t?n.author=t:r.themeConfig.author&&(n.author=r.themeConfig.author)}),n.mixin(hc)},{},({Vue:n})=>{n.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},({Vue:n,router:e})=>{e.options.scrollBehavior=(e,t,r)=>{if(r)return window.scrollTo({top:r.y,behavior:"smooth"});if(e.hash){if(n.$vuepress.$get("disableScrollBehavior"))return!1;const t=document.querySelector(e.hash);return!!t&&window.scrollTo({top:kc(t).y,behavior:"smooth"})}return window.scrollTo({top:0,behavior:"smooth"})}},({Vue:n})=>{n.component("Comment",Oc)}],Rc=["Comment"];class Mc extends class{constructor(){this.store=new Jt({data:{state:{}}})}$get(n){return this.store.state[n]}$set(n,e){Jt.set(this.store.state,n,e)}$emit(...n){this.store.$emit(...n)}$on(...n){this.store.$on(...n)}}{}Object.assign(Mc.prototype,{getPageAsyncComponent:as,getLayoutAsyncComponent:ss,getAsyncComponent:cs,getVueComponent:ls});var jc={install(n){const e=new Mc;n.$vuepress=e,n.prototype.$vuepress=e}};function Lc(n,e){const t=e.toLowerCase();return n.options.routes.some(n=>n.path.toLowerCase()===t)}var Bc={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(n){const e=this.pageKey||this.$parent.$page.key;return us("pageKey",e),Jt.component(e)||Jt.component(e,as(e)),Jt.component(e)?n(e):n("")}},Kc={functional:!0,props:{slotKey:String,required:!0},render:(n,{props:e,slots:t})=>n("div",{class:["content__"+e.slotKey]},t()[e.slotKey])},Nc={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Dc=(t(255),t(256),Object(cc.a)(Nc,(function(){var n=this._self._c;return n("span",[n("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[n("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),n("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),n("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),$c={functional:!0,render(n,{parent:e,children:t}){if(e._isMounted)return t;e.$once("hook:mounted",()=>{e.$forceUpdate()})}};Jt.config.productionTip=!1,Jt.use(Ua),Jt.use(jc),Jt.mixin(function(n,e,t=Jt){!function(n){n.locales&&Object.keys(n.locales).forEach(e=>{n.locales[e].path=e});Object.freeze(n)}(e),t.$vuepress.$set("siteData",e);const r=new(n(t.$vuepress.$get("siteData"))),o=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(r)),i={};return Object.keys(o).reduce((n,e)=>(e.startsWith("$")&&(n[e]=o[e].get),n),i),{computed:i}}(n=>class{setPage(n){this.__page=n}get $site(){return n}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:n={}}=this.$site;let e,t;for(const r in n)"/"===r?t=n[r]:0===this.$page.path.indexOf(r)&&(e=n[r]);return e||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:n}=this.$page.frontmatter;return"string"==typeof n&&n}get $title(){const n=this.$page,{metaTitle:e}=this.$page.frontmatter;if("string"==typeof e)return e;const t=this.$siteTitle,r=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?r?r+" | "+t:t:r||"VuePress"}get $description(){const n=function(n){if(n){const e=n.filter(n=>"description"===n.name)[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(n,e){for(let t=0;t<n.length;t++){const r=n[t];if(r.path.toLowerCase()===e.toLowerCase())return r}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},uc)),Jt.component("Content",Bc),Jt.component("ContentSlotsDistributor",Kc),Jt.component("OutboundLink",Dc),Jt.component("ClientOnly",$c),Jt.component("Layout",ss("Layout")),Jt.component("NotFound",ss("NotFound")),Jt.prototype.$withBase=function(n){const e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.10",hash:"f235d7a"},async function(n){const e="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:uc.routerBase||uc.base,t=new Ua({base:e,mode:"history",fallback:!1,routes:pc,scrollBehavior:(n,e,t)=>t||(n.hash?!Jt.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})});!function(n){n.beforeEach((e,t,r)=>{if(Lc(n,e.path))r();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){const t=e.path.replace(/\/$/,"")+".html";Lc(n,t)?r(t):r()}else r();else{const t=e.path+"/",o=e.path+".html";Lc(n,o)?r(o):Lc(n,t)?r(t):r()}})}(t);const r={};try{await Promise.all(Ic.filter(n=>"function"==typeof n).map(e=>e({Vue:Jt,options:r,router:t,siteData:uc,isServer:n})))}catch(n){console.error(n)}return{app:new Jt(Object.assign(r,{router:t,render:n=>n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},Rc.map(e=>n(e)))])})),router:t}}(!1).then(({app:n,router:e})=>{e.onReady(()=>{n.$mount("#app")})})}]);