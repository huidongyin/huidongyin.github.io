(window.webpackJsonp=window.webpackJsonp||[]).push([[55],{402:function(e,t,_){"use strict";_.r(t);var a=_(4),v=Object(a.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[e._v("在 KafkaConsumer 中，除了前面提及的4个默认的客户端参数，大部分的参数都有合理的默认值，一般我们也不需要去修改它们。不过了解这些参数可以让我们更好地使用消费者客户端，其中还有一些重要的参数涉及程序的可用性和性能，如果能够熟练掌握它们，也可以让我们在编写相关的程序时能够更好地进行性能调优与故障排查。")]),e._v(" "),t("h4",{attrs:{id:"_1-fetch-min-bytes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-fetch-min-bytes"}},[e._v("#")]),e._v(" 1) "),t("code",[e._v("fetch.min.bytes")])]),e._v(" "),t("p",[e._v("该参数用来配置 Consumer 在一次拉取请求(调用 poll()方法)中能从 Kafka 中拉取的最小数据量，默认值为 1(B)。Kafka 在收到Consumer的拉取请求时，如果返回给Consumer的数据量小于这个参数所配置的值，那么它就需要进行等待，直到数据量满足这个参数的配置大小。可以适当调大这个参数的值以提高一定的吞吐量，不过也会造成额外的延迟 (latency)，对于延迟敏感的应用可能就不可取了。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_2-fetch-max-bytes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-fetch-max-bytes"}},[e._v("#")]),e._v(" 2) "),t("code",[e._v("fetch.max.bytes")])]),e._v(" "),t("p",[e._v("该参数与 "),t("code",[e._v("fetch.min.bytes")]),e._v(" 参数对应,它用来配置 Consumer在一次拉取请求中从 Kafka中拉取的最大数据量，默认值为 52428800(B)，也就是 50MB。如果这个参数设置的值比任何一条写入 Kafka 中的消息要小，那么会不会造成无法消费呢? **该参数设定的不是绝对的最大值，如果在第一个非空分区中拉取的第一条消息大于该值,那么该消息将仍然返回，以确保消费者继续工作。**也就是说，上面问题的答案是可以正常消费。与此相关的，Kafka 中所能接收的最大消息的大小通过服务端参数 "),t("code",[e._v("message.max.bytes")]),e._v(" (对应于主题端参数 "),t("code",[e._v("max.message.bytes")]),e._v(")来设置。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_3-fetch-max-wait-ms"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-fetch-max-wait-ms"}},[e._v("#")]),e._v(" 3) "),t("code",[e._v("fetch.max.wait.ms")])]),e._v(" "),t("p",[e._v("这个参数也和 "),t("code",[e._v("fetch.min.bytes")]),e._v(" 参数有关，如果 Kafka 仅仅参考 "),t("code",[e._v("fetch.min.bytes")]),e._v("参数的要求，那么有可能会一直阻塞等待而无法发送响应给Consumer，显然这是不合理的。"),t("code",[e._v("fetch.max.wait.ms")]),e._v(" 参数用于指定 Kafka的等待时间，默认值为500 (ms)。如果 Kafka中没有足够多的消息而满足不了 "),t("code",[e._v("fetch.min.bytes")]),e._v(" 参数的要求，那么最终会等待500ms。这个参数的设定和 Consumer 与 Kafka之间的延迟也有关系，如果业务应用对延迟敏感，那么可以适当调小这个参数。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_4-max-partition-fetch-bytes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-max-partition-fetch-bytes"}},[e._v("#")]),e._v(" 4) "),t("code",[e._v("max.partition.fetch.bytes")])]),e._v(" "),t("p",[e._v("这个参数用来配置从每个分区里返回给 Consumer 的最大数据量，默认值为 1048576(B)，即 IMB。这个参数与 "),t("code",[e._v("fetch.max.bytes")]),e._v("参数相似，只不过前者用来限制一次拉取中每个分区的消息大小，而后者用来限制一次拉取中整体消息的大小。同样，如果这个参数设定的值比消息的大小要小，那么也不会造成无法消费，Kafka为了保持消费逻辑的正常运转不会对强硬的限制。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_5-max-poll-records"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-max-poll-records"}},[e._v("#")]),e._v(" 5) "),t("code",[e._v("max.poll.records")])]),e._v(" "),t("p",[e._v("这个参数用来配置 Consumer 在一次拉取请求中拉取的最大消息数，默认值为 500(条)。如果消息的大小都比较小，则可以适当调大这个参数值来提升一定的消费速度。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_6-connections-max-idle-ms"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6-connections-max-idle-ms"}},[e._v("#")]),e._v(" 6) "),t("code",[e._v("connections.max.idle.ms")])]),e._v(" "),t("p",[e._v("这个参数用来指定在多久之后关闭闲置的连接，默认值是 540000 (ms)，即 9分钟。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_7-exclude-internal-topics"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7-exclude-internal-topics"}},[e._v("#")]),e._v(" 7) "),t("code",[e._v("exclude.internal.topics")])]),e._v(" "),t("p",[e._v("Kafka 中有两个内部的主题: "),t("code",[e._v("_consumer_offsets")]),e._v(" 和 "),t("code",[e._v("_transaction_state")]),e._v("。"),t("code",[e._v("exclude.internal.topics")]),e._v("用来指定Kafka中的内部主题是否可以向消费者公开，默认值为 true。如果设置为 true，那么能使用 "),t("code",[e._v("subscribe(Collection)")]),e._v("的方式而不能使用 "),t("code",[e._v("subscribe(Pattern)")]),e._v("的方式来订阅内部主题,设置 false 则没有这个限制。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_8-receive-buffer-bytes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_8-receive-buffer-bytes"}},[e._v("#")]),e._v(" 8) "),t("code",[e._v("receive.buffer.bytes")])]),e._v(" "),t("p",[e._v("这个参数用来设置 Socket 接收消息缓冲区(SO_RECBUF)的大小，默认值为 65536(B)即 64KB。如果设置为-1，则使用操作系统的默认值。如果Consumer与 Kafka 处于不同的机房则可以适当调大这个参数值。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_9-send-buffer-bytes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_9-send-buffer-bytes"}},[e._v("#")]),e._v(" 9) "),t("code",[e._v("send.buffer.bytes")])]),e._v(" "),t("p",[e._v("这个参数用来设置 Socket 发送消息缓冲区(SO_SNDBUF)的大小，默认值为 131072(B)即 128KB。与"),t("code",[e._v("receive.buffer.bytes")]),e._v("参数一样，如果设置为-1，则使用操作系统的默认值。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_10-request-timeout-ms"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_10-request-timeout-ms"}},[e._v("#")]),e._v(" 10) "),t("code",[e._v("request.timeout.ms")])]),e._v(" "),t("p",[e._v("这个参数用来配置 Consumer 等待请求响应的最长时间，默认值为 30000(ms)。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_11-metadata-max-age-ms"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_11-metadata-max-age-ms"}},[e._v("#")]),e._v(" 11) "),t("code",[e._v("metadata.max.age.ms")])]),e._v(" "),t("p",[e._v("这个参数用来配置元数据的过期时间，默认值为 300000(ms)，即 5 分钟。如果元数据在此参数所限定的时间范围内没有进行更新，则会被强制更新，即使没有任何分区变化或有新broker加入。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_12-reconnect-backoff-ms"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_12-reconnect-backoff-ms"}},[e._v("#")]),e._v(" 12) "),t("code",[e._v("reconnect.backoff.ms")])]),e._v(" "),t("p",[e._v("这个参数用来配置尝试重新连接指定主机之前的等待时间(也称为退避时间)，避免频繁地连接主机，默认值为 50(ms)。这种机制适用于消费者向broker发送的所有请求。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_13-retry-backoff-ms"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_13-retry-backoff-ms"}},[e._v("#")]),e._v(" 13) "),t("code",[e._v("retry.backoff.ms")])]),e._v(" "),t("p",[e._v("这个参数用来配置尝试重新发送失败的请求到指定的主题分区之前的等待 (退避)时间，避免在某些故障情况下频繁地重复发送，默认值为100 (ms)。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_14-isolation-level"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_14-isolation-level"}},[e._v("#")]),e._v(" 14) "),t("code",[e._v("isolation.level")])]),e._v(" "),t("p",[e._v("这个参数用来配置消费者的事务隔离级别。字符串类型，有效值为"),t("code",[e._v("read_uncommitted")]),e._v("和"),t("code",[e._v("read_committed")]),e._v("，表示消费者所消费到的位置，如果设置为"),t("code",[e._v("read_committed")]),e._v("，那么消费者就会忽略事务未提交的消息，即只能消费到 LSO (LastStableOffset)的位置，默认情况下为"),t("code",[e._v("read_uncommitted")]),e._v("，即可以消费到 HW (High Watermark)处的位置。")]),e._v(" "),t("hr"),e._v(" "),t("h4",{attrs:{id:"_15-汇总"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_15-汇总"}},[e._v("#")]),e._v(" 15) 汇总")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("参数名称")]),e._v(" "),t("th",[e._v("默认值")]),e._v(" "),t("th",[e._v("参数释义")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("bootstrap.servers")])]),e._v(" "),t("td",[e._v('""')]),e._v(" "),t("td",[e._v("指定连接 Kafka 集群所需的broker 地址清单")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("key.deserializer")])]),e._v(" "),t("td"),e._v(" "),t("td",[e._v("消息中 key 所对应的反序列化类，需要实现"),t("code",[e._v("org.apache.kafka.common.serialization.Deserializer")]),e._v("接口")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("value.deserializer")])]),e._v(" "),t("td"),e._v(" "),t("td",[e._v("消息中 key 所对应的反序列化类，需要实现"),t("code",[e._v("org.apache.kafka.common.serialization.Deserializer")]),e._v("接口")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("group.id")])]),e._v(" "),t("td",[e._v('""')]),e._v(" "),t("td",[e._v("此消费者所隶属的消费组的唯一标识，即消费组的名称")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("client.id")])]),e._v(" "),t("td",[e._v('""')]),e._v(" "),t("td",[e._v("消费者客户端的 id")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("heartbeat.interval.ms")])]),e._v(" "),t("td",[e._v("3000")]),e._v(" "),t("td",[e._v("当使用 Kafka 的分组管理功能时，心跳到消费者协调器之间的预计时间。心跳用于确保消费者的会话保持活动状态，当有新消费者加入或离开组时方便重新平衡。该值必须比"),t("code",[e._v("session.timeout.ms")]),e._v("小，通常不高于 1/3。它可以调整得更低，以控制正常重新平衡的预期时间")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("session.timeout.ms")])]),e._v(" "),t("td",[e._v("10000")]),e._v(" "),t("td",[e._v("组管理协议中用来检测消费者是否失效的超时时间")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("max.poll.interval.ms")])]),e._v(" "),t("td",[e._v("300000")]),e._v(" "),t("td",[e._v("当通过消费组管理消费者时，该配置指定拉取消息线程最长空闲时间，若超过这个时间间隔还没有发起 poll 操作，则消费组认为该消费者已离开了消费组，将进行再均衡操作")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("auto.offset.reset")])]),e._v(" "),t("td",[e._v("latest")]),e._v(" "),t("td",[e._v("参数值为字符串类型，有效值为"),t("code",[e._v("earliest")]),e._v(" "),t("code",[e._v("latest")]),e._v(" "),t("code",[e._v("none")]),e._v("，配置为其余值会报出异常")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("enable.auto.commit")])]),e._v(" "),t("td",[e._v("true")]),e._v(" "),t("td",[e._v("boolean 类型，配置是否开启自动提交消费位点的功能，默认开启")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("auto.commit.interval.ms")])]),e._v(" "),t("td",[e._v("5000")]),e._v(" "),t("td",[e._v("当"),t("code",[e._v("enbale.auto.commit")]),e._v(" 参数设置为 true 时才生效,表示开启自动提交消费位点功能时自动提交消费位点的时间间隔")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("partition.assignment.strategy")])]),e._v(" "),t("td",[t("code",[e._v("org.apache.kafka.clients.consumer.RangeAssignor")])]),e._v(" "),t("td",[e._v("消费者的分区分配策略")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("interceptor.class")])]),e._v(" "),t("td",[e._v('""')]),e._v(" "),t("td",[e._v("用来配置消费者客户端的拦截器")])])])]),e._v(" "),t("hr")])}),[],!1,null,null,null);t.default=v.exports}}]);