---
title: 日志存储-日志清理
date: 2023-11-19 09:40:39
permalink: /pages/6d202b6e-f2ab-36fc-8783-a3ebce635b7a/
categories:
  - Kafka
tags:
  - Kafka
  - 消息队列
author: 
  name: huidong.yin
  link: https://huidongyin.github.io
---

Kafka 将消息存储在磁盘中，为了控制磁盘占用空间的不断增加就需要对消息做一定的清理操作。Kafka 中每一个分区副本都对应一个 Log，而 Log 又可以分为多个日志分段，这样也便于日志的清理操作。Kafka 提供了两种日志清理策略。

1. 日志删除(Log Retention):按照一定的保留策略直接删除不符合条件的日志分段。
2. 日志压缩(Log Compaction):针对每个消息的 key 进行整合，对于有相同 key 的不同 value 值，只保留最后一个版本。

我们可以通过 broker 端参数 `log.cleanup.policy` 来设置日志清理策略，此参数的默认值为`delete`，即采用日志删除的清理策略。如果要采用日志压缩的清理策略，就需要将`log.cleanup.policy` 设置为`compact`，并且还需要将 `log.cleaner.enable`(默认值为 true)设定为 true。通过将 `log.cleanup.policy` 参数设置为`delete,compact`，还可以同时支持日志删除和日志压缩两种策略。日志清理的粒度可以控制到主题级别，比如与`log.cleanup.policy` 对应的主题级别的参数为 `cleanup.policy`。

---

## 1.日志删除

在 Kafka 的日志管理器中会有一个专门的日志删除任务来周期性地检测和删除不符合保留条件的日志分段文件，这个周期可以通过 broker端参数 `log.retention.check.interval.ms`来配置，默认值为 300000，即 5 分钟。当前日志分段的保留策略有 3 种:基于时间的保留策略、基于日志大小的保留策略和基于日志起始偏移量的保留策略。

---

### 1.1 基于时间

日志删除任务会检查当前日志文件中是否有保留时间超过设定的阙值 (**retentionMs**)来寻找可删除的日志分段文件集合(**deletableSegments**),如图所示。`retentionMs` 可以通过 broker端参数 `log.retention.hours、log.retention.minutes 和log.retention.ms` 来设置，其中 `log.retention.ms` 的优先级最高，`log.retention.minutes` 次之`log.retention.hours` 最低。默认情况下只配置了 `log.retention,hours` 参数，其值为168，故默认情况下日志分段文件的保留时间为 7 天。

![](https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311202121914.png)

查找过期的日志分段文件，并不是简单地根据日志分段的最近修改时间 `lastModifiedTime` 来计算的，而是根据日志分段中最大的时间戳 `largestTimeStamp` 来计算的。因为日志分段的 `lastModifiedTime` 可以被有意或无意地修改，比如执行了 `touch` 操作，或者分区副本进行了重新分配，`lastModifiedTime` 并不能真实地反映出日志分段在磁盘的保留时间。要获取日志分段中最大时间戳 `largestTimeStamp` 的值，首先要查询该日志分段所对应的时间戳索引文件，查找时间戳索引文件中最后一条索引项，若最后一条索引项的时间戳字段值大于 0，则取其值，否则 才设置为最近修改时间 `lastModifiedTime`。

若待删除的日志分段的总数等于该日志文件中所有的日志分段的数量，那么说明所有的日志分段都已过期，但该日志文件中还要有一个日志分段用于接收消息的写入，即必须要保证有一个活跃的日志分段 `activeSegment`，在此种情况下，会先切分出一个新的日志分段作为`activeSegment`，然后执行删除操作。

删除日志分段时,首先会从 Log 对象中所维护日志分段的跳跃表中移除待删除的日志分段以保证没有线程对这些日志分段进行读取操作。然后将日志分段所对应的所有文件添加上`.deleted`的后缀(当然也包括对应的索引文件)。最后交由一个以`delete-file`命名的延迟任务来删除这些以`.deleted`为后缀的文件，这个任务的延迟执行时间可以通过 `file.delete.delay.ms` 参数来调配，此参数的默认值为 60000，即 1分钟。

---

### 1.2 基于日志大小

日志删除任务会检查当前日志的大小是否超过设定的阙值 (**retentionSize**)来寻找可删除的日志分段的文件集合(**deletableSegments**)，如图所示。`retentionSize` 可以通过 broker 端参数 `log.retention.bytes` 来配置,默认值为-1,表示无穷大。注意 `log.retention.bytes` 配置的是 Log 中所有日志文件的总大小，而不是单个日志分段(确切地说应该为`.log`日志文件)的大小。单个日志分段的大小由 broker 端参数 `log.segment.bytes` 来限制，默认值为1073741824，即 1GB。

![](https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311202127338.png)

基于日志大小的保留策略与基于时间的保留策略类似，首先计算日志文件的总大小 `size 和retentionSize` 的差值 `diff`，即计算需要删除的日志总大小，然后从日志文件中的第一个日志分段开始进行查找可删除的日志分段的文件集合 `deletableSegments`。查找出 `deletableSegments` 之后就执行删除操作，这个删除操作和基于时间的保留策略的删除操作相同。

---

### 1.3 基于日志起始偏移量

一般情况下，日志文件的起始偏移量 `logStartOffset` 等于第一个日志分段的 `baseOffset`，但这并不是绝对的，`logStartOffset` 的值可以通过 `DeleteRecordsRequest` 请求 (比如使用`KafkaAdminClient` 的 `deleteRecords()`方法、使用 `kafka-delete-records.sh` 脚本)、日志的清理和截断等操作进行修改。

基于日志起始偏移量的保留策略的判断依据是某日志分段的下一个日志分段的起始偏移量`baseOffset` 是否小于等于 `logStartOffset`，若是，则可以删除此日志分段。如图所示，假设`logStartOffset` 等于 25，日志分段 1的起始偏移量为 0，日志分段 2 的起始偏移量为 11，日志分段3 的起始偏移量为 23，通过如下动作收集可删除的日志分段的文件集合 `deletableSegments`:

1. 从头开始遍历每个日志分段，日志分段 1 的下一个日志分段的起始偏移量为 11，小于`logStartOffset` 的大小，将日志分段1加入 `deletableSegments`。
2. 日志分段 2 的下一个日志偏移量的起始偏移量为 23，也小于 `logStartOffset` 的大小,将日志分段 2也加入 `deletableSegments`。
3. 日志分段 3 的下一个日志偏移量在`logStartOffset`的右侧，故从日志分段 3 开始的所有日志分段都不会加入 `deletableSegments`。

![](https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311202131435.png)

收集完可以删除的日志分段的文件集合之后的删除操作同基于日志大小的保留策略和基于时间的保留策略相同。

---

## 2.日志压缩

