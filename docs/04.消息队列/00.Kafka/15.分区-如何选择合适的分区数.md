---
title: 分区-如何选择合适的分区数
date: 2023-01-01 00:00:00
tags:
  - Kafka
  - 消息队列
categories:
  - Kafka
description: 分区-如何选择合适的分区数
toc_number: false
author:
  name: huidong.yin
  link: https://huidongyin.github.io
permalink: /pages/bd36a2fb-82ce-3f34-bf5a-91f5703e12a6/
---

## 1.性能测试工具

本节要讨论的性能测试工具是kafka本身提供的生产者性能测试的 `kafka-producer-perf-test.sh`和用于消费者性能测试的`kafka-consumer-perf-test.sh`。

首先通过一个示例来了解一下`kafka-producer-perf-test.sh`脚本的使用。我们向一个只有一个分区和一个副本的主题`topic-1`中发送1万条消息，并且每条消息大小为1024B，生产者对应的`acks`参数为1。

```bash
bash-5.1# ./kafka-producer-perf-test.sh --topic topic-1 --num-records 10000 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=localhost:9092 acks=1
4756 records sent, 913.4 records/sec (0.89 MB/sec), 2026.3 ms avg latency, 4547.0 ms max latency.
4740 records sent, 942.2 records/sec (0.92 MB/sec), 6926.3 ms avg latency, 9514.0 ms max latency.
10000 records sent, 932.227091 records/sec (0.91 MB/sec), 4734.96 ms avg latency, 9983.00 ms max latency, 4767 ms 50th, 9513 ms 95th, 9777 ms 99th, 9982 ms 99.9th.
bash-5.1#
```

上面在使用`kafka-producer-perf-test.sh`脚本的时候多了一个参数，其中`topic`用来指定生产者发送消息的目标主题；`num-records`用来指定发送消息的总条数；`record-size`用来设置每条消息的字节数；`produceer-props`参数用来指定生产者的配置，可以同时指定多组配置，各组配置之间用空格分隔，与`producer-props`参数对应的还有一个`producer.config`参数，他用来指定生产者的配置文件；`throughput`参数用来进行限流控制，当设定的值小于0时不限流，当设定的值大于0时，当发送的吞吐量大于该值时会被限流阻塞一段时间。下面的示例中设置了`throughout`的值为100字节：

```bash
bash-5.1# ./kafka-producer-perf-test.sh --topic topic-1 --num-records 10000 --record-size 1024 --throughput 100 --producer-props bootstrap.servers=localhost:9092 acks=1
502 records sent, 100.3 records/sec (0.10 MB/sec), 4.9 ms avg latency, 513.0 ms max latency.
501 records sent, 100.0 records/sec (0.10 MB/sec), 1.3 ms avg latency, 2.0 ms max latency.
500 records sent, 99.9 records/sec (0.10 MB/sec), 1.2 ms avg latency, 3.0 ms max latency.
501 records sent, 100.2 records/sec (0.10 MB/sec), 1.2 ms avg latency, 3.0 ms max latency.
500 records sent, 100.0 records/sec (0.10 MB/sec), 1.2 ms avg latency, 5.0 ms max latency.
500 records sent, 100.0 records/sec (0.10 MB/sec), 1.2 ms avg latency, 4.0 ms max latency.
500 records sent, 100.0 records/sec (0.10 MB/sec), 1.2 ms avg latency, 4.0 ms max latency.
501 records sent, 100.1 records/sec (0.10 MB/sec), 1.1 ms avg latency, 4.0 ms max latency.
500 records sent, 100.0 records/sec (0.10 MB/sec), 1.1 ms avg latency, 4.0 ms max latency.
501 records sent, 100.0 records/sec (0.10 MB/sec), 1.2 ms avg latency, 5.0 ms max latency.
500 records sent, 99.9 records/sec (0.10 MB/sec), 1.2 ms avg latency, 5.0 ms max latency.
501 records sent, 100.1 records/sec (0.10 MB/sec), 1.1 ms avg latency, 2.0 ms max latency.
501 records sent, 100.0 records/sec (0.10 MB/sec), 1.1 ms avg latency, 5.0 ms max latency.
501 records sent, 100.1 records/sec (0.10 MB/sec), 1.1 ms avg latency, 3.0 ms max latency.
500 records sent, 100.0 records/sec (0.10 MB/sec), 1.1 ms avg latency, 4.0 ms max latency.
500 records sent, 99.9 records/sec (0.10 MB/sec), 1.1 ms avg latency, 2.0 ms max latency.
501 records sent, 100.1 records/sec (0.10 MB/sec), 1.1 ms avg latency, 2.0 ms max latency.
501 records sent, 100.1 records/sec (0.10 MB/sec), 1.1 ms avg latency, 4.0 ms max latency.
500 records sent, 99.9 records/sec (0.10 MB/sec), 1.1 ms avg latency, 3.0 ms max latency.
10000 records sent, 99.993000 records/sec (0.10 MB/sec), 1.34 ms avg latency, 513.00 ms max latency, 1 ms 50th, 2 ms 95th, 2 ms 99th, 26 ms 99.9th.
bash-5.1#
```

`kafka-producer-perf-test.sh`脚本中还有一个有意思的参数`print-metrics`，指定了这个参数时会在测试完成之后打印很多指标信息，对很多测试任务而言具有一定参考价值。

```bash
bash-5.1# ./kafka-producer-perf-test.sh --topic topic-1 --num-records 10000 --record-size 1024 --throughput -1 --print-metrics --producer-props bootstrap.servers=localhost:9092 acks=1
4906 records sent, 969.0 records/sec (0.95 MB/sec), 1854.0 ms avg latency, 4444.0 ms max latency.
4875 records sent, 940.0 records/sec (0.92 MB/sec), 6912.0 ms avg latency, 9593.0 ms max latency.
10000 records sent, 955.474871 records/sec (0.93 MB/sec), 4489.89 ms avg latency, 9807.00 ms max latency, 4449 ms 50th, 9150 ms 95th, 9600 ms 99th, 9807 ms 99.9th.

Metric Name                                                                         Value
app-info:commit-id:{client-id=producer-1}                                         : 839b886f9b732b15
app-info:start-time-ms:{client-id=producer-1}                                     : 1698903621840
app-info:version:{client-id=producer-1}                                           : 2.8.1
kafka-metrics-count:count:{client-id=producer-1}                                  : 102.000
producer-metrics:batch-size-avg:{client-id=producer-1}                            : 15548.256
producer-metrics:batch-size-max:{client-id=producer-1}                            : 15556.000
producer-metrics:batch-split-rate:{client-id=producer-1}                          : 0.000
producer-metrics:batch-split-total:{client-id=producer-1}                         : 0.000
producer-metrics:buffer-available-bytes:{client-id=producer-1}                    : 33554432.000
producer-metrics:buffer-exhausted-rate:{client-id=producer-1}                     : 0.000
producer-metrics:buffer-exhausted-total:{client-id=producer-1}                    : 0.000
producer-metrics:buffer-total-bytes:{client-id=producer-1}                        : 33554432.000
producer-metrics:bufferpool-wait-ratio:{client-id=producer-1}                     : 0.000
producer-metrics:bufferpool-wait-time-total:{client-id=producer-1}                : 0.000
producer-metrics:compression-rate-avg:{client-id=producer-1}                      : 1.000
producer-metrics:connection-close-rate:{client-id=producer-1}                     : 0.000
producer-metrics:connection-close-total:{client-id=producer-1}                    : 0.000
producer-metrics:connection-count:{client-id=producer-1}                          : 2.000
producer-metrics:connection-creation-rate:{client-id=producer-1}                  : 0.049
producer-metrics:connection-creation-total:{client-id=producer-1}                 : 2.000
producer-metrics:failed-authentication-rate:{client-id=producer-1}                : 0.000
producer-metrics:failed-authentication-total:{client-id=producer-1}               : 0.000
producer-metrics:failed-reauthentication-rate:{client-id=producer-1}              : 0.000
producer-metrics:failed-reauthentication-total:{client-id=producer-1}             : 0.000
producer-metrics:incoming-byte-rate:{client-id=producer-1}                        : 989.038
producer-metrics:incoming-byte-total:{client-id=producer-1}                       : 39699.000
producer-metrics:io-ratio:{client-id=producer-1}                                  : 0.002
producer-metrics:io-time-ns-avg:{client-id=producer-1}                            : 74919.058
producer-metrics:io-wait-ratio:{client-id=producer-1}                             : 0.236
producer-metrics:io-wait-time-ns-avg:{client-id=producer-1}                       : 7621808.752
producer-metrics:io-waittime-total:{client-id=producer-1}                         : 9557748175.000
producer-metrics:iotime-total:{client-id=producer-1}                              : 93948499.000
producer-metrics:metadata-age:{client-id=producer-1}                              : 10.037
producer-metrics:network-io-rate:{client-id=producer-1}                           : 33.382
producer-metrics:network-io-total:{client-id=producer-1}                          : 1340.000
producer-metrics:outgoing-byte-rate:{client-id=producer-1}                        : 259220.658
producer-metrics:outgoing-byte-total:{client-id=producer-1}                       : 10404858.000
producer-metrics:produce-throttle-time-avg:{client-id=producer-1}                 : 0.000
producer-metrics:produce-throttle-time-max:{client-id=producer-1}                 : 0.000
producer-metrics:reauthentication-latency-avg:{client-id=producer-1}              : NaN
producer-metrics:reauthentication-latency-max:{client-id=producer-1}              : NaN
producer-metrics:record-error-rate:{client-id=producer-1}                         : 0.000
producer-metrics:record-error-total:{client-id=producer-1}                        : 0.000
producer-metrics:record-queue-time-avg:{client-id=producer-1}                     : 4419.091
producer-metrics:record-queue-time-max:{client-id=producer-1}                     : 9601.000
producer-metrics:record-retry-rate:{client-id=producer-1}                         : 0.000
producer-metrics:record-retry-total:{client-id=producer-1}                        : 0.000
producer-metrics:record-send-rate:{client-id=producer-1}                          : 250.275
producer-metrics:record-send-total:{client-id=producer-1}                         : 10000.000
producer-metrics:record-size-avg:{client-id=producer-1}                           : 1110.000
producer-metrics:record-size-max:{client-id=producer-1}                           : 1110.000
producer-metrics:records-per-request-avg:{client-id=producer-1}                   : 14.993
producer-metrics:request-latency-avg:{client-id=producer-1}                       : 73.406
producer-metrics:request-latency-max:{client-id=producer-1}                       : 270.000
producer-metrics:request-rate:{client-id=producer-1}                              : 16.691
producer-metrics:request-size-avg:{client-id=producer-1}                          : 15529.639
producer-metrics:request-size-max:{client-id=producer-1}                          : 15607.000
producer-metrics:request-total:{client-id=producer-1}                             : 670.000
producer-metrics:requests-in-flight:{client-id=producer-1}                        : 0.000
producer-metrics:response-rate:{client-id=producer-1}                             : 16.692
producer-metrics:response-total:{client-id=producer-1}                            : 670.000
producer-metrics:select-rate:{client-id=producer-1}                               : 30.991
producer-metrics:select-total:{client-id=producer-1}                              : 1254.000
producer-metrics:successful-authentication-no-reauth-total:{client-id=producer-1} : 0.000
producer-metrics:successful-authentication-rate:{client-id=producer-1}            : 0.000
producer-metrics:successful-authentication-total:{client-id=producer-1}           : 0.000
producer-metrics:successful-reauthentication-rate:{client-id=producer-1}          : 0.000
producer-metrics:successful-reauthentication-total:{client-id=producer-1}         : 0.000
producer-metrics:waiting-threads:{client-id=producer-1}                           : 0.000
producer-node-metrics:incoming-byte-rate:{client-id=producer-1, node-id=node--1}  : 14.823
producer-node-metrics:incoming-byte-rate:{client-id=producer-1, node-id=node-0}   : 978.407
producer-node-metrics:incoming-byte-total:{client-id=producer-1, node-id=node--1} : 595.000
producer-node-metrics:incoming-byte-total:{client-id=producer-1, node-id=node-0}  : 39104.000
producer-node-metrics:outgoing-byte-rate:{client-id=producer-1, node-id=node--1}  : 2.591
producer-node-metrics:outgoing-byte-rate:{client-id=producer-1, node-id=node-0}   : 260307.573
producer-node-metrics:outgoing-byte-total:{client-id=producer-1, node-id=node--1} : 104.000
producer-node-metrics:outgoing-byte-total:{client-id=producer-1, node-id=node-0}  : 10404754.000
producer-node-metrics:request-latency-avg:{client-id=producer-1, node-id=node--1} : NaN
producer-node-metrics:request-latency-avg:{client-id=producer-1, node-id=node-0}  : 73.406
producer-node-metrics:request-latency-max:{client-id=producer-1, node-id=node--1} : NaN
producer-node-metrics:request-latency-max:{client-id=producer-1, node-id=node-0}  : 270.000
producer-node-metrics:request-rate:{client-id=producer-1, node-id=node--1}        : 0.050
producer-node-metrics:request-rate:{client-id=producer-1, node-id=node-0}         : 16.712
producer-node-metrics:request-size-avg:{client-id=producer-1, node-id=node--1}    : 52.000
producer-node-metrics:request-size-avg:{client-id=producer-1, node-id=node-0}     : 15575.979
producer-node-metrics:request-size-max:{client-id=producer-1, node-id=node--1}    : 54.000
producer-node-metrics:request-size-max:{client-id=producer-1, node-id=node-0}     : 15607.000
producer-node-metrics:request-total:{client-id=producer-1, node-id=node--1}       : 2.000
producer-node-metrics:request-total:{client-id=producer-1, node-id=node-0}        : 668.000
producer-node-metrics:response-rate:{client-id=producer-1, node-id=node--1}       : 0.050
producer-node-metrics:response-rate:{client-id=producer-1, node-id=node-0}        : 16.714
producer-node-metrics:response-total:{client-id=producer-1, node-id=node--1}      : 2.000
producer-node-metrics:response-total:{client-id=producer-1, node-id=node-0}       : 668.000
producer-topic-metrics:byte-rate:{client-id=producer-1, topic=topic-1}            : 259559.179
producer-topic-metrics:byte-total:{client-id=producer-1, topic=topic-1}           : 10370687.000
producer-topic-metrics:compression-rate:{client-id=producer-1, topic=topic-1}     : 1.000
producer-topic-metrics:record-error-rate:{client-id=producer-1, topic=topic-1}    : 0.000
producer-topic-metrics:record-error-total:{client-id=producer-1, topic=topic-1}   : 0.000
producer-topic-metrics:record-retry-rate:{client-id=producer-1, topic=topic-1}    : 0.000
producer-topic-metrics:record-retry-total:{client-id=producer-1, topic=topic-1}   : 0.000
producer-topic-metrics:record-send-rate:{client-id=producer-1, topic=topic-1}     : 250.282
producer-topic-metrics:record-send-total:{client-id=producer-1, topic=topic-1}    : 10000.000
bash-5.1#
```

我们来看一下`kafka-producer-perf-test.sh`脚本的输出信息：

```
10000 records sent, 955.474871 records/sec (0.93 MB/sec), 4489.89 ms avg latency, 9807.00 ms max latency, 4449 ms 50th, 9150 ms 95th, 9600 ms 99th, 9807 ms 99.9th.
```

`records sent`表示测试时发送的消息总数；`records/sec`表示以每秒发送的消息数来统计吞吐量，括号中的`MB/sec`表示以每秒发送的消息大小来统计吞吐量，注意这两者的纬度；`avg latency`表示消息处理的平均耗时；`max latency`表示消息处理的最大耗时；`50th, 95th ,99th`分别表示`P50，P95，P99`指标。

`kafka-consumer-perf-test.sh`脚本的使用也比较简单，下面的示例演示了其使用方式：

```bash
bash-5.1# ./kafka-consumer-perf-test.sh --topic topic-1 --messages 10000 --broker-list localhost:9092
start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec
2023-11-02 05:48:03:299, 2023-11-02 05:48:15:277, 9.8096, 0.8190, 10045, 838.6208, 1578, 10400, 0.9432, 965.8654
bash-5.1#
```

示例中只是简单的消费主题`topic-1`中的1万条消息。脚本中还包含了很多其他的参数。输出结果中包含了多项信息，对应关系如下：

| start.time | end.time | data.consumed.in.MB | nMsg.sec      | rebalance.time.ms | fetch.time.ms | fetch.MB.sec | fetch.nMsg.sec |
|------------|----------|---------------------|---------------|-------------------|---------------|--------------|----------------|
| 开始运行时间     | 结束时间     | 消费的消息总量             | 按消息个数计算消费的吞吐量 | 再平衡的时间            | 拉取消息的持续时间     | 每秒拉取消息的字节数   | 每秒拉取消息的个数      |

其中`fetch.time.ms=end.time-start.time-rebalance.time.ms`。

---

## 2.分区数越多吞吐量就越高么

分区是kafka中最小的并行操作单元，对生产者而言，每一个分区的数据写入完全是可以并行化的；对消费者而言，kafka只允许单个分区中的消息被一个消费者线程消费，一个消费者的消费并行度完全依赖于所消费的分区数。如此看来，如果一个主题中的分区数越多，理论上能达到的吞吐量就越大，但是实际上并不是这样。

首先分别创建分区数为`1，20,50，100，200，500,1000`的主题，对应的主题名称分别为`topic-1,topic-20,topic-50,topic-100,topic-200,topic-500,topic-1000`，所有主题的副本因子都设置为1。

消息中间件的性能一般是指吞吐量。抛开硬件资源的影响，消息写入的吞吐量还会收到消息大小，消息压缩方式，消息发送方式（同步/异步），消息确认类型（acks），副本因子等参数影响，所有的测试除了主题的分区数不同，其余的因素都保持相同。

使用`kafka-producer-perf-test.sh`脚本分别向这些主题中发送100万条消息体大小为1kb的消息，测试命令如下：

```bash
./kafka-producer-perf-test.sh --topic topic-xxx --num-records 1000000 --records-size 1024 --throughput -1 --producer-props bootstrap.servers=localhost:9092 acks=1
```

对于生产者测试的结果，不同的硬件环境，甚至不同批次的测试得到的测试结果也不会完全相同，但是总体趋势是先升后降。

分区数为1时吞吐量最低，随着分区数的增长，相应的吞吐量也跟着上涨。一旦分区数超过了某个阈值之后，整体的吞吐量是不增反降的。也就是说并不是分区数越多吞吐量越大。这里的分区数临界阈值针对不同的测试环境也会表现出不同的结果，实际应用中可以通过类似的案例找到一个合理的临界值区间。

对消息消费者而言同样有吞吐量方面的考量。使用`kafka-consumer-perf-test.sh`脚本分别消费这些主题中的100w条消息，对应的测试命令如下：

```bash
./kafka-consumer-perf-test.sh --topic topic-xxx --messages 1000000 --broker-list localhost:9092
```

消费者的测试结果也和生产者类似，总体趋势保持先升后降。随着分区数的增加，相应的吞吐量也会增长，一旦分区数超过了某个阈值，整体的吞吐量是不升反降的，同样说明了分区数越多并不会让吞吐量一直增长。

---

## 3.分区数的上限

一味的增加分区数并不能使吞吐量一直得到提升，并且分区数也并不能一直增加，如果超过默认的配置值，会引起kafka进程的崩溃。尝试在kafka上执行如下命令：

```
./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb --replication-factor 1 --partitions 10000
```

执行完成后使用`jps`命令或者`ps -aux|grep kafka`命令检查kafka进程是否还存在。一般情况下，会发现原本运行完好的kafka进程已经崩溃。创建这么多分区是不是因为内存不足而引起的进程崩溃？其实不是，创建这些分区而引起的内存增长kafka完全cover的住。

为了分析真实原因，我们可以打开kafka的服务日志文件（`$KAFKA_HOME/logs/server.log`）来排查问题，会发现服务日志中出现大量异常：

```
java.io.Exception:Too many open files
```

异常中最关键的信息是`Too many open files`，这是一种常见的Linux系统错误，通常意味着文件描述符不足，他一般发生在创建进程，创建`Socket`，打开文件这些场景下。在Linux系统默认设置下，这个文件描述符的个数不是很多，通过下面的命令可以查看：

```bash
[root@VM-24-3-centos ~]# ulimit -n
1024
[root@VM-24-3-centos ~]# ulimit -Sn 
1024
[root@VM-24-3-centos ~]# ulimit -Hn
4096
```

S表示当前软件限制 H表示硬限制。硬限制设定之后不能再添加，而软限制则可以增加到硬限制规定的值。

接下来我们来验证kafka进程的崩溃是否是由于文件描述符。

首先通过ps命令查看kafka进程的当前pid：

```bash
root@7b4579bd9e87:/# ps -aux | grep kafka
root         1 10.6  2.2 7871756 371664 ?   ....
```

查看当前kafka进程所占用的文件描述符个数：

```bash
ls /proc/1/fd | wc -l
```

在新建一个只有一个分区的主题，并查看kafka进程所占用的文件描述符的个数：

```bash
root@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-1 --replication-factor 1 --partitions 1
Created topic topic-bomb-1.
root@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ls /proc/1/fd | wc -l
148
root@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin#
```

可以看到增加了一个分区，对应的也只增加了一个文件描述符。之前我们通过`ulimit`命令可以看到软限制是1024，我们创建一个具有829个分区的主题：

```bash
root@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-2 --replication-factor 1 --partitions 829
```

此时kafka进程占用了1024个文件描述符，并且运行完好。这时我们还可以联想到硬限制4096这个关键数字，我们在创建一个包含3071个分区的主题，此时占用4095个文件描述符。

```bash
root@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-3 --replication-factor 1 --partitions 3071
```

kafka进程依旧完好，文件描述符占用为4095，最后我们在创建一个只有一个分区的主题：

```bash
root@7b4579bd9e87:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181/kafka --create --topic topic-bomb-4 --replication-factor 1 --partitions 1
```

此时kafka进程已经崩溃，查看进程号时已经没有相关信息，查看kafka日志还会发现前面的异常`Too many open files` ，表明已经达到上限。

如何避免这种异常情况？对于一个高并发，高性能的应用来说，1024或者4096太小了，可以设置成65535，这样足以应对大多数的情况。

```bash
ulimit -n 65535
```

`limits.conf`文件修改之后需要重启才能生效。`limits.conf`文件与`ulimit`命令的区别在于前者针对所有用户，而且在任何shell都生效，后者只针对特定用户的当前shell。

---

## 4.考量因素

如何选择合适的分区数？看具体情况而定。

1. 从吞吐量方面考虑，增加合适的分区数可以在一定程度上提升整体的吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求，则建议在发布之前做压测。
2. 有些应用场景会要求主题中的消息都能保证顺序性，这种情况下在创建主题时可以设定分区数为1，通过分区有序性的这一特性来达到主题有序性的目的。

> 当然分区也不能一味的增加，分区数会占用文件描述符，而一个进程所能支配的文件描述符是有限的，这也是通常所说的文件句柄开销。在选择合适的分区数之前，最好在考量一下当前kafka进程中已经使用的文件描述符个数。

3.分区数的多少还会影响系统可用性。kafka通过多副本机制实现集群高可用，每个分区都会有一到多个副本，每个副本分别存在于不同的broker节点上，并且只有leader副本对外提供服务。在kafka集群的内部，所有的副本都采用自动化的方式进行管理，并确保所有副本中的数据都能保持一定程度上的不同。当broker发生故障时，leader节点上的所有分区将暂时处于不可用状态，此时kafka会自动在其他follower副本之间选举新的leader用于接收外部客户端请求，整个过程由kafka控制器负责完成，分区在进行leader角色切换过程中会变得不可用，不过对于单个分区而言这个过程非常短暂，对用户可以忽略不计。如果集群中的某个broker节点宕机，那么会有大量分区同时进行leader角色切换，这个切换过程会相对较长，并且在这个时间窗口内这些分区会变得不可用。

> 分区数越多也会让kafka的正常启动和关闭的耗时变得越长，与此同时，主题的分区数越多不仅会增加日志清理耗时，而且在被删除时也会耗费更多的时间。对于旧版本的客户端而言，分区数多也会增加他们的开销，不过这一点在新版本的客户端得到了有效的抑制。


如何选择合适的分区数？

一般情况下，根据预估的吞吐量以及是否与key相关的规则来设定分区数即可，后期可以通过增加分区数，增加broker或者分区重分配等手段来进行改进。如果一定要一个准则，建议将分数设置为集群中broker的倍数，至于倍数的选定可以参考预估的吞吐量。不过如果集群中的broker节点很多，这种准则也不适用，在选定分区数时进一步可以引入机架等参考因素。

---

