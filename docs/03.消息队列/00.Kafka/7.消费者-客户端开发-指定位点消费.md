---
title: 消费者-客户端开发-指定消费位点
date: 2023-01-01 00:00:00
tags:
  - Kafka
  - 消息队列
categories:
  - Kafka
description: 消费者-客户端开发-指定消费位点
toc_number: false
author:
  name: huidong.yin
  link: https://huidongyin.github.io
permalink: /pages/5ab26239-f80c-3f5e-affc-fc2c33f5178f/
---

当一个新的消费组建立的时候，它根本没有可以查找的消费位点。或者消费组内的一个新消费者订阅了一个新的主题，它也没有可以查找的消费位点。当 `consumor_offsets`主题中有关这个消费组的位点信息过期而被删除后，它也没有可以查找的消费位点。

在 Kafka 中每当消费者查找不到所记录的消费位点时，就会根据消费者客户端参数`auto.offset.reset`的配置来决定从何处开始进行消费，这个参数的默认值为`latest`，表示从分区末尾开始消费消息。参考下图，按照默认的配置，消费者会从9开始进行消费 9 是下一条要写入消息的位置,更加确地说是从 9 开始拉取消息。如果将 `auto.offset.reset`参数配置为`earliest`，那么消费者会从起始处，也就是 0开始消费。

![](/images/kafka/消费者/05.png)

> 除了查找不到消费位点，位点越界也会触发 `auto.offset.reset` 参数的执行。

`auto.offset.reset` 参数还有一个可配置的值一`none`，配置为此值就意味着出现查不到消费位点的时候，既不从最新的消息位置处开始消费，也不从最早的消息位置处开始消费，此时会报出**NoOffsetForPartitionException** 异常。如果能够找到消费位点，那么配置为`none`不会出现任何异常。如果配置的不是`latest,earliest,和none`，则会报出 **ConfigException** 异常。

消息的拉取是根据 `poll()` 方法中的逻辑来处理的，这个 `poll()`方法中的逻辑对于普通的开发人员而言是一个黑盒，无法精确地掌控其消费的起始位置。提供的`auto.offset.reset`参数也只能在找不到消费位点或位点越界的情况下粗粒度地从开头或末尾开始消费。有些时候，我们需要一种更细粒度的掌控，可以让我们从特定的位点处开始拉取消息，而KafkaConsumer中的 `seek()` 方法正好提供了这个功能，让我们得以追前消费或回溯消费。

```java
public void seek(TopicPartition partition,long offset);
```

`seek()`方法中的参数 `partition` 表示分区，而 `offset` 参数用来指定从分区的哪个位置开始消费。`seek()`方法只能重置消费者分配到的分区的消费位置，而分区的分配是在 `poll()` 方法的调用过程中实现的。也就是说，在执行 `seek()`方法之前需要先执行一次 `poll()` 方法，等到分配到分区之后才可以重置消费位置。

以下是seek方法的使用示例：

```java
        Properties props=new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,brokerList);
        props.put(ConsumerConfig.GROUP_ID_CONFIG,groupName);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());

        KafkaConsumer<String, String> consumer=new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList(topicName));
        consumer.poll(Duration.ofMillis(1000));
        Set<TopicPartition> assignment=consumer.assignment();
        for(TopicPartition partition:assignment){
        consumer.seek(partition,10);
        }
        while(true){
        ConsumerRecords<String, String> records=consumer.poll(Duration.ofMillis(1000));
        for(ConsumerRecord<String, String> record:records){
        System.out.println("message : "+record.value());
        }
        }

```

`assignment()`方法是用来获取消费者所分配到的分区信息的。

```java
public Set<TopicPartition> assignment0);
```

> 在上面的`seek()`方法使用的示例代码中，如果第一次调用`poll()`方法的时间间隔设置为0，在此之后，会发现 `seek()`方法并未有任何作用。因为当 `poll()` 方法中的参数为 0 时，此方法立刻返回，那么 `poll()`方法内部进行分区分配的逻辑就会来不及实施。也就是说，消费者此时并未分配到任何分区。那么我们应该如何优雅的`seek`呢？

```java
    private void test(){
        Properties props=new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,brokerList);
        props.put(ConsumerConfig.GROUP_ID_CONFIG,groupName);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());

        KafkaConsumer<String, String> consumer=new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList(topicName));
        Set<TopicPartition> assignment=new HashSet<>();
        while(assignment==null||assignment.size()==0){
        consumer.poll(Duration.ofMillis(100));
        assignment=consumer.assignment();
        }

        for(TopicPartition partition:assignment){
        consumer.seek(partition,10);
        }
        while(true){
        ConsumerRecords<String, String> records=consumer.poll(Duration.ofMillis(1000));
        for(ConsumerRecord<String, String> record:records){
        System.out.println("message : "+record.value());
        }
        }

```

如果对未分配到的分区执行 `seek()` 方法，那么会报出 **IllegalStateException** 的异常。类似在调用 `subscribe()`方法之后直接调用 `seek()` 方法:

```java
consumer.subscribe(Arrays.asList(topic));
consumer.seek(new TopicPartition(topic,0),10);
```

如果消费组内的消费者在启动的时候能够找到消费位点，除非发生位点越界，否则 `auto.offset.reset`参数并不会奏效,此时如果想指定从开头或末尾开始消费,就要使用 `seck()` 方法了。

```java
    private void test(){
        Properties props=new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,brokerList);
        props.put(ConsumerConfig.GROUP_ID_CONFIG,groupName);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());

        KafkaConsumer<String, String> consumer=new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList(topicName));
        Set<TopicPartition> assignment=new HashSet<>();
        while(assignment==null||assignment.size()==0){
        consumer.poll(Duration.ofMillis(100));
        assignment=consumer.assignment();
        }
        Map<TopicPartition, Long> map=consumer.endOffsets(assignment);
        for(TopicPartition partition:assignment){
        consumer.seek(partition,map.get(partition));
        }
        while(true){
        ConsumerRecords<String, String> records=consumer.poll(Duration.ofMillis(1000));
        for(ConsumerRecord<String, String> record:records){
        System.out.println("message : "+record.value());
        }

        }
```

> `endOffsets()`方法用来获取指定分区的末尾的消息位置。

```java
    Map<TopicPartition, Long> endOffsets(Collection<TopicPartition> partitions);

    Map<TopicPartition, Long> endOffsets(Collection<TopicPartition> partitions,Duration timeout);
```

与 `endOffsets()` 方法 对应的是 `beginningOffsets()` 方法，一个分区的起始位置起初是0，但并不代表每时每刻都为0，因为日志清理的动作会清旧的数据，所以分区的起始位置会自然而然地增加。

```java
    Map<TopicPartition, Long> beginningOffsets(Collection<TopicPartition> partitions);

    Map<TopicPartition, Long> beginningOffsets(Collection<TopicPartition> partitions,Duration timeout);
```

其实 KafkaConsumer 中直接提供了 `seekToBeginning()` 方法, `seekToEnd()` 方法来实现这两个功能。

```java
    void seekToBeginning(Collection<TopicPartition> partitions);

        void seekToEnd(Collection<TopicPartition> partitions);
```

有时候我们并不知道特定的消费位置，却知道一个相关的时间点，比如我们想要消费昨天8点之后的消息，这个需求更符合正常的思维逻辑。此时我们无法直接使用 `seek()`方法来追溯到相应的位置。KafkaConsumer 同样考虑到了这种情况，它提供了一个 `offsetsForTimes()` 方法，通过timestamp来查询与此对应的分区位置。

```java
Map<TopicPartition, OffsetAndTimestamp> offsetsForTimes(Map<TopicPartition, Long> timestampsToSearch);

Map<TopicPartition, OffsetAndTimestamp> offsetsForTimes(Map<TopicPartition, Long> timestampsToSearch,Duration timeout);
```

`offsetsForTimes()` 方法的参数 timestampsToSearch 是一个 Map 类型,key 为待查询的分区，而value为待查询的时间戳，该方法会返回时间戳大于等于待查询时间的第一条消息对应的位置和时间戳，对应于 OffsetAndTimestamp中的offset 和 timestamp 字段。

前面说过位点越界也会触发 `auto.offset.reset` 参数的执行，位点越界是指知道消费位置却无法在实际的分区中查找到，比如想要从上图中的位置10处拉取消息时就会发生位点越界。注意拉取上图中位置 9 处的消息时并未越界，这个位置代表特定的含义 (LEO)。

Kafka中的消费位点是存储在一个内部主题中的，而本节的 `seek()` 方法可以突破这一限制：消费位点可以保存在任意的存储介质中，比如数据库，文件系统等等。

`seek()`方法为我们提供了从特定位置读取消息的能力，我们可以通过这个方法来向前跳过若干消息，也可以通过这个方法来向后回溯若干消息，这样为消息的消费提供了很大的灵活性。`seek()`方法也为我们提供了将消费位点保存在外部存储介质中的能力，还可以配合再均衡监听器来提供更加精准的消费能力。

---
