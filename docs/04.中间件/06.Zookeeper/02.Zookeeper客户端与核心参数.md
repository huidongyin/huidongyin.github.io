---
title: Zookeeper客户端与核心参数
date: 2023-01-01 00:00:00
tags: 
  - Zookeeper
  - 中间件
categories: 
  - Zookeeper
description: Zookeeper客户端与核心参数
toc_number: false
author:
  name: huidong.yin
  link: https://huidongyin.github.io
permalink: /pages/b4af8eb8-0a51-36d2-845c-2e7d0a5fc536/
---

前面两篇我们讲解了 ZooKeeper 的一些核心概念，也对部分核心概念进行了实战演示，比如节点以及节点类型，这两块我们实战操作了一下，也用到了一些 ZooKeeper Client 的相关 API。

本篇幅我会先讲解以及实操一下原生 zkCli 所支持的命令与语法，然后我会实操下 ZooKeeper 当前最流行的客户端框架 Curator 的核心 API，最后我会讲解几个 ZooKeeper Server 核心参数的含义。

我们先来看第一个内容：**zkCli 的命令语法**。

---

## 1.zkCli操作

> 如何执行 `zkCli`？`zkCli`是一个Zookeeper原生的客户端工具，它的位置在 `Zookeeper/bin`目录下，直接 `sh zkCli.sh`就可以进入。

首先看一下都有哪些命令？

```bash
[zk: localhost:2181(CONNECTED) 0] help
ZooKeeper -server host:port -client-configuration properties-file cmd args
	addWatch [-m mode] path # optional mode is one of [PERSISTENT, PERSISTENT_RECURSIVE] - default is PERSISTENT_RECURSIVE
	addauth scheme auth
	close 
	config [-c] [-w] [-s]
	connect host:port
	create [-s] [-e] [-c] [-t ttl] path [data] [acl]
	delete [-v version] path
	deleteall path [-b batch size]
	delquota [-n|-b|-N|-B] path
	get [-s] [-w] path
	getAcl [-s] path
	getAllChildrenNumber path
	getEphemerals path
	history 
	listquota path
	ls [-s] [-w] [-R] path
	printwatches on|off
	quit 
	reconfig [-s] [-v version] [[-file path] | [-members serverID=host:port1:port2;port3[,...]*]] | [-add serverId=host:port1:port2;port3[,...]]* [-remove serverId[,...]*]
	redo cmdno
	removewatches path [-c|-d|-a] [-l]
	set [-s] [-v version] path data
	setAcl [-s] [-v version] [-R] path acl
	setquota -n|-b|-N|-B val path
	stat [-w] path
	sync path
	version 
	whoami 
Command not found: Command not found help
[zk: localhost:2181(CONNECTED) 1] 

```

当然我们不会逐个讲解，我们只是来看几个常用的。

1. 如何查看版本？

直接使用 `version`命令。

```bash
[zk: localhost:2181(CONNECTED) 1] version
ZooKeeper CLI version: 3.7.1-a2fb57c55f8e59cdd76c34b357ad5181df1258d5, built on 2022-05-07 06:45 UTC
[zk: localhost:2181(CONNECTED) 2] 
```

2. 如何创建一个节点？

使用 `create`命令。

```bash
[zk: localhost:2181(CONNECTED) 2] create -e /xxx
Created /xxx
[zk: localhost:2181(CONNECTED) 3] 
```

3. 如何给节点设置值？

`set/get`命令。

```bash
[zk: localhost:2181(CONNECTED) 3] set /xxx aaa
[zk: localhost:2181(CONNECTED) 4] get /xxx
aaa
[zk: localhost:2181(CONNECTED) 5] 
```

4. 如何删除一个节点？

`delete`命令。

```bash
[zk: localhost:2181(CONNECTED) 5] delete /xxx
[zk: localhost:2181(CONNECTED) 6] ls /
[zookeeper]
[zk: localhost:2181(CONNECTED) 7] 
```

5. 如何查看节点状态？

`stat`命令。

```bash
[zk: localhost:2181(CONNECTED) 7] stat /zookeeper
cZxid = 0x0
ctime = Thu Jan 01 00:00:00 UTC 1970
mZxid = 0x0
mtime = Thu Jan 01 00:00:00 UTC 1970
pZxid = 0x0
cversion = -2
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 0
numChildren = 2
[zk: localhost:2181(CONNECTED) 8] 
```

6. 如何查看节点下有哪些子节点？

`ls`命令。

```bash
[zk: localhost:2181(CONNECTED) 9] ls /
[zookeeper]
[zk: localhost:2181(CONNECTED) 10] 
```

7. 如何查看曾经执行过的命令？

`history`命令。

```bash
[zk: localhost:2181(CONNECTED) 10] history
0 - help
1 - version
2 - create -e /xxx
3 - set /xxx aaa
4 - get /xxx
5 - delete /xxx
6 - ls /
7 - stat /zookeeper
8 - ls
9 - ls /
10 - history
[zk: localhost:2181(CONNECTED) 11] 
```

8. 如何移除一个节点的 `watchers`？

直接使用 `removewatches`命令，如果没有 Watcher，那么会提示 `No such watcher for path`。

```bash
[zk: localhost:2181(CONNECTED) 11] removewatches /zookeeper
KeeperErrorCode = No such watcher for /zookeeper
[zk: localhost:2181(CONNECTED) 12] 
```

> 对应的还有 addWatch，注册监听。

9. 如何正确退出客户端？

`ctrl + c`不会主动通知 ZooKeeper Server，所以它不会立即让临时节点断开连接，只能等到下次心跳的时候发现断连了，才会删除临时节点。而 `quit`是主动通知 ZooKeeper 服务端说要断开连接，会立即删除临时节点。

**ZooKeeper 的客户端命令和 Linux 文件系统的很像，比如 ls、history 这两个命令完全和 Linux 的一样，其他命令也都很简单粗暴，比如 create 是创建、delete 是删除、set/get 是设置/获取值等。**

上面全是命令行操作，那 Java 怎么调用呢？自然是有大佬已经把底层命令封装成框架了，而且是 Java 写的框架： **Curator** 。

---

## 2.Curator操作

我们通过使用 Curator 来完成一个元数据的 CRUD 功能，进而熟悉它的 API 使用。

### 2.1 依赖引入

首先，我们需要集成 maven 坐标：

- `curator-framework`：Curator 框架本身的依赖，提供了高级别的 API，简化了与 ZooKeeper 的交互。这个模块包括了创建连接、会话管理、节点操作等功能。
- `curator-recipes`：这个模块提供了一系列高级别的、基于 Curator Framework 的“食谱”，用于解决分布式系统中的一些常见问题，例如分布式锁、选举、队列等。
- `curator-x-async` : Curator 框架的一个扩展模块，用于提供异步操作的支持。它包含了一些异步操作的实现，让你可以使用 Curator 框架进行异步式的 ZooKeeper 操作。
- `curator-x-discovery` : Curator 提供的服务发现模块，用于实现服务注册和发现的功能。它提供了一种在 ZooKeeper 上实现服务注册和发现的机制，让不同的服务可以注册到 ZooKeeper 中，同时其他服务可以通过 ZooKeeper 来发现和获取这些服务的信息。
- `curator-x-discovery-server` : Curator 框架的服务发现模块中的一个额外组件，用于提供一个可视化的服务发现服务器。它允许你在一个可视化界面上查看和管理服务的注册和发现，为服务治理提供了更方便的管理界面。

```xml
        <dependency>
            <groupId>org.apache.curator</groupId>
            <artifactId>curator-framework</artifactId>
            <version>5.5.0</version>
        </dependency>
        <dependency>
            <groupId>org.apache.curator</groupId>
            <artifactId>curator-recipes</artifactId>
            <version>5.5.0</version>
        </dependency>
```

---

### 2.2 增删改查

接下来就可以代码操作了：

Curator 提供了几种重试策略来处理与 ZooKeeper 的连接和操作过程中可能出现的错误情况。这些重试策略可以在初始化 Curator 客户端时进行配置。

以下是 Curator 内置的几种重试策略：

1. **ExponentialBackoffRetry（指数补偿重试）**：这种重试策略会在每次重试时逐渐增加等待时间间隔，以指数级增长。它会从一个基础的等待时间开始，然后在每次重试时乘以一个补偿因子。
2. **BoundedExponentialBackoffRetry（有限指数补偿重试）**：类似于 ExponentialBackoffRetry，但限制了最大等待时间间隔，防止等待时间无限增长。
3. **RetryNTimes（重试指定次数）**：简单的重试策略，它会尝试指定次数的重试。
4. **RetryOneTime（重试一次）**：只进行一次重试的策略。
5. **RetryUntilElapsed（超时重试）**：在指定的时间范围内进行重试，超过指定的时间后停止重试。

这些重试策略可以根据应用的需求选择和配置。它们允许在网络故障或 ZooKeeper 临时不可用等情况下，自动重试连接和操作，提高了系统的稳定性和可靠性。

接下来看一下节点操作的API：

- `create()`创建节点
- `setDate()`写数据
- `creatingParentsIfNeeded()`父节点不存在则创建
- `withMode()`节点类型
- `getData()`获取数据
- `getChildren()`获取子节点
- `checkExists()`检查是否存在
- `delete()`删除节点
- `quietly()`用于在删除节点时忽略删除过程中可能抛出的异常
- `deletingChildrenIfNeeded()`如果指定节点有子节点，将会同时删除子节点。它用于递归地删除指定路径下的所有子节点及其本身

```java
class CuratorDemoApplicationTests2 {

    private static final String PATH = "/example/curator";

    private static final String URI = "127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183";

    @Test
    void contextLoads() throws Exception {
        //建立curator客户端
        CuratorFramework client = CuratorFrameworkFactory.builder().connectString(URI).sessionTimeoutMs(600000).connectionTimeoutMs(300000).retryPolicy(new ExponentialBackoffRetry(1000, 3)).build();
        //启动curator客户端
        client.start();
        String path = PATH + "/huidong";
        //create()创建节点
        //setDate()写数据
        //creatingParentsIfNeeded()父节点不存在则创建
        //withMode()节点类型
        client.create().orSetData().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT).forPath(path, "aaa".getBytes());
        //getData()获取数据
        byte[] bytes = client.getData().forPath(PATH);
        System.out.println(new String(bytes));
        //getChildren()获取子节点
        List<String> list = client.getChildren().forPath(PATH);
        if (!CollectionUtils.isEmpty(list)) {
            for (String s : list) {
                System.out.println("s:" + s);
            }
        }
        //checkExists()检查是否存在
        System.out.println("client.checkExists().forPath(path) = " + client.checkExists().forPath(path).toString());
        System.out.println("client.getData().forPath(path) = " + new String(client.getData().forPath(path)));
        //setData()更新节点数据
        client.setData().forPath(path, "bbb".getBytes());
        System.out.println("client.getData().forPath(path) = " + new String(client.getData().forPath(path)));
        //delete()删除节点
        //quietly()用于在删除节点时忽略删除过程中可能抛出的异常
        //deletingChildrenIfNeeded()如果指定节点有子节点，将会同时删除子节点。它用于递归地删除指定路径下的所有子节点及其本身
        client.delete().quietly().deletingChildrenIfNeeded().forPath(path);
        System.out.println("client.checkExists().forPath(path) = " + client.checkExists().forPath(path));
        //关闭 curator 客户端
        client.close();
    }

}
```

一些其他的 API 就不演示了，可以看下这个类 `org.apache.curator.framework.CuratorFramework`，这里面包含很多核心 API，而且 API 的命名风格和上面介绍的 `zkCli` 的命令命名很像。

当然它不只是有元数据 CRUD 的功能，它还基于 ZooKeeper 的临时节点特性实现了分布式锁。不光分布式锁，它还封装了选 Leader、Wacther 监听等功能。

---

### 2.3 节点缓存&事件监听

Watcher 监听机制是 Zookeeper 中非常重要的特性，我们基于zookeeper 上创建的节点，可以对这些节点绑定监听事件，比如可以监听节点数据变更、节点删除、子节点状态变更等事件，通过这个事件机制，可以基于 zookeeper 实现分布式锁、集群管理等功能。

ZooKeeper 的事件类型主要包括了节点的创建、删除、数据变更以及子节点变更等。但是需要注意的是，**ZooKeeper 事件是针对节点级别的，主要针对节点状态的变化**。

除了节点级别的事件，ZooKeeper 还支持 `Watcher.Event.EventType` 中定义的其他事件类型，包括：

1. **None（无事件）**：Watcher 被移除时会触发这个事件类型。
2. **NodeDataChanged（节点数据变更）**：与之前提到的相同，当一个节点的数据发生变化时触发。
3. **NodeChildrenChanged（子节点变更）**：同样是节点级别的事件，当一个节点的子节点列表发生变化时触发。
4. **NodeCreated（节点创建）**：当一个节点被创建时触发。
5. **NodeDeleted（节点删除）**：当一个节点被删除时触发。
6. **DataWatchRemoved（数据监视被移除）**：当一个节点的数据监视被移除时触发。

这些事件类型覆盖了对节点状态变化的监听，能够满足大多数的节点操作监控需求。

**在 ZooKeeper 中，Watcher 事件是一次性的，也就是说，一旦触发 Watcher 事件，对应的 Watcher 就会失效，需要重新注册才能再次监听节点状态的变化**。但是，当客户端收到节点的变更通知后，并不代表 Watcher 就会永久失效。客户端可以在收到通知后，再次注册新的 Watcher，以便持续监听节点的变更。


当涉及到与 ZooKeeper 交互时，Curator 提供了 `CuratorCache` 和 `CuratorCacheListener` 这两个组件来简化对节点数据的监听和缓存。

`CuratorCache` 是 Curator 提供的一个节点数据缓存，它会自动维护 ZooKeeper 节点的数据，并在数据变更时通知注册的监听器。它的主要功能包括：

- **自动缓存节点数据**：CuratorCache 会缓存指定节点的数据，使得读取数据更快速，并提供快速访问缓存的能力。
- **监听节点变更**：CuratorCache 可以注册监听器，监听节点的创建、更新、删除等事件，并在这些事件发生时触发注册的监听器。
- **异步更新数据**：通过异步方式更新缓存，确保数据的实时性。

`CuratorCacheListener` 是用于监听 `CuratorCache` 缓存的组件，它提供了不同类型的回调函数，用于处理节点的变更。主要的回调函数包括：

- **节点创建回调**：当指定节点被创建时触发。
- **节点更新回调**：当指定节点的数据发生变更时触发。
- **节点删除回调**：当指定节点被删除时触发。
- **缓存初始化回调**：当缓存初始化完成时触发。

这些回调函数可以被定制以执行特定的逻辑，例如在节点变更时更新本地缓存、通知其他组件等。

使用 CuratorCache 和 CuratorCacheListener，可以方便地管理 ZooKeeper 节点数据的变更，并根据需求处理节点变更的通知。

- `forCreates()`:节点创建回调
- `forChanges()`:节点更新回调
- `forDeletes()`:节点删除回调
- `forInitialized()`:缓存初始化回调

```java
class CuratorDemoApplicationTests {

    private static final String PATH = "/example/curator";

    private static final String URI = "127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183";

    @Test
    void contextLoads() throws Exception {
        //建立curator客户端
        CuratorFramework client = CuratorFrameworkFactory.builder().connectString(URI).sessionTimeoutMs(600000).connectionTimeoutMs(300000).retryPolicy(new ExponentialBackoffRetry(1000, 3)).build();
        //启动curator客户端
        client.start();
        //初始化curator cache
        CuratorCache cache = CuratorCache.build(client, PATH);
        //声明curator cache 监听器
        CuratorCacheListener listener = CuratorCacheListener.builder()
                //节点创建回调
                .forCreates(node -> System.out.printf("===Node created: [%s]%n", node))
                //节点更新回调
                .forChanges((oldNode, node) -> System.out.printf("===Node changed. Old: [%s] New: [%s]%n", oldNode, node))
                //节点删除回调
                .forDeletes(oldNode ->
                        System.out.printf("===Node deleted. Old value: [%s]%n", oldNode))
                //缓存初始化回调
                .forInitialized(() -> System.out.println("===Cache initialized"))
                .build();

        //注册监听器到 curator cache
        cache.listenable().addListener(listener);
        //启动 curator cache
        cache.start();
        String path = PATH + "/huidong";
  
        client.create().orSetData().creatingParentsIfNeeded().forPath(path, "aaa".getBytes());
        byte[] bytes = client.getData().forPath(PATH);
        System.out.println(new String(bytes));
        client.setData().forPath(path, "bbb".getBytes());
        System.out.println("client.getData().forPath(path) = " + new String(client.getData().forPath(path)));
        client.delete().quietly().deletingChildrenIfNeeded().forPath(path);
        //关闭curator cache
        cache.close();
        //关闭 curator 客户端
        client.close();
    }

}
```

---

### 2.4 分布式锁

如果在多线程并行情况下去访问某一个共享资源，比如说共享变量，那么势必会造成线程安全问题。那么我们可以用很多种方法来解决，比如 synchronized、 比如 Lock 之类的锁操作来解决线程安全问题，那么在分布式架构下，涉及到多个进程访问某一个共享资源的情况，这个时候我们需要一些互斥手段来防止彼此之间的干扰。在分布式情况下，synchronized 或者 Lock 之类的锁只能控制单一进程的资源访问，在多进程架构下，这些 api 就没办法解决我们的问题了。

可以利用 zookeeper 节点的特性来实现独占锁，就是同级节点的唯一性，多个进程往 zookeeper 的指定节点下创建一个相同名称的节点，只有一个能成功，另外一个是创建失败；创建失败的节点全部通过 zookeeper 的 watcher 机制来监听 zookeeper 这个子节点的变化，一旦监听到子节点的删除事件，则再次触发所有进程去写锁。这种实现方式很简单，但是会产生“惊群效应”，简单来说就是如果存在许多的客户端在等待获取锁，当成功获取到锁的进程释放该节点后，所有处于等待状态的客户端都会被唤醒，这个时候 zookeeper 在短时间内发送大量子节点变更事件给所有待获取锁的客户端，然后实际情况是只会有一个客户端获得锁。如果在集群规模比较大的情况下，会对 zookeeper 服务器的性能产生比较的影响。

可以通过有序节点来实现分布式锁，每个客户端都往指定的节点下注册一个临时有序节点，越早创建的节点，节点的顺序编号就越小，那么我们可以判断子节点中最小的节点设置为获得锁。如果自己的节点不是所有子节点中最小的，意味着还没有获得锁。这个的实现和前面单节点实现的差异性在于，每个节点只需要监听比自己小的节点，当比自己小的节点删除以后，客户端会收到 watcher 事件，此时再次判断自己的节点是不是所有子节点中最小的，如果是则获得锁，否则就不断重复这个过程，这样就不会导致羊群效应，因为每个客户端只需要监控一个节点。

Curator 对于锁这块做了一些封装，curator 提供了 InterProcessMutex 这样一个 api。除了分布式锁之外，还提供了 leader 选举、分布式队列等常用的功能。

Curator 提供了一些常见的分布式锁实现，包括：

#### 1) InterProcessMutex（分布式可重入锁）

- **简介**：`InterProcessMutex` 实现了可重入的分布式锁。它基于 ZooKeeper 实现，允许同一个客户端在同一个线程中重复获取锁。
- **使用示例**：

```java
InterProcessMutex lock = new InterProcessMutex(client, "/lockPath");
try {
    if (lock.acquire(10, TimeUnit.SECONDS)) {
        // 获取锁后的业务逻辑
    }
} finally {
    lock.release();
}
```

- **场景**：适用于需要可重入性质的场景，确保同一个客户端在同一个线程中能够多次获取锁。

#### 2)InterProcessSemaphoreMutex（分布式信号量锁）

- **简介**：`InterProcessSemaphoreMutex` 是一种基于 ZooKeeper 的分布式锁实现，与 `InterProcessMutex` 类似，但它不支持可重入性。
- **使用示例**：

```java
InterProcessSemaphoreMutex lock = new InterProcessSemaphoreMutex(client, "/lockPath");
try {
    if (lock.acquire(10, TimeUnit.SECONDS)) {
        // 获取锁后的业务逻辑
    }
} finally {
    lock.release();
}
```

- **场景**：适用于不需要可重入性质的场景，每次只能由一个客户端获取锁。

#### 3)InterProcessReadWriteLock（分布式读写锁）

- **简介**：`InterProcessReadWriteLock` 提供了分布式的读写锁实现，允许多个客户端同时获取读锁，但只允许一个客户端获取写锁。
- **使用示例**：

```java
InterProcessReadWriteLock lock = new InterProcessReadWriteLock(client, "/lockPath");
InterProcessMutex readLock = lock.readLock();
InterProcessMutex writeLock = lock.writeLock();

try {
    // 获取读锁
    readLock.acquire();
    // 获取写锁
    writeLock.acquire();
    // 释放读锁
    readLock.release();
    // 释放写锁
    writeLock.release();
} catch (Exception e) {
    // 处理异常
}
```

- **场景**：适用于读多写少的场景，允许多个客户端同时获取读锁，但只允许一个客户端获取写锁。

除了 `InterProcessMutex`、`InterProcessSemaphoreMutex` 和 `InterProcessReadWriteLock` 之外，Curator 还提供了其他一些分布式锁实现，例如：

#### 4) InterProcessMultiLock（多重锁）

- **简介**：`InterProcessMultiLock` 允许一个客户端同时获取多个锁。它接受一组锁作为参数，并在获取所有锁后进行业务逻辑处理。
- **使用示例**：

```java
InterProcessMutex lock1 = new InterProcessMutex(client, "/lockPath1");
InterProcessMutex lock2 = new InterProcessMutex(client, "/lockPath2");

InterProcessMultiLock multiLock = new InterProcessMultiLock(Arrays.asList(lock1, lock2));
try {
    if (multiLock.acquire(10, TimeUnit.SECONDS)) {
        // 获取所有锁后的业务逻辑
    }
} finally {
    multiLock.release();
}
```

- **场景**：适用于需要同时获取多个锁的情况，确保多个资源的同步访问。

#### 5) InterProcessSemaphoreV2（分布式信号量）

- **简介**：`InterProcessSemaphoreV2` 是一种分布式的计数信号量实现，用于控制同时访问的客户端数量。
- **使用示例**：

```java
InterProcessSemaphoreV2 semaphore = new InterProcessSemaphoreV2(client, "/semaphorePath", permits);
Lease lease = semaphore.acquire(10, TimeUnit.SECONDS);
if (lease != null) {
    // 获取信号量后的业务逻辑
    semaphore.returnLease(lease);
}
```

- **场景**：适用于需要控制同时访问的客户端数量的场景，类似于控制连接池中资源的并发访问量。

以上是 Curator 中的一些常用的分布式锁实现，不同的锁类型适用于不同的场景，根据具体需求选择合适的锁类型能更好地满足分布式环境下的并发控制需求。

---

### 2.5 Leader选举

Curator 提供了几种实现Leader选举的方式：

### 1） LeaderLatch

- **描述：** 参与选举的所有节点，会创建一个顺序节点，其中最小的节点会设置为 master 节点, 没抢到 Leader 的节点都监听前一个节点的删除事件，在前一个节点删除后进行重新抢主，当 master 节点手动调用 `close()` 方法或者 master节点挂了之后，后续的子节点会抢占 master。其中 spark 使用的就是这种方法。
- **原理：** 多个候选者尝试创建一个节点，成功创建的成为Leader，其他的成为参与者。Leader节点存在则表示Leader已经选举成功，Leader断开连接或主动释放Leader节点时会触发重新选举。
- **特点：**
  - **公平性：** 所有节点在加入时具有相同的权利，选举的公平性较高。
  - **固定 Leader：** 选出的 Leader 节点在没有发生连接中断或主动释放情况下，一直是 Leader 节点。
  - **自动重连：** 当连接断开时会自动重连，保证Leader选举的可靠性。
  - **高可用性：** 支持高可用，即使 Leader 断开连接，其他参与者可以重新选举 Leader。


```java
public class LeaderLatchExample {

    private static final String CONNECTION_STRING = "127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183";
    private static final String PATH = "/leader/election/path";
    
    public static void main(String[] args) throws Exception {
        CuratorFramework client = CuratorFrameworkFactory.newClient(CONNECTION_STRING, new ExponentialBackoffRetry(1000, 3));
        client.start();

        LeaderLatch leaderLatch = new LeaderLatch(client, PATH);
        leaderLatch.start();
        //阻塞当前线程，直到选举出结果
        leaderLatch.await(); 
        
        if (leaderLatch.hasLeadership()) {
            // 成为 Leader 后执行的逻辑
            System.out.println("I am the leader!");
        } else {
            // 成为 Follower 后执行的逻辑
            System.out.println("I am a follower.");
        }
        TimeUnit.SECONDS.sleep(60);
        // 停止和关闭
        leaderLatch.close();
        client.close();
    }
}
```

### 2） LeaderSelector

- **描述：** 基于 ZooKeeper 实现的Leader选举机制。
- **原理：** 多个候选者争夺Leader权利，实现一个类似于抢锁的机制。当Leader无法执行工作时（比如会话超时），其他候选者可以尝试成为Leader。
- **特点：**
  - **竞争性：** 类似于“抢锁”机制，根据选举策略、超时机制等进行Leader选举。
  - **支持权重：** 可以根据节点的权重决定Leader选举的优先级。
  - **自动重连：** 在Leader断开连接后，其他节点会重新竞选。
  - **超时机制：** 可以设置选举超时，避免节点持续无法选出Leader的情况。
  - **自定义回调：** 作为 `LeaderSelector` 的监听器接口实现，允许用户自定义选举过程中的回调行为。
  - **适配器模式：** 可以根据需要继承适配器类并覆写感兴趣的回调方法，减少了代码量。


```java
@Slf4j
public class CuratorTest3 {


    private static final String PATH = "/leader";

    private static final String URI = "127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183";

    @Test
    void test() throws IOException, InterruptedException {
        //建立curator客户端
        CuratorFramework client = CuratorFrameworkFactory.builder().connectString(URI).sessionTimeoutMs(600000).connectionTimeoutMs(300000).retryPolicy(new ExponentialBackoffRetry(1000, 3)).build();
        //启动curator客户端
        client.start();

        SelectorClient selectorClient = new SelectorClient(client, PATH, "AAA");
        selectorClient.start();
        log.info("{}  {} ", this.getClass().getSimpleName(), Thread.currentThread().getName());
        while (true) {
            Thread.sleep(5000);
            log.info("Current Node is leader ? {}", selectorClient.isLeader());
        }


    }


    public static class SelectorClient extends LeaderSelectorListenerAdapter implements Closeable {

        private final String name;
        private final LeaderSelector leaderSelector;

        private boolean isLeader = false;

        public SelectorClient(CuratorFramework curatorFramework, String path, String name) {
            this.name = name;
            /*
             * 利用一个给定的路径创建一个 leader selector
             * 执行 leader 选举的所有参与者对应的路径必须一样
             * SelectorClient 也是一个 LeaderSelectorListener ,但是这个不是必须的。
             */
            leaderSelector = new LeaderSelector(curatorFramework, path, this);
            //在大多数情况下，我们会希望一个 selector 放弃 leader 后还要重新参与 leader 选举
            leaderSelector.autoRequeue();
        }

        public void start() {
            leaderSelector.start();
        }

        public boolean isLeader() {
            return isLeader;
        }

        @Override
        public void close() throws IOException {
            leaderSelector.close();
        }

        @Override
        public void takeLeadership(CuratorFramework curatorFramework) throws Exception {
            isLeader = true;
            System.out.println(name + "now is leader , continue leader !");
            log.info("{}  {} ", this.getClass().getSimpleName(), Thread.currentThread().getName());
            //选举master
            System.in.read();//阻塞，让当前获得 leader 权限的节点一直持有，直到该进程关闭

        }
    }
}
```

这些机制在 Curator 中提供了多样化的Leader选举策略，可以根据应用需求和场景选择最适合的机制来实现Leader选举。接下来我们看一下最后的一块内容：Server 端核心参数有哪些？

---

## 3.Server 端核心参数

这里当然不会列举出全部参数，然后逐个解释，大可不必浪费时间，我只列举出一些，其他想了解的可以去官方看，官方最权威。

先来看第一组参数： **tickTime、initLimit、syncLimit** 。

* `tickTime`：ZooKeeper 服务器与客户端之间的心跳时间间隔。单位是毫秒值。也就是每隔多少毫秒发一次心跳。
* `initLimit `：Leader 与 Follower 之间建立连接后，能容忍同步数据的最长时间，单位是 `n * tickTime `，比如配置的是 `initLimit: 3 `，那就是 Leader 和 Follower 之间同步数据的最大时间是 `3*tickTime`毫秒。假如你的 ZooKeeper 里存储的数据量已经比较大了，那么 Follower 同步数据需要的时间肯定相对较长，此时可以调大这个参数，防止超时断开同步。超时后，此次同步 Leader 就不会管这个 Follower 了。
* `syncLimit`：Leader 和 Follower 之间能容忍的最大请求响应时间，单位是 `n * tickTime `，比如配置的是 `syncLimit: 3 `，那就是 Leader 和 Follower 之间一次请求响应的最大时间是 `3*tickTime `毫秒。如果超过 `3*tickTime`毫秒没有心跳，那么 Leader 就把这个 Follower 给踢出去了，认为这个 Follower 已经挂掉了。

**总结一个重点：initLimit 和 syncLimit 都是以 tickTime 为基准来进行设置，相当于 tickTime 是这三个里面的最小基本单位。**

接下来再看第二组参数： **dataDir、dataLogDir、snapCount** 。

* `dataDir`：存放 ZooKeeper 里的数据快照文件。ZooKeeper 里会存储很多的数据，内存里有一份快照，在磁盘里其实也会有一份数据的快照，用于重启、异常宕机等情况能正常恢复之前的数据。
* `dataLogDir `：存储事务日志。比如：写数据的时候按照 2PC 两阶段提交 `proposal`，然后每台机器都会写入一个本地磁盘的事务日志，这个事务日志就存放在 `dataLogDir`，如果没有显示配置 `dataLogDir`，那么事务日志会存储在 `dataDir` 目录下。
* `snapCount`：多少个事务生成一个快照。默认是 10 万个事务生成一次快照，快照文件存储到 `dataDir` 目录下。

**总结一句话：dataDir 是存放节点数据快照的地方，dataLogDir 是存放写请求两阶段提交所产生的事务日志的地方，如果 dataLogDir 没有配置，那么事务日志默认存放在 dataDir 中。而 snapCount 是决定多少个事务才生成快照文件的。**

再来看看第三组参数： **端口号** 。

我们在搭建 ZooKeeper 集群的时候都会配置两个端口号，比如如下：

```plaintext
server.1=zk1:2888:3888;2181
server.2=zk2:2888:3888;2181
server.3=zk3:2888:3888;2181
```

那为啥是两个端口号呢？这里用通俗的语言解释下。

* 2888 端口：用于 Leader 和 Follower 之间进行数据同步和通信的。
* 3888 端口：用于集群恢复模式的时候进行 Leader 选举投票的，也就是说所有的机器之间进行选举投票的时候都是基于 3888 端口来的。

我们前面已经知道 Leader 和 Follower 之间通信是有超时时间配置的，现在我们又知道 3888 端口是集群内选举投票通信用的，那这个 3888 端口的作用有没有超时时间呢？肯定也是有的～在进行 Leader 选举的时候，各个机器会基于 3888 那个端口建立 TCP 连接，在这个过程中建立 TCP 连接的超时时间可以通过如下参数来设置。

* `cnxTimeout`：5000，毫秒值。

**其实很简单：2888 是 Leader 和其他节点进行数据同步和心跳等通信的，3888是 Leader 挂了后用于机器间通信选举投票的。**

最后再来看几个参数。

一个 Znode 能保存的数据大小是多少呢？这个大小也可以通过如下参数来指定。

* `jute.maxbuffer`：默认是 1mb。也就是 1048575 字节（bytes）。

一台机器上能建立多少个客户端与 ZooKeeper 服务端的连接呢？这个肯定不是无穷大的，也可以通过参数来配置的。

* `maxClientCnxns`：默认是 60 个。假设每次请求都创建一个 ZooKeeper 客户端，跟 ZooKeeper 服务端建立连接、通信、销毁 ZooKeeper 客户端的话，那么如果并发有很多个请求一起连接 ZooKeeper 服务端，此时可能会被 ZooKeeper Server 拒绝的，因为可能超出了限制。

最后一个知识点：我们知道 Follower 无法处理写请求，写请求到 Follower 上的时候会转发到 Leader 去处理，那 Leader 一定要处理吗？能不能拒绝？可以的！

* `leaderServers`：yes。

我们知道中间件大多就配一个可视化页面，也就是管理页面来很直观地统计一些信息，比如：性能、连接数、配置等。可视化页面是前端，底层肯定要去查性能、配置、连接数等项，那怎么查呢？ZooKeeper 也为我们提供了一些运维相关的命令。

---

## 4.运维相关命令

这个就很简单易懂了，我们先列举一下有哪些常用的运维相关命令。

* `conf`：查看配置信息，也就是查 ZooKeeper 的 `zoo.conf` 配置文件。
* `cons`：查看当前 Server 被哪些 Client 连接。
* `crst`：重置客户端的统计信息。
* `srst`：重置 Server 服务端的统计信息。
* `wchs`：查看 Watcher 信息。
* `wchc`：查看 Watcher 的详细信息。
* `wchp`：也是查看 Watcher，但是会按照 znode 进行分组。
* `stat`：查看 Server 运行时状态。
* `mntr`：比上面的 stat 更为强大，`mntr` 的输出比 `stat` 更详细。
* `ruok`：检查服务是否在运行。
* `dump`：输出 `dump` 相关信息。
* `envi`：查看环境变量。

知道了这些命令的含义了，那我们怎么去用呢？很简单，语法 `echo xxx | nc localhost 2181`，比如我们演示几个。

 **先演示一下第一个：查看配置信息（conf）** 。

```bash
root@026536ecbe0c:/apache-zookeeper-3.7.1-bin# echo conf | nc localhost 2181
clientPort=2181
secureClientPort=-1
dataDir=/data/version-2
dataDirSize=201326640
dataLogDir=/datalog/version-2
dataLogSize=612
tickTime=2000
maxClientCnxns=60
minSessionTimeout=4000
maxSessionTimeout=40000
clientPortListenBacklog=-1
serverId=1
initLimit=5
syncLimit=2
electionAlg=3
electionPort=3888
quorumPort=2888
peerType=0
membership: 
server.1=zk1:2888:3888:participant;0.0.0.0:2181
server.2=zk2:2888:3888:participant;0.0.0.0:2181
server.3=zk3:2888:3888:participant;0.0.0.0:2181
version=0root@026536ecbe0c:/apache-zookeeper-3.7.1-bin# 

```

ZooKeeper 的四字命令被配置为仅允许白名单中的命令执行。在 ZooKeeper 的安全配置中，有一个配置项叫做 `4lw.commands.whitelist`，用于定义允许执行的四字命令列表。

默认情况下，大多数命令都是被禁用的，只有一部分命令在白名单中允许执行。在你尝试执行 `conf` 命令时，它被拒绝执行，因为它不在白名单中。

如果需要执行某个四字命令，需要将该命令添加到白名单中。在 ZooKeeper 的配置文件（`zoo.cfg`）中添加或修改 `4lw.commands.whitelist` 配置项，将需要执行的命令加入其中。

例如，要允许执行 `conf` 命令，你可以这样设置：

```plaintext
4lw.commands.whitelist=conf,stat
```

然后重启 ZooKeeper 服务，使配置生效。请谨慎操作白名单配置，确保只允许安全的命令。

---

> [Zookeeper 官网](https://link.juejin.cn/?target=https%3A%2F%2Fzookeeper.apache.org%2Fdoc%2Fr3.6.0%2FzookeeperCLI.html "https://zookeeper.apache.org/doc/r3.6.0/zookeeperCLI.html")
>
> [Curator 官网](https://link.juejin.cn/?target=https%3A%2F%2Fcurator.apache.org%2F "https://curator.apache.org/")

---
