---
title: 索引操作实践与深度解析
date: 2021年9月11日22:50:43
permalink: /pages/0b26e1ad-e45e-3710-a377-d9ed6d1c288f/
tags:
  - 搜索引擎
  - ElasticSearch
author:
  name: huidong.yin
  link: https://huidongyin.github.io
categories:
  - ElasticSearch
---

在现代数据驱动的应用中，高效地管理和检索数据是至关重要的。Elasticsearch（ES）作为一款强大的开源搜索和分析引擎，为我们提供了强大的数据索引和检索能力，使得数据处理变得更加高效和灵活。在ES 7.x版本中，索引API及其相关功能扮演着关键角色，帮助我们在复杂的数据场景中实现数据的有效组织和快速查询。本文将带您深入探索ES 7.x版本中索引API的基本操作，索引别名的灵活应用，以及索引的常用设置和Mapping定义。同时，我们还将探讨索引模板的概念和操作，深入了解如何启用、禁用索引，以及Reindex在开发中的实际应用场景和操作方法。最终，我们还将深入研究Reindex的官方文档，探讨其原理和源码实现，帮助您更好地理解这一重要工具的内部工作机制。

---

## 1.开发&测试中操作索引
**注意：当前这种方式仅仅推荐在开发和测试环境使用，不建议生产环境这么使用，具体原因会在下面的内容慢慢说明。**
### 1.1 创建索引
```bash
## 创建索引的最基本形式，没有指定 Mapping
PUT huidong_order

## 创建带 setting 和 Mapping 的索引
PUT huidong_order
{
  "mappings": {
    "properties": {
      "id": {
        "type": "keyword"
      },
      "name": {
        "type": "text"
      }
    }
  },
  "settings": {
    "number_of_shards": 3, 
    "number_of_replicas": 1 
  }
}
```

创建索引的限制有以下几个：

- 只能是小写字母。
- 不能包含 \，/，*，?，"，<，>，|，(空格)，,，#等字符。
- 7.0 之后的版本不能再包含 : （冒号）字符了。
- 不能以 -，_，+ 开头。名字不能是 . 或者 ..。
- 不能长于 255 字节。需要注意的是某些字符是需要多个字节来表示的。

---

### 1.2 删除索引
索引删除比较简单，没啥说的。
```bash
## 删除一个索引
DELETE huidong_order
```

删除成功返回：`{ "acknowledged" : true }`,如果索引不存在返回`404`。

---

### 1.3 判断索引是否存在
```bash
HEAD huidong_order
```

如果索引存在，那么返回的 HTTP 状态码为 200，不存在的话为 404。

---

## 2. 索引别名
ES的索引别名（Index Alias）是一个用于将一个或者多个索引关联到一个虚拟名称的标识符。这种虚拟名称可以在查询，索引，更新和删除操作中使用，从而提供了更高级别的索引管理和操作。

使用别名的好处在于，您可以在别名上执行操作，而不必担心具体的索引名称。这使得索引的维护和管理变得更加灵活和容易。通过 Elasticsearch 的 API，您可以创建、更新、删除和切换索引别名。

---

### 2.1 给索引指定别名
```bash
POST /_aliases
{
  "actions" : [
    { "add" : { "index" : "huidong_order_v1", "alias" : "huidong_order" } }
  ]
}
```

---

### 2.2 别名删除
```bash
POST /_aliases
{
  "actions" : [
    { "remove" : { "index" : "huidong_order_v1", "alias" : "huidong_order" } }
  ]
}
```

---

### 2.3 修改别名
```bash
POST /_aliases
{
  "actions" : [
    { "remove" : { "index" : "huidong_order_v1", "alias" : "huidong_order" } },
    { "add" : { "index" : "huidong_order_v1", "alias" : "order" } }
  ]
}
```

在 Elasticsearch 中，修改索引别名是一个原子性操作，它涉及两个关键步骤：删除原有别名并创建新别名。这种原子性操作确保了要么修改别名完全成功，要么完全失败，不会出现中间状态。

这一原子性机制的实现保证了在高并发访问情况下的数据一致性。一旦别名被成功修改，对应的索引指向会立即生效，所有的读取和写入操作会自动应用到新的别名所指向的索引上。

这种原子性别名修改机制为 Elasticsearch 中的索引切换、重命名、版本迁移等操作提供了更高的安全性和便利性。无论是在繁忙的业务高峰期还是日常操作中，都能够确保数据的一致性和可用性。这为数据管理带来了更大的灵活性和可控性，可以更方便地管理和操作索引别名。

---

### 2.4 为多个索引指定同一个别名
```bash
POST /_aliases
{
  "actions" : [
    { "add" : { "indices" : ["huidong_order_v1", "huidong_order_v2"], "alias" : "huidong_order" } }
  ]
}
```

---

### 2.5 为一个索引指定多个别名
```bash
PUT /huidong_order_v1/_alias/huidong_order,order
```

---

### 2.6 创建索引的时候指定别名
```json
PUT /my_index
{
  "aliases": {
    "alias_name": {}
  }
}
```
在上面的示例中，当创建名为 "my_index" 的索引时，同时为该索引指定了一个别名 "alias_name"。

---

## 3.索引设置
在 Elasticsearch 7.x 版本中，索引的设置（settings）是用来配置索引的各种行为和属性的。以下是一些常见的索引设置参数示例：

1. "number_of_shards": 设置主分片的数量。
2. "number_of_replicas": 设置副本分片的数量。
3. "analysis": 配置索引的文本分析器，包括分词器、过滤器等。
4. "refresh_interval": 设置刷新间隔，控制索引刷新的频率。
5. "max_result_window": 设置查询时的最大结果窗口大小。
6. "codec": 设置索引的压缩编解码器。
7. "routing": 自定义分片路由策略。
8. "mapping.total_fields.limit": 设置映射中允许的字段总数限制。
9. "unassigned.node_left.delayed_timeout": 配置未分配分片的延迟超时。
10. "translog.durability": 设置事务日志的持久性级别。

这只是一小部分可用的索引设置参数，Elasticsearch 提供了丰富的设置选项，允许您根据不同的需求来调整索引的行为和性能。您可以在创建索引时通过请求体中的 "settings" 字段来指定这些参数，例如：

```json
PUT /my_index
{
  "settings": {
    "number_of_shards": 5,
    "number_of_replicas": 1,
    "refresh_interval": "1s",
    "analysis": {
      "analyzer": {
        "custom_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["lowercase"]
        }
      }
    }
    // 其他设置参数...
  }
}
```

通过在创建索引请求中设置合适的索引设置参数，您可以优化索引的性能、搜索体验以及数据存储方式。如果在索引已经创建后，需要增加或修改索引的设置，可以使用 "index settings" API 来实现。这可以在不重新创建索引的情况下，更新现有索引的设置。

以下是一些示例步骤，演示如何使用 "index settings" API 来更新已存在索引的设置：

1. 获取当前索引的设置：
```json
GET /my_index/_settings
```

2. 修改索引的设置，例如增加新的分片数量、副本数量，或者修改分析器等：
```json
PUT /my_index/_settings
{
  "settings": {
    "index.number_of_shards": 5,
    "index.number_of_replicas": 2,
    "analysis": {
      "analyzer": {
        "custom_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": ["lowercase", "asciifolding"]
        }
      }
    }
  }
}
```

3. 确认修改后的设置：
```json
GET /my_index/_settings
```

通过这种方式，可以根据后期的需求变化，灵活地更新索引的设置，而无需重新创建整个索引。记得在进行任何修改之前，先对索引的设置做备份，以免意外情况导致数据丢失或不可预料的结果。

`**number_of_shards**`** 设定后是无法改变的，要修改索引的分片数量可以通过 **`**Reindex API**`** 或者收缩索引的 API 做处理。**

---

## 4. Mapping设置
在 Elasticsearch 中，通过 mappings 可以定义索引中字段的数据类型、分析器、索引选项等配置。以下是一些可以通过 mappings 设置的参数示例：

1. "properties": 定义索引中的字段及其属性，包括数据类型、分析器、索引选项等。
2. "dynamic": 设置字段的动态映射行为，控制是否允许动态添加字段。
3. "dynamic_templates": 定义动态模板，用于匹配并自动映射新字段。
4. "date_detection": 控制是否自动检测日期字段。
5. "numeric_detection": 控制是否自动检测数字字段。
6. "coerce": 控制是否尝试将字符串转换为数字或日期。
7. "format": 指定日期、数字等字段的格式。
8. "fields": 定义多字段，用于在同一个字段上应用不同的分析器。
9. "analyzer"、"normalizer"、"search_analyzer"、"index_analyzer": 为字段指定分析器和检索时使用的分析器。
10. "copy_to": 将字段的内容复制到指定字段中，以便全文搜索。
11. "index": 控制字段是否需要被索引。

这些参数可以在创建索引时通过 mappings 字段来设置，例如：
```json
PUT /my_index
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "analyzer": "standard",
        "search_analyzer": "english"
      },
      "timestamp": {
        "type": "date",
        "format": "yyyy-MM-dd HH:mm:ss"
      },
      "age": {
        "type": "integer"
      },
      // 其他字段...
    }
  }
}
```
通过定义合适的 mappings，可以确保索引中的字段被正确地映射为适当的数据类型，应用合适的分析器，以及满足特定的搜索和索引需求。

**在 Mapping 中已经定义好的字段是不能修改的。**
```json
{
    "error": {
        "root_cause": [
            {
                "type": "illegal_argument_exception",
                "reason": "mapper [name] cannot be changed from type [keyword] to [text]"
            }
        ]
    },
    "status": 400
}
```

---

## 5.索引模板
当管理和维护 Elasticsearch 索引时，利用索引模板（Index Templates）是一项强大的工具，它能够根据预定义的规则，自动将 Mapping 和 Settings 设置应用到新创建的索引中。索引模板的核心作用在于确保新索引按照预期的方式进行设置，从而提升索引的一致性和可维护性。

使用索引模板的方式如下：

1.  **定义模板：** 首先，您可以通过 Elasticsearch API 或 Kibana 界面定义一个索引模板，其中包括您希望应用于新索引的 Mapping 和 Settings 设置。 
2.  **规则匹配：** 在模板中，可以指定一些规则（通常使用通配符），以便确定哪些索引将会受到模板的影响。例如，可以使用通配符匹配索引名称、类型、别名等信息。 
3.  **自动应用：** 当新的索引被创建时，Elasticsearch 会根据模板中的规则自动应用相应的 Mapping 和 Settings 设置到新索引中。这确保了每个新索引都遵循相同的规范。 
4.  **灵活性：** 索引模板具备高度灵活性，您可以根据业务需求定义多个不同的模板，以适应不同类型的索引创建需求。 

需要注意的是，**索引模板仅在索引被新创建时产生作用。一旦索引被创建，并且模板中的规则匹配了该索引，模板将不再对已有索引的 Mapping 或 Settings 产生直接影响。**如果您希望更新已有索引的 Mapping 或 Settings，需要使用其他工具（例如 ReIndex）来完成操作。通过使用索引模板，您能够确保新创建的索引遵循统一的规则和设置，减少了手动操作的工作量，从而提高了索引管理的效率和一致性。

---

### 5.1 创建索引模板
**通过 Elasticsearch Template API 创建索引模板：**

可以使用 Elasticsearch 的 Template API 来创建索引模板。以下是通过 API 创建索引模板的步骤：

1. 向 Elasticsearch 集群发送 PUT 请求来创建一个索引模板。示例如下：

```json
PUT /_index_template/my_template
{
  "index_patterns": ["index*"],
  "template": {
    "settings": {
      "number_of_shards": 1
    },
    "mappings": {
      "properties": {
        "field1": {
          "type": "text"
        },
        "field2": {
          "type": "keyword"
        }
      }
    }
  }
}
```

上述示例中，`my_template` 是模板的名称，`index*` 是匹配的索引模式（可以使用通配符），然后定义了模板的 Settings 和 Mappings 设置。所有`index*`开头的索引会自动匹配该模板。

**通过 Kibana 创建索引模板：**

1. 打开 Kibana 控制台。
2. 在左侧导航栏中选择 "Stack Management"（堆栈管理）。
3. 在 "Index Management"（索引管理）下，点击 "Index Templates"（索引模板）选项卡。
4. 点击 "Create index template"（创建索引模板）按钮。
5. 在 "Name"（名称）字段中输入模板的名称。
6. 在 "Index patterns"（索引模式）字段中，输入匹配的索引模式，可以使用通配符。
7. 在 "Settings" 和 "Mappings" 标签下，您可以定义模板的设置和映射。
8. 完成设置后，点击 "Create index template"（创建索引模板）按钮。

无论选择使用 Template API 还是 Kibana，都可以根据业务需求定义索引模板，并在新索引被创建时自动应用模板的规则。这将确保新索引遵循一致的规范和设置。

---

### 5.2 创建索引的时候指定模板
在创建索引的请求中，使用 template 参数来指定要使用的模板名称，Elasticsearch 将根据该模板为新索引应用相应的设置和映射。
```json
PUT /my_index
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 1
  },
  "mappings": {
    "properties": {
      "id": {
        "type": "keyword"
      },
      "name": {
        "type": "text"
      }
    }
  },
  "template": "my_template"  ## 关联的模板名称
}
```
在上面的示例中，通过 template 参数指定了要使用的模板名称为 "my_template"。创建索引时，Elasticsearch 将应用该模板的设置和映射到新索引中。请确保在创建索引之前已经定义了名为 "my_template" 的索引模板。

---

## 6.启用&禁用索引
当需要对特定索引执行操作时，可能需要临时禁用或启用该索引。Elasticsearch 提供了 `_close` API 和 `_open` API 来实现索引的禁用和启用操作。

禁用索引的操作非常高效且开销较小，同时会阻塞对该索引的读写操作。在禁用状态下，索引不再允许执行任何操作，直到再次启用为止。下面是禁用和启用索引的示例：

禁用索引（使用 `_close` API）：

```json
POST /huidong_test_v1/_close
```

启用索引（使用 `_open` API）：

```json
POST /huidong_test_v1/_open
```

需要注意的是，**禁用和启用索引的操作是原子性的，确保了操作的完整性和一致性**。在某些情况下，禁用索引可以用于临时阻止对索引的操作，如进行维护或数据迁移。一旦操作完成，您可以使用 `_open` API 来启用索引，使其恢复正常的读写操作。

通过使用 `_close` 和 `_open` API，您可以在需要的时候有效地管理索引的状态，从而更灵活地进行索引维护和操作。

---

## 7.~~收缩索引~~
如果最初创建的索引分片设置过大，您可以使用 Elasticsearch 提供的收缩索引 API 来将该索引的分片数减少。

在执行索引收缩操作之前，需要确保执行以下操作：

1. 源索引必须处于只读状态，不允许进行写入操作。
2. 源索引的所有副本（包括主分片和副本分片）必须位于同一节点上，确保该节点上包含了源索引的所有数据。
3. 源索引的状态必须为健康状态（green）。

收缩后的新索引的主分片数量必须是源索引主分片数量的一个因子，例如，源索引的主分片分配了 12 个，那么收缩后的新索引的主分片数只能为 `1、2、3、4、6`。

**在 Elasticsearch 7.x 版本中，不再支持通过 _shrink 操作来执行索引的收缩。该功能在 Elasticsearch 6.x 版本中是支持的，但在 Elasticsearch 7.x 版本中被移除了。**如果需要收缩索引或执行其他类似的操作，可能需要考虑使用其他方法，如创建新的索引并重新索引数据。

---

## 8.ReIndex
### 8.1 基本介绍
在某些情况下，当索引的需求发生变化，如字段类型的修改或分片数量的调整，需要进行索引重建以保持数据的准确性和一致性。在这种情况下，可以借助 Elasticsearch 提供的 ReIndex API 来高效地将数据从一个索引迁移到另一个索引。

假设当前我们需要将数据从名为 huidong_test_v1 的索引迁移到名为 huidong_test_v2 的索引，以下是迁移的一般步骤：

1.  创建目标索引：首先，需要创建一个新的 huidong_test_v2 索引，确保其满足新的需求，包括修改后的 Mapping、分片数量等设置。 
2.  使用 ReIndex API：通过 Elasticsearch 的 ReIndex API，将 huidong_test_v1 索引的数据迁移到 huidong_test_v2 索引。ReIndex 操作会将数据按照指定的方式从源索引复制到目标索引，并根据新的 Mapping 进行重新索引。 
3.  监控进度和处理错误：在 ReIndex 过程中，可以监控操作的进度和状态，确保数据的准确性和完整性。如果出现错误，可以根据日志信息进行调查和处理。 
4.  验证和测试：迁移完成后，需要对 huidong_test_v2 索引的数据进行验证和测试，确保数据的正确性和可用性。 

```bash
POST _reindex?wait_for_completion=false
{
	"source":{
                ### 旧的索引
		"index":"huidong_test_v1",
		"size":5000
	},
	"dest":{
                ### 新的索引
		"index":"huidong_test_v2",
		"op_type":"index"
	},
	"conflicts":"proceed"
}
```

1.  `"source"`（源索引设置）： 
   - `"index": "huidong_test_v1"`：指定源索引的名称，即从哪个索引复制数据。
   - `"size": 5000`：每次从源索引获取的文档数量。这里设置为 5000，表示每次从源索引复制 5000 条文档。
2.  `"dest"`（目标索引设置）： 
   - `"index": "huidong_test_v2"`：指定目标索引的名称，即数据将被复制到哪个索引中。
   - `"op_type": "index"`：指定操作类型。在这里设置为 `"index"`，表示执行索引操作，将文档添加到目标索引中。其他可选的操作类型还包括 `"create"` 和 `"update"`。
3.  `"conflicts": "proceed"`：定义冲突处理策略。 
   - `"proceed"`：表示如果存在冲突，继续执行操作。如果文档在目标索引中已经存在，就继续执行并覆盖已存在的文档。
   - 其他可选值包括 `"abort"`（中止操作）和 `"replace"`（替换操作）。

这个请求的作用是将源索引 `huidong_test_v1` 中的数据以每次 5000 条的速度复制到目标索引 `huidong_test_v2` 中，如果遇到冲突，则继续执行并覆盖已存在的文档。同时，这个操作是在后台异步执行，不会等待操作完成。

如果索引中的数据很多，reindex的时间会很长，这种情况下同步等待其实会导致http请求超时，所以在上面的bash中添加了`?wait_for_completion=false`参数，这表示该操作需要异步执行，此时会返回一个TaskId，我们可以根据这个TaskId查询任务的执行情况。

```bash
GET _tasks/uhWJdRy3SkOy9ueR_-fbMg:28112265
```

---

### 8.2 常用操作
需求：由于业务变更，目前的索引字段已经不满足，需要新增两个字段。
分析：使用reindex api。

1. 修改索引模板。
2. 创建新的索引。
3. 数据迁移
4. 给新索引添加别名并移除旧索引
#### 1）修改索引模板
```bash
PUT _template/huidong_test
{
  "order": 0,
  "aliases": {
    
  },
  "index_patterns": [
    "huidong_test*"
  ],
  "mappings": {
    "properties": {
      "id":{
        "type": "keyword"
      },
      "name":{
        "type": "keyword",
        "fields": {
          "text":{
            "type":"text"
          }
        }
      },
      "age":{
        "type": "integer"
      },
      "occupation":{
        "type": "text"
      },
      "hobby":{
        "type": "text"
      }
    }
  }
}
```

---

#### 2）创建新的索引
```bash
PUT huidong_test_v2
{
  
}
```

---

#### 3）数据迁移ReIndex
```bash
POST _reindex?wait_for_completion=false
{
	"source":{
		"index":"huidong_test_v1",
		"size":5000
	},
	"dest":{
		"index":"huidong_test_v2",
		"op_type":"index"
	},
	"conflicts":"proceed"
}
```

---

#### 4）给新索引添加别名并移除旧的索引
```bash
POST /_aliases
{
	"actions":[
		{
			"add":{
				"index":"huidong_test_v2",
				"alias":"huidong_test"
			}
		},
		{
			"remove_index":{
				"index":"huidong_test_v1"
			}
		}
	]
}
```
这个操作是在 Elasticsearch 中使用 _aliases API 来执行两个操作：添加一个索引别名，然后移除一个索引。

1. **添加别名操作**：这个操作将索引别名 huidong_test 绑定到索引 huidong_test_v2 上。这意味着以后可以通过别名 huidong_test 访问和查询索引 huidong_test_v2 中的数据。

2. **移除索引操作**：这个操作会将索引 huidong_test_v1 从集群中移除，即删除该索引。一旦这个操作执行成功，与索引 huidong_test_v1 相关的所有数据都会被清除，包括文档、设置等。

总的来说，这个操作的目的是通过别名切换来实现索引的更新和删除。首先，它将一个别名绑定到一个新的索引上，以便后续操作可以通过这个别名进行访问。然后，它移除一个旧的索引，以完成索引的删除或更新操作。

---

### 8.3 官方文档解读
#### 1）参数
##### ①URL参数
| 参数 | 注释 |
| --- | --- |
| refresh | 默认是false，目标索引是否立即刷新，也就是让数据立马可以搜索到。 |
| timeout | 默认为1m(一分钟)。这保证了Elasticsearch在失败前至少等待超时。实际等待时间可能会更长，尤其是在发生多次等待的情况下。 |
| wait_for_active_shards | 在继续操作之前必须处于活动状态的分区副本的数量。设置为all或任意正整数，最大值为索引中的分片总数(副本数+1)。默认值:1，主分片。 |
| Scroll | 滚动查询时快照的保留时间 |
| slicing | reindex并行任务切片 |
| Max_docs | 单次最大数据量，条数 |
| requests_per_second | 单次执行的重建文档数据量 |


---

##### ②请求体参数
| 参数 | 注释 |
| --- | --- |
| confilicts | 索引数据冲突如何解决，直接覆盖还是中断，默认值：abort。 |
| source | 源索引配置信息 |
| dest | 目标索引的配置信息 |
| script | 脚本处理，修改源索引信息后再写入新索引 |


---

#### 2）reindex高级应用
##### ①每秒数据量阈值控制

`requests_per_second`字段控制每秒迁移数据量的大小，默认不设置是1000，设置-1则表示没有限制；生产环境重建时，建议控制在500-1000这个范围内，控制重建速度，主要是为了防止集群瞬间IO过大。
```bash
target_time = 1000 / 500 per second = 2 seconds
wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
```

---

##### ②手动切片

1. 手动指定切片数量，并行任务。
2. 用于降低索引reindex的速度。

```bash
POST _reindex
{
    "source":{
        "index":"old-index",
        "slice":{
            //执行下标，从0开始，即0切第一批数据做迁移，1切第二批数据做迁移
            "id":0,
            //切分分片数
            "max":2
        }
    },
    "dest":{
        "index":"new-index"
    }
}
```

---

##### ③自动切片
仅仅需要指定自动切片的大小即可，后续的调度交给ES异步处理。
```bash
POST _reindex?slices=5&refresh
{
    "source":{
        "index":"old-index"
    },
    "dest":{
        "index":"new-index"
    }
}
```

---

##### ④限制reindex重建数据的范围
###### query
基于DEL语言规则编写，可以任意复杂，限制数据范围。

```bash
POST _reindex
{
  "source": {
    "index": "my-index-000001",
    "query": {
      "term": {
        "user.id": "zhangsan"
      }
    }
  },
  "dest": {
    "index": "my-new-index-000001"
  }
}
```

---

###### max docs
限制重建数据总条数，默认全部。
```bash
POST _reindex
{
  "max_docs": 1,
  "source": {
    "index": "my-index-000001"
  },
  "dest": {
    "index": "my-new-index-000001"
  }
}
```

---

##### ⑤多索引重建
Es支持将多个索引的数据合并到一个索引里面，如果出现Id冲突的情况，则会互相覆盖。

```bash
POST_reindex
{
  "source": {
    "index": ["my-index-000001", "my-index-000002"]
  },
  "dest": {
    "index": "my-new-index-000002"
  }
}
```

---

##### ⑥限制重建索引的字段
使用 `_source` 进行过滤。

```bash
POST_reindex
{
  "source": {
    "index": "my-index-000001",
    "_source": ["user.id", "_doc"]
  },
  "dest": {
    "index": "my-new-index-000001"
  }
}
```

---

##### ⑦重建并修改字段名
基于Es脚本机制实现。

> ES字段名称原始是不允许修改的，但通过脚本可以操作。


```bash
POST _reindex
{
  "source": {
    "index": "my-index-000001"
  },
  "dest": {
    "index": "my-new-index-000001"
  },
  "script": {
    // reindex && change field name from flag -> tag
    "source": "ctx._source.tag = ctx._source.remove("flag")"
  }
}
```

---

##### ⑧重建并修改原始文档数据
同样是基于Es脚本实现。

```bash
POST _reindex
{
  "source": {
    "index": "metricbeat-*"
  },
  "dest": {
    "index": "metricbeat"
  },
  "script": {
    "lang": "painless",
    "source": "ctx._index = 'metricbeat-' + (ctx._index.substring('metricbeat-'.length(), ctx._index.length())) + '-1'"
  }
}
```

---

#### 3）Reindex Routing
默认情况下，如果`_reindex`扫描到一个带路由的文档，除非用脚本更改，否则路由将会被保留。可以通过在`dest`参数上设置路由来改变这种情况。

- `keep`：如果文档带有路由，就继续保留使用原来的路由。
- `discard`：即使有路由也将路由设置成`null`。
- `=<some text>`：等于号后面是什么内容就设置每一个文档的路由是什么。

For Example：将所有公司名称为cat的文档reindex到新的路由，并设置路由为cat。

```bash
POST _reindex
{
  "source": {
    "index": "source",
    "query": {
      "match": {
        "company": "cat"
      }
    }
  },
  "dest": {
    "index": "dest",
    "routing": "=cat"
  }
}
```

> 注意：路由设置的不好会导致集群中的数据发生倾斜，请谨慎设置。


默认`_reindex`使用的游标查询分页大小为1000，可以通过source里面的size字段来更改这个值。

```bash
POST _reindex
{
  "source": {
    "index": "source",
    "size": 100
  },
  "dest": {
    "index": "dest",
    "routing": "=cat"
  }
}
```

---

#### 4）跨集群索引重建

1. 基于集群通信，类同远程机制。
2. 需要设置跨集群白名单，配置在dist集群。

```bash
POST _reindex
{
  "source": {
    "remote": {
      "host": "http://otherhost:9200",
      "username": "user",
      "password": "pass"
    },
    "index": "my-index-000001",
    "query": {
      "match": {
        "test": "data"
      }
    }
  },
  "dest": {
    "index": "my-new-index-000001"
  }
}
```

1. `host` 参数必须包含 `scheme，host，port` 可以包含可选路径。
2. `username & password`参数是可选的，当他们存在时，`_reindex`将使用安全连接到远程Es节点。使用基本身份验证时，请确保使用https请求，否则密码将以明文发送。
3. 必须使用`reindex.remote.whitelist`属性在`elasticsearch.yml`中明确允许远程主机。他可以设置为允许的远程主机和端口组合的逗号分隔列表，`scheme`被忽略，仅仅使用IP和端口。

```yaml
reindex.remote.whitelist: "otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"
```

在每个协调节点上都需要配置白名单。

Elasticsearch不支持在不同主要版本之间进行向前兼容。举例来说，无法将数据从一个7.x版本的集群重新索引到一个6.x版本的集群中。为了能够成功地将请求发送到旧版本的节点，系统不会对请求参数进行验证或修改。

在跨集群的 reindex 操作中，无法使用手动或自动分片切片（slicing）。跨集群的 reindex 操作默认最大使用100MB的堆外内存。如果待重新索引的索引中包含大量文档，需要将每个批次的大小调小。下面的示例演示了如何将批大小修改为10。

```bash
POST _reindex
{
  "source": {
    "remote": {
      "host": "http://otherhost:9200"
    },
    "index": "source",
    "size": 10,
    "query": {
      "match": {
        "test": "data"
      }
    }
  },
  "dest": {
    "index": "dest"
  }
}
```

可以通过`socket_timeout` & `connect_timeout`参数设置跨集群的connect超时时间和socket缓冲区的超时时间，二者默认都是30s。下面的示例是将socket读超时时间设置为1分钟并且将连接超时时间设置为10s。

```bash
POST _reindex
{
  "source": {
    "remote": {
      "host": "http://otherhost:9200",
      "socket_timeout": "1m",
      "connect_timeout": "10s"
    },
    "index": "source",
    "query": {
      "match": {
        "test": "data"
      }
    }
  },
  "dest": {
    "index": "dest"
  }
}
```

---

### 8.4 Reindex原理分析
Reindex 操作其实就是将数据从一个索引复制到另一个索引，**本质其实就是数据的读写**。

---

#### 1）Reindex读操作
数据的读取和复制通常最高效的方法就是将数据从一个索引复制到另一个索引，不过这需要目标索引和源索引的主分片数量相匹配。

当进行Reindex操作时，Elasticsearch默认会需要读取完整的数据集。具体的数据获取过程是通过使用Scroll查询来实现的。Reindex操作的源码位于一个独立的模块中，其中核心逻辑包含在`TransportReindexAction`的`doExecute`方法中。这个方法会将Reindex任务转换为`BulkByScrollTask`类型的任务，并将这个转换后的任务交给`Reindexer`的`execute`方法进行处理。

在执行`execute`方法时，实际上会调用`executeSlicedAction`方法。这个方法的作用是将任务进行切片，并以并行方式获取数据。这样做有助于提高数据获取的效率，特别是当处理大规模数据时。

在每个并行操作中，会启动一个异步的`searchAction`来获取数据。这个过程是在多个线程或者任务中同时进行的，以加速数据的获取过程。这种并行化的操作对于优化数据获取的性能非常重要，尤其是在处理大量数据时。通过并行化，Elasticsearch可以更加高效地执行Reindex操作，确保数据迁移和转换过程的高效完成。

---

#### 2）Reindex写操作
数据写入时，首先会根据数据的路由规则被导向相应的处理节点。随后，这些数据会被写入索引缓冲区（Index Buffer），该缓冲区允许对数据进行快速写入，而不需要立即写入磁盘。接下来，相关记录会被写入事务日志，这样可以确保即使在意外宕机等情况下，数据的变更也能够被恢复。在这个过程中，系统会返回写入成功的响应，让用户得知操作已成功提交。

默认情况下，Elasticsearch每秒执行一次刷新（Refresh）操作，将索引缓冲区中的数据写入实际的文件系统，并生成新的段（Segment）文件。此外，在满足一些触发条件的情况下，还会执行Flush和Merge操作。Flush会将缓冲区中的数据持久化到磁盘，而Merge则是对多个段进行合并和优化，以减少搜索时的开销，提高查询性能。

在Reindex操作中，一旦数据被读取，`Reindexer`会借助静态内部类`AbstractAsyncBulkByScrollAction`创建批量请求。这些请求会被分发到相应的节点进行处理。这种异步批量操作机制能够有效地处理大量数据的迁移和复制，从而提升了数据操作的效率和性能。这样的设计使得Elasticsearch在处理数据时能够保持高吞吐率和可靠性。

---

### 8.5 Reindex性能优化
在实际开发中，如果使用Reindex API重建大量数据的索引，可能会遇到默认性能较低的情况，即使是在同一集群内进行Reindex操作，数据传输速度也可能仅达到每秒几兆字节的级别。

正如前文所述，Reindex的读操作基于底层的并行Scroll查询，而写操作则涉及异步的批量请求。利用这些信息，我们可以对Reindex进行优化，以提高执行效率，关键在于对读写操作进行适当的调优控制。

---

#### 1）大胆假设
Reindex API 为什么会慢呢？

1. 批量写的参数设置不合理，比如bulk一批数据量太大，比如触发写策略没有调整好。
2. 并行Scroll读操作在不同数据量下面没有控制好并发度。
3. 硬件配置 | 网络带宽 垃圾。

抛开硬件|网络带宽，我们考虑从读写两个方面优化。

---

#### 2）读操作优化

通过并行的Scroll操作读取数据。并行读的方式有两种：手动和自动；上面已经介绍过了。

虽然使用 Slicing 可以提高 Reindex 的效率，但如果使用不当，效果可能会适得其反。下面是几个 Slicing 设置的注意事项：

1. slices 除了可以设定为数字外，slices 也可以设置为 `auto`，设置为 auto 表示：如果源索引是单索引，则 slices = 源索引的主分片数量值；如果源索引是多索引，则 slices = 各个源索引中最小的主分片数量值。
2. slices 的值并不是越大越好的，过大的 slices 会影响性能。slices 的值等于源索引主分片数量值的时候效率会最高，当 slices 大于源索引主分片数量值时，不会提高效率，反而会增加开销，

**没有特定需求的情况下，slices 设置为 **`**auto**`** 即可。**

---

#### 3）写操作优化

1. 设置合适的bulk大小。
2. 设置目标索引的副本数为0。

> 减少副本数量可以提高写入的效率，在数据 Reindex 完成后，再设置需要的副本数，这样系统会自动创建出需要的副本数。


3. 调整 `index.refresh_interval`。

> 减少 `Index Refresh` 的次数可以减少生成 Segment 的数量，也减少了 Merge 的频率。默认的情况下，`ES Refresh` 操作会每秒进行一次，可以通过调整 `index.refresh_interval` 的值来调整 Refresh 的时间间隔。
>  
> 可以将 `refresh_interval` 设置为 -1 来关闭 Refresh，当然在 `Index Buffer` 写满时还是会进行 Refresh的。
>  
> 在 Reindex 完成后，需要把这个设置回原来的值。


4. 加大 Translog Flush 的间隔。

> 为了防止数据丢失，保证数据的可靠性，默认的情况下是每个请求 `Translog` 都刷盘。如果我们是在导入数据的应用场景，那么为了提高写入的性能，可以不每个请求都对 `Translog` 进行刷盘。


**如何改变**`**Translog**`**的设置？**

```bash
PUT /myindex/_settings
{
  "index.translog.durability":"async",
  "index.translog.sync_interval": "240s",
  "index.translog.flush_threshold_size": "512m"
}
```

async 是指异步刷盘，每隔 `index.translog.sync_interval` 进行刷盘。当然，当 `Translog` 的量达到 `flush_threshold_size` 的时候也会触发刷盘。

---

### 8.6 性能调优
回头在搞。

---

> [[更多内容->官网文档](https://www.elastic.co/guide/en/elasticsearch/reference/7.17/docs-reindex.html)]

