---
title: 高级应用-过期时间TTL
date: 2023-01-01 00:00:00
tags:
    - Kafka
    - 消息队列
categories:
    - Kafka
description: 高级应用-过期时间TTL
toc_number: false
author:
name: huidong.yin
link: https://huidongyin.github.io
permalink: /pages/804a1c7c-f9ca-31ce-920e-2fac4cc38efe/

---

消息超时之后不是只能被直接丢弃， 因为从消息可靠性层面而言这些消息就丢失了，消息超时可以配合死信队列使用，这样原本被丢弃的消息可以被再次保存起来，方便应用在此之后通过消费死信队列中的消息来诊断系统的运行概况。如果要实现自定义每条消息TTL的功能， 那么应该如何处理呢?

这里可以沿用消息的`timestamp`字段和拦截器ConsumerInterceptor接口的`onConsume()`方法， 不过我们还需要消息中的`headers`字段来做配合。我们可以将消息的TTL的设定值以键值对的形式保存在消息的`headers`字段中， 这样消费者消费到这条消息的时候可以在拦截器中根据`headers`字段设定的超时时间来判断此条消息是否超时。

下面我们来通过一个具体的示例来演示自定义消息TTL的实现方式。这里使用了消息的`headers`字段， 而`headers`字段涉及Headers和Header两个接口， Headers是对多个Header的封装， Header接口表示的是一个键值对， 具体实现如下：

```java
package org.apache.kafka.common.header;
public interface Header{
	String key() ;
	byte[] value() ;
}
```

这里可以直接使用Kafka提供的实现类`org.apache.kafka.common.header.internals.RecordHeaders`和`org.apache.kafka.common.header.internals.RecordHeader`。这里只需使用一个Header，key可以固定为`ttl`，而value用来表示超时的秒数， 超时时间一般用Long类型表示， 但是RecordHeader中的构造方法`RecordHeader(String key， byte[] value)`和`value()` 方法的返回值对应的value都是`byte[]` 类型， 这里还需要一个小工具实现整型类型与`byte[]` 的互转， 具体实现如下：

```java
public class BytesUtils {
    public static byte[] longToBytes(long res) {
        byte[] buffer = new byte[8];
        for (int i = 0; i < 8; i++) {
            int offset = 64 - (i + 1) * 8;
            buffer[i] = (byte) ((res >> offset) & 0xff);
        }
        return buffer;
    }

    public static long bytesToLong(byte[] b) {
        long values = 0;
        for (int i = 0; i < 8; i++) {
            values <<= 8;
            values |= (b[i] & 0xff);
        }
        return values;
    }
}
```

下面我们向Kafka中发送3条TTL分别为20秒、5秒和30秒的3条消息， 主要代码如下。

```java
    public static void produce()throws Exception {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
        props.put(ProducerConfig.RETRIES_CONFIG, 10);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, UserSerializer.class.getName());
        props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, DefaultPartitioner.class.getName());
        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, "");
        props.put(ProducerConfig.ACKS_CONFIG, "0");
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);

        ProducerRecord<String, String> record1 = new ProducerRecord<>(topicName, 0, System.currentTimeMillis(), null, "msg_ttl_1", new RecordHeaders().add(new RecordHeader("ttl", BytesUtils.longToBytes(20))));
        //超时的消息
        ProducerRecord<String, String> record2 = new ProducerRecord<>(topicName, 0, System.currentTimeMillis()-5*1000, null, "msg_ttl_2", new RecordHeaders().add(new RecordHeader("ttl", BytesUtils.longToBytes(5))));
        ProducerRecord<String, String> record3 = new ProducerRecord<>(topicName, 0, System.currentTimeMillis(), null, "msg_ttl_3", new RecordHeaders().add(new RecordHeader("ttl", BytesUtils.longToBytes(30))));

        producer.send(record1).get();
        producer.send(record2).get();
        producer.send(record3).get();
        
        producer.close();
    }
```

ProducerRecord 中包 Headers 字段的构造方法只有2个，具体如下：

```java
public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value, Iterable<Header> headers)；
public ProducerRecord(String topic, Integer partition, K key, V value, Iterable<Header> headers)
```


上面代码中的第2条消息`record2`是故意被设定为超时的， 因为这条消息的创建时间为`System.currentTimeMillis() - 5×1000`，往前推进了5秒， 而这条消息的超时时间也为5秒。如果在发送这3条消息的时候也开启了消费者，那么经过拦截器处理后应该只会收到`msg_ttl_1`和`msg_ttl_3`这两条消息。

我们再来看一下经过改造之后拦截器的具体实现。

```java
public class TtlConsumerInterceptor implements ConsumerInterceptor<String, String> {
    @Override
    public ConsumerRecords<String, String> onConsume(ConsumerRecords<String, String> records) {
        long now = System.currentTimeMillis();
        Map<TopicPartition, List<ConsumerRecord<String, String>>> newRecords = new HashMap<>();
        for (TopicPartition tp : records.partitions()) {
            List<ConsumerRecord<String, String>> tpRecords = records.records(tp);
            List<ConsumerRecord<String, String>> newTpRecords = new ArrayList<>();
            for (ConsumerRecord<String, String> record : tpRecords) {
                Headers headers = record.headers();
                long ttl = -1;
                for (Header header : headers) {
                    if (header.key().equalsIgnoreCase("ttl")) {
                        ttl = BytesUtils.bytesToLong(header.value());
                    }
                }

                if ((ttl > 0 && now - record.timestamp() < ttl * 1000) || ttl < 0) {
                    newTpRecords.add(record);
                }
            }

            if (!newTpRecords.isEmpty()) {
                newRecords.put(tp, newTpRecords);
            }
        }
        return new ConsumerRecords<>(newRecords);
    }

    @Override
    public void close() {

    }

    @Override
    public void onCommit(Map offsets) {

    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}
```

上面代码中判断每条消息的`headers`字段中是否包含key为`ttl`的Header，如果包含则对其进行超时判定；如果不包含，则不需要超时判定，即无须拦截处理。

使用这种方式实现自定义消息TTL时同样需要注意的是：使用类似这种带参数的位点提交的方式，有可能会提交错误的位点信息。在一次消息拉取的批次中，可能含有最大偏移量的消息会被消费者拦截器过滤。不过这个也很好解决，比如在过滤之后的消息集中的头部或尾部设置一个状态消息，专门用来存放这一批消息的最大偏移量。

到目前为止， 无论固定消息TTL， 还是自定义消息TTL， 都是在消费者客户端通过拦截器来实现的， 其实这个功能也可以放在Kafka服务端来实现， 而且具体实现也并不太复杂。不过这样会降低系统的灵活性和扩展性，并不建议这么做，通过扩展客户端就足以应对此项功能。

---