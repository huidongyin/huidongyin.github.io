---
title: 主题-主题管理
date: 2023-01-01 00:00:00
tags:
  - Kafka
  - 消息队列
categories:
  - Kafka
description: 主题-主题管理
toc_number: false
author:
  name: huidong.yin
  link: https://huidongyin.github.io
permalink: /pages/dbe6fcd9-6490-3b92-804a-ea7117ef815d/
---

生产者和消费者的设计理念所针对的都是主题和分区层面的操作。主题作为消息的归类，可以再细分为一到多个分区，分区可以看做是对消息的二次分类。分区的划分为kafka提供了可伸缩性，水平扩展功能，还可以通过多副本机制来为kafka提供数据冗余以提高数据可靠性。

从kafka的底层实现来看，主题和分区都是逻辑上的概念，分区可以有一到多个副本，每个副本对应一个日志文件，每个日志文件对应一到多个日志分段，每个日志分段还可以细分为**索引文件** ，**日志存储文件** 和 **快照文件** 等。

Topic管理包括创建，查看Topic信息，修改和删除等操作。可以通过Kafka提供的 `kafka-topics.sh`脚本来执行这些操作，这个脚本位于`$KAFKA_HOME/bin/`目录下，其核心代码仅仅只有一行：

```bash
exec $ (dirname $0) /kafka-run-class.sh kafka.admin.TopicCommand "$@"
```

可以看到其实质上是调用了 `kafka.admin.TopicCommand`类来执行主题管理的操作。主题的管理并非只有使用`kafka-topics.sh`脚本这一种方式，我们还可以通过`KafkaAdminClient`的方式实现（这种方式本质上是通过发送`CreateTopicsRequest`,`DeleteTopicsRequest`等请求来实现的）。

---

## 1. 创建主题

如果 broker 端配置参数 `auto.create.topics.enable` 设置为 tue(默认值就是 true)，那么当生产者向一个尚未创建的主题发送消息时,会自动创建一个分区数为 `num.partitions`(默认值为1)、副本因子为 `default.replication.factor` (默认值为1)的主题。除此之外，当一个消费者开始从未知主题中读取消息时，或者当任意一个客户端向未知主题发送元数据请求时，都会按照配置参数 `num.partitions`和 `default.replication.factor`的值来创建一个相应的主题。很多时候，这种自动创建主题的行为都是非预期的。除非有特殊应用需求，否则不建议将 `auto.create.topics.enable`参数设置为 true，这个参数会增加主题的管理与维护的难度。

下面通过 `kafka-topics.sh`脚本创建一个Topic。

```bash
root@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-create --replication-factor 2 --partitions 4
Created topic topic-create.
root@101ed4754423:/opt/kafka_2.13-2.8.1/bin#
```

上面的示例中创建了一个分区数为 4、副本因子为 2 的主题。示例中的环境是一个包含 3个 broker 节点的集群，每个节点的名称和 brokerld 的对照关系如下:

| 节点名称   | brokerId |
|--------|----------|
| Kafka0 | 0        |
| Kafka1 | 1        |
| Kafka2 | 2        |

在执行完脚本之后，Kafka 会在 `log.dir` 或 `log.dirs`参数所配置的目录下创建相应的主题分区，默认情况下这个目录为`/tmp/kafka-logs/`。我们来看当前broker节点上创建的主题分区：

```bash
root@101ed4754423:/kafka# cd kafka-logs-101ed4754423/
root@101ed4754423:/kafka/kafka-logs-101ed4754423# ls -al ./ | grep topic-create
drwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-0
drwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-1
root@101ed4754423:/kafka/kafka-logs-101ed4754423#
```

可以看到当前节点中创建了 2 个文件夹 `topic-create-0` 和 `topic-create-1`，对应主题 `topic-create` 的2 个分区编号为0和1 的分区，命名方式可以概括为`<topic>-<partition>`。严谨地说，其实`<topic>-<partition>`这类文件夹对应的不是分区，分区同主题一样是一个逻辑的概念而没有物理上的存在。并且这里我们也只是看到了 2 个分区，而我们创建的是 4 个分区，其余 2个分区被分配到了 Kafka1 和 Kafka2 节点中。

```bash
# ls -al ./ |grep topic-create
drwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-1
drwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-2
drwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-3
#
```

```bash
# ls -al ./ |grep topic-create
drwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-0
drwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-2
drwxr-xr-x  2 root root 4096 Oct 31 13:49 topic-create-3
#
```

三个 broker 节点一共创建了 8 个文件夹，这个数字 8 实质上是分区数 4与副本因子2 的乘积。每个副本(或者更确切地说应该是日志，副本与日志一一对应)才真正对应了一个命名形式如`<topic>-<partition>`的文件夹。

主题和分区都是提供给上层用户的抽象，而在副本层面或更加确切地说是 Log 层面才有实际物理上的存在。同一个分区中的多个副本必须分布在不同的 broker 中，这样才能提供有效的数据冗余。对于示例中的分区数为 4副本因子为 2、broker 数为 3 的情况下，按照 2、3、3 的分区副本个数分配给各个 broker 是最优的选择。再比如在分区数为 3、副本因子为 3，并且 broker 数同样为 3 的情况下，分配 3、3、3的分区副本个数给各个 broker 是最优的选择，也就是每个 broker 中都拥有所有分区的一个副本。

![](https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311041758651.png)

我们不仅可以通过日志文件的根目录来查看集群中各个 broker 的分区副本的分配情况,还可以通过 ZooKeeper 客户端来获取。当创建一个主题时会在 ZooKeeper 的`/brokers/topics`目录下创建一个同名的实节点，该节点中记录了该主题的分区副本分配方案。示例如下，

```bash
[zk: localhost:2181(CONNECTED) 0] get /brokers/topics/topic-create
{"partitions":{"0":[2,0],"1":[0,1],"2":[1,2],"3":[2,1]},"topic_id":"iBO5jkiXSVuDFrlFowPUVQ","adding_replicas":{},"removing_replicas":{},"version":3}
[zk: localhost:2181(CONNECTED) 1]
```

示例数据中的`2:[1,2]`表示分区 2 分配了 2 个副本，分别在 brokerId 为 1和 2 的 broker节点中。

通过 `describe` 指令类型来查看分区副本的分配细节。

```bash
root@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-create 
Topic: topic-create	TopicId: iBO5jkiXSVuDFrlFowPUVQ	PartitionCount: 4	ReplicationFactor: 2	Configs: 
	Topic: topic-create	Partition: 0	Leader: 2	Replicas: 2,0	Isr: 2,0
	Topic: topic-create	Partition: 1	Leader: 0	Replicas: 0,1	Isr: 0,1
	Topic: topic-create	Partition: 2	Leader: 1	Replicas: 1,2	Isr: 1,2
	Topic: topic-create	Partition: 3	Leader: 2	Replicas: 2,1	Isr: 2,1
root@101ed4754423:/opt/kafka_2.13-2.8.1/bin#
```

示例中的 `Topic`和 `Partition` 分别表示主题名称和分区号。`PartitionCount` 表示主题中分区的个数，`ReplicationFactor`表示副本因子，而 `Configs` 表示创建或修改主题指定的参数配置。`Leader`表示分区的 `leader` 副本所对应的 `brokerId`,`Isr`表示分区的ISR集合`Replicas` 表示分区的所有的副本分配情况，即 AR 集合，其中的数字都表示的是 `brokerld`。

`kafka-topics.sh`脚本中还提供了一个 `replica-assignment`参数来手动指定分区副本的分配方案。这种方式根据分区号的数值大小按照从小到大的顺序进行排列，分区与分区之间用逗号“，”隔开，分区内多个副本用冒号“:”隔开。并且在使用 `replica-assignment` 参数创建主题时不需要原本必备的 `partitions` 和 `replication-factor` 这两个参数。

通过`replica-assignment`参数来创建一个与主题`topic-create`相同的分配方案的主题 `topic-create-same`和不同的分配方案的主题 `topic-create-diff`。

```bash
root@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-create-same --replica-assignment 2:0,0:1,1:2,2:1
Created topic topic-create-same.
root@101ed4754423:/opt/kafka_2.13-2.8.1/bin# 
root@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe  --topic topic-create-same
Topic: topic-create-same	TopicId: Uza2jU5bQymPfChvfbstUg	PartitionCount: 4	ReplicationFactor: 2	Configs: 
	Topic: topic-create-same	Partition: 0	Leader: 2	Replicas: 2,0	Isr: 2,0
	Topic: topic-create-same	Partition: 1	Leader: 0	Replicas: 0,1	Isr: 0,1
	Topic: topic-create-same	Partition: 2	Leader: 1	Replicas: 1,2	Isr: 1,2
	Topic: topic-create-same	Partition: 3	Leader: 2	Replicas: 2,1	Isr: 2,1
	
root@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-create-diff --replica-assignment 1:2,2:0,0:1,1:0
Created topic topic-create-diff.
root@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe  --topic topic-create-diff
Topic: topic-create-diff	TopicId: caPBCVSDQQGfE3DNJZKfOQ	PartitionCount: 4	ReplicationFactor: 2	Configs: 
	Topic: topic-create-diff	Partition: 0	Leader: 1	Replicas: 1,2	Isr: 1,2
	Topic: topic-create-diff	Partition: 1	Leader: 2	Replicas: 2,0	Isr: 2,0
	Topic: topic-create-diff	Partition: 2	Leader: 0	Replicas: 0,1	Isr: 0,1
	Topic: topic-create-diff	Partition: 3	Leader: 1	Replicas: 1,0	Isr: 1,0
root@101ed4754423:/opt/kafka_2.13-2.8.1/bin#
```

> 同一个分区内的副本不能有重复,比如指定了0:0,1:1这种,就会报出**AdminCommandFailedException**异常。


如果分区之间所指定的副本数不同,比如`0:1,0,1:0` 这种,就会报出**AdminOperationException**异常。类似 `0:1,,0:1,1:0`这种企图跳过一个分区的行为也是不被允许的。

在创建主题时我们还可以通过 `config`参数来设置所要创建主题的相关参数，通过这个参数可以覆盖原本的默认配置。在创建主题时可以同时设置多个参数。下面的示例使用了 `config`参数来创建一个主题 `topic-config`。

```bash
root@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-config --replication-factor 1 --partitions 1 --config cleanup.policy=compact --config max.message.bytes=10000

Created topic topic-config.

root@101ed4754423:/opt/kafka_2.13-2.8.1/bin# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe  --topic topic-config

Topic: topic-config	TopicId: XOsn8iRBTYaRGR6ZRlr3Wg	PartitionCount: 1	ReplicationFactor: 1	Configs: cleanup.policy=compact,max.message.bytes=10000
	Topic: topic-config	Partition: 0	Leader: 1	Replicas: 1	Isr: 1

root@101ed4754423:/opt/kafka_2.13-2.8.1/bin#
```

可以看到 Configs 一栏中包含了创建时所设置的参数。我们还可以通过 ZooKeeper 客户端查看所设置的参数，对应的ZooKeeper 节点为`/config/topics/[topic]`。

```bash
[zk: localhost:2181(CONNECTED) 2] get /config/topics/topic-config
{"version":1,"config":{"cleanup.policy":"compact","max.message.bytes":"10000"}}
[zk: localhost:2181(CONNECTED) 3]
```

创建主题时对于主题名称的命名方式也很有讲究。首先是不能与已经存在的主题同名，如果创建了同名的主题就会报错。

> 加了 `--if-not-exists` 如果存在会忽略，不会报错。


`kafka-topics.sh` 脚本在创建主题时还会检测是否包含`.`或`_`字符。为什么要检测这两个字符呢?因为在 Kafka的内部做埋点时会根据主题的名称来命名`metrics`的名称，并且会将点号`.`改成下划线`_`。假设遇到一个名称为`topic.1_2`的主题，还有一个名称为`topic_1_2`的主题，那么最后的`metrics`的名称都会为`topic_1_2`，这样就发生了名称冲突。

> 主题的命名同样不推荐(虽然可以这样做)使用双下划线`__`开头，因为以双下划线开头的主题一般看作 Kafka 的内部主题,比如`__consumer_offsets` 和`__transaction_state`主题的名称必须由大小写字母、数字、点号`.`、连接线`-`、下划线`_`组成，不能为空不能只有点号`.`，也不能只有双点号`..`，且长度不能超过 249。


Kafka 从 `0.10.x` 版本开始支持指定 broker 的机架信息 (机架的名称)。如果指定了机架信息，则在分区副本分配时会尽可能地让分区副本分配到不同的机架上。指定机架信息是通过broker 端参数 `broker.rack` 来配置的，比如配置当前 broker 所在的机架为`RACK1`:

```bash
broker.rack=RACK1
```

如果一个集群中有部分 broker 指定了机架信息，并且其余的 broker 没有指定机架信息，那么在执行 `kafka-topics.sh` 脚本创建主题时会报出的**AdminOperationException** 的异常。此时若要成功创建主题，要么将集群中的所有 broker 都加上机架信息或都去掉机架信息，要么使用 `--disable-rack-aware` 参数来忽略机架信息。如果集群中的所有 broker 都有机架信息，那么也可以使用 `--disable-rack-aware` 参数来忽略机架信息对分区副本的分配影响。

---

## 2. 分区副本的分配

生产者的分区分配是指为每条消息指定其所要发往的分区，消费者的分区分配指定是为消费者指定其可以消费消息的分区，而这里说的分区分配是指为集群指定创建主题时的分区副本分配方案，即在哪个broker中创建哪些分区的副本。

使用`kafka-topics.sh`脚本创建主题时的内部分配逻辑按照机架信息划分为两种策略；未指定机架信息和指定机架信息。如果集群中所有的broker节点都没有配置 `broker.rack`参数，或者使用`disable-rack-aware`参数来创建主题，那么采用的就是未指定机架信息的分配策略，否则采用的就是指定机架信息的分配策略。

默认情况下，kafka使用的是基本的 `_Round Robin_` 分配策略，它只考虑可用的 Broker，而不会明确考虑机架信息。然而，Kafka 提供了一种叫做**Rack Awareness**（机架感知）的机制（也就是指定机架信息的分配策略），允许开发人员配置 Broker 所在的机架信息，并在分配分区时考虑机架信息，以提高数据的可用性和容错性。这通常用于确保分区的副本尽量分布在不同的机架上，以应对机架级别的故障。在配置**Rack Awareness**时，开发人员可以将不同的 Broker 分配到不同的机架，并指定每个 Broker 的机架信息。然后，Kafka 在分配分区副本时，会考虑确保每个分区的副本尽量分布在不同的机架上，以增加系统的可用性。另外对于_Round Robin_策略：

1. Kafka 会首先根据集群中可用的 Broker 数量来确定要创建的分区数。通常，如果没有指定 `partitions` 参数，它将使用默认值。
2. 分区将被逐一分配给可用的 Broker，按照它们的编号顺序，从第一个 Broker 开始，然后依次分配给后续的 Broker。
3. 一旦所有分区分配完毕，如果还有剩余的 Broker，分区分配将重新从第一个 Broker 开始，以循环方式继续分配。

这意味着在默认情况下，Kafka 会将分区均匀地分配给可用的 Broker，以实现负载均衡。这种默认的分配策略有助于确保分区在集群中的分布是相对均匀的，以确保各个 Broker 上的负载大致相等。

> 默认的分配逻辑可能不考虑各个 Broker 的硬件配置、网络带宽、负载等因素，因此在某些情况下，开发人员可能需要自定义分配策略来更好地满足特定的需求。


另外默认情况下创建主题时总是从编号为0的分区依次轮询进行分配。

创建主题时，无论通过 `kafka-topics.sh` 脚本还是通过其他方式实质上是在 ZooKeeper 中的`/brokers/topics`节点下建与该主题对应的子节点并写入分区副本分配方案，并且在`/config/topics/`节点下创建该主题对应的子节点并写入主题相关的配置信息(这个步骤可以省略不执行)。而 Kafka 创建主题的实质性动作是交由控制器异步去完成的。

---

## 3.查看主题

通过`list`指令可以查看当前所有可用的主题。

```java
./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka-list
```

前面我们是通过`describe`指令来查看单个主题信息的，如果不使用`--topic`指定主题，则会展示出所有主题的详细信息。`--topic`还支持指定多个主题。

```java
./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--describe--topic topic-aaa,topic-bbb
```

`under-replicated-partitions` 和`unavailable-partitions` 参数都可以找出有问题的分区通过 `under-replicated-partitions`参数可以找出所有包含失效副本的分区。包含失效副本的分区可能正在进行同步操作，也有可能同步发生异常，此时分区的ISR集合小于AR 集合。对于通过该参数查询到的分区要重点监控，因为这很可能意味着集群中的某个 broker 已经失效或同步效率降低等。

```java
./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--describe--topic topic-aaa--under-replicated-partitions
```

通过 `unavailable-partitions` 参数可以查看主题中没有 leader 副本的分区，这些分区已经处于离线状态，对于外界的生产者和消费者来说处于不可用的状态。

```java
./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--describe--topic topic-aaa unavailable-partitions
```

---

## 4.修改主题

当一个主题被创建之后，依然允许我们对其做一定的修改，比如修改分区个数，修改配置等，这个修改的功能就是由`kafka-topics.sh`脚本中的`alter`指令提供的。

```java
./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--alter--topic topic-config--partitions 3
```

当主题中的消息包含 key 时 (即 key 不为 null)，根据 key 计算分区的行为就会受到影响。当 topic-config 的分区数为 1 时，不管消息的 key 为何值，消息都会发往这一个分区;当分区数增加到 3 时，就会根据消息的 key 来计算分区号，原本发往分区 0 的消息现在有可能会发往分区 1 或分区 2。如此还会影响既定消息的顺序，所以在增加分区数时一定要三思而后行。对于基于 key 计算的主题而言，建议在一开始就设置好分区数量避免以后对其进行调整。

目前 Kafka 只支持增加分区数而不支持减少分区数。比如我们再将主题 `topic-config` 的分区数修改为 1，就会报出 **InvalidPartitionException** 的异常。为什么不支持减少分区？

按照 Kafka 现有的代码逻辑，此功能完全可以实现，不过也会使代码的复杂度急剧增大。实现此功能需要考虑的因素很多，比如删除的分区中的消息该如何处理? 如果随着分区一起消失则消息的可靠性得不到保障;如果需要保留则又需要考虑如何保留。直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于 Spark、Flink 这类需要消息时间戳(事件时间)的组件将会受到影响; 如果分散插入现有的分区，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障?与此同时，顺序性问题.事务性问题，以及分区和副本的状态机切换问题都是不得不面对的。反观这个功能的收益点却是很低的，如果真的需要实现此类功能，则完全可以重新创建一个分区数较小的主题，然后将现有主题中的消息按照既定的逻辑复制过去即可。

除了修改分区数，我们还可以使用 `kafka-topics.sh` 脚本的 `alter`指令来变更主题的配置。在创建主题的时候我们可以通过 `config`参数来设置所要创建主题的相关参数，通过这个参数可以覆盖原本的默认配置。在创建完主题之后，我们还可以通过 `alter`指令配合 `config` 参数增加或修改一些配置以覆盖它们配置原有的值。

```java
./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--alter--topic topic-config--config max.message.bytes=20000
```

我们可以通过 `delete-config` 参数来删除之前覆盖的配置，使其恢复原有的默认值。下面的示例将主题 `topic-config`中所有修改过的配置都删除:

```java
./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--alter--topic topic-config--delete-config segment.bytes
```

注意到在变更 (增、删、改)配置的操作执行之后都会提示一段告警信息，指明了使用`kafka-topics.sh`脚本的 `alter`指令来变更主题配置的功能已经过时 (`deprecated`)，将在未来的版本中删除，并且推荐使用 `kafka-configs.sh` 脚本来实现相关功能。

---

## 5.配置管理

`kafka-configs.sh`脚本是专门用来对配置进行操作的，这里的操作是指在运行状态下修改原有的配置，如此可以达到动态变更的目的。`kafka-configs.sh`脚本包含变更配置 `alter` 和查看配置 `describe` 这两种指令类型。同使用 `kafka-topics.sh`脚本变更配置的原则一样，增、删、改的行为都可以看作变更操作，不过 `kafka-configs.sh` 脚本不仅可以支持操作主题相关的配置，还可以支持操作 broker、用户和客户端这3个类型的配置。

`kafka-configs.sh` 脚本使用`entity-type`参数来指定操作配置的类型，并且使用`entity-name`参数来指定操作配置的名称。比如查看主题 `topic-config` 的配置可以按如下方式执行:

```java
./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--describe--entity-typetopics--entity-name topic-config
```

`--describe`指定了查看配置的指令动作,`--entity-type`指定了查看配置的实体类`--entity-name`指定了查看配置的实体名称。`entity-type` 只可以配置 4个值: `topics 、brokers 、clients 和users`,`entity-type`与`entity-name` 的对应关系如下。

| entity-type 的释义          | entity-name 的释义 |
|--------------------------|-----------------|
| 主题类型的配置，取值为 topics       | 指定主题的名称         |
| broker 类型的配置，取值为 brokers | 指定brokerId的值    |
| 客户端类型的配置，取值为 clients     | 指定clientId的值    |
| 用户类型的配置，取值为 users        | 指定用户名           |

使用 `alter` 指令变更配置时，需要配合 `add-config`和 `delete-config` 这两个参数起使用。`add-config`参数用来实现配置的增、改，即覆盖原有的配置;`delete-config`参数用来实现配置的删，即删除被覆盖的配置以恢复默认值。下面的示例演示了 `add-config` 参数的用法，覆盖了主题 `topic-config`的两个配置`cleanup.policy`和`max.message.bytes`(示例执行之前主题 `topic-config` 无任何被覆盖的配置):

```java
        ./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--alter--entity-type topics--entity-name topic-config--add-configcleanup.policy=compact,max.message.bytes=10000

        ./kafka-configs.sh--zookeeper kafka-zookeeper:2181kafka--describe--entity-type topics--entity-name topic-config

        ./kafka-topics.sh--zookeeper kafka-zookeeper:2181kafka--describe--topic topic-config--topics-with-overrides
```

上面示例中还使用了两种方式来查看主题 `topic-config` 中配置信息，注意比较这两者之间的差别。

使用`delete-config`参数删除配置时，同`add-config`参数一样支持多个配置的操作，多个配置之间用逗号`,`分隔，下面的示例中演示了如何删除上面刚刚增加的主题配置:

```java
        ./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--alter--entity-type topics--entity-name topic-config--delete-configcleanup.policy,max.message.bytes

        ./kafka-configs.sh--zookeeper kafka-zookeeper:2181/kafka--describe--entity-type topics--entity-name topic-config
```

---

## 6.主题端参数

与主题相关的所有配置参数在 broker 层面都有对应参数，比如主题端参数 `cleanup.policy` 对应 broker 层面的 `log.cleanup.policy`。如果没有修改过主题的任何配置参数那么就会使用 broker 端的对应参数作为其默认值。可以在创建主题时覆盖相应参数的默认值.也可以在创建完主题之后变更相应参数的默认值。比如在创建主题的时候没有指定`cleanup.policy`参数的值，那么就使用 `log.cleanup.policy` 参数所配置的值作为`cleanup.policy`的值。

下表列出了主题端参数与 broker 端参数的对照关系。

| 主题端参数                                   | 作用                                                                                                       | broker端参数                               |
|-----------------------------------------|----------------------------------------------------------------------------------------------------------|-----------------------------------------|
| cleanup.policy                          | 日志压缩策略。默认值为 delete，还可以配置为 compact。                                                                       | log.cleanup.policy                      |
| compression.type                        | 消息的压缩类型。默认值为 producer，表示保留生产者中所使用的原始压缩类型。还可以配置为 uncompressed、snappy、Iz4、gzip                             | compression.type                        |
| delete.retention.ms                     | 被标识为删除的数据能够保留多久。默认值为 86400000，即1天                                                                        | log.cleaner.delete.retention.ms         |
| file.delete.delay.ms                    | 清理文件之前可以等待多长时间，默认值为60000，即1分钟                                                                            | log.segment.delete.delay.ms             |
| flush. messages                         | 需要收集多少消息才会将它们强制刷新到磁盘，默认值为 Long.MAX VALUE，即让操作系统来决定。建议不要修改此参数的默认值                                         | log.flush.interval.messages             |
| flush.ms                                | 需要等待多久才会将消息强制刷新到磁盘，默认值为 Long.MAX VALUE，即让操作系统来决定。建议不要修改此参数的默认值                                           | log.flush.interval.ms                   |
| follower.replication.throttled.replicas | 用来配置被限制速率的主题所对应的follower 副本列表                                                                            | follower.replication.throttled.replicas |
| index.interval.bytes                    | 用来控制添加索引项的频率。每超过这个参数所设置的消息字节数时就可以添加一个新的索引项，默认值为 4096                                                     | log.index.interval.bytes                |
| leader.replication.throttled.replicas   | 用来配置被限制速率的主题所对应的 leader副本列表                                                                              | leader.replication.throttled.replicas   |
| max.message.bytes                       | 消息的最大字节数，默认值为 1000012                                                                                    | message.max.bytes                       |
| message.format. version                 | 消息格式的版本，默认值为 2.0-IV1                                                                                     | log. message. format.version            |
| message.timestamp.difference.max.ms     | 消息中自带的时间戳与 broker 收到消息时的时间戳之间最大的差值，默认值为Long.MAX VALUE。此参数只有在meesage.timestamp.type 参数设置为 CreateTime 时才有效 | log.message.timestamp.difference.max.ms |
| message.timestamp.type                  | 消息的时间戳类型。默认值为 CreateTime,还可以设置为 LogAppendTime                                                            | log.message.timestamp.type              |
| min.cleanable.dirty.ratio               | 日志清理时的最小污浊率，默认值为 0.5                                                                                     | log.cleaner.min.cleanable.ratio         |
| min.compaction.lag.ms                   | 日志再被清理前的最小保留时间，默认值为0                                                                                     | log.cleaner.min.compaction.lag.ms       |
| min.insync.replicas                     | 分区 ISR 集合中至少要有多少个副本，默认值为 1                                                                               | min.insync.replicas                     |
| preallocate                             | 在创建日志分段的时候是否要预分配空间,默认值为 false                                                                            | log.preallocate                         |
| retention.bytes                         | 分区中所能保留的消息总量，默认值为-1,即没有限制                                                                                | log.retention.bytes                     |
| retention.ms                            | 使用 delete 的日志清理策略时消息能够保留多长时间，默认值为 604800000，即 7 天。如果设置为-1，则表示没有限制                                        | log.retention.ms                        |
| segment.bytes                           | 日志分段的最大值，默认值为 1073741824,即 1GB                                                                           | log.segment.bytes                       |
| segment.index.bytes                     | 日志分段索引的最大值，默认值为 10485760,即 10MB                                                                          | log.index.size.max.bytes                |
| segment.jitter.ms                       | 滚动日志分段时，在 segment.ms 的基础之上增加的随机数，默认为 0                                                                   | log.roll.jitter.ms                      |
| segment.ms                              | 最长多久滚动一次日志分段，默认值为604800000，即 7 天                                                                         | log.roll.ms                             |
| unclean.leader.election.enable          | 是否可以从非 ISR 集合中选举 leader 副本默认值为 false，如果设置为 true，则可能造成数据丢失                                                | unclean.leader.election.enable          |

---

## 7.删除主题

如果确定不再使用一个主题，那么最好的方式是将其删除，这样可以释放一些资源，比如磁盘、文件句柄等。`kafka-topics.sh`脚本中的 `delete` 指令就可以用来删除主题，比如删除一个主题 `topic-delete`:

```java
./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--delete--topic topic-delete
```

可以看到在执行完删除命令之后会有相关的提示信息，这个提示信息和 broker 端配置参数`delete.topic.enable`有关。必须将 `delete.topic.enable` 参数配置为 true 才能够除主题，这个参数的默认值就是 true，如果配置为 false，那么删除主题的操作将会被忽略。在实际生产环境中，建议将这个参数的值设置为 true。

如果要删除的主题是 Kafka 的内部主题，那么删除时就会报错。截至 `Kaka 2.0.0`，Kafka的内部一共包含 2 个主题，分别为`__consumer__offsets 和__transaction__state`。下面的示例中尝试删除内部主题`__consumer__offsets`:

```java
./kafka-topics.sh--zookeeper kafka-zookeeper:2181/kafka--delete--topic __consumer_offsets
```

尝试删除一个不存在的主题也会报错。这里同 `alter` 指令一样，也可以通过 `if-exists` 参数来忽略异常。

使用 `kafka-topics.sh` 脚本删除主题的行为本质上只是在 ZooKeeper 中的`/admin/delete/topics`路径下创建一个与待删除主题同名的节点，以此标记该主题为待删除的状态。与创建主题相同的是，真正删除主题的动作也是由Kafka 的控制器负责完成的。

删除主题是一个不可逆的操作，一旦主题被删除，与其相关的所有消息数据会被全部删除。

下面列出了`kafka-topics.sh`脚本中的参数。

| 参数名称                        | 作用                                     |
|-----------------------------|----------------------------------------|
| alter                       | 用于修改主题，包括分区数及主题的配置                     |
| config<键值对>                 | 创建或修改主题时，用于设置主题级别的参数                   |
| create                      | 创建主题                                   |
| delete                      | 删除主题                                   |
| delete-config<配置名称>         | 删除主题级别被覆盖的配置                           |
| describe                    | 查看主题的详细信息                              |
| disable-rack-aware          | 创建主题时不考虑机架信息                           |
| help                        | 打印帮助信息                                 |
| if-exists                   | 修改或删除主题时使用，只有当主题存在时才会执行动作              |
| if-not-exists               | 创建主题时使用，只有主题不存在时才会执行动作                 |
| list                        | 列出所有可用的主题                              |
| partitions <分区数>            | 创建主题或增加分区时指定分区数                        |
| replica-assignment<分配方案>    | 手工指定分区副本分配方案                           |
| replication-factor<副本数>     | 创建主题时指定副本因子                            |
| topic <主题名称>                | 指定主题名称                                 |
| topics-with-overrides       | 使用 describe 查看主题信息时，只展示包含覆盖配置的主题       |
| unavailable-partitions      | 使用 describe 查看主题信息时，只展示包含没有 leader 副本的分区                          |
| under-replicated-partitions | 使用 describe 查看主题信息时，只展示包含失效副本的分区       |
| zookeeper                   | 指定连接的 ZooKeeper 地址信息 (必填项)             |

---


