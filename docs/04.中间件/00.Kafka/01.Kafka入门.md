---
title: Kafka入门
date: 2023-01-01 00:00:00
tags: 
  - Kafka
  - 消息队列
categories: 
  - Kafka
description: Kafka入门
toc_number: false
author:
  name: huidong.yin
  link: https://huidongyin.github.io
permalink: /pages/kafka/
---

当涉及 Kafka 时，有三个关键方面需要考虑，它们构成了 Kafka 的核心特性，为各种应用场景提供了强大的支持：

1. **消息系统**：Kafka是一个高性能、分布式的消息系统，具有多重关键特性。首先，它支持异步通信，这意味着生产者和消费者不必等待对方的响应，从而提高了系统的吞吐量和响应速度。其次，Kafka能够处理削峰（smoothing）——在瞬时高负载时，它能够暂存消息以确保系统的稳定性。此外，它支持消息的解耦，允许不同组件之间独立开发和部署，提高了系统的可维护性。Kafka还提供卓越的扩展性，能够轻松地适应不断增长的工作负载。同时，Kafka具备出色的恢复性，即使在硬件或网络故障的情况下，消息仍然能够被可靠地传递。此外，Kafka支持顺序性消费，确保消息按照其产生的顺序被消费。最后，它还支持回溯消息，允许消费者重新处理历史消息，这对于分析和数据挖掘非常有用。
2. **存储系统**：除了作为消息系统，Kafka还可用作强大的分布式数据存储系统。它能够可靠地存储消息，使得这些消息可以被后续应用程序或系统查询、分析和处理。这种存储功能使Kafka成为了一个持久性的、高度可扩展的数据存储引擎，用于存储和管理各种类型的数据，包括事件日志、指标、日志文件、以及其他业务数据。因此，Kafka适用于实时大数据处理、日志存储、监控、以及各种其他数据管理需求。
3. **流式处理平台**：Kafka不仅仅是一个消息传递系统和数据存储引擎，它还提供了一个流式处理平台，能够为流式处理框架提供数据来源。通过Kafka，数据可以被实时地传递到流处理应用程序，这使得开发者可以构建实时分析、事件驱动型应用、以及复杂的数据处理流程。Kafka还提供了一套完整的流式处理类库，包括窗口处理、连接操作、数据变换以及聚合功能，使开发者能够轻松构建强大的实时数据处理应用。

这三个方面的特性使 Kafka 成为一种强大的工具，适用于各种现代数据处理和数据流应用，从事件驱动架构到实时数据分析和监控。

---

## 1.体系架构

Kafka 是一个强大的分布式消息传递系统，其核心体系架构包括四个主要组件：Producer、Broker、Consumer 和 ZooKeeper (zk)。

1. **ZooKeeper**：Kafka 使用 ZooKeeper 来负责集群元数据的管理、控制器的选举等操作，确保 Kafka 集群的协调和一致性。
2. **Producer**：生产者负责将消息发送到 Kafka 的 Broker 中。
3. **Broker**：Broker 是 Kafka 集群中的消息存储节点，它们接收、存储和分发消息。
4. **Consumer**：消费者从 Broker 订阅并消费消息，采用拉模型（pull-based）来获取消息。

![](https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311041742622.png)
一台部署了 Kafka Broker 的服务器可以看作是一个 Kafka 服务器。

---

## 2.主题分区

- **Topic**：生产者在发送消息时需要指定一个 Topic。Topic 是消息的逻辑分类，用于组织和标识消息。
- **Partition**：每个 Topic 可以划分为多个 Partition，每个Partition是一个有序、追加的日志文件，每条消息都会分配一个唯一的偏移量（offset）。偏移量用于保证消息在分区内的顺序。

> Kafka 保证 Partition 内的消息有序，但不保证 Topic 有序。Topic 可能有多个 Partition，它们可以分布在不同的 Broker 上。

Topic的多个分区可以分布在不同的Broker上，消息在发送到Broker之前会首先根据分区规则计算出储存到哪一个分区。如果一个Topic只有一个分区，那么这个Topic的性能瓶颈就是这个分区所在Broker的I/O。创建Topic时可以指定分区的数量，也可以随时增加分区以实现水平扩展。

---

## 3.副本机制

- Kafka 引入了副本（Replica）机制用于实现容灾备份。每个 Partition 可能有多个副本。
- 副本分为三种状态：AR（All Replica，所有副本），ISR（In Sync Replica，同步中的副本），OSR（Out Sync Replica，同步之外的副本）。
- 在同一时刻，副本之间并非完全一样。Leader 副本负责处理读写请求，而 Follower 副本只负责与 Leader 副本的消息同步。当Leader所在的Broker 出现故障时，从 Follower 副本中重新选举新的 Leader 副本对外提供服务。
- ISR（In Sync Replica）指的是同步中的副本，它们具备资格被选为 Leader 副本。
- AR = ISR + OSR。正常情况下 AR = ISR，OSR = 0。
- 副本有一个重要的概念，即 HW（High Watermark），消费者只能拉取消息直到 HW 位置。HW 是所有 ISR 集合内的副本的LEO（LogEndOffset）的最小值。
- LEO（Log End Offset）标识当前 Partition 日志文件中下一条待写入的消息的 offset。LEO = 当前日志文件的最后一条消息的偏移量+1。
- kafka客户端也具备一定的容灾备份能力，消费者使用拉模型从服务端拉消息，并且保存消费的具体位置，当消费者宕机后恢复上线时可以根据之前保存的消费位点重新拉消息。

![](https://raw.githubusercontent.com/huidongyin/DrawingBed/main/kafka/202311041743440.jpeg)

相比于同步复制的性能损耗和异步复制的不可靠性，ISR的方式在两者之间做了更好的权衡。

---

## 4.安装配置

[Kafka官方下载地址：http://kafka.apache.org/downloads。](http://kafka.apache.org/downloads)

> kafka-xx-yy: xx 是scala版本，yy是kafka版本。

下面我们使用docker安装和配置zk和kafka。

1. 首先创建一个桥接网络，方便zk和kafka因为重启docker导致ip变化时需要重新修正配置的问题。

```bash
docker network create kafka-net
```

2. 拉取zk镜像并安装。

```bash
docker pull zookeeper:3.5.9

docker run -d --privileged=true  --name kafka-zookeeper  -p 2181:2181  --network kafka-net  --network-alias kafka-zookeeper  -v /Users/huidong/docker/zk/data:/data  -v /Users/huidong/docker/zk/conf:/conf  -v /Users/huidong/docker/zk/logs:/datalog  zookeeper:3.5.9
```

2888为组成zookeeper服务器之间的通信端口，3888为用来选举leader的端口。如果想要查看zk的运行状态：

```bash
# 1. 进入zk容器
docker exec -it 容器id /bin/bash

# 2. 找到配置文件位置
cat /conf/zoo.cfg

# 3. 查看zk状态
zkServer.sh status
```

3. 拉取kafka镜像并安装。

```bash
docker pull wurstmeister/kafka

docker run -d  --privileged=true \
--name kafka0 -p 9092:9092 \
--network kafka-net \
--network-alias kafka0 \
-e KAFKA_BROKER_ID=0 \
-e KAFKA_ZOOKEEPER_CONNECT=kafka-zookeeper:2181 \
-e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \
-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.1.5:9092 \
-e ALLOW_PLAINTEXT_LISTENER=yes \
wurstmeister/kafka:latest

docker run -d  --privileged=true \
--name kafka1 -p 9093:9092 \
--network kafka-net \
--network-alias kafka1 \
-e KAFKA_BROKER_ID=1 \
-e KAFKA_ZOOKEEPER_CONNECT=kafka-zookeeper:2181 \
-e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \
-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.1.5:9093 \
-e ALLOW_PLAINTEXT_LISTENER=yes \
wurstmeister/kafka:latest

docker run -d  --privileged=true \
--name kafka2 -p 9094:9092 \
--network kafka-net \
--network-alias kafka2 \
-e KAFKA_BROKER_ID=2 \
-e KAFKA_ZOOKEEPER_CONNECT=kafka-zookeeper:2181 \
-e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \
-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.1.5:9094 \
-e ALLOW_PLAINTEXT_LISTENER=yes \
wurstmeister/kafka:latest
```

**KAFKA_LISTENERS** 与 **KAFKA_ADVERTISED_LISTENERS** 是为了区分内网和外网的，如果只有内网访问，就可以只配置 **KAFKA_LISTENERS**。如果涉及了外网访问，比如要在云服务器上部署使用，就需要配置 **KAFKA_ADVERTISED_LISTENERS**参数了，在开始时配置了一个 `kafka-net` 的网络，也就是处于这个网络下的访问才属于内网访问，而 `kafka`部署完毕后，需要在其他服务器上访问 `kafka`，这就需要通过外网访问 `kafka`，所以必须配置 **KAFKA_ADVERTISED_LISTENERS**，且值为 `PLAINTEXT://<服务器ip>:<暴露端口>` ，例如我的电脑IP为 `192.168.1.5`，端口为容器暴露的端口。

- **KAFKA_BROKER_ID** : broker的ID，这个ID是集群的标识，不能重复。
- **KAFKA_ZOOKEEPER_CONNECT**：zookeeper的连接地址。
- **KAFKA_LISTENERS**：标识kafka服务运行在容器内的9092端口，因为没有指定host，所以是`0.0.0.0`标识所有的网络接口。
- **KAFKA_ADVERTISED_LISTENERS**：kafka发布到zookeeper供客户端使用的服务地址。

至此，一个单节点的zk和三个broker的kafka集群就安装成功了。

---

## 5.生产消费

### 5.1使用脚本测试

我们知道生产者将消息发送到Topic,而消费者也是通过订阅Topic来消费消息的。进入kafka-broker所在的docker容器，在 `/opt/kafka_2.13-2.8.1/bin` 目录下有kafka的一些脚本，我们首先通过脚本来创建Topic并测试生产和消费。

1. 创建Topic

```bash
./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --create --topic topic-demo --replication-factor 3 --partitions 4
```

- factor：表示topic的副本因子，也就是每一个partition有几个副本。
- partition：表示分区数。
- zookeeper：指定kafka连接的zk的地址。
- topic：指定要创建的主题的名字。

2. 查看Topic的信息

```bash
./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-demo
```

返回信息如下：

```bash
# ./kafka-topics.sh --zookeeper kafka-zookeeper:2181 --describe --topic topic-demo
Topic: topic-demo       TopicId: yCY_qq7XQaaGlYp6Fnod-A PartitionCount: 4       ReplicationFactor: 3    Configs: 
        Topic: topic-demo       Partition: 0    Leader: 0       Replicas: 0,2,1 Isr: 0,2,1
        Topic: topic-demo       Partition: 1    Leader: 1       Replicas: 1,0,2 Isr: 1,0,2
        Topic: topic-demo       Partition: 2    Leader: 2       Replicas: 2,1,0 Isr: 2,1,0
        Topic: topic-demo       Partition: 3    Leader: 0       Replicas: 0,1,2 Isr: 0,1,2
```

3. 生产消息

```bash
./kafka-console-producer.sh --bootstrap-server kafka0:9092 --topic topic-demo
```

- bootstrap-server：指定连接的kafka集群地址。

4. 消费消息

```bash
./kafka-console-consumer.sh --bootstrap-server kafka0:9092 --topic topic-demo
```

---

### 5.2使用代码测试

我们以Java客户端测试Kafka集群的生产消费。

1. 首先在项目中引入Kafka客户端的依赖。

```bash
  <dependency>
      <groupId>org.apache.kafka</groupId>
      <artifactId>kafka-clients</artifactId>
      <version>2.8.1</version>
  </dependency>
```

2. 使用kafka消费者消费消息。

- 设置 Kafka 消费者配置：配置 Kafka 消费者，包括指定 Kafka 服务器地址、消费者组、键值反序列化器等。
- 创建 Kafka 消费者：使用上述配置创建 Kafka 消费者。
- 订阅主题：使用 subscribe 方法订阅一个或多个主题。
- 轮询并处理消息：使用 poll 方法轮询 Kafka 主题以获取消息，并处理这些消息。处理逻辑可以根据需求来定制。
- 关闭 Kafka 消费者：在完成消费后，关闭 Kafka 消费者以释放资源。

```bash
public static void consume() {
    Properties props = new Properties();
    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
    props.put(ConsumerConfig.GROUP_ID_CONFIG, groupName);
    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
    consumer.subscribe(Collections.singletonList(topicName));

    while (true) {
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
        records.forEach(record -> System.out.println("Received message: key = " + record.key() + ", value = " + record.value()));
    }
}
```

3. 使用kafka生产者发送消息。

- 设置 Kafka 生产者配置：首先，配置 Kafka 生产者。这包括指定 Kafka 服务器地址、序列化器、主题名称等。
- 创建 Kafka 生产者：使用上述配置创建 Kafka 生产者。
- 发送消息：使用 send 方法向 Kafka 主题发送消息。消息需要指定主题名称、消息键和消息值。
- 关闭 Kafka 生产者：在完成发送后，记得关闭 Kafka 生产者以释放资源。

```bash
public static void produce() {
    Properties props = new Properties();
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");

    KafkaProducer<String, String> producer = new KafkaProducer<>(props);

    ProducerRecord<String, String> record = new ProducerRecord<>(topicName, "key", "value");

    for (int i = 0; i < 100; i++) {
        producer.send(record, (metadata, exception) -> {
            if (exception == null) {
                System.out.println("Message sent to partition " + metadata.partition() + " with offset " + metadata.offset());
            } else {
                exception.printStackTrace();
            }
        });
    }

    producer.close();
}
```

---

## 6.服务端参数说明

### 6.1`zookeeper.connect`

`zookeeper.connect` 是 Kafka 配置中的一个重要参数，它用于指定 Kafka与ZooKeeper集群之间的连接信息。以下是关于 `zookeeper.connect` 参数的详细介绍：

- **参数名称**：`zookeeper.connect`
- **作用**：指定 Kafka 集群与 ZooKeeper 集群之间的连接信息。
- **格式**：`zookeeper.connect`参数的值通常以逗号分隔的形式列出多个 ZooKeeper 服务器的连接地址。格式如下：

```
host1:port1,host2:port2,host3:port3
```

其中，`host1:port1`、`host2:port2`、`host3:port3` 是 ZooKeeper 服务器的主机名（或 IP地址）和端口号。使用者可以列出多个ZooKeeper服务器以增加可用性和冗余性。Kafka 客户端会自动选择其中一个 ZooKeeper 服务器来进行连接。

- **示例**：以下是一个示例 `zookeeper.connect` 参数的值：

```
zookeeper.connect=zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
```

- **用途**：`zookeeper.connect` 参数用于告知 Kafka客户端如何连接到ZooKeeper集群，以获取元数据、执行领导者选举等操作。ZooKeeper还用于管理消费者组的偏移量（offset）信息，以确保Kafka消费者能够继续从上次停止的地方消费消息。
- **注意事项**：在配置 `zookeeper.connect` 参数时，确保指定了正确的 ZooKeeper 服务器地址和端口号。同时，也需要确保ZooKeeper集群与 Kafka 集群之间有良好的网络连接，以确保正常的协调和管理功能。

`zookeeper.connect` 参数也可以配置 ZooKeeper 的 chroot 路径。chroot路径允许在ZooKeeper服务器上创建一个命名空间（类似于文件系统的目录），以便不同的应用程序或服务可以在同一个ZooKeeper集群上维护独立的配置和元数据信息。在Kafka 中，chroot 路径通常用于隔离不同的 Kafka 集群或服务。

以下是关于在 `zookeeper.connect` 参数中配置 chroot 路径的说明：

- **格式**：要配置 chroot 路径，可以将其附加到 `zookeeper.connect` 的值中，使用斜杠（`/`）分隔。例如：

```
zookeeper.connect=zk1:2181,zk2:2181/kafka-chroot
```

在上述示例中，`kafka-chroot` 是 chroot 路径，它指定了一个命名空间，Kafka 将在其中执行与 ZooKeeper 相关的操作。

---

### 6.2`listeners`

上面在安装配置小节已经介绍过 `listeners` 和 `advertised.listeners` 参数。前者主要是对内网配置，后者是公网配置。

`listeners`:
1. 可以同时配置多个，并且用逗号隔开
2. 监听器的名称和端口必须是唯一的,端口相同,就冲突了。
3. `host name` 如果为空,例如(`listeners=://host_ name;port`),则会绑定到默认的接口(网卡),一般情况下是 `localhost`，底层调用的是 `java.net.InetAddress.getCanonicalHostName()`。
4. 将 `host name` 设置为 `0.0.0.0` 则会绑定所有的网卡,也就是说不管从哪个网卡进入的请求都会被接受处理。但是请注意,假如你设置的是 `0.0.0.0`,那么 `advertised.listeners` 必须要设置,因为`advertised.listeners` 默认情况下使用的是 `listeners` 的配置发布到 zk 中,发布到 zk 中是给其他Brokers/Clients 来跟你通信的,所以它必须要指定并明确IP:PORT。
5. `listener_name` 是监听名,唯一值,他并不是安全协议(大部分人都会搞错)因为默认的4个安全协议已经做好了映射,例如: `PLAINTEXT ==> PLAINTEXT`.所以你经常看到的配置，这个`PLAINTEXT`是监听名称,刚好他对应的安全协议就是 `PLAINTEXT`。
6. `listeners = PLAINTEXT://your.host.name:9092`。
7. 可动态配置该属性。

`advertised.listeners`:
1. 默认情况下， `advertised.listeners` 不设置会自动使用 `listeners` 属性。
2. `advertised.listeners` 不支持 `0.0.0.0` 这种形式,所以如果 `listeners` 属性设置成 `0.0.0.0`，则必须设置 `advertised.listeners` 属性。
3. 可以同时配置多个，并且用逗号隔开。
4. 可动态配置该属性。

---

### 6.3`broker.id`

该参数用来指定Kafka集群中broker的唯一标识，默认值为-1。如果没有配置，那么kafka会自动生成一个。

---

### 6.4`log.dir & log.dirs`

Kafka 把所有的消息都保存在磁盘上，而这两个参数用来配置Kafka日志文件存放的根目录。通常 `log.dir`用来配置单个根目录，`log.dirs` 用来配置多个根目录（多个之间用逗号分隔），但是Kafka并没有做强限制。另外 `log.dirs`的优先级比 `log.dir` 高，默认只有 `log.dir` 有默认值 `/tmp/kafka-logs` 。

---

### 6.5`message.max.bytes`

该参数用来指定broker所能接收的消息的最大值，默认是 `1000012B`，约等于`976KB`。如果生产者发送的消息大于这个值，就会抛出 `RecordTooLargeException`。如果需要修改这个参数还要考虑客户端的参数 `max.request.size` 和Topic的参数 `max.message.bytes` 的影响。

---

至此，我们已经对Kafka有了初步的了解，接下来我们继续深入学习Kafka。
