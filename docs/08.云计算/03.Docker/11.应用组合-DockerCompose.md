---
title: 应用组合-DockerCompose
date: 2024-01-09 00:00:00
tags:
    - Docker
    - 云计算
categories:
    - Docker
description: 应用组合-DockerCompose
toc_number: false
author:
    name: huidong.yin
    link: https://huidongyin.github.io
permalink: /pages/299ec4fe-1e43-31a4-af2e-0ab7258a19ec/

---

我们已经基本掌握了构建、运行容器的方法，但是由于 Docker 采用轻量级容器的设计，每个容器一般只运行一个软件，而绝大多数应用系统都绝不是一个软件所能组成的。虽然我们之前提到了容器间互相连接、交换数据的各种方法，通过这些方法足以搭建起完整的用于应用系统运行的容器群，但是这个容器群的搭建需要执行太多命令，更重要的是需要考虑太多应用和容器间的依赖关系处理。在这一节中，我们就来介绍解决这些问题的一种方案 **Docker Compose**。

---

## 1.Docker Compose是什么

Docker Compose能够在 Docker 节点上，以单引擎模式(Single-Engine Mode)进行多容器应用的部 署和管理。多数的现代应用通过多个更小的微服务互相协同来组成一个完整可用的应用。

部署和管理繁多的服务是困难的。而这正是 Docker Compose 要解决的问题。Docker Compose 并不是通过脚本和各种冗长的 docker 命令来将应用组件组织起来，而是通过一个声明式的配置文件描述整个应用，从而使用一条命令完成部署。应用部署成功后，还可以通过一系列简单的命令实现对其完整生命周期的管理。甚至，配置文件还可以置于版本控制系统中进行存储和管理。

如果说 Dockerfile 是将容器内运行环境的搭建固化下来，那么 Docker Compose 我们就可以理解为将多个容器运行的方式和配置固化下来。

![](https://raw.githubusercontent.com/huidongyin/DrawingBed/main/Docker/202401112209216.webp)

---

### 1.1 Docker Compose 安装

Docker Compose 目前是由 Docker 官方主要维护，但是却不属于 Docker Engine 的一部分，而是一个独立的软件。所以如果我们要在 Linux 中使用它，要单独下载使用。

Docker Compose 是一个由 Python 编写的软件，在拥有 Python 运行环境的机器上，我们可以直接运行它，不需要其它的操作。

我们可以通过下面的命令下载 Docker Compose 到应用执行目录，并附上运行权限，这样 Docker Compose 就可以在机器中使用了。

```bash
$ curl -L "https://github.com/docker/compose/releases/download/1.22.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
$ chmod +x /usr/local/bin/docker-compose
$
$ docker-compose version
Docker Compose version v2.23.3-desktop.2
```

我们也可以通过 Python 的包管理工具 `pip` 来安装 Docker Compose。

```python
pip install docker-compose
```

对于Window和Mac，使用 Docker for Win 或者 Docker for Mac来搭建 Docker 运行环境，可以直接使用 `docker-compose` 这个命令。这款软件已经将 Docker Compose 内置在其中，供我们使用。

---

### 1.2 配置文件及常用命令

Docker Compose 使用 YAML 文件来定义多服务的应用。YAML 是 JSON 的一个子集，因此也可以使用JSON。Docker Compose 默认使用文件名 `docker-compose.yml`。当然，也可以使用 `-f` 参数指定具体文件。

```yaml
version: '3'
services:
     mysql:
      build:
        context: ./mysql
      environment:
        MYSQL_ROOT_PASSWORD: root
      restart: always
      container_name: mysql
      volumes:
        - /data/bom/mysql/test:/var/lib/mysql
      image: mysql/mysql:5.7
      ports:
        - "3306:3306"

     eureka:
      build:
        context: ./eureka-boot
      restart: always
      ports:
        - "8761:8761"
      container_name: eureka-boot
      hostname: eureka-boot
      image: eureka:1.0
      depends_on:
        - mysql

networks:
    net:
volumes:
    vol:
```


Docker Compose 的 YAML 文件包含 4 个一级 key:`version`、`services`、`networks`、`volumes`。

* `version` 是必须指定的，而且总是位于文件的第一行。它定义了 Compose 文件格式(主要是 API)的版本。注意，version 并非定义 Docker Compose 或 Docker 引擎的版本号。
* `services` 用于定义不同的应用服务。上边的例子定义了两个服务:一个名为 mysql数据库服 务以及一个名为eureka的微服。Docker Compose 会将每个服务部署在各自的容器中。
* `networks` 用于指引 Docker 创建新的网络。默认情况下，Docker Compose 会创建 `bridge` 网络。 这是一种单主机网络，只能够实现同一主机上容器的连接。当然，也可以使用 `driver` 属性来指定不 同的网络类型。
* `volumes` 用于指引 Docker 来创建新的卷。

---

#### 1)启动和停止

Docker Compose 的启动和停止命令是 `docker-compose up` 和 `docker-compose down` 。

`docker-compose up` 命令类似于 Docker Engine 中的 `docker run`，它会根据 `docker-compose.yml` 中配置的内容，创建所有的容器、网络、数据卷等等内容，并将它们启动。与 `docker run `一样，默认情况下 `docker-compose up `会在“前台”运行，我们可以用 `-d `选项使其“后台”运行。

```yaml
docker-compose up -d
```

>  `docker-compose` 命令默认会识别当前控制台所在目录内的 `docker-compose.yml` 文件，而会以这个目录的名字作为组装的应用项目的名称。如果我们需要改变它们，可以通过选项 `-f `来修改识别的 Docker Compose 配置文件，通过 `-p` 选项来定义项目名。

```yaml
docker-compose -f ~/docker-compose.yml -p dev-env up -d
```

与 `docker-compose up` 相反，`docker-compose down` 命令用于停止所有的容器，并将它们删除，同时消除网络等配置内容，也就是几乎将这个 Docker Compose 项目的所有影响从 Docker 中清除。

```yaml
docker-compose down
```

借助 Docker 容器的秒级启动和停止特性，我们在使用 `docker-compose up` 和 `docker-compose down` 时可以非常快的完成操作。这就意味着，我们可以在不到半分钟的时间内停止一套环境，切换到另外一套环境。通过 Docker 让我们能够在开发过程中搭建一套不受干扰的独立环境，让开发过程能够基于稳定的环境下进行。而 Docker Compose 则让我们更近一步，同时让我们处理好多套开发环境，并进行快速切换。

---

#### 2)容器命令

1. 列出所有运行的容器

```yaml
docker-compose ps
```

2. 查看服务日志

```yaml
docker-compose logs
```

3. 构建服务

```yaml
docker-compose build
```

4. 启动服务

- `start` 命令会启动之前通过 `docker-compose stop` 命令停止的服务容器。
- `start` 只能启动已经存在但当前处于停止状态的容器，无法创建新的容器。
- 与 `up` 不同，`start` 不会读取 `docker-compose.yml` 文件。它专门用于重新启动先前停止的容器。

`up` 主要用于首次启动和创建容器，而 `start` 用于重新启动之前停止的容器。如果需要启动整个应用程序并创建新容器，使用 `up`。如果只是想重新启动已经停止的容器，使用 `start`。

```yaml
docker-compose start
```

5. 停止已经运行的服务

- `stop` 命令会停止通过 `docker-compose up` 启动的所有容器，但并不会删除这些容器。
- 这个命令保留了容器的状态，可以通过 `docker-compose start` 或 `docker-compose restart` 恢复这些容器的运行。
- 使用 `stop` 不会删除关联的网络、卷等。

`down` 用于完全停止并清理整个 Docker Compose 项目，而 `stop` 仅用于停止容器，保留项目的状态，方便后续重新启动。选择使用哪个命令取决于需求：是要彻底清理整个项目，还是只是停止容器并保留相关状态。

```yaml
docker-compose stop
```

6. 重启服务

```yaml
docker-compose restart
```

---

## 2.Docker Compose 配置项

### 2.1 服务定义

#### 1)指定镜像

在 Docker Compose 里，我们可以通过两种方式为服务指定所采用的镜像。一种是通过 image 这个配置，这个相对简单，给出能在镜像仓库中找到镜像的名称即可。

另外一种指定镜像的方式就是直接采用 Dockerfile 来构建镜像，通过 `build` 这个配置我们能够定义构建的环境目录，这与 `docker build` 中的环境目录是同一个含义。如果我们通过这种方式指定镜像，那么 Docker Compose 先会帮助我们执行镜像的构建，之后再通过这个镜像启动容器。

当然，在 `docker build` 里我们还能通过选项定义许多内容，这些在 Docker Compose 里我们依然可以。

```yaml
services:
     mysql:
          build:
               context: ./mysql
      dockerfile: mysql-dockerfile
      args: 
	- JAVA_VERSION=1.6
```

在配置文件里，我们还能用 Map 的形式来定义 build，在这种格式下，我们能够指定更多的镜像构建参数，例如 Dockerfile 的文件名，构建参数等等。

当然，对于一些可以不通过重新构建镜像的方式便能修改的内容，还是不建议重新构建镜像，而是使用原有的镜像做简单的修改。

例如，我们希望修改 Redis 的启动命令，加入配置文件以便对 Redis 服务进行配置，那么我们可以直接通过 `command` 配置来修改。而在 MySQL 的定义，我们通过 `environment`配置为 MySQL 设置了初始密码。

由于 Docker Compose 的配置已经固化下来，所以我们不需要担心忘记之前执行了哪些命令来启动容器，当每次需要开启或关闭环境时，只需要 `docker-compose up -d` 和 `docker-compose down` 命令，就能轻松完成操作。

---

#### 2)依赖声明

虽然我们在 Docker Compose 的配置文件里定义服务，在书写上有由上至下的先后关系，但实际在容器启动中，由于各种因素的存在，其顺序还是无法保障的。

所以，如果我们的服务间有非常强的依赖关系，我们就必须告知 Docker Compose 容器的先后启动顺序。只有当被依赖的容器完全启动后，Docker Compose 才会创建和启动这个容器。

定义依赖的方式很简单，在上面的例子里我们已经看到了，也就是 depends_on 这个配置项，我们只需要通过它列出这个服务所有依赖的其他服务即可。在 Docker Compose 为我们启动项目的时候，会检查所有依赖，形成正确的启动顺序并按这个顺序来依次启动容器。

```yaml
     eureka:
          build:
               context: ./eureka-boot
          restart: always
          ports:
               - 8761:8761
          container_name: eureka-boot
          hostname: eureka-boot
          image: eureka:1.0
          depends_on:
               - mysql
          networks:
               net:
```

---

### 2.2 文件挂载

在 Docker Compose 里定义文件挂载的方式与 Docker Engine 里也并没有太多的区别，使用 `volumes` 配置可以像 docker CLI 里的 `-v` 选项一样来指定外部挂载和数据卷挂载。

我们能够直接挂载宿主机文件系统中的目录，也可以通过数据卷的形式挂载内容。在使用外部文件挂载的时候，我们可以直接指定相对目录进行挂载，这里的相对目录是指相对于 `docker-compose.yml` 文件的目录。

由于有相对目录这样的机制，我们可以将 `docker-compose.yml` 和所有相关的挂载文件放置到同一个文件夹下，形成一个完整的项目文件夹。这样既可以很好的整理项目文件，也利于完整的进行项目迁移。

虽然 Docker 提倡将代码或编译好的程序通过构建镜像的方式打包到镜像里，随整个 CI 流部署到服务器中，但对于开发者来说，每次修改程序进行简单测试都要重新构建镜像简直是浪费生命的操作。所以在开发时，我们推荐直接将代码挂载到容器里，而不是通过镜像构建的方式打包成镜像。

同时，在开发过程中，对于程序的配置等内容，我们也建议直接使用文件挂载的形式挂载到容器里，避免经常修改所带来的麻烦。

---

#### 1)使用数据卷

如果我们要在项目中使用数据卷来存放特殊的数据，我们也可以让 Docker Compose 自动完成对数据卷的创建，而不需要我们单独进行操作。

独立于 `services` 的 `volumes` 配置就是用来声明数据卷的。定义数据卷最简单的方式仅需要提供数据卷的名称，对于我们在 Docker Engine 中创建数据卷时能够使用的其他定义，也能够放入 Docker Compose 的数据卷定义中。

如果我们想把属于 Docker Compose 项目以外的数据卷引入进来直接使用，我们可以将数据卷定义为外部引入，通过 `external` 这个配置就能完成这个定义。

```yaml
## ......
volumes:
  mysql-data:
    external: true
## ......
```

在加入 `external` 定义后，Docker Compose 在创建项目时不会直接创建数据卷，而是优先从 Docker Engine 中已有的数据卷里寻找并直接采用。

---

### 2.3 配置网络

在 Docker Compose 里，我们可以为整个应用系统设置一个或多个网络。要使用网络，我们必须先声明网络。声明网络的配置同样独立于 `services` 存在，是位于根配置下的 `networks` 配置。

除了简单的声明网络名称，让 Docker Compose 自动按默认形式完成网络配置外，我们还可以显式的指定网络的参数。

```yaml
networks:
  dev-env-net:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 10.10.1.0/24
## ......
```

在这里，我们为网络定义了网络驱动的类型，并指定了子网的网段。

---

直接使用容器名或服务名来作为连接其他服务的网络地址，因为缺乏灵活性，常常还不能满足我们的需要。这时候我们可以为服务单独设置网络别名，在其他容器里，我们将这个别名作为网络地址进行访问。网络别名的定义方式很简单，这里需要将之前简单的网络 List 定义结构修改成 Map 结构，以便在网络中加入更多的定义。

```yaml
## ......
  database:
    networks:
      backend:
        aliases:
          - backend.database
## ......
  eureka:
    networks:
      backend:
        aliases:
          - backend.eureka
      frontend:
        aliases:
          - frontend.eureka
## ......
```

在我们进行这样的配置后，我们便可以使用这里我们所设置的网络别名对其他容器进行访问了。

---

在 Docker Compose 的每个服务配置里，我们还看到了 `ports` 这个配置项，它是用来定义端口映射的。我们可以利用它进行宿主机与容器端口的映射，这个配置与 docker CLI 中 `-p` 选项的使用方法是近似的。

> 由于 YAML 格式对 `xx:yy` 这种格式的解析有特殊性，在设置小于 60 的值时，会被当成时间而不是字符串来处理，所以我们最好使用引号将端口映射的定义包裹起来，避免歧义。

---

## 3.Docker Compose 最佳实践

### 3.1 搭建ELK

```yaml
version: "3"
services:
  my-elasticsearch:
    environment:
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - "discovery.type=single-node"
    restart: always
    container_name: my-elasticsearch
    image: "elasticsearch:7.16.2"
    ports:
        - 9200:9200
        - 9300:9300
    networks:
      - dev-env-net
  my-kibana:
    restart: always
    container_name: my-kibana
    image: "kibana:7.16.2"
    volumes:
       - /Users/HuidongYin/elk/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml
    ports:
        - "5601:5601"
    networks:
      - dev-env-net
    depends_on:
      - my-elasticsearch
networks:
  dev-env-net:
    driver: bridge

```

---

### 3.2 搭建Zookeeper集群

1. 目录结构

```plaintext
👨 HuidongYin 📌  ~/zk-cluster ⌚ 24-01-11 14:43:20
$ tree ./              
./
├── docker-compose.yml
├── zookeeper1
│         ├── conf
│         │         └── zoo.cfg
│         ├── data
│         │         ├── myid
│         │         └── version-2
│         │             ├── acceptedEpoch
│         │             ├── currentEpoch
│         │             └── snapshot.0
│         └── logs
│             └── version-2
│                 ├── log.100000001
│                 └── log.200000001
├── zookeeper2
│         ├── conf
│         │         └── zoo.cfg
│         ├── data
│         │         ├── myid
│         │         └── version-2
│         │             ├── acceptedEpoch
│         │             ├── currentEpoch
│         │             └── snapshot.0
│         └── logs
│             └── version-2
│                 ├── log.100000001
│                 └── log.200000001
└── zookeeper3
    ├── conf
    │         └── zoo.cfg
    ├── data
    │         ├── myid
    │         └── version-2
    │             ├── acceptedEpoch
    │             ├── currentEpoch
    │             ├── snapshot.0
    │             └── snapshot.100000001
    └── logs
        └── version-2
            ├── log.100000001
            └── log.200000001

19 directories, 23 files
👨 HuidongYin 📌  ~/zk-cluster ⌚ 24-01-11 14:43:45
```

从上面的目录结构可以看出，这里我们仅仅需要再每一个 `conf` 目录下创建一个 `zoo.cfg` 文件。具体内容如下：

```plaintext
tickTime=2000
initLimit=5
syncLimit=2
dataDir=/data
dataLogDir=/datalog
autopurge.snapRetainCount=3
autopurge.purgeInterval=0
maxClientCnxns=60
admin.enableServer=true
4lw.commands.whitelist=conf,stat
server.1=zookeeper1:2888:3888;2181
server.2=zookeeper2:2888:3888;2181
server.3=zookeeper3:2888:3888;2181
```

关于 `data` 目录下的 `myid` 文件，因为我们将会在 `docker-compose.yml` 里面指定该参数，所以可以不需要创建这个文件。如果需要创建该文件，仅仅在里面写数字即可。

```yaml
version: '3'
services:
  zookeeper1:
    image: zookeeper:3.7.1
    volumes:
      - /Users/HuidongYin/zk-cluster/zookeeper1/conf:/conf
      - /Users/HuidongYin/zk-cluster/zookeeper1/data:/data
      - /Users/HuidongYin/zk-cluster/zookeeper1/logs:/datalog
    restart: always
    container_name: zookeeper1
    ports:
      - "2181:2181"
    environment:
      ZOO_MY_ID: 1
    networks:
      - zookeeper-net

  zookeeper2:
    image: zookeeper:3.7.1
    volumes:
      - /Users/HuidongYin/zk-cluster/zookeeper2/conf:/conf
      - /Users/HuidongYin/zk-cluster/zookeeper2/data:/data
      - /Users/HuidongYin/zk-cluster/zookeeper2/logs:/datalog
    restart: always
    container_name: zookeeper2
    ports:
      - "2182:2181"
    environment:
      ZOO_MY_ID: 2
    networks:
      - zookeeper-net

  zookeeper3:
    image: zookeeper:3.7.1
    volumes:
      - /Users/HuidongYin/zk-cluster/zookeeper3/conf:/conf
      - /Users/HuidongYin/zk-cluster/zookeeper3/data:/data
      - /Users/HuidongYin/zk-cluster/zookeeper3/logs:/datalog
    restart: always
    container_name: zookeeper3
    ports:
      - "2183:2181"
    environment:
      ZOO_MY_ID: 3
    networks:
      - zookeeper-net
## 如果单单是Zookeeper集群可以使用这个网络
networks:
  zookeeper-net:
    driver: bridge
## 如果是和另一个docker compose 的 kafka 集群连接 ，使用此种方式
#  docker network create zk-net
# networks:
#  zookeeper-net:
#    name: zk-net
#    external: true
```

---

### 3.3 搭建Kafka集群

这里我们要在 `docker-compose.yml`里面引用当前主机的IP，我们可以将当前主机的IP配置在 `.env`文件，然后在 `docker-compose.yml` 文件里面引用。

```yaml
LOCAL_IP=宿主机IP
```

```yaml
version: "3"

services:
  kafka-1:
    image: wurstmeister/kafka
    container_name: kafka-1
    restart: always
    ports:
      - "9092:9092"
    environment:
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${LOCAL_IP}:9092
      ALLOW_PLAINTEXT_LISTENER: yes
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper1:2181,zookeeper2:2181,zookeeper3:2181/kafka-cluster"
      KAFKA_BROKER_ID: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - zookeeper-net

  kafka-2:
    image: wurstmeister/kafka
    container_name: kafka-2
    restart: always
    ports:
      - "9093:9092"
    environment:
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${LOCAL_IP}:9093
      ALLOW_PLAINTEXT_LISTENER: yes
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper1:2181,zookeeper2:2181,zookeeper3:2181/kafka-cluster"
      KAFKA_BROKER_ID: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - zookeeper-net

  kafka-3:
    image: wurstmeister/kafka
    container_name: kafka-3
    restart: always
    ports:
      - "9094:9092"
    environment:
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${LOCAL_IP}:9094
      ALLOW_PLAINTEXT_LISTENER: yes
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper1:2181,zookeeper2:2181,zookeeper3:2181/kafka-cluster"
      KAFKA_BROKER_ID: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - zookeeper-net

networks:
  zookeeper-net:
    name: zk-net
    external: true
```

目录结构如下：

```yaml
👨 HuidongYin 📌  ~/kafka-cluster ⌚ 24-01-11 16:58:05
$ tree ./ -al
./
├── .env
└── docker-compose.yml

1 directory, 2 files
👨 HuidongYin 📌  ~/kafka-cluster ⌚ 24-01-11 16:58:10
```

---

### 3.4 搭建MySQL&Redis

目录结构如下：

```plaintext
👨 HuidongYin 📌  ~/mysql_redis ⌚ 24-01-11 17:36:25
$ tree ./    
./
├── docker-compose.yml
├── mysql
│         └── my.cnf
└── redis
    ├── data
    │         ├── dump.rdb
    │         └── redis.log
    └── redis.conf

4 directories, 5 files
👨 HuidongYin 📌  ~/mysql_redis ⌚ 24-01-11 17:36:35
```

`docker-compose.yml`内容如下：

```yaml
version: '3'
services:
  mysql:
    image: mysql/mysql-server:5.7
    volumes:
      - /Users/HuidongYin/mysql_redis/mysql/my.cnf:/etc/my.cnf
    restart: always
    container_name: mysql
    ports:
      - "3306:3306"
    environment:
      - "MYSQL_ROOT_PASSWORD=root"
    networks:
      - mysql-redis-net
  redis:
    image: redis:6
    command: redis-server /etc/redis/redis.conf  --appendonly no
    volumes:
      - /Users/HuidongYin/mysql_redis/redis/redis.conf:/etc/redis/redis.conf
      - /Users/HuidongYin/mysql_redis/redis/data:/data
    restart: always
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - mysql-redis-net

networks:
  mysql-redis-net:
    driver: bridge
```

`redis.conf`配置文件如下：

```plaintext
# 记得把这个配置屏蔽掉，否则你会浪费很多时间
# bind 127.0.0.1

protected-mode no
port 6379
tcp-backlog 511
timeout 0

tcp-keepalive 300

# 如果命令行使用了-d 这个地方必须设置为no，否则容器无法启动
daemonize no
supervised no
pidfile /var/run/redis_6379.pid
loglevel notice

# 这个目录也会针对本机做一个映射
logfile "/data/redis.log"


databases 16
always-show-logo yes
```

`my.cnf`配置如下：

```plaintext
# For advice on how to change settings please see
# http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html

[mysqld]
#
# Remove leading # and set to the amount of RAM for the most important data
# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.
# innodb_buffer_pool_size = 128M
#
# Remove leading # to turn on a very important data integrity option: logging
# changes to the binary log between backups.
# log_bin
#
# Remove leading # to set options mainly useful for reporting servers.
# The server defaults are faster for transactions and fast SELECTs.
# Adjust sizes as needed, experiment to find the optimal values.
# join_buffer_size = 128M
# sort_buffer_size = 2M
# read_rnd_buffer_size = 2M
skip-host-cache
skip-name-resolve
datadir=/var/lib/mysql
socket=/var/lib/mysql/mysql.sock
secure-file-priv=/var/lib/mysql-files
user=mysql

# Disabling symbolic-links is recommended to prevent assorted security risks
symbolic-links=0

#log-error=/var/log/mysqld.log
pid-file=/var/run/mysqld/mysqld.pid

[client]
default_character_set=utf8
[mysqld]
collation_server = utf8_general_ci
character_set_server = utf8
```

---
